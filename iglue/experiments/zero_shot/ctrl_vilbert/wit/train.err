WARNING:tensorflow:From /home/projects/ku_00062/envs/iglue/lib/python3.6/site-packages/tensorpack/callbacks/hooks.py:17: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.

WARNING:tensorflow:From /home/projects/ku_00062/envs/iglue/lib/python3.6/site-packages/tensorpack/tfutils/optimizer.py:18: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

WARNING:tensorflow:From /home/projects/ku_00062/envs/iglue/lib/python3.6/site-packages/tensorpack/tfutils/sesscreate.py:20: The name tf.train.SessionCreator is deprecated. Please use tf.compat.v1.train.SessionCreator instead.

12/06/2021 10:04:53 - INFO - __main__ -   device: cuda n_gpu: 1, distributed training: False
12/06/2021 10:04:53 - INFO - volta.task_utils -   Loading RetrievalWIT Dataset with batch size 16
12/06/2021 10:04:56 - INFO - volta.train_utils -   logging file at: /home/projects/ku_00062/logs/iglue/wit/ctrl_vilbert_base/RetrievalWIT_ctrl_vilbert_base
12/06/2021 10:04:56 - INFO - volta.utils -   loading weights file /home/projects/ku_00062/checkpoints/iglue/pretrain/ctrl_vilbert/ctrl_vilbert_base/pytorch_model_9.bin
12/06/2021 10:05:06 - INFO - volta.utils -   
12/06/2021 10:05:06 - INFO - volta.utils -   Weights of BertForVLTasks not initialized from pretrained model: ['clfs_dict.TASK20.weight', 'clfs_dict.TASK20.bias']
12/06/2021 10:05:06 - INFO - volta.utils -   Weights from pretrained model not used in BertForVLTasks: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.bi_seq_relationship.weight', 'cls.bi_seq_relationship.bias', 'cls.imagePredictions.transform.dense.weight', 'cls.imagePredictions.transform.dense.bias', 'cls.imagePredictions.transform.LayerNorm.weight', 'cls.imagePredictions.transform.LayerNorm.bias', 'cls.imagePredictions.decoder_dict.0.weight', 'cls.imagePredictions.decoder_dict.0.bias']
12/06/2021 10:05:10 - INFO - __main__ -   ** ** * Saving model * ** ** 
/home/projects/ku_00062/envs/iglue/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:216: UserWarning: Please also save or load the state of the optimizer when saving or loading the scheduler.
  warnings.warn(SAVE_STATE_WARNING, UserWarning)
12/06/2021 10:05:18 - INFO - __main__ -   >> Parameters:
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |Name                                                         |Dtype            |Shape           |#Params     |Trainable|
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.embeddings.word_embeddings.weight                       |torch.float32    |(30522, 768)    |23440896    |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.embeddings.position_embeddings.weight                   |torch.float32    |(512, 768)      |393216      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.embeddings.token_type_embeddings.weight                 |torch.float32    |(2, 768)        |1536        |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.embeddings.LayerNorm.weight                             |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.embeddings.LayerNorm.bias                               |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.v_embeddings.image_embeddings.weight                    |torch.float32    |(768, 2048)     |1572864     |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.v_embeddings.image_embeddings.bias                      |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.v_embeddings.image_location_embeddings.weight           |torch.float32    |(768, 5)        |3840        |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.v_embeddings.image_location_embeddings.bias             |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.v_embeddings.LayerNorm.weight                           |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.v_embeddings.LayerNorm.bias                             |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.0.attention_self.query.weight             |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.0.attention_self.query.bias               |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.0.attention_self.key.weight               |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.0.attention_self.key.bias                 |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.0.attention_self.value.weight             |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.0.attention_self.value.bias               |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.0.attention_output.dense.weight           |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.0.attention_output.dense.bias             |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.0.attention_output.LayerNorm.weight       |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.0.attention_output.LayerNorm.bias         |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.1.intermediate.dense.weight               |torch.float32    |(3072, 768)     |2359296     |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.1.intermediate.dense.bias                 |torch.float32    |(3072,)         |3072        |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.1.output.dense.weight                     |torch.float32    |(768, 3072)     |2359296     |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.1.output.dense.bias                       |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.1.output.LayerNorm.weight                 |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.1.output.LayerNorm.bias                   |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.2.attention_self.query.weight             |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.2.attention_self.query.bias               |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.2.attention_self.key.weight               |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.2.attention_self.key.bias                 |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.2.attention_self.value.weight             |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.2.attention_self.value.bias               |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.2.attention_output.dense.weight           |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.2.attention_output.dense.bias             |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.2.attention_output.LayerNorm.weight       |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.2.attention_output.LayerNorm.bias         |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.3.intermediate.dense.weight               |torch.float32    |(3072, 768)     |2359296     |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.3.intermediate.dense.bias                 |torch.float32    |(3072,)         |3072        |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.3.output.dense.weight                     |torch.float32    |(768, 3072)     |2359296     |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.3.output.dense.bias                       |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.3.output.LayerNorm.weight                 |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.3.output.LayerNorm.bias                   |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.4.attention_self.query.weight             |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.4.attention_self.query.bias               |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.4.attention_self.key.weight               |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.4.attention_self.key.bias                 |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.4.attention_self.value.weight             |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.4.attention_self.value.bias               |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.4.attention_output.dense.weight           |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.4.attention_output.dense.bias             |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.4.attention_output.LayerNorm.weight       |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.4.attention_output.LayerNorm.bias         |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.5.intermediate.dense.weight               |torch.float32    |(3072, 768)     |2359296     |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.5.intermediate.dense.bias                 |torch.float32    |(3072,)         |3072        |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.5.output.dense.weight                     |torch.float32    |(768, 3072)     |2359296     |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.5.output.dense.bias                       |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.5.output.LayerNorm.weight                 |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.5.output.LayerNorm.bias                   |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.6.attention_self.query.weight             |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.6.attention_self.query.bias               |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.6.attention_self.key.weight               |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.6.attention_self.key.bias                 |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.6.attention_self.value.weight             |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.6.attention_self.value.bias               |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.6.attention_output.dense.weight           |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.6.attention_output.dense.bias             |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.6.attention_output.LayerNorm.weight       |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.6.attention_output.LayerNorm.bias         |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.7.intermediate.dense.weight               |torch.float32    |(3072, 768)     |2359296     |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.7.intermediate.dense.bias                 |torch.float32    |(3072,)         |3072        |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.7.output.dense.weight                     |torch.float32    |(768, 3072)     |2359296     |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.7.output.dense.bias                       |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.7.output.LayerNorm.weight                 |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.7.output.LayerNorm.bias                   |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.8.attention_self.query.weight             |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.8.attention_self.query.bias               |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.8.attention_self.key.weight               |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.8.attention_self.key.bias                 |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.8.attention_self.value.weight             |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.8.attention_self.value.bias               |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.8.attention_output.dense.weight           |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.8.attention_output.dense.bias             |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.8.attention_output.LayerNorm.weight       |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.8.attention_output.LayerNorm.bias         |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.9.intermediate.dense.weight               |torch.float32    |(3072, 768)     |2359296     |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.9.intermediate.dense.bias                 |torch.float32    |(3072,)         |3072        |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.9.output.dense.weight                     |torch.float32    |(768, 3072)     |2359296     |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.9.output.dense.bias                       |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.9.output.LayerNorm.weight                 |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.9.output.LayerNorm.bias                   |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.10.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.10.attention_self.query.bias              |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.10.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.10.attention_self.key.bias                |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.10.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.10.attention_self.value.bias              |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.10.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.10.attention_output.dense.bias            |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.10.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.10.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.11.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.11.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.11.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.11.output.dense.bias                      |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.11.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.11.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.12.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.12.attention_self.query.bias              |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.12.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.12.attention_self.key.bias                |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.12.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.12.attention_self.value.bias              |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.12.attention_self.v_query.weight          |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.12.attention_self.v_query.bias            |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.12.attention_self.v_key.weight            |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.12.attention_self.v_key.bias              |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.12.attention_self.v_value.weight          |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.12.attention_self.v_value.bias            |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.12.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.12.attention_output.dense.bias            |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.12.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.12.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.12.attention_output.v_dense.weight        |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.12.attention_output.v_dense.bias          |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.12.attention_output.v_LayerNorm.weight    |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.12.attention_output.v_LayerNorm.bias      |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.13.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.13.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.13.intermediate.v_dense.weight            |torch.float32    |(3072, 768)     |2359296     |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.13.intermediate.v_dense.bias              |torch.float32    |(3072,)         |3072        |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.13.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.13.output.dense.bias                      |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.13.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.13.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.13.output.v_dense.weight                  |torch.float32    |(768, 3072)     |2359296     |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.13.output.v_dense.bias                    |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.13.output.v_LayerNorm.weight              |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.13.output.v_LayerNorm.bias                |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.14.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.14.attention_self.query.bias              |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.14.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.14.attention_self.key.bias                |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.14.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.14.attention_self.value.bias              |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.14.attention_self.v_query.weight          |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.14.attention_self.v_query.bias            |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.14.attention_self.v_key.weight            |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.14.attention_self.v_key.bias              |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.14.attention_self.v_value.weight          |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.14.attention_self.v_value.bias            |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.14.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.14.attention_output.dense.bias            |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.14.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.14.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.14.attention_output.v_dense.weight        |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.14.attention_output.v_dense.bias          |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.14.attention_output.v_LayerNorm.weight    |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.14.attention_output.v_LayerNorm.bias      |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.15.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.15.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.15.intermediate.v_dense.weight            |torch.float32    |(3072, 768)     |2359296     |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.15.intermediate.v_dense.bias              |torch.float32    |(3072,)         |3072        |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.15.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.15.output.dense.bias                      |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.15.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.15.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.15.output.v_dense.weight                  |torch.float32    |(768, 3072)     |2359296     |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.15.output.v_dense.bias                    |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.15.output.v_LayerNorm.weight              |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.15.output.v_LayerNorm.bias                |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.16.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.16.attention_self.query.bias              |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.16.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.16.attention_self.key.bias                |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.16.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.16.attention_self.value.bias              |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.16.attention_self.v_query.weight          |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.16.attention_self.v_query.bias            |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.16.attention_self.v_key.weight            |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.16.attention_self.v_key.bias              |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.16.attention_self.v_value.weight          |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.16.attention_self.v_value.bias            |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.16.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.16.attention_output.dense.bias            |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.16.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.16.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.16.attention_output.v_dense.weight        |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.16.attention_output.v_dense.bias          |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.16.attention_output.v_LayerNorm.weight    |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.16.attention_output.v_LayerNorm.bias      |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.17.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.17.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.17.intermediate.v_dense.weight            |torch.float32    |(3072, 768)     |2359296     |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.17.intermediate.v_dense.bias              |torch.float32    |(3072,)         |3072        |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.17.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.17.output.dense.bias                      |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.17.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.17.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.17.output.v_dense.weight                  |torch.float32    |(768, 3072)     |2359296     |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.17.output.v_dense.bias                    |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.17.output.v_LayerNorm.weight              |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.17.output.v_LayerNorm.bias                |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.18.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.18.attention_self.query.bias              |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.18.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.18.attention_self.key.bias                |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.18.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.18.attention_self.value.bias              |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.18.attention_self.v_query.weight          |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.18.attention_self.v_query.bias            |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.18.attention_self.v_key.weight            |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.18.attention_self.v_key.bias              |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.18.attention_self.v_value.weight          |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.18.attention_self.v_value.bias            |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.18.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.18.attention_output.dense.bias            |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.18.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.18.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.18.attention_output.v_dense.weight        |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.18.attention_output.v_dense.bias          |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.18.attention_output.v_LayerNorm.weight    |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.18.attention_output.v_LayerNorm.bias      |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.19.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.19.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.19.intermediate.v_dense.weight            |torch.float32    |(3072, 768)     |2359296     |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.19.intermediate.v_dense.bias              |torch.float32    |(3072,)         |3072        |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.19.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.19.output.dense.bias                      |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.19.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.19.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.19.output.v_dense.weight                  |torch.float32    |(768, 3072)     |2359296     |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.19.output.v_dense.bias                    |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.19.output.v_LayerNorm.weight              |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.19.output.v_LayerNorm.bias                |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.20.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.20.attention_self.query.bias              |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.20.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.20.attention_self.key.bias                |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.20.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.20.attention_self.value.bias              |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.20.attention_self.v_query.weight          |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.20.attention_self.v_query.bias            |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.20.attention_self.v_key.weight            |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.20.attention_self.v_key.bias              |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.20.attention_self.v_value.weight          |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.20.attention_self.v_value.bias            |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.20.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.20.attention_output.dense.bias            |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.20.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.20.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.20.attention_output.v_dense.weight        |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.20.attention_output.v_dense.bias          |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.20.attention_output.v_LayerNorm.weight    |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.20.attention_output.v_LayerNorm.bias      |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.21.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.21.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.21.intermediate.v_dense.weight            |torch.float32    |(3072, 768)     |2359296     |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.21.intermediate.v_dense.bias              |torch.float32    |(3072,)         |3072        |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.21.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.21.output.dense.bias                      |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.21.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.21.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.21.output.v_dense.weight                  |torch.float32    |(768, 3072)     |2359296     |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.21.output.v_dense.bias                    |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.21.output.v_LayerNorm.weight              |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.21.output.v_LayerNorm.bias                |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.22.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.22.attention_self.query.bias              |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.22.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.22.attention_self.key.bias                |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.22.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.22.attention_self.value.bias              |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.22.attention_self.v_query.weight          |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.22.attention_self.v_query.bias            |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.22.attention_self.v_key.weight            |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.22.attention_self.v_key.bias              |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.22.attention_self.v_value.weight          |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.22.attention_self.v_value.bias            |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.22.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.22.attention_output.dense.bias            |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.22.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.22.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.22.attention_output.v_dense.weight        |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.22.attention_output.v_dense.bias          |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.22.attention_output.v_LayerNorm.weight    |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.22.attention_output.v_LayerNorm.bias      |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.23.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.23.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.23.intermediate.v_dense.weight            |torch.float32    |(3072, 768)     |2359296     |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.23.intermediate.v_dense.bias              |torch.float32    |(3072,)         |3072        |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.23.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.23.output.dense.bias                      |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.23.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.23.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.23.output.v_dense.weight                  |torch.float32    |(768, 3072)     |2359296     |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.23.output.v_dense.bias                    |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.23.output.v_LayerNorm.weight              |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.23.output.v_LayerNorm.bias                |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.24.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.24.attention_self.query.bias              |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.24.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.24.attention_self.key.bias                |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.24.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.24.attention_self.value.bias              |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.24.attention_self.v_query.weight          |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.24.attention_self.v_query.bias            |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.24.attention_self.v_key.weight            |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.24.attention_self.v_key.bias              |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.24.attention_self.v_value.weight          |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.24.attention_self.v_value.bias            |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.24.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.24.attention_output.dense.bias            |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.24.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.24.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.24.attention_output.v_dense.weight        |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.24.attention_output.v_dense.bias          |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.24.attention_output.v_LayerNorm.weight    |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.24.attention_output.v_LayerNorm.bias      |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.25.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.25.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.25.intermediate.v_dense.weight            |torch.float32    |(3072, 768)     |2359296     |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.25.intermediate.v_dense.bias              |torch.float32    |(3072,)         |3072        |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.25.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.25.output.dense.bias                      |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.25.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.25.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.25.output.v_dense.weight                  |torch.float32    |(768, 3072)     |2359296     |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.25.output.v_dense.bias                    |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.25.output.v_LayerNorm.weight              |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.25.output.v_LayerNorm.bias                |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.26.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.26.attention_self.query.bias              |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.26.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.26.attention_self.key.bias                |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.26.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.26.attention_self.value.bias              |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.26.attention_self.v_query.weight          |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.26.attention_self.v_query.bias            |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.26.attention_self.v_key.weight            |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.26.attention_self.v_key.bias              |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.26.attention_self.v_value.weight          |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.26.attention_self.v_value.bias            |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.26.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.26.attention_output.dense.bias            |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.26.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.26.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.26.attention_output.v_dense.weight        |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.26.attention_output.v_dense.bias          |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.26.attention_output.v_LayerNorm.weight    |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.26.attention_output.v_LayerNorm.bias      |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.27.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.27.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.27.intermediate.v_dense.weight            |torch.float32    |(3072, 768)     |2359296     |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.27.intermediate.v_dense.bias              |torch.float32    |(3072,)         |3072        |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.27.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.27.output.dense.bias                      |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.27.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.27.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.27.output.v_dense.weight                  |torch.float32    |(768, 3072)     |2359296     |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.27.output.v_dense.bias                    |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.27.output.v_LayerNorm.weight              |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.27.output.v_LayerNorm.bias                |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.28.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.28.attention_self.query.bias              |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.28.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.28.attention_self.key.bias                |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.28.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.28.attention_self.value.bias              |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.28.attention_self.v_query.weight          |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.28.attention_self.v_query.bias            |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.28.attention_self.v_key.weight            |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.28.attention_self.v_key.bias              |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.28.attention_self.v_value.weight          |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.28.attention_self.v_value.bias            |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.28.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.28.attention_output.dense.bias            |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.28.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.28.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.28.attention_output.v_dense.weight        |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.28.attention_output.v_dense.bias          |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.28.attention_output.v_LayerNorm.weight    |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.28.attention_output.v_LayerNorm.bias      |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.29.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.29.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.29.intermediate.v_dense.weight            |torch.float32    |(3072, 768)     |2359296     |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.29.intermediate.v_dense.bias              |torch.float32    |(3072,)         |3072        |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.29.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.29.output.dense.bias                      |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.29.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.29.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.29.output.v_dense.weight                  |torch.float32    |(768, 3072)     |2359296     |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.29.output.v_dense.bias                    |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.29.output.v_LayerNorm.weight              |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.29.output.v_LayerNorm.bias                |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.30.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.30.attention_self.query.bias              |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.30.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.30.attention_self.key.bias                |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.30.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.30.attention_self.value.bias              |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.30.attention_self.v_query.weight          |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.30.attention_self.v_query.bias            |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.30.attention_self.v_key.weight            |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.30.attention_self.v_key.bias              |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.30.attention_self.v_value.weight          |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.30.attention_self.v_value.bias            |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.30.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.30.attention_output.dense.bias            |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.30.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.30.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.30.attention_output.v_dense.weight        |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.30.attention_output.v_dense.bias          |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.30.attention_output.v_LayerNorm.weight    |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.30.attention_output.v_LayerNorm.bias      |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.31.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.31.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.31.intermediate.v_dense.weight            |torch.float32    |(3072, 768)     |2359296     |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.31.intermediate.v_dense.bias              |torch.float32    |(3072,)         |3072        |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.31.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.31.output.dense.bias                      |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.31.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.31.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.31.output.v_dense.weight                  |torch.float32    |(768, 3072)     |2359296     |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.31.output.v_dense.bias                    |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.31.output.v_LayerNorm.weight              |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.31.output.v_LayerNorm.bias                |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.32.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.32.attention_self.query.bias              |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.32.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.32.attention_self.key.bias                |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.32.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.32.attention_self.value.bias              |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.32.attention_self.v_query.weight          |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.32.attention_self.v_query.bias            |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.32.attention_self.v_key.weight            |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.32.attention_self.v_key.bias              |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.32.attention_self.v_value.weight          |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.32.attention_self.v_value.bias            |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.32.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.32.attention_output.dense.bias            |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.32.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.32.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.32.attention_output.v_dense.weight        |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.32.attention_output.v_dense.bias          |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.32.attention_output.v_LayerNorm.weight    |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.32.attention_output.v_LayerNorm.bias      |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.33.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.33.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.33.intermediate.v_dense.weight            |torch.float32    |(3072, 768)     |2359296     |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.33.intermediate.v_dense.bias              |torch.float32    |(3072,)         |3072        |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.33.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.33.output.dense.bias                      |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.33.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.33.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.33.output.v_dense.weight                  |torch.float32    |(768, 3072)     |2359296     |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.33.output.v_dense.bias                    |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.33.output.v_LayerNorm.weight              |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.33.output.v_LayerNorm.bias                |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.34.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.34.attention_self.query.bias              |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.34.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.34.attention_self.key.bias                |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.34.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.34.attention_self.value.bias              |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.34.attention_self.v_query.weight          |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.34.attention_self.v_query.bias            |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.34.attention_self.v_key.weight            |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.34.attention_self.v_key.bias              |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.34.attention_self.v_value.weight          |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.34.attention_self.v_value.bias            |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.34.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.34.attention_output.dense.bias            |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.34.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.34.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.34.attention_output.v_dense.weight        |torch.float32    |(768, 768)      |589824      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.34.attention_output.v_dense.bias          |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.34.attention_output.v_LayerNorm.weight    |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.34.attention_output.v_LayerNorm.bias      |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.35.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.35.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.35.intermediate.v_dense.weight            |torch.float32    |(3072, 768)     |2359296     |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.35.intermediate.v_dense.bias              |torch.float32    |(3072,)         |3072        |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.35.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.35.output.dense.bias                      |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.35.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.35.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.35.output.v_dense.weight                  |torch.float32    |(768, 3072)     |2359296     |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.35.output.v_dense.bias                    |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.35.output.v_LayerNorm.weight              |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.encoder.layer.35.output.v_LayerNorm.bias                |torch.float32    |(768,)          |768         |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.t_pooler.dense.weight                                   |torch.float32    |(1024, 768)     |786432      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.t_pooler.dense.bias                                     |torch.float32    |(1024,)         |1024        |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.v_pooler.dense.weight                                   |torch.float32    |(1024, 768)     |786432      |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |bert.v_pooler.dense.bias                                     |torch.float32    |(1024,)         |1024        |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |clfs_dict.TASK20.weight                                      |torch.float32    |(1, 1024)       |1024        |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   |clfs_dict.TASK20.bias                                        |torch.float32    |(1,)            |1           |True    |
12/06/2021 10:05:19 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/06/2021 10:05:19 - INFO - __main__ -   >> # TrainableParams:       	239.63	M
12/06/2021 10:05:19 - INFO - __main__ -   >> # NonTrainableParams:    	0.00	M
12/06/2021 10:05:19 - INFO - __main__ -   >> # TotalParams:           	239.63	M
Epoch:   0%|          | 0/2 [00:00<?, ?it/s]/home/projects/ku_00062/envs/iglue/lib/python3.6/site-packages/pytorch_transformers/optimization.py:166: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
12/06/2021 10:06:08 - INFO - volta.train_utils -   [RetrievalWIT]: iter 80 Ep: 0.00 loss 0.084 score 0.083 lr 3.36e-08 
12/06/2021 10:06:57 - INFO - volta.train_utils -   [RetrievalWIT]: iter 160 Ep: 0.01 loss 0.083 score 0.097 lr 9.76e-08 
12/06/2021 10:07:46 - INFO - volta.train_utils -   [RetrievalWIT]: iter 240 Ep: 0.01 loss 0.080 score 0.109 lr 1.616e-07 
12/06/2021 10:08:35 - INFO - volta.train_utils -   [RetrievalWIT]: iter 320 Ep: 0.01 loss 0.076 score 0.136 lr 2.256e-07 
12/06/2021 10:09:24 - INFO - volta.train_utils -   [RetrievalWIT]: iter 400 Ep: 0.01 loss 0.070 score 0.162 lr 2.896e-07 
12/06/2021 10:10:14 - INFO - volta.train_utils -   [RetrievalWIT]: iter 480 Ep: 0.02 loss 0.064 score 0.173 lr 3.536e-07 
12/06/2021 10:11:03 - INFO - volta.train_utils -   [RetrievalWIT]: iter 560 Ep: 0.02 loss 0.056 score 0.182 lr 4.176e-07 
12/06/2021 10:11:52 - INFO - volta.train_utils -   [RetrievalWIT]: iter 640 Ep: 0.02 loss 0.047 score 0.188 lr 4.816e-07 
12/06/2021 10:12:41 - INFO - volta.train_utils -   [RetrievalWIT]: iter 720 Ep: 0.02 loss 0.044 score 0.188 lr 5.456e-07 
12/06/2021 10:13:30 - INFO - volta.train_utils -   [RetrievalWIT]: iter 800 Ep: 0.03 loss 0.044 score 0.188 lr 6.096e-07 
12/06/2021 10:14:19 - INFO - volta.train_utils -   [RetrievalWIT]: iter 880 Ep: 0.03 loss 0.040 score 0.188 lr 6.736e-07 
12/06/2021 10:15:08 - INFO - volta.train_utils -   [RetrievalWIT]: iter 960 Ep: 0.03 loss 0.033 score 0.202 lr 7.376e-07 
12/06/2021 10:15:57 - INFO - volta.train_utils -   [RetrievalWIT]: iter 1040 Ep: 0.03 loss 0.034 score 0.204 lr 8.016e-07 
12/06/2021 10:16:46 - INFO - volta.train_utils -   [RetrievalWIT]: iter 1120 Ep: 0.04 loss 0.031 score 0.202 lr 8.656e-07 
12/06/2021 10:17:35 - INFO - volta.train_utils -   [RetrievalWIT]: iter 1200 Ep: 0.04 loss 0.037 score 0.202 lr 9.296e-07 
12/06/2021 10:18:24 - INFO - volta.train_utils -   [RetrievalWIT]: iter 1280 Ep: 0.04 loss 0.026 score 0.202 lr 9.936e-07 
12/06/2021 10:19:13 - INFO - volta.train_utils -   [RetrievalWIT]: iter 1360 Ep: 0.04 loss 0.033 score 0.205 lr 1.0576e-06 
12/06/2021 10:20:03 - INFO - volta.train_utils -   [RetrievalWIT]: iter 1440 Ep: 0.05 loss 0.030 score 0.206 lr 1.1216e-06 
12/06/2021 10:20:52 - INFO - volta.train_utils -   [RetrievalWIT]: iter 1520 Ep: 0.05 loss 0.028 score 0.204 lr 1.1856e-06 
12/06/2021 10:21:41 - INFO - volta.train_utils -   [RetrievalWIT]: iter 1600 Ep: 0.05 loss 0.029 score 0.207 lr 1.2496e-06 
12/06/2021 10:22:30 - INFO - volta.train_utils -   [RetrievalWIT]: iter 1680 Ep: 0.05 loss 0.030 score 0.207 lr 1.3136e-06 
12/06/2021 10:23:19 - INFO - volta.train_utils -   [RetrievalWIT]: iter 1760 Ep: 0.06 loss 0.023 score 0.211 lr 1.3776e-06 
12/06/2021 10:24:08 - INFO - volta.train_utils -   [RetrievalWIT]: iter 1840 Ep: 0.06 loss 0.025 score 0.206 lr 1.4416e-06 
12/06/2021 10:24:57 - INFO - volta.train_utils -   [RetrievalWIT]: iter 1920 Ep: 0.06 loss 0.026 score 0.213 lr 1.5056e-06 
12/06/2021 10:25:46 - INFO - volta.train_utils -   [RetrievalWIT]: iter 2000 Ep: 0.06 loss 0.022 score 0.216 lr 1.5696e-06 
12/06/2021 10:26:35 - INFO - volta.train_utils -   [RetrievalWIT]: iter 2080 Ep: 0.07 loss 0.024 score 0.212 lr 1.6336e-06 
12/06/2021 10:27:24 - INFO - volta.train_utils -   [RetrievalWIT]: iter 2160 Ep: 0.07 loss 0.024 score 0.211 lr 1.6976e-06 
12/06/2021 10:28:14 - INFO - volta.train_utils -   [RetrievalWIT]: iter 2240 Ep: 0.07 loss 0.023 score 0.212 lr 1.7616e-06 
12/06/2021 10:29:03 - INFO - volta.train_utils -   [RetrievalWIT]: iter 2320 Ep: 0.07 loss 0.022 score 0.215 lr 1.8256e-06 
12/06/2021 10:29:52 - INFO - volta.train_utils -   [RetrievalWIT]: iter 2400 Ep: 0.08 loss 0.027 score 0.211 lr 1.8896e-06 
12/06/2021 10:30:41 - INFO - volta.train_utils -   [RetrievalWIT]: iter 2480 Ep: 0.08 loss 0.025 score 0.214 lr 1.9536e-06 
12/06/2021 10:31:30 - INFO - volta.train_utils -   [RetrievalWIT]: iter 2560 Ep: 0.08 loss 0.023 score 0.213 lr 2.0176e-06 
12/06/2021 10:32:19 - INFO - volta.train_utils -   [RetrievalWIT]: iter 2640 Ep: 0.08 loss 0.024 score 0.220 lr 2.0816e-06 
12/06/2021 10:33:08 - INFO - volta.train_utils -   [RetrievalWIT]: iter 2720 Ep: 0.09 loss 0.019 score 0.217 lr 2.1456e-06 
12/06/2021 10:33:58 - INFO - volta.train_utils -   [RetrievalWIT]: iter 2800 Ep: 0.09 loss 0.018 score 0.217 lr 2.2096e-06 
12/06/2021 10:34:47 - INFO - volta.train_utils -   [RetrievalWIT]: iter 2880 Ep: 0.09 loss 0.021 score 0.217 lr 2.2736e-06 
12/06/2021 10:35:36 - INFO - volta.train_utils -   [RetrievalWIT]: iter 2960 Ep: 0.09 loss 0.024 score 0.216 lr 2.3376e-06 
12/06/2021 10:36:25 - INFO - volta.train_utils -   [RetrievalWIT]: iter 3040 Ep: 0.10 loss 0.019 score 0.218 lr 2.4016e-06 
12/06/2021 10:37:14 - INFO - volta.train_utils -   [RetrievalWIT]: iter 3120 Ep: 0.10 loss 0.020 score 0.223 lr 2.4656e-06 
12/06/2021 10:38:03 - INFO - volta.train_utils -   [RetrievalWIT]: iter 3200 Ep: 0.10 loss 0.023 score 0.216 lr 2.5296e-06 
12/06/2021 10:38:52 - INFO - volta.train_utils -   [RetrievalWIT]: iter 3280 Ep: 0.10 loss 0.024 score 0.217 lr 2.5936e-06 
12/06/2021 10:39:41 - INFO - volta.train_utils -   [RetrievalWIT]: iter 3360 Ep: 0.11 loss 0.022 score 0.222 lr 2.6576e-06 
12/06/2021 10:40:30 - INFO - volta.train_utils -   [RetrievalWIT]: iter 3440 Ep: 0.11 loss 0.020 score 0.216 lr 2.7216e-06 
12/06/2021 10:41:20 - INFO - volta.train_utils -   [RetrievalWIT]: iter 3520 Ep: 0.11 loss 0.020 score 0.222 lr 2.7856e-06 
12/06/2021 10:42:09 - INFO - volta.train_utils -   [RetrievalWIT]: iter 3600 Ep: 0.12 loss 0.015 score 0.221 lr 2.8496e-06 
12/06/2021 10:42:58 - INFO - volta.train_utils -   [RetrievalWIT]: iter 3680 Ep: 0.12 loss 0.021 score 0.220 lr 2.9136e-06 
12/06/2021 10:43:47 - INFO - volta.train_utils -   [RetrievalWIT]: iter 3760 Ep: 0.12 loss 0.020 score 0.222 lr 2.9776e-06 
12/06/2021 10:44:36 - INFO - volta.train_utils -   [RetrievalWIT]: iter 3840 Ep: 0.12 loss 0.019 score 0.219 lr 3.0416e-06 
12/06/2021 10:45:25 - INFO - volta.train_utils -   [RetrievalWIT]: iter 3920 Ep: 0.13 loss 0.021 score 0.216 lr 3.1056e-06 
12/06/2021 10:47:19 - INFO - volta.train_utils -   Eval task TASK20 on iteration 3996 
12/06/2021 10:47:19 - INFO - volta.train_utils -   Validation [RetrievalWIT]: loss 0.282 score 88.776 
12/06/2021 10:47:19 - INFO - __main__ -   ** ** * Saving model * ** ** 
12/06/2021 10:48:47 - INFO - volta.train_utils -   Eval task TASK20 on iteration 3996 
12/06/2021 10:48:47 - INFO - volta.train_utils -   Validation [RetrievalWIT]: loss 0.278 score 89.035 
12/06/2021 10:48:47 - INFO - __main__ -   ** ** * Saving model * ** ** 
12/06/2021 10:50:14 - INFO - volta.train_utils -   Eval task TASK20 on iteration 3996 
12/06/2021 10:50:14 - INFO - volta.train_utils -   Validation [RetrievalWIT]: loss 0.281 score 89.144 
12/06/2021 10:50:14 - INFO - __main__ -   ** ** * Saving model * ** ** 
12/06/2021 10:51:42 - INFO - volta.train_utils -   Eval task TASK20 on iteration 4000 
12/06/2021 10:51:42 - INFO - volta.train_utils -   Validation [RetrievalWIT]: loss 0.300 score 88.711 
12/06/2021 10:51:43 - INFO - volta.train_utils -   [RetrievalWIT]: iter 4000 Ep: 0.13 loss 0.017 score 0.222 lr 3.1696e-06 
12/06/2021 10:52:32 - INFO - volta.train_utils -   [RetrievalWIT]: iter 4080 Ep: 0.13 loss 0.024 score 0.219 lr 3.2336e-06 
12/06/2021 10:53:21 - INFO - volta.train_utils -   [RetrievalWIT]: iter 4160 Ep: 0.13 loss 0.018 score 0.219 lr 3.2976e-06 
12/06/2021 10:54:10 - INFO - volta.train_utils -   [RetrievalWIT]: iter 4240 Ep: 0.14 loss 0.020 score 0.222 lr 3.3616e-06 
12/06/2021 10:54:59 - INFO - volta.train_utils -   [RetrievalWIT]: iter 4320 Ep: 0.14 loss 0.017 score 0.220 lr 3.4256e-06 
12/06/2021 10:55:48 - INFO - volta.train_utils -   [RetrievalWIT]: iter 4400 Ep: 0.14 loss 0.020 score 0.221 lr 3.4896e-06 
12/06/2021 10:56:37 - INFO - volta.train_utils -   [RetrievalWIT]: iter 4480 Ep: 0.14 loss 0.020 score 0.222 lr 3.5536e-06 
12/06/2021 10:57:27 - INFO - volta.train_utils -   [RetrievalWIT]: iter 4560 Ep: 0.15 loss 0.013 score 0.226 lr 3.6176e-06 
12/06/2021 10:58:16 - INFO - volta.train_utils -   [RetrievalWIT]: iter 4640 Ep: 0.15 loss 0.016 score 0.221 lr 3.6816e-06 
12/06/2021 10:59:05 - INFO - volta.train_utils -   [RetrievalWIT]: iter 4720 Ep: 0.15 loss 0.017 score 0.224 lr 3.7456e-06 
12/06/2021 10:59:54 - INFO - volta.train_utils -   [RetrievalWIT]: iter 4800 Ep: 0.15 loss 0.019 score 0.223 lr 3.8096e-06 
12/06/2021 11:00:43 - INFO - volta.train_utils -   [RetrievalWIT]: iter 4880 Ep: 0.16 loss 0.017 score 0.222 lr 3.8736e-06 
12/06/2021 11:01:32 - INFO - volta.train_utils -   [RetrievalWIT]: iter 4960 Ep: 0.16 loss 0.014 score 0.224 lr 3.9376e-06 
12/06/2021 11:02:21 - INFO - volta.train_utils -   [RetrievalWIT]: iter 5040 Ep: 0.16 loss 0.017 score 0.223 lr 4.0016e-06 
12/06/2021 11:03:10 - INFO - volta.train_utils -   [RetrievalWIT]: iter 5120 Ep: 0.16 loss 0.020 score 0.223 lr 4.0656e-06 
12/06/2021 11:03:59 - INFO - volta.train_utils -   [RetrievalWIT]: iter 5200 Ep: 0.17 loss 0.018 score 0.225 lr 4.1296e-06 
12/06/2021 11:04:48 - INFO - volta.train_utils -   [RetrievalWIT]: iter 5280 Ep: 0.17 loss 0.016 score 0.222 lr 4.1936e-06 
12/06/2021 11:05:37 - INFO - volta.train_utils -   [RetrievalWIT]: iter 5360 Ep: 0.17 loss 0.017 score 0.223 lr 4.2576e-06 
12/06/2021 11:06:26 - INFO - volta.train_utils -   [RetrievalWIT]: iter 5440 Ep: 0.17 loss 0.020 score 0.226 lr 4.3216e-06 
12/06/2021 11:07:15 - INFO - volta.train_utils -   [RetrievalWIT]: iter 5520 Ep: 0.18 loss 0.013 score 0.224 lr 4.3856e-06 
12/06/2021 11:08:04 - INFO - volta.train_utils -   [RetrievalWIT]: iter 5600 Ep: 0.18 loss 0.017 score 0.226 lr 4.4496e-06 
12/06/2021 11:08:53 - INFO - volta.train_utils -   [RetrievalWIT]: iter 5680 Ep: 0.18 loss 0.015 score 0.226 lr 4.5136e-06 
12/06/2021 11:09:43 - INFO - volta.train_utils -   [RetrievalWIT]: iter 5760 Ep: 0.18 loss 0.020 score 0.220 lr 4.5776e-06 
12/06/2021 11:10:32 - INFO - volta.train_utils -   [RetrievalWIT]: iter 5840 Ep: 0.19 loss 0.016 score 0.222 lr 4.6416e-06 
12/06/2021 11:11:21 - INFO - volta.train_utils -   [RetrievalWIT]: iter 5920 Ep: 0.19 loss 0.016 score 0.225 lr 4.7056e-06 
12/06/2021 11:12:10 - INFO - volta.train_utils -   [RetrievalWIT]: iter 6000 Ep: 0.19 loss 0.021 score 0.222 lr 4.7696e-06 
12/06/2021 11:12:59 - INFO - volta.train_utils -   [RetrievalWIT]: iter 6080 Ep: 0.19 loss 0.020 score 0.224 lr 4.8336e-06 
12/06/2021 11:13:48 - INFO - volta.train_utils -   [RetrievalWIT]: iter 6160 Ep: 0.20 loss 0.017 score 0.222 lr 4.8976e-06 
12/06/2021 11:14:38 - INFO - volta.train_utils -   [RetrievalWIT]: iter 6240 Ep: 0.20 loss 0.016 score 0.222 lr 4.9616e-06 
12/06/2021 11:15:27 - INFO - volta.train_utils -   [RetrievalWIT]: iter 6320 Ep: 0.20 loss 0.018 score 0.220 lr 4.9968e-06 
12/06/2021 11:16:16 - INFO - volta.train_utils -   [RetrievalWIT]: iter 6400 Ep: 0.20 loss 0.017 score 0.223 lr 4.99004e-06 
12/06/2021 11:17:05 - INFO - volta.train_utils -   [RetrievalWIT]: iter 6480 Ep: 0.21 loss 0.017 score 0.225 lr 4.98293e-06 
12/06/2021 11:17:54 - INFO - volta.train_utils -   [RetrievalWIT]: iter 6560 Ep: 0.21 loss 0.015 score 0.227 lr 4.97582e-06 
12/06/2021 11:18:43 - INFO - volta.train_utils -   [RetrievalWIT]: iter 6640 Ep: 0.21 loss 0.017 score 0.224 lr 4.96871e-06 
12/06/2021 11:19:32 - INFO - volta.train_utils -   [RetrievalWIT]: iter 6720 Ep: 0.22 loss 0.015 score 0.225 lr 4.9616e-06 
12/06/2021 11:20:21 - INFO - volta.train_utils -   [RetrievalWIT]: iter 6800 Ep: 0.22 loss 0.012 score 0.230 lr 4.95449e-06 
12/06/2021 11:21:10 - INFO - volta.train_utils -   [RetrievalWIT]: iter 6880 Ep: 0.22 loss 0.017 score 0.221 lr 4.94738e-06 
12/06/2021 11:22:00 - INFO - volta.train_utils -   [RetrievalWIT]: iter 6960 Ep: 0.22 loss 0.019 score 0.225 lr 4.94027e-06 
12/06/2021 11:22:49 - INFO - volta.train_utils -   [RetrievalWIT]: iter 7040 Ep: 0.23 loss 0.015 score 0.225 lr 4.93316e-06 
12/06/2021 11:23:38 - INFO - volta.train_utils -   [RetrievalWIT]: iter 7120 Ep: 0.23 loss 0.014 score 0.226 lr 4.92604e-06 
12/06/2021 11:24:27 - INFO - volta.train_utils -   [RetrievalWIT]: iter 7200 Ep: 0.23 loss 0.017 score 0.226 lr 4.91893e-06 
12/06/2021 11:25:16 - INFO - volta.train_utils -   [RetrievalWIT]: iter 7280 Ep: 0.23 loss 0.013 score 0.230 lr 4.91182e-06 
12/06/2021 11:26:05 - INFO - volta.train_utils -   [RetrievalWIT]: iter 7360 Ep: 0.24 loss 0.017 score 0.225 lr 4.90471e-06 
12/06/2021 11:26:54 - INFO - volta.train_utils -   [RetrievalWIT]: iter 7440 Ep: 0.24 loss 0.011 score 0.228 lr 4.8976e-06 
12/06/2021 11:27:43 - INFO - volta.train_utils -   [RetrievalWIT]: iter 7520 Ep: 0.24 loss 0.013 score 0.225 lr 4.89049e-06 
12/06/2021 11:28:32 - INFO - volta.train_utils -   [RetrievalWIT]: iter 7600 Ep: 0.24 loss 0.016 score 0.228 lr 4.88338e-06 
12/06/2021 11:29:21 - INFO - volta.train_utils -   [RetrievalWIT]: iter 7680 Ep: 0.25 loss 0.014 score 0.226 lr 4.87627e-06 
12/06/2021 11:30:10 - INFO - volta.train_utils -   [RetrievalWIT]: iter 7760 Ep: 0.25 loss 0.015 score 0.224 lr 4.86916e-06 
12/06/2021 11:30:59 - INFO - volta.train_utils -   [RetrievalWIT]: iter 7840 Ep: 0.25 loss 0.016 score 0.227 lr 4.86204e-06 
12/06/2021 11:31:49 - INFO - volta.train_utils -   [RetrievalWIT]: iter 7920 Ep: 0.25 loss 0.010 score 0.228 lr 4.85493e-06 
12/06/2021 11:33:36 - INFO - volta.train_utils -   Eval task TASK20 on iteration 7992 
12/06/2021 11:33:36 - INFO - volta.train_utils -   Validation [RetrievalWIT]: loss 0.235 score 90.830 
12/06/2021 11:33:36 - INFO - __main__ -   ** ** * Saving model * ** ** 
12/06/2021 11:35:07 - INFO - volta.train_utils -   Eval task TASK20 on iteration 7992 
12/06/2021 11:35:07 - INFO - volta.train_utils -   Validation [RetrievalWIT]: loss 0.239 score 90.722 
12/06/2021 11:36:10 - INFO - volta.train_utils -   Eval task TASK20 on iteration 7992 
12/06/2021 11:36:10 - INFO - volta.train_utils -   Validation [RetrievalWIT]: loss 0.244 score 90.376 
12/06/2021 11:37:15 - INFO - volta.train_utils -   Eval task TASK20 on iteration 7996 
12/06/2021 11:37:15 - INFO - volta.train_utils -   Validation [RetrievalWIT]: loss 0.238 score 90.549 
12/06/2021 11:37:18 - INFO - volta.train_utils -   [RetrievalWIT]: iter 8000 Ep: 0.26 loss 0.018 score 0.224 lr 4.84782e-06 
12/06/2021 11:38:07 - INFO - volta.train_utils -   [RetrievalWIT]: iter 8080 Ep: 0.26 loss 0.015 score 0.224 lr 4.84071e-06 
12/06/2021 11:38:56 - INFO - volta.train_utils -   [RetrievalWIT]: iter 8160 Ep: 0.26 loss 0.017 score 0.224 lr 4.8336e-06 
12/06/2021 11:39:45 - INFO - volta.train_utils -   [RetrievalWIT]: iter 8240 Ep: 0.26 loss 0.015 score 0.228 lr 4.82649e-06 
12/06/2021 11:40:34 - INFO - volta.train_utils -   [RetrievalWIT]: iter 8320 Ep: 0.27 loss 0.016 score 0.225 lr 4.81938e-06 
12/06/2021 11:41:23 - INFO - volta.train_utils -   [RetrievalWIT]: iter 8400 Ep: 0.27 loss 0.019 score 0.229 lr 4.81227e-06 
12/06/2021 11:42:12 - INFO - volta.train_utils -   [RetrievalWIT]: iter 8480 Ep: 0.27 loss 0.018 score 0.230 lr 4.80516e-06 
12/06/2021 11:43:01 - INFO - volta.train_utils -   [RetrievalWIT]: iter 8560 Ep: 0.27 loss 0.015 score 0.229 lr 4.79804e-06 
12/06/2021 11:43:50 - INFO - volta.train_utils -   [RetrievalWIT]: iter 8640 Ep: 0.28 loss 0.018 score 0.220 lr 4.79093e-06 
12/06/2021 11:44:39 - INFO - volta.train_utils -   [RetrievalWIT]: iter 8720 Ep: 0.28 loss 0.013 score 0.230 lr 4.78382e-06 
12/06/2021 11:45:28 - INFO - volta.train_utils -   [RetrievalWIT]: iter 8800 Ep: 0.28 loss 0.015 score 0.229 lr 4.77671e-06 
12/06/2021 11:46:17 - INFO - volta.train_utils -   [RetrievalWIT]: iter 8880 Ep: 0.28 loss 0.018 score 0.227 lr 4.7696e-06 
12/06/2021 11:47:06 - INFO - volta.train_utils -   [RetrievalWIT]: iter 8960 Ep: 0.29 loss 0.017 score 0.226 lr 4.76249e-06 
12/06/2021 11:47:55 - INFO - volta.train_utils -   [RetrievalWIT]: iter 9040 Ep: 0.29 loss 0.016 score 0.228 lr 4.75538e-06 
12/06/2021 11:48:44 - INFO - volta.train_utils -   [RetrievalWIT]: iter 9120 Ep: 0.29 loss 0.013 score 0.227 lr 4.74827e-06 
12/06/2021 11:49:33 - INFO - volta.train_utils -   [RetrievalWIT]: iter 9200 Ep: 0.29 loss 0.014 score 0.226 lr 4.74116e-06 
12/06/2021 11:50:23 - INFO - volta.train_utils -   [RetrievalWIT]: iter 9280 Ep: 0.30 loss 0.014 score 0.224 lr 4.73404e-06 
12/06/2021 11:51:12 - INFO - volta.train_utils -   [RetrievalWIT]: iter 9360 Ep: 0.30 loss 0.014 score 0.226 lr 4.72693e-06 
12/06/2021 11:52:01 - INFO - volta.train_utils -   [RetrievalWIT]: iter 9440 Ep: 0.30 loss 0.015 score 0.229 lr 4.71982e-06 
12/06/2021 11:52:51 - INFO - volta.train_utils -   [RetrievalWIT]: iter 9520 Ep: 0.30 loss 0.016 score 0.225 lr 4.71271e-06 
12/06/2021 11:53:40 - INFO - volta.train_utils -   [RetrievalWIT]: iter 9600 Ep: 0.31 loss 0.015 score 0.226 lr 4.7056e-06 
12/06/2021 11:54:29 - INFO - volta.train_utils -   [RetrievalWIT]: iter 9680 Ep: 0.31 loss 0.016 score 0.227 lr 4.69849e-06 
12/06/2021 11:55:17 - INFO - volta.train_utils -   [RetrievalWIT]: iter 9760 Ep: 0.31 loss 0.015 score 0.227 lr 4.69138e-06 
12/06/2021 11:56:06 - INFO - volta.train_utils -   [RetrievalWIT]: iter 9840 Ep: 0.31 loss 0.015 score 0.226 lr 4.68427e-06 
12/06/2021 11:56:55 - INFO - volta.train_utils -   [RetrievalWIT]: iter 9920 Ep: 0.32 loss 0.016 score 0.227 lr 4.67716e-06 
12/06/2021 11:57:44 - INFO - volta.train_utils -   [RetrievalWIT]: iter 10000 Ep: 0.32 loss 0.014 score 0.229 lr 4.67004e-06 
12/06/2021 11:58:33 - INFO - volta.train_utils -   [RetrievalWIT]: iter 10080 Ep: 0.32 loss 0.013 score 0.227 lr 4.66293e-06 
12/06/2021 11:59:23 - INFO - volta.train_utils -   [RetrievalWIT]: iter 10160 Ep: 0.33 loss 0.013 score 0.230 lr 4.65582e-06 
12/06/2021 12:00:12 - INFO - volta.train_utils -   [RetrievalWIT]: iter 10240 Ep: 0.33 loss 0.018 score 0.229 lr 4.64871e-06 
12/06/2021 12:01:01 - INFO - volta.train_utils -   [RetrievalWIT]: iter 10320 Ep: 0.33 loss 0.012 score 0.226 lr 4.6416e-06 
12/06/2021 12:01:50 - INFO - volta.train_utils -   [RetrievalWIT]: iter 10400 Ep: 0.33 loss 0.012 score 0.229 lr 4.63449e-06 
12/06/2021 12:02:39 - INFO - volta.train_utils -   [RetrievalWIT]: iter 10480 Ep: 0.34 loss 0.013 score 0.228 lr 4.62738e-06 
12/06/2021 12:03:28 - INFO - volta.train_utils -   [RetrievalWIT]: iter 10560 Ep: 0.34 loss 0.013 score 0.230 lr 4.62027e-06 
12/06/2021 12:04:17 - INFO - volta.train_utils -   [RetrievalWIT]: iter 10640 Ep: 0.34 loss 0.015 score 0.228 lr 4.61316e-06 
12/06/2021 12:05:06 - INFO - volta.train_utils -   [RetrievalWIT]: iter 10720 Ep: 0.34 loss 0.012 score 0.230 lr 4.60604e-06 
12/06/2021 12:05:55 - INFO - volta.train_utils -   [RetrievalWIT]: iter 10800 Ep: 0.35 loss 0.013 score 0.225 lr 4.59893e-06 
12/06/2021 12:06:45 - INFO - volta.train_utils -   [RetrievalWIT]: iter 10880 Ep: 0.35 loss 0.011 score 0.227 lr 4.59182e-06 
12/06/2021 12:07:34 - INFO - volta.train_utils -   [RetrievalWIT]: iter 10960 Ep: 0.35 loss 0.014 score 0.229 lr 4.58471e-06 
12/06/2021 12:08:23 - INFO - volta.train_utils -   [RetrievalWIT]: iter 11040 Ep: 0.35 loss 0.016 score 0.227 lr 4.5776e-06 
12/06/2021 12:09:12 - INFO - volta.train_utils -   [RetrievalWIT]: iter 11120 Ep: 0.36 loss 0.014 score 0.230 lr 4.57049e-06 
12/06/2021 12:10:01 - INFO - volta.train_utils -   [RetrievalWIT]: iter 11200 Ep: 0.36 loss 0.012 score 0.229 lr 4.56338e-06 
12/06/2021 12:10:50 - INFO - volta.train_utils -   [RetrievalWIT]: iter 11280 Ep: 0.36 loss 0.010 score 0.229 lr 4.55627e-06 
12/06/2021 12:11:39 - INFO - volta.train_utils -   [RetrievalWIT]: iter 11360 Ep: 0.36 loss 0.013 score 0.231 lr 4.54916e-06 
12/06/2021 12:12:28 - INFO - volta.train_utils -   [RetrievalWIT]: iter 11440 Ep: 0.37 loss 0.012 score 0.229 lr 4.54204e-06 
12/06/2021 12:13:17 - INFO - volta.train_utils -   [RetrievalWIT]: iter 11520 Ep: 0.37 loss 0.017 score 0.228 lr 4.53493e-06 
12/06/2021 12:14:06 - INFO - volta.train_utils -   [RetrievalWIT]: iter 11600 Ep: 0.37 loss 0.012 score 0.226 lr 4.52782e-06 
12/06/2021 12:14:55 - INFO - volta.train_utils -   [RetrievalWIT]: iter 11680 Ep: 0.37 loss 0.012 score 0.233 lr 4.52071e-06 
12/06/2021 12:15:45 - INFO - volta.train_utils -   [RetrievalWIT]: iter 11760 Ep: 0.38 loss 0.015 score 0.228 lr 4.5136e-06 
12/06/2021 12:16:34 - INFO - volta.train_utils -   [RetrievalWIT]: iter 11840 Ep: 0.38 loss 0.017 score 0.225 lr 4.50649e-06 
12/06/2021 12:17:23 - INFO - volta.train_utils -   [RetrievalWIT]: iter 11920 Ep: 0.38 loss 0.014 score 0.231 lr 4.49938e-06 
12/06/2021 12:19:09 - INFO - volta.train_utils -   Eval task TASK20 on iteration 11988 
12/06/2021 12:19:09 - INFO - volta.train_utils -   Validation [RetrievalWIT]: loss 0.203 score 92.258 
12/06/2021 12:19:09 - INFO - __main__ -   ** ** * Saving model * ** ** 
12/06/2021 12:20:37 - INFO - volta.train_utils -   Eval task TASK20 on iteration 11988 
12/06/2021 12:20:37 - INFO - volta.train_utils -   Validation [RetrievalWIT]: loss 0.212 score 91.933 
12/06/2021 12:21:41 - INFO - volta.train_utils -   Eval task TASK20 on iteration 11988 
12/06/2021 12:21:41 - INFO - volta.train_utils -   Validation [RetrievalWIT]: loss 0.219 score 92.150 
12/06/2021 12:22:46 - INFO - volta.train_utils -   Eval task TASK20 on iteration 11992 
12/06/2021 12:22:46 - INFO - volta.train_utils -   Validation [RetrievalWIT]: loss 0.215 score 92.063 
12/06/2021 12:22:52 - INFO - volta.train_utils -   [RetrievalWIT]: iter 12000 Ep: 0.38 loss 0.010 score 0.231 lr 4.49227e-06 
12/06/2021 12:23:41 - INFO - volta.train_utils -   [RetrievalWIT]: iter 12080 Ep: 0.39 loss 0.017 score 0.229 lr 4.48516e-06 
12/06/2021 12:24:30 - INFO - volta.train_utils -   [RetrievalWIT]: iter 12160 Ep: 0.39 loss 0.016 score 0.225 lr 4.47804e-06 
12/06/2021 12:25:20 - INFO - volta.train_utils -   [RetrievalWIT]: iter 12240 Ep: 0.39 loss 0.015 score 0.229 lr 4.47093e-06 
12/06/2021 12:26:09 - INFO - volta.train_utils -   [RetrievalWIT]: iter 12320 Ep: 0.39 loss 0.012 score 0.229 lr 4.46382e-06 
12/06/2021 12:26:58 - INFO - volta.train_utils -   [RetrievalWIT]: iter 12400 Ep: 0.40 loss 0.013 score 0.228 lr 4.45671e-06 
12/06/2021 12:27:47 - INFO - volta.train_utils -   [RetrievalWIT]: iter 12480 Ep: 0.40 loss 0.016 score 0.227 lr 4.4496e-06 
12/06/2021 12:28:37 - INFO - volta.train_utils -   [RetrievalWIT]: iter 12560 Ep: 0.40 loss 0.016 score 0.224 lr 4.44249e-06 
12/06/2021 12:29:26 - INFO - volta.train_utils -   [RetrievalWIT]: iter 12640 Ep: 0.40 loss 0.017 score 0.229 lr 4.43538e-06 
12/06/2021 12:30:15 - INFO - volta.train_utils -   [RetrievalWIT]: iter 12720 Ep: 0.41 loss 0.015 score 0.226 lr 4.42827e-06 
12/06/2021 12:31:04 - INFO - volta.train_utils -   [RetrievalWIT]: iter 12800 Ep: 0.41 loss 0.016 score 0.229 lr 4.42116e-06 
12/06/2021 12:31:53 - INFO - volta.train_utils -   [RetrievalWIT]: iter 12880 Ep: 0.41 loss 0.013 score 0.230 lr 4.41404e-06 
12/06/2021 12:32:43 - INFO - volta.train_utils -   [RetrievalWIT]: iter 12960 Ep: 0.41 loss 0.015 score 0.228 lr 4.40693e-06 
12/06/2021 12:33:32 - INFO - volta.train_utils -   [RetrievalWIT]: iter 13040 Ep: 0.42 loss 0.013 score 0.231 lr 4.39982e-06 
12/06/2021 12:34:21 - INFO - volta.train_utils -   [RetrievalWIT]: iter 13120 Ep: 0.42 loss 0.013 score 0.227 lr 4.39271e-06 
12/06/2021 12:35:10 - INFO - volta.train_utils -   [RetrievalWIT]: iter 13200 Ep: 0.42 loss 0.011 score 0.229 lr 4.3856e-06 
12/06/2021 12:35:59 - INFO - volta.train_utils -   [RetrievalWIT]: iter 13280 Ep: 0.42 loss 0.016 score 0.230 lr 4.37849e-06 
12/06/2021 12:36:48 - INFO - volta.train_utils -   [RetrievalWIT]: iter 13360 Ep: 0.43 loss 0.013 score 0.232 lr 4.37138e-06 
12/06/2021 12:37:37 - INFO - volta.train_utils -   [RetrievalWIT]: iter 13440 Ep: 0.43 loss 0.015 score 0.229 lr 4.36427e-06 
12/06/2021 12:38:26 - INFO - volta.train_utils -   [RetrievalWIT]: iter 13520 Ep: 0.43 loss 0.012 score 0.228 lr 4.35716e-06 
12/06/2021 12:39:15 - INFO - volta.train_utils -   [RetrievalWIT]: iter 13600 Ep: 0.44 loss 0.011 score 0.229 lr 4.35004e-06 
12/06/2021 12:40:04 - INFO - volta.train_utils -   [RetrievalWIT]: iter 13680 Ep: 0.44 loss 0.016 score 0.230 lr 4.34293e-06 
12/06/2021 12:40:53 - INFO - volta.train_utils -   [RetrievalWIT]: iter 13760 Ep: 0.44 loss 0.011 score 0.231 lr 4.33582e-06 
12/06/2021 12:41:42 - INFO - volta.train_utils -   [RetrievalWIT]: iter 13840 Ep: 0.44 loss 0.014 score 0.231 lr 4.32871e-06 
12/06/2021 12:42:32 - INFO - volta.train_utils -   [RetrievalWIT]: iter 13920 Ep: 0.45 loss 0.012 score 0.231 lr 4.3216e-06 
12/06/2021 12:43:21 - INFO - volta.train_utils -   [RetrievalWIT]: iter 14000 Ep: 0.45 loss 0.012 score 0.229 lr 4.31449e-06 
12/06/2021 12:44:10 - INFO - volta.train_utils -   [RetrievalWIT]: iter 14080 Ep: 0.45 loss 0.011 score 0.231 lr 4.30738e-06 
12/06/2021 12:44:59 - INFO - volta.train_utils -   [RetrievalWIT]: iter 14160 Ep: 0.45 loss 0.014 score 0.227 lr 4.30027e-06 
12/06/2021 12:45:48 - INFO - volta.train_utils -   [RetrievalWIT]: iter 14240 Ep: 0.46 loss 0.014 score 0.230 lr 4.29316e-06 
12/06/2021 12:46:37 - INFO - volta.train_utils -   [RetrievalWIT]: iter 14320 Ep: 0.46 loss 0.019 score 0.226 lr 4.28604e-06 
12/06/2021 12:47:26 - INFO - volta.train_utils -   [RetrievalWIT]: iter 14400 Ep: 0.46 loss 0.013 score 0.230 lr 4.27893e-06 
12/06/2021 12:48:15 - INFO - volta.train_utils -   [RetrievalWIT]: iter 14480 Ep: 0.46 loss 0.017 score 0.228 lr 4.27182e-06 
12/06/2021 12:49:04 - INFO - volta.train_utils -   [RetrievalWIT]: iter 14560 Ep: 0.47 loss 0.014 score 0.233 lr 4.26471e-06 
12/06/2021 12:49:54 - INFO - volta.train_utils -   [RetrievalWIT]: iter 14640 Ep: 0.47 loss 0.019 score 0.228 lr 4.2576e-06 
12/06/2021 12:50:43 - INFO - volta.train_utils -   [RetrievalWIT]: iter 14720 Ep: 0.47 loss 0.013 score 0.231 lr 4.25049e-06 
12/06/2021 12:51:32 - INFO - volta.train_utils -   [RetrievalWIT]: iter 14800 Ep: 0.47 loss 0.015 score 0.231 lr 4.24338e-06 
12/06/2021 12:52:21 - INFO - volta.train_utils -   [RetrievalWIT]: iter 14880 Ep: 0.48 loss 0.012 score 0.230 lr 4.23627e-06 
12/06/2021 12:53:10 - INFO - volta.train_utils -   [RetrievalWIT]: iter 14960 Ep: 0.48 loss 0.010 score 0.231 lr 4.22916e-06 
12/06/2021 12:53:59 - INFO - volta.train_utils -   [RetrievalWIT]: iter 15040 Ep: 0.48 loss 0.011 score 0.229 lr 4.22204e-06 
12/06/2021 12:54:48 - INFO - volta.train_utils -   [RetrievalWIT]: iter 15120 Ep: 0.48 loss 0.014 score 0.228 lr 4.21493e-06 
12/06/2021 12:55:37 - INFO - volta.train_utils -   [RetrievalWIT]: iter 15200 Ep: 0.49 loss 0.014 score 0.229 lr 4.20782e-06 
12/06/2021 12:56:26 - INFO - volta.train_utils -   [RetrievalWIT]: iter 15280 Ep: 0.49 loss 0.016 score 0.229 lr 4.20071e-06 
12/06/2021 12:57:15 - INFO - volta.train_utils -   [RetrievalWIT]: iter 15360 Ep: 0.49 loss 0.015 score 0.230 lr 4.1936e-06 
12/06/2021 12:58:05 - INFO - volta.train_utils -   [RetrievalWIT]: iter 15440 Ep: 0.49 loss 0.010 score 0.230 lr 4.18649e-06 
12/06/2021 12:58:54 - INFO - volta.train_utils -   [RetrievalWIT]: iter 15520 Ep: 0.50 loss 0.011 score 0.229 lr 4.17938e-06 
12/06/2021 12:59:43 - INFO - volta.train_utils -   [RetrievalWIT]: iter 15600 Ep: 0.50 loss 0.014 score 0.229 lr 4.17227e-06 
12/06/2021 13:00:32 - INFO - volta.train_utils -   [RetrievalWIT]: iter 15680 Ep: 0.50 loss 0.010 score 0.232 lr 4.16516e-06 
12/06/2021 13:01:21 - INFO - volta.train_utils -   [RetrievalWIT]: iter 15760 Ep: 0.50 loss 0.014 score 0.229 lr 4.15804e-06 
12/06/2021 13:02:10 - INFO - volta.train_utils -   [RetrievalWIT]: iter 15840 Ep: 0.51 loss 0.014 score 0.233 lr 4.15093e-06 
12/06/2021 13:02:59 - INFO - volta.train_utils -   [RetrievalWIT]: iter 15920 Ep: 0.51 loss 0.014 score 0.232 lr 4.14382e-06 
12/06/2021 13:04:43 - INFO - volta.train_utils -   Eval task TASK20 on iteration 15984 
12/06/2021 13:04:43 - INFO - volta.train_utils -   Validation [RetrievalWIT]: loss 0.215 score 91.782 
12/06/2021 13:05:48 - INFO - volta.train_utils -   Eval task TASK20 on iteration 15984 
12/06/2021 13:05:48 - INFO - volta.train_utils -   Validation [RetrievalWIT]: loss 0.227 score 91.522 
12/06/2021 13:06:53 - INFO - volta.train_utils -   Eval task TASK20 on iteration 15984 
12/06/2021 13:06:53 - INFO - volta.train_utils -   Validation [RetrievalWIT]: loss 0.210 score 92.258 
12/06/2021 13:07:58 - INFO - volta.train_utils -   Eval task TASK20 on iteration 15988 
12/06/2021 13:07:58 - INFO - volta.train_utils -   Validation [RetrievalWIT]: loss 0.205 score 91.998 
12/06/2021 13:08:06 - INFO - volta.train_utils -   [RetrievalWIT]: iter 16000 Ep: 0.51 loss 0.011 score 0.231 lr 4.13671e-06 
12/06/2021 13:08:55 - INFO - volta.train_utils -   [RetrievalWIT]: iter 16080 Ep: 0.51 loss 0.015 score 0.231 lr 4.1296e-06 
12/06/2021 13:09:45 - INFO - volta.train_utils -   [RetrievalWIT]: iter 16160 Ep: 0.52 loss 0.018 score 0.228 lr 4.12249e-06 
12/06/2021 13:10:34 - INFO - volta.train_utils -   [RetrievalWIT]: iter 16240 Ep: 0.52 loss 0.014 score 0.229 lr 4.11538e-06 
12/06/2021 13:11:23 - INFO - volta.train_utils -   [RetrievalWIT]: iter 16320 Ep: 0.52 loss 0.015 score 0.230 lr 4.10827e-06 
12/06/2021 13:12:13 - INFO - volta.train_utils -   [RetrievalWIT]: iter 16400 Ep: 0.52 loss 0.012 score 0.232 lr 4.10116e-06 
12/06/2021 13:13:02 - INFO - volta.train_utils -   [RetrievalWIT]: iter 16480 Ep: 0.53 loss 0.016 score 0.229 lr 4.09404e-06 
12/06/2021 13:13:51 - INFO - volta.train_utils -   [RetrievalWIT]: iter 16560 Ep: 0.53 loss 0.011 score 0.231 lr 4.08693e-06 
12/06/2021 13:14:40 - INFO - volta.train_utils -   [RetrievalWIT]: iter 16640 Ep: 0.53 loss 0.010 score 0.230 lr 4.07982e-06 
12/06/2021 13:15:29 - INFO - volta.train_utils -   [RetrievalWIT]: iter 16720 Ep: 0.54 loss 0.015 score 0.229 lr 4.07271e-06 
12/06/2021 13:16:19 - INFO - volta.train_utils -   [RetrievalWIT]: iter 16800 Ep: 0.54 loss 0.011 score 0.231 lr 4.0656e-06 
12/06/2021 13:17:08 - INFO - volta.train_utils -   [RetrievalWIT]: iter 16880 Ep: 0.54 loss 0.015 score 0.229 lr 4.05849e-06 
12/06/2021 13:17:57 - INFO - volta.train_utils -   [RetrievalWIT]: iter 16960 Ep: 0.54 loss 0.012 score 0.230 lr 4.05138e-06 
12/06/2021 13:18:46 - INFO - volta.train_utils -   [RetrievalWIT]: iter 17040 Ep: 0.55 loss 0.012 score 0.232 lr 4.04427e-06 
12/06/2021 13:19:35 - INFO - volta.train_utils -   [RetrievalWIT]: iter 17120 Ep: 0.55 loss 0.012 score 0.232 lr 4.03716e-06 
12/06/2021 13:20:24 - INFO - volta.train_utils -   [RetrievalWIT]: iter 17200 Ep: 0.55 loss 0.012 score 0.232 lr 4.03004e-06 
12/06/2021 13:21:13 - INFO - volta.train_utils -   [RetrievalWIT]: iter 17280 Ep: 0.55 loss 0.011 score 0.233 lr 4.02293e-06 
12/06/2021 13:22:03 - INFO - volta.train_utils -   [RetrievalWIT]: iter 17360 Ep: 0.56 loss 0.012 score 0.229 lr 4.01582e-06 
12/06/2021 13:22:52 - INFO - volta.train_utils -   [RetrievalWIT]: iter 17440 Ep: 0.56 loss 0.014 score 0.231 lr 4.00871e-06 
12/06/2021 13:23:41 - INFO - volta.train_utils -   [RetrievalWIT]: iter 17520 Ep: 0.56 loss 0.010 score 0.229 lr 4.0016e-06 
12/06/2021 13:24:30 - INFO - volta.train_utils -   [RetrievalWIT]: iter 17600 Ep: 0.56 loss 0.013 score 0.231 lr 3.99449e-06 
12/06/2021 13:25:19 - INFO - volta.train_utils -   [RetrievalWIT]: iter 17680 Ep: 0.57 loss 0.012 score 0.230 lr 3.98738e-06 
12/06/2021 13:26:09 - INFO - volta.train_utils -   [RetrievalWIT]: iter 17760 Ep: 0.57 loss 0.010 score 0.232 lr 3.98027e-06 
12/06/2021 13:26:58 - INFO - volta.train_utils -   [RetrievalWIT]: iter 17840 Ep: 0.57 loss 0.012 score 0.231 lr 3.97316e-06 
12/06/2021 13:27:47 - INFO - volta.train_utils -   [RetrievalWIT]: iter 17920 Ep: 0.57 loss 0.012 score 0.228 lr 3.96604e-06 
12/06/2021 13:28:36 - INFO - volta.train_utils -   [RetrievalWIT]: iter 18000 Ep: 0.58 loss 0.011 score 0.230 lr 3.95893e-06 
12/06/2021 13:29:25 - INFO - volta.train_utils -   [RetrievalWIT]: iter 18080 Ep: 0.58 loss 0.016 score 0.229 lr 3.95182e-06 
12/06/2021 13:30:14 - INFO - volta.train_utils -   [RetrievalWIT]: iter 18160 Ep: 0.58 loss 0.011 score 0.229 lr 3.94471e-06 
12/06/2021 13:31:04 - INFO - volta.train_utils -   [RetrievalWIT]: iter 18240 Ep: 0.58 loss 0.012 score 0.232 lr 3.9376e-06 
12/06/2021 13:31:53 - INFO - volta.train_utils -   [RetrievalWIT]: iter 18320 Ep: 0.59 loss 0.009 score 0.232 lr 3.93049e-06 
12/06/2021 13:32:42 - INFO - volta.train_utils -   [RetrievalWIT]: iter 18400 Ep: 0.59 loss 0.013 score 0.230 lr 3.92338e-06 
12/06/2021 13:33:31 - INFO - volta.train_utils -   [RetrievalWIT]: iter 18480 Ep: 0.59 loss 0.013 score 0.231 lr 3.91627e-06 
12/06/2021 13:34:20 - INFO - volta.train_utils -   [RetrievalWIT]: iter 18560 Ep: 0.59 loss 0.011 score 0.229 lr 3.90916e-06 
12/06/2021 13:35:09 - INFO - volta.train_utils -   [RetrievalWIT]: iter 18640 Ep: 0.60 loss 0.012 score 0.231 lr 3.90204e-06 
12/06/2021 13:35:59 - INFO - volta.train_utils -   [RetrievalWIT]: iter 18720 Ep: 0.60 loss 0.010 score 0.230 lr 3.89493e-06 
12/06/2021 13:36:48 - INFO - volta.train_utils -   [RetrievalWIT]: iter 18800 Ep: 0.60 loss 0.013 score 0.229 lr 3.88782e-06 
12/06/2021 13:37:37 - INFO - volta.train_utils -   [RetrievalWIT]: iter 18880 Ep: 0.60 loss 0.013 score 0.232 lr 3.88071e-06 
12/06/2021 13:38:26 - INFO - volta.train_utils -   [RetrievalWIT]: iter 18960 Ep: 0.61 loss 0.015 score 0.229 lr 3.8736e-06 
12/06/2021 13:39:15 - INFO - volta.train_utils -   [RetrievalWIT]: iter 19040 Ep: 0.61 loss 0.014 score 0.230 lr 3.86649e-06 
12/06/2021 13:40:04 - INFO - volta.train_utils -   [RetrievalWIT]: iter 19120 Ep: 0.61 loss 0.014 score 0.234 lr 3.85938e-06 
12/06/2021 13:40:54 - INFO - volta.train_utils -   [RetrievalWIT]: iter 19200 Ep: 0.61 loss 0.013 score 0.232 lr 3.85227e-06 
12/06/2021 13:41:43 - INFO - volta.train_utils -   [RetrievalWIT]: iter 19280 Ep: 0.62 loss 0.013 score 0.229 lr 3.84516e-06 
12/06/2021 13:42:32 - INFO - volta.train_utils -   [RetrievalWIT]: iter 19360 Ep: 0.62 loss 0.012 score 0.229 lr 3.83804e-06 
12/06/2021 13:43:21 - INFO - volta.train_utils -   [RetrievalWIT]: iter 19440 Ep: 0.62 loss 0.011 score 0.231 lr 3.83093e-06 
12/06/2021 13:44:10 - INFO - volta.train_utils -   [RetrievalWIT]: iter 19520 Ep: 0.62 loss 0.013 score 0.231 lr 3.82382e-06 
12/06/2021 13:44:59 - INFO - volta.train_utils -   [RetrievalWIT]: iter 19600 Ep: 0.63 loss 0.011 score 0.232 lr 3.81671e-06 
12/06/2021 13:45:48 - INFO - volta.train_utils -   [RetrievalWIT]: iter 19680 Ep: 0.63 loss 0.012 score 0.230 lr 3.8096e-06 
12/06/2021 13:46:37 - INFO - volta.train_utils -   [RetrievalWIT]: iter 19760 Ep: 0.63 loss 0.012 score 0.231 lr 3.80249e-06 
12/06/2021 13:47:26 - INFO - volta.train_utils -   [RetrievalWIT]: iter 19840 Ep: 0.63 loss 0.012 score 0.231 lr 3.79538e-06 
12/06/2021 13:48:15 - INFO - volta.train_utils -   [RetrievalWIT]: iter 19920 Ep: 0.64 loss 0.014 score 0.231 lr 3.78827e-06 
12/06/2021 13:49:57 - INFO - volta.train_utils -   Eval task TASK20 on iteration 19980 
12/06/2021 13:49:57 - INFO - volta.train_utils -   Validation [RetrievalWIT]: loss 0.184 score 92.993 
12/06/2021 13:49:57 - INFO - __main__ -   ** ** * Saving model * ** ** 
12/06/2021 13:51:24 - INFO - volta.train_utils -   Eval task TASK20 on iteration 19980 
12/06/2021 13:51:24 - INFO - volta.train_utils -   Validation [RetrievalWIT]: loss 0.186 score 92.755 
12/06/2021 13:52:29 - INFO - volta.train_utils -   Eval task TASK20 on iteration 19980 
12/06/2021 13:52:29 - INFO - volta.train_utils -   Validation [RetrievalWIT]: loss 0.181 score 93.382 
12/06/2021 13:52:29 - INFO - __main__ -   ** ** * Saving model * ** ** 
12/06/2021 13:53:57 - INFO - volta.train_utils -   Eval task TASK20 on iteration 19984 
12/06/2021 13:53:57 - INFO - volta.train_utils -   Validation [RetrievalWIT]: loss 0.191 score 92.647 
12/06/2021 13:54:07 - INFO - volta.train_utils -   [RetrievalWIT]: iter 20000 Ep: 0.64 loss 0.011 score 0.232 lr 3.78116e-06 
12/06/2021 13:54:57 - INFO - volta.train_utils -   [RetrievalWIT]: iter 20080 Ep: 0.64 loss 0.015 score 0.230 lr 3.77404e-06 
12/06/2021 13:55:46 - INFO - volta.train_utils -   [RetrievalWIT]: iter 20160 Ep: 0.65 loss 0.011 score 0.231 lr 3.76693e-06 
12/06/2021 13:56:36 - INFO - volta.train_utils -   [RetrievalWIT]: iter 20240 Ep: 0.65 loss 0.012 score 0.233 lr 3.75982e-06 
12/06/2021 13:57:25 - INFO - volta.train_utils -   [RetrievalWIT]: iter 20320 Ep: 0.65 loss 0.015 score 0.231 lr 3.75271e-06 
12/06/2021 13:58:15 - INFO - volta.train_utils -   [RetrievalWIT]: iter 20400 Ep: 0.65 loss 0.016 score 0.231 lr 3.7456e-06 
12/06/2021 13:59:04 - INFO - volta.train_utils -   [RetrievalWIT]: iter 20480 Ep: 0.66 loss 0.011 score 0.232 lr 3.73849e-06 
12/06/2021 13:59:53 - INFO - volta.train_utils -   [RetrievalWIT]: iter 20560 Ep: 0.66 loss 0.013 score 0.229 lr 3.73138e-06 
12/06/2021 14:00:42 - INFO - volta.train_utils -   [RetrievalWIT]: iter 20640 Ep: 0.66 loss 0.012 score 0.229 lr 3.72427e-06 
12/06/2021 14:01:31 - INFO - volta.train_utils -   [RetrievalWIT]: iter 20720 Ep: 0.66 loss 0.012 score 0.230 lr 3.71716e-06 
12/06/2021 14:02:21 - INFO - volta.train_utils -   [RetrievalWIT]: iter 20800 Ep: 0.67 loss 0.011 score 0.231 lr 3.71004e-06 
12/06/2021 14:03:10 - INFO - volta.train_utils -   [RetrievalWIT]: iter 20880 Ep: 0.67 loss 0.009 score 0.233 lr 3.70293e-06 
12/06/2021 14:03:59 - INFO - volta.train_utils -   [RetrievalWIT]: iter 20960 Ep: 0.67 loss 0.011 score 0.233 lr 3.69582e-06 
12/06/2021 14:04:48 - INFO - volta.train_utils -   [RetrievalWIT]: iter 21040 Ep: 0.67 loss 0.010 score 0.231 lr 3.68871e-06 
12/06/2021 14:05:37 - INFO - volta.train_utils -   [RetrievalWIT]: iter 21120 Ep: 0.68 loss 0.012 score 0.231 lr 3.6816e-06 
12/06/2021 14:06:26 - INFO - volta.train_utils -   [RetrievalWIT]: iter 21200 Ep: 0.68 loss 0.009 score 0.232 lr 3.67449e-06 
12/06/2021 14:07:16 - INFO - volta.train_utils -   [RetrievalWIT]: iter 21280 Ep: 0.68 loss 0.012 score 0.232 lr 3.66738e-06 
12/06/2021 14:08:05 - INFO - volta.train_utils -   [RetrievalWIT]: iter 21360 Ep: 0.68 loss 0.014 score 0.230 lr 3.66027e-06 
12/06/2021 14:08:54 - INFO - volta.train_utils -   [RetrievalWIT]: iter 21440 Ep: 0.69 loss 0.013 score 0.229 lr 3.65316e-06 
12/06/2021 14:09:43 - INFO - volta.train_utils -   [RetrievalWIT]: iter 21520 Ep: 0.69 loss 0.011 score 0.236 lr 3.64604e-06 
12/06/2021 14:10:32 - INFO - volta.train_utils -   [RetrievalWIT]: iter 21600 Ep: 0.69 loss 0.016 score 0.229 lr 3.63893e-06 
12/06/2021 14:11:22 - INFO - volta.train_utils -   [RetrievalWIT]: iter 21680 Ep: 0.69 loss 0.011 score 0.232 lr 3.63182e-06 
12/06/2021 14:12:11 - INFO - volta.train_utils -   [RetrievalWIT]: iter 21760 Ep: 0.70 loss 0.010 score 0.231 lr 3.62471e-06 
12/06/2021 14:13:00 - INFO - volta.train_utils -   [RetrievalWIT]: iter 21840 Ep: 0.70 loss 0.010 score 0.233 lr 3.6176e-06 
12/06/2021 14:13:49 - INFO - volta.train_utils -   [RetrievalWIT]: iter 21920 Ep: 0.70 loss 0.012 score 0.233 lr 3.61049e-06 
12/06/2021 14:14:38 - INFO - volta.train_utils -   [RetrievalWIT]: iter 22000 Ep: 0.70 loss 0.012 score 0.230 lr 3.60338e-06 
12/06/2021 14:15:27 - INFO - volta.train_utils -   [RetrievalWIT]: iter 22080 Ep: 0.71 loss 0.011 score 0.231 lr 3.59627e-06 
12/06/2021 14:16:16 - INFO - volta.train_utils -   [RetrievalWIT]: iter 22160 Ep: 0.71 loss 0.010 score 0.233 lr 3.58916e-06 
12/06/2021 14:17:05 - INFO - volta.train_utils -   [RetrievalWIT]: iter 22240 Ep: 0.71 loss 0.011 score 0.233 lr 3.58204e-06 
12/06/2021 14:17:54 - INFO - volta.train_utils -   [RetrievalWIT]: iter 22320 Ep: 0.71 loss 0.012 score 0.233 lr 3.57493e-06 
12/06/2021 14:18:44 - INFO - volta.train_utils -   [RetrievalWIT]: iter 22400 Ep: 0.72 loss 0.011 score 0.231 lr 3.56782e-06 
12/06/2021 14:19:33 - INFO - volta.train_utils -   [RetrievalWIT]: iter 22480 Ep: 0.72 loss 0.012 score 0.228 lr 3.56071e-06 
12/06/2021 14:20:22 - INFO - volta.train_utils -   [RetrievalWIT]: iter 22560 Ep: 0.72 loss 0.010 score 0.232 lr 3.5536e-06 
12/06/2021 14:21:11 - INFO - volta.train_utils -   [RetrievalWIT]: iter 22640 Ep: 0.72 loss 0.012 score 0.231 lr 3.54649e-06 
12/06/2021 14:22:00 - INFO - volta.train_utils -   [RetrievalWIT]: iter 22720 Ep: 0.73 loss 0.013 score 0.235 lr 3.53938e-06 
12/06/2021 14:22:49 - INFO - volta.train_utils -   [RetrievalWIT]: iter 22800 Ep: 0.73 loss 0.009 score 0.234 lr 3.53227e-06 
12/06/2021 14:23:38 - INFO - volta.train_utils -   [RetrievalWIT]: iter 22880 Ep: 0.73 loss 0.010 score 0.234 lr 3.52516e-06 
12/06/2021 14:24:27 - INFO - volta.train_utils -   [RetrievalWIT]: iter 22960 Ep: 0.73 loss 0.014 score 0.229 lr 3.51804e-06 
12/06/2021 14:25:17 - INFO - volta.train_utils -   [RetrievalWIT]: iter 23040 Ep: 0.74 loss 0.012 score 0.230 lr 3.51093e-06 
12/06/2021 14:26:06 - INFO - volta.train_utils -   [RetrievalWIT]: iter 23120 Ep: 0.74 loss 0.011 score 0.233 lr 3.50382e-06 
12/06/2021 14:26:55 - INFO - volta.train_utils -   [RetrievalWIT]: iter 23200 Ep: 0.74 loss 0.015 score 0.229 lr 3.49671e-06 
12/06/2021 14:27:44 - INFO - volta.train_utils -   [RetrievalWIT]: iter 23280 Ep: 0.74 loss 0.015 score 0.228 lr 3.4896e-06 
12/06/2021 14:28:33 - INFO - volta.train_utils -   [RetrievalWIT]: iter 23360 Ep: 0.75 loss 0.012 score 0.234 lr 3.48249e-06 
12/06/2021 14:29:22 - INFO - volta.train_utils -   [RetrievalWIT]: iter 23440 Ep: 0.75 loss 0.014 score 0.231 lr 3.47538e-06 
12/06/2021 14:30:11 - INFO - volta.train_utils -   [RetrievalWIT]: iter 23520 Ep: 0.75 loss 0.009 score 0.233 lr 3.46827e-06 
12/06/2021 14:31:00 - INFO - volta.train_utils -   [RetrievalWIT]: iter 23600 Ep: 0.76 loss 0.010 score 0.232 lr 3.46116e-06 
12/06/2021 14:31:49 - INFO - volta.train_utils -   [RetrievalWIT]: iter 23680 Ep: 0.76 loss 0.011 score 0.230 lr 3.45404e-06 
12/06/2021 14:32:39 - INFO - volta.train_utils -   [RetrievalWIT]: iter 23760 Ep: 0.76 loss 0.011 score 0.233 lr 3.44693e-06 
12/06/2021 14:33:28 - INFO - volta.train_utils -   [RetrievalWIT]: iter 23840 Ep: 0.76 loss 0.007 score 0.234 lr 3.43982e-06 
12/06/2021 14:34:17 - INFO - volta.train_utils -   [RetrievalWIT]: iter 23920 Ep: 0.77 loss 0.011 score 0.231 lr 3.43271e-06 
12/06/2021 14:35:56 - INFO - volta.train_utils -   Eval task TASK20 on iteration 23976 
12/06/2021 14:35:56 - INFO - volta.train_utils -   Validation [RetrievalWIT]: loss 0.189 score 93.209 
12/06/2021 14:37:01 - INFO - volta.train_utils -   Eval task TASK20 on iteration 23976 
12/06/2021 14:37:01 - INFO - volta.train_utils -   Validation [RetrievalWIT]: loss 0.184 score 93.166 
12/06/2021 14:38:06 - INFO - volta.train_utils -   Eval task TASK20 on iteration 23976 
12/06/2021 14:38:06 - INFO - volta.train_utils -   Validation [RetrievalWIT]: loss 0.198 score 92.950 
12/06/2021 14:39:10 - INFO - volta.train_utils -   Eval task TASK20 on iteration 23980 
12/06/2021 14:39:10 - INFO - volta.train_utils -   Validation [RetrievalWIT]: loss 0.188 score 93.209 
12/06/2021 14:39:23 - INFO - volta.train_utils -   [RetrievalWIT]: iter 24000 Ep: 0.77 loss 0.010 score 0.236 lr 3.4256e-06 
12/06/2021 14:40:13 - INFO - volta.train_utils -   [RetrievalWIT]: iter 24080 Ep: 0.77 loss 0.015 score 0.232 lr 3.41849e-06 
12/06/2021 14:41:02 - INFO - volta.train_utils -   [RetrievalWIT]: iter 24160 Ep: 0.77 loss 0.010 score 0.230 lr 3.41138e-06 
12/06/2021 14:41:51 - INFO - volta.train_utils -   [RetrievalWIT]: iter 24240 Ep: 0.78 loss 0.013 score 0.235 lr 3.40427e-06 
12/06/2021 14:42:41 - INFO - volta.train_utils -   [RetrievalWIT]: iter 24320 Ep: 0.78 loss 0.015 score 0.232 lr 3.39716e-06 
12/06/2021 14:43:30 - INFO - volta.train_utils -   [RetrievalWIT]: iter 24400 Ep: 0.78 loss 0.012 score 0.232 lr 3.39004e-06 
12/06/2021 14:44:19 - INFO - volta.train_utils -   [RetrievalWIT]: iter 24480 Ep: 0.78 loss 0.011 score 0.233 lr 3.38293e-06 
12/06/2021 14:45:08 - INFO - volta.train_utils -   [RetrievalWIT]: iter 24560 Ep: 0.79 loss 0.012 score 0.229 lr 3.37582e-06 
12/06/2021 14:45:58 - INFO - volta.train_utils -   [RetrievalWIT]: iter 24640 Ep: 0.79 loss 0.013 score 0.231 lr 3.36871e-06 
12/06/2021 14:46:47 - INFO - volta.train_utils -   [RetrievalWIT]: iter 24720 Ep: 0.79 loss 0.011 score 0.232 lr 3.3616e-06 
12/06/2021 14:47:36 - INFO - volta.train_utils -   [RetrievalWIT]: iter 24800 Ep: 0.79 loss 0.013 score 0.232 lr 3.35449e-06 
12/06/2021 14:48:25 - INFO - volta.train_utils -   [RetrievalWIT]: iter 24880 Ep: 0.80 loss 0.010 score 0.231 lr 3.34738e-06 
12/06/2021 14:49:14 - INFO - volta.train_utils -   [RetrievalWIT]: iter 24960 Ep: 0.80 loss 0.013 score 0.232 lr 3.34027e-06 
12/06/2021 14:50:03 - INFO - volta.train_utils -   [RetrievalWIT]: iter 25040 Ep: 0.80 loss 0.010 score 0.231 lr 3.33316e-06 
12/06/2021 14:50:52 - INFO - volta.train_utils -   [RetrievalWIT]: iter 25120 Ep: 0.80 loss 0.014 score 0.231 lr 3.32604e-06 
12/06/2021 14:51:41 - INFO - volta.train_utils -   [RetrievalWIT]: iter 25200 Ep: 0.81 loss 0.012 score 0.232 lr 3.31893e-06 
12/06/2021 14:52:30 - INFO - volta.train_utils -   [RetrievalWIT]: iter 25280 Ep: 0.81 loss 0.009 score 0.233 lr 3.31182e-06 
12/06/2021 14:53:20 - INFO - volta.train_utils -   [RetrievalWIT]: iter 25360 Ep: 0.81 loss 0.010 score 0.231 lr 3.30471e-06 
12/06/2021 14:54:09 - INFO - volta.train_utils -   [RetrievalWIT]: iter 25440 Ep: 0.81 loss 0.011 score 0.235 lr 3.2976e-06 
12/06/2021 14:54:58 - INFO - volta.train_utils -   [RetrievalWIT]: iter 25520 Ep: 0.82 loss 0.011 score 0.232 lr 3.29049e-06 
12/06/2021 14:55:47 - INFO - volta.train_utils -   [RetrievalWIT]: iter 25600 Ep: 0.82 loss 0.015 score 0.230 lr 3.28338e-06 
12/06/2021 14:56:36 - INFO - volta.train_utils -   [RetrievalWIT]: iter 25680 Ep: 0.82 loss 0.011 score 0.231 lr 3.27627e-06 
12/06/2021 14:57:25 - INFO - volta.train_utils -   [RetrievalWIT]: iter 25760 Ep: 0.82 loss 0.011 score 0.232 lr 3.26916e-06 
12/06/2021 14:58:14 - INFO - volta.train_utils -   [RetrievalWIT]: iter 25840 Ep: 0.83 loss 0.013 score 0.232 lr 3.26204e-06 
12/06/2021 14:59:04 - INFO - volta.train_utils -   [RetrievalWIT]: iter 25920 Ep: 0.83 loss 0.013 score 0.232 lr 3.25493e-06 
12/06/2021 14:59:53 - INFO - volta.train_utils -   [RetrievalWIT]: iter 26000 Ep: 0.83 loss 0.010 score 0.233 lr 3.24782e-06 
12/06/2021 15:00:42 - INFO - volta.train_utils -   [RetrievalWIT]: iter 26080 Ep: 0.83 loss 0.007 score 0.235 lr 3.24071e-06 
12/06/2021 15:01:31 - INFO - volta.train_utils -   [RetrievalWIT]: iter 26160 Ep: 0.84 loss 0.012 score 0.236 lr 3.2336e-06 
12/06/2021 15:02:21 - INFO - volta.train_utils -   [RetrievalWIT]: iter 26240 Ep: 0.84 loss 0.011 score 0.234 lr 3.22649e-06 
12/06/2021 15:03:10 - INFO - volta.train_utils -   [RetrievalWIT]: iter 26320 Ep: 0.84 loss 0.011 score 0.233 lr 3.21938e-06 
12/06/2021 15:03:59 - INFO - volta.train_utils -   [RetrievalWIT]: iter 26400 Ep: 0.84 loss 0.012 score 0.233 lr 3.21227e-06 
12/06/2021 15:04:48 - INFO - volta.train_utils -   [RetrievalWIT]: iter 26480 Ep: 0.85 loss 0.010 score 0.233 lr 3.20516e-06 
12/06/2021 15:05:38 - INFO - volta.train_utils -   [RetrievalWIT]: iter 26560 Ep: 0.85 loss 0.008 score 0.233 lr 3.19804e-06 
12/06/2021 15:06:27 - INFO - volta.train_utils -   [RetrievalWIT]: iter 26640 Ep: 0.85 loss 0.015 score 0.233 lr 3.19093e-06 
12/06/2021 15:07:16 - INFO - volta.train_utils -   [RetrievalWIT]: iter 26720 Ep: 0.86 loss 0.012 score 0.235 lr 3.18382e-06 
12/06/2021 15:08:05 - INFO - volta.train_utils -   [RetrievalWIT]: iter 26800 Ep: 0.86 loss 0.009 score 0.232 lr 3.17671e-06 
12/06/2021 15:08:54 - INFO - volta.train_utils -   [RetrievalWIT]: iter 26880 Ep: 0.86 loss 0.012 score 0.230 lr 3.1696e-06 
12/06/2021 15:09:44 - INFO - volta.train_utils -   [RetrievalWIT]: iter 26960 Ep: 0.86 loss 0.013 score 0.230 lr 3.16249e-06 
12/06/2021 15:10:33 - INFO - volta.train_utils -   [RetrievalWIT]: iter 27040 Ep: 0.87 loss 0.012 score 0.233 lr 3.15538e-06 
12/06/2021 15:11:22 - INFO - volta.train_utils -   [RetrievalWIT]: iter 27120 Ep: 0.87 loss 0.011 score 0.232 lr 3.14827e-06 
12/06/2021 15:12:11 - INFO - volta.train_utils -   [RetrievalWIT]: iter 27200 Ep: 0.87 loss 0.012 score 0.232 lr 3.14116e-06 
12/06/2021 15:13:00 - INFO - volta.train_utils -   [RetrievalWIT]: iter 27280 Ep: 0.87 loss 0.011 score 0.234 lr 3.13404e-06 
12/06/2021 15:13:49 - INFO - volta.train_utils -   [RetrievalWIT]: iter 27360 Ep: 0.88 loss 0.011 score 0.233 lr 3.12693e-06 
12/06/2021 15:14:38 - INFO - volta.train_utils -   [RetrievalWIT]: iter 27440 Ep: 0.88 loss 0.009 score 0.235 lr 3.11982e-06 
12/06/2021 15:15:28 - INFO - volta.train_utils -   [RetrievalWIT]: iter 27520 Ep: 0.88 loss 0.010 score 0.231 lr 3.11271e-06 
12/06/2021 15:16:17 - INFO - volta.train_utils -   [RetrievalWIT]: iter 27600 Ep: 0.88 loss 0.013 score 0.230 lr 3.1056e-06 
12/06/2021 15:17:06 - INFO - volta.train_utils -   [RetrievalWIT]: iter 27680 Ep: 0.89 loss 0.014 score 0.230 lr 3.09849e-06 
12/06/2021 15:17:55 - INFO - volta.train_utils -   [RetrievalWIT]: iter 27760 Ep: 0.89 loss 0.013 score 0.235 lr 3.09138e-06 
12/06/2021 15:18:44 - INFO - volta.train_utils -   [RetrievalWIT]: iter 27840 Ep: 0.89 loss 0.009 score 0.236 lr 3.08427e-06 
12/06/2021 15:19:33 - INFO - volta.train_utils -   [RetrievalWIT]: iter 27920 Ep: 0.89 loss 0.015 score 0.228 lr 3.07716e-06 
12/06/2021 15:21:09 - INFO - volta.train_utils -   Eval task TASK20 on iteration 27972 
12/06/2021 15:21:09 - INFO - volta.train_utils -   Validation [RetrievalWIT]: loss 0.172 score 93.361 
12/06/2021 15:22:14 - INFO - volta.train_utils -   Eval task TASK20 on iteration 27972 
12/06/2021 15:22:14 - INFO - volta.train_utils -   Validation [RetrievalWIT]: loss 0.176 score 93.101 
12/06/2021 15:23:20 - INFO - volta.train_utils -   Eval task TASK20 on iteration 27972 
12/06/2021 15:23:20 - INFO - volta.train_utils -   Validation [RetrievalWIT]: loss 0.166 score 93.663 
12/06/2021 15:23:20 - INFO - __main__ -   ** ** * Saving model * ** ** 
12/06/2021 15:24:47 - INFO - volta.train_utils -   Eval task TASK20 on iteration 27976 
12/06/2021 15:24:47 - INFO - volta.train_utils -   Validation [RetrievalWIT]: loss 0.172 score 93.469 
12/06/2021 15:25:02 - INFO - volta.train_utils -   [RetrievalWIT]: iter 28000 Ep: 0.90 loss 0.009 score 0.235 lr 3.07004e-06 
12/06/2021 15:25:51 - INFO - volta.train_utils -   [RetrievalWIT]: iter 28080 Ep: 0.90 loss 0.007 score 0.236 lr 3.06293e-06 
12/06/2021 15:26:41 - INFO - volta.train_utils -   [RetrievalWIT]: iter 28160 Ep: 0.90 loss 0.009 score 0.232 lr 3.05582e-06 
12/06/2021 15:27:30 - INFO - volta.train_utils -   [RetrievalWIT]: iter 28240 Ep: 0.90 loss 0.006 score 0.236 lr 3.04871e-06 
12/06/2021 15:28:19 - INFO - volta.train_utils -   [RetrievalWIT]: iter 28320 Ep: 0.91 loss 0.015 score 0.231 lr 3.0416e-06 
12/06/2021 15:29:08 - INFO - volta.train_utils -   [RetrievalWIT]: iter 28400 Ep: 0.91 loss 0.008 score 0.233 lr 3.03449e-06 
12/06/2021 15:29:57 - INFO - volta.train_utils -   [RetrievalWIT]: iter 28480 Ep: 0.91 loss 0.012 score 0.233 lr 3.02738e-06 
12/06/2021 15:30:46 - INFO - volta.train_utils -   [RetrievalWIT]: iter 28560 Ep: 0.91 loss 0.010 score 0.230 lr 3.02027e-06 
12/06/2021 15:31:35 - INFO - volta.train_utils -   [RetrievalWIT]: iter 28640 Ep: 0.92 loss 0.014 score 0.232 lr 3.01316e-06 
12/06/2021 15:32:24 - INFO - volta.train_utils -   [RetrievalWIT]: iter 28720 Ep: 0.92 loss 0.010 score 0.234 lr 3.00604e-06 
12/06/2021 15:33:14 - INFO - volta.train_utils -   [RetrievalWIT]: iter 28800 Ep: 0.92 loss 0.009 score 0.234 lr 2.99893e-06 
12/06/2021 15:34:03 - INFO - volta.train_utils -   [RetrievalWIT]: iter 28880 Ep: 0.92 loss 0.012 score 0.233 lr 2.99182e-06 
12/06/2021 15:34:52 - INFO - volta.train_utils -   [RetrievalWIT]: iter 28960 Ep: 0.93 loss 0.009 score 0.234 lr 2.98471e-06 
12/06/2021 15:35:41 - INFO - volta.train_utils -   [RetrievalWIT]: iter 29040 Ep: 0.93 loss 0.013 score 0.231 lr 2.9776e-06 
12/06/2021 15:36:30 - INFO - volta.train_utils -   [RetrievalWIT]: iter 29120 Ep: 0.93 loss 0.009 score 0.231 lr 2.97049e-06 
12/06/2021 15:37:19 - INFO - volta.train_utils -   [RetrievalWIT]: iter 29200 Ep: 0.93 loss 0.011 score 0.233 lr 2.96338e-06 
12/06/2021 15:38:08 - INFO - volta.train_utils -   [RetrievalWIT]: iter 29280 Ep: 0.94 loss 0.008 score 0.236 lr 2.95627e-06 
12/06/2021 15:38:57 - INFO - volta.train_utils -   [RetrievalWIT]: iter 29360 Ep: 0.94 loss 0.011 score 0.233 lr 2.94916e-06 
12/06/2021 15:39:46 - INFO - volta.train_utils -   [RetrievalWIT]: iter 29440 Ep: 0.94 loss 0.012 score 0.233 lr 2.94204e-06 
12/06/2021 15:40:36 - INFO - volta.train_utils -   [RetrievalWIT]: iter 29520 Ep: 0.94 loss 0.013 score 0.230 lr 2.93493e-06 
12/06/2021 15:41:25 - INFO - volta.train_utils -   [RetrievalWIT]: iter 29600 Ep: 0.95 loss 0.012 score 0.234 lr 2.92782e-06 
12/06/2021 15:42:14 - INFO - volta.train_utils -   [RetrievalWIT]: iter 29680 Ep: 0.95 loss 0.012 score 0.234 lr 2.92071e-06 
12/06/2021 15:43:03 - INFO - volta.train_utils -   [RetrievalWIT]: iter 29760 Ep: 0.95 loss 0.010 score 0.236 lr 2.9136e-06 
12/06/2021 15:43:52 - INFO - volta.train_utils -   [RetrievalWIT]: iter 29840 Ep: 0.95 loss 0.012 score 0.233 lr 2.90649e-06 
12/06/2021 15:44:41 - INFO - volta.train_utils -   [RetrievalWIT]: iter 29920 Ep: 0.96 loss 0.010 score 0.235 lr 2.89938e-06 
12/06/2021 15:45:31 - INFO - volta.train_utils -   [RetrievalWIT]: iter 30000 Ep: 0.96 loss 0.007 score 0.233 lr 2.89227e-06 
12/06/2021 15:46:20 - INFO - volta.train_utils -   [RetrievalWIT]: iter 30080 Ep: 0.96 loss 0.008 score 0.232 lr 2.88516e-06 
12/06/2021 15:47:09 - INFO - volta.train_utils -   [RetrievalWIT]: iter 30160 Ep: 0.97 loss 0.010 score 0.230 lr 2.87804e-06 
12/06/2021 15:47:58 - INFO - volta.train_utils -   [RetrievalWIT]: iter 30240 Ep: 0.97 loss 0.012 score 0.234 lr 2.87093e-06 
12/06/2021 15:48:47 - INFO - volta.train_utils -   [RetrievalWIT]: iter 30320 Ep: 0.97 loss 0.011 score 0.236 lr 2.86382e-06 
12/06/2021 15:49:37 - INFO - volta.train_utils -   [RetrievalWIT]: iter 30400 Ep: 0.97 loss 0.011 score 0.233 lr 2.85671e-06 
12/06/2021 15:50:25 - INFO - volta.train_utils -   [RetrievalWIT]: iter 30480 Ep: 0.98 loss 0.009 score 0.233 lr 2.8496e-06 
12/06/2021 15:51:15 - INFO - volta.train_utils -   [RetrievalWIT]: iter 30560 Ep: 0.98 loss 0.009 score 0.234 lr 2.84249e-06 
12/06/2021 15:52:04 - INFO - volta.train_utils -   [RetrievalWIT]: iter 30640 Ep: 0.98 loss 0.012 score 0.232 lr 2.83538e-06 
12/06/2021 15:52:53 - INFO - volta.train_utils -   [RetrievalWIT]: iter 30720 Ep: 0.98 loss 0.010 score 0.233 lr 2.82827e-06 
12/06/2021 15:53:42 - INFO - volta.train_utils -   [RetrievalWIT]: iter 30800 Ep: 0.99 loss 0.011 score 0.234 lr 2.82116e-06 
12/06/2021 15:54:31 - INFO - volta.train_utils -   [RetrievalWIT]: iter 30880 Ep: 0.99 loss 0.010 score 0.234 lr 2.81404e-06 
12/06/2021 15:55:20 - INFO - volta.train_utils -   [RetrievalWIT]: iter 30960 Ep: 0.99 loss 0.012 score 0.236 lr 2.80693e-06 
12/06/2021 15:56:09 - INFO - volta.train_utils -   [RetrievalWIT]: iter 31040 Ep: 0.99 loss 0.010 score 0.231 lr 2.79982e-06 
12/06/2021 15:56:58 - INFO - volta.train_utils -   [RetrievalWIT]: iter 31120 Ep: 1.00 loss 0.013 score 0.234 lr 2.79271e-06 
12/06/2021 15:57:47 - INFO - volta.train_utils -   [RetrievalWIT]: iter 31200 Ep: 1.00 loss 0.008 score 0.237 lr 2.7856e-06 
12/06/2021 15:59:22 - INFO - volta.train_utils -   Eval task TASK20 on iteration 31248 
12/06/2021 15:59:22 - INFO - volta.train_utils -   Validation [RetrievalWIT]: loss 0.165 score 94.031 
12/06/2021 15:59:22 - INFO - __main__ -   ** ** * Saving model * ** ** 
Epoch:  50%|█████     | 1/2 [5:54:23<5:54:23, 21263.44s/it]12/06/2021 16:00:32 - INFO - volta.train_utils -   [RetrievalWIT]: iter 31328 Ep: 1.00 loss 0.009 score 0.240 lr 2.77636e-06 
12/06/2021 16:01:21 - INFO - volta.train_utils -   [RetrievalWIT]: iter 31408 Ep: 1.01 loss 0.008 score 0.239 lr 2.76711e-06 
12/06/2021 16:02:10 - INFO - volta.train_utils -   [RetrievalWIT]: iter 31488 Ep: 1.01 loss 0.009 score 0.235 lr 2.76e-06 
12/06/2021 16:02:59 - INFO - volta.train_utils -   [RetrievalWIT]: iter 31568 Ep: 1.01 loss 0.009 score 0.238 lr 2.75289e-06 
12/06/2021 16:03:48 - INFO - volta.train_utils -   [RetrievalWIT]: iter 31648 Ep: 1.01 loss 0.015 score 0.235 lr 2.74578e-06 
12/06/2021 16:04:38 - INFO - volta.train_utils -   [RetrievalWIT]: iter 31728 Ep: 1.02 loss 0.008 score 0.234 lr 2.73867e-06 
12/06/2021 16:05:27 - INFO - volta.train_utils -   [RetrievalWIT]: iter 31808 Ep: 1.02 loss 0.007 score 0.238 lr 2.73156e-06 
12/06/2021 16:06:16 - INFO - volta.train_utils -   [RetrievalWIT]: iter 31888 Ep: 1.02 loss 0.010 score 0.237 lr 2.72444e-06 
12/06/2021 16:07:06 - INFO - volta.train_utils -   [RetrievalWIT]: iter 31968 Ep: 1.02 loss 0.008 score 0.236 lr 2.71733e-06 
12/06/2021 16:07:55 - INFO - volta.train_utils -   [RetrievalWIT]: iter 32048 Ep: 1.03 loss 0.011 score 0.237 lr 2.71022e-06 
12/06/2021 16:08:44 - INFO - volta.train_utils -   [RetrievalWIT]: iter 32128 Ep: 1.03 loss 0.011 score 0.236 lr 2.70311e-06 
12/06/2021 16:09:33 - INFO - volta.train_utils -   [RetrievalWIT]: iter 32208 Ep: 1.03 loss 0.012 score 0.235 lr 2.696e-06 
12/06/2021 16:10:22 - INFO - volta.train_utils -   [RetrievalWIT]: iter 32288 Ep: 1.03 loss 0.011 score 0.236 lr 2.68889e-06 
12/06/2021 16:11:12 - INFO - volta.train_utils -   [RetrievalWIT]: iter 32368 Ep: 1.04 loss 0.010 score 0.239 lr 2.68178e-06 
12/06/2021 16:12:01 - INFO - volta.train_utils -   [RetrievalWIT]: iter 32448 Ep: 1.04 loss 0.009 score 0.237 lr 2.67467e-06 
12/06/2021 16:12:50 - INFO - volta.train_utils -   [RetrievalWIT]: iter 32528 Ep: 1.04 loss 0.007 score 0.236 lr 2.66756e-06 
12/06/2021 16:13:40 - INFO - volta.train_utils -   [RetrievalWIT]: iter 32608 Ep: 1.04 loss 0.010 score 0.235 lr 2.66044e-06 
12/06/2021 16:14:29 - INFO - volta.train_utils -   [RetrievalWIT]: iter 32688 Ep: 1.05 loss 0.007 score 0.238 lr 2.65333e-06 
12/06/2021 16:15:18 - INFO - volta.train_utils -   [RetrievalWIT]: iter 32768 Ep: 1.05 loss 0.007 score 0.238 lr 2.64622e-06 
12/06/2021 16:16:07 - INFO - volta.train_utils -   [RetrievalWIT]: iter 32848 Ep: 1.05 loss 0.006 score 0.239 lr 2.63911e-06 
12/06/2021 16:16:56 - INFO - volta.train_utils -   [RetrievalWIT]: iter 32928 Ep: 1.05 loss 0.010 score 0.239 lr 2.632e-06 
12/06/2021 16:17:45 - INFO - volta.train_utils -   [RetrievalWIT]: iter 33008 Ep: 1.06 loss 0.005 score 0.237 lr 2.62489e-06 
12/06/2021 16:18:35 - INFO - volta.train_utils -   [RetrievalWIT]: iter 33088 Ep: 1.06 loss 0.009 score 0.235 lr 2.61778e-06 
12/06/2021 16:19:24 - INFO - volta.train_utils -   [RetrievalWIT]: iter 33168 Ep: 1.06 loss 0.011 score 0.233 lr 2.61067e-06 
12/06/2021 16:20:13 - INFO - volta.train_utils -   [RetrievalWIT]: iter 33248 Ep: 1.06 loss 0.009 score 0.235 lr 2.60356e-06 
12/06/2021 16:21:02 - INFO - volta.train_utils -   [RetrievalWIT]: iter 33328 Ep: 1.07 loss 0.011 score 0.232 lr 2.59644e-06 
12/06/2021 16:21:52 - INFO - volta.train_utils -   [RetrievalWIT]: iter 33408 Ep: 1.07 loss 0.008 score 0.235 lr 2.58933e-06 
12/06/2021 16:22:41 - INFO - volta.train_utils -   [RetrievalWIT]: iter 33488 Ep: 1.07 loss 0.012 score 0.233 lr 2.58222e-06 
12/06/2021 16:23:30 - INFO - volta.train_utils -   [RetrievalWIT]: iter 33568 Ep: 1.07 loss 0.008 score 0.233 lr 2.57511e-06 
12/06/2021 16:24:19 - INFO - volta.train_utils -   [RetrievalWIT]: iter 33648 Ep: 1.08 loss 0.010 score 0.236 lr 2.568e-06 
12/06/2021 16:25:08 - INFO - volta.train_utils -   [RetrievalWIT]: iter 33728 Ep: 1.08 loss 0.012 score 0.234 lr 2.56089e-06 
12/06/2021 16:25:57 - INFO - volta.train_utils -   [RetrievalWIT]: iter 33808 Ep: 1.08 loss 0.010 score 0.234 lr 2.55378e-06 
12/06/2021 16:26:46 - INFO - volta.train_utils -   [RetrievalWIT]: iter 33888 Ep: 1.08 loss 0.008 score 0.234 lr 2.54667e-06 
12/06/2021 16:27:36 - INFO - volta.train_utils -   [RetrievalWIT]: iter 33968 Ep: 1.09 loss 0.010 score 0.234 lr 2.53956e-06 
12/06/2021 16:28:25 - INFO - volta.train_utils -   [RetrievalWIT]: iter 34048 Ep: 1.09 loss 0.007 score 0.235 lr 2.53244e-06 
12/06/2021 16:30:14 - INFO - volta.train_utils -   Eval task TASK20 on iteration 34120 
12/06/2021 16:30:14 - INFO - volta.train_utils -   Validation [RetrievalWIT]: loss 0.168 score 93.404 
12/06/2021 16:31:19 - INFO - volta.train_utils -   Eval task TASK20 on iteration 34120 
12/06/2021 16:31:19 - INFO - volta.train_utils -   Validation [RetrievalWIT]: loss 0.160 score 93.253 
12/06/2021 16:32:25 - INFO - volta.train_utils -   Eval task TASK20 on iteration 34120 
12/06/2021 16:32:25 - INFO - volta.train_utils -   Validation [RetrievalWIT]: loss 0.172 score 93.166 
12/06/2021 16:33:30 - INFO - volta.train_utils -   Eval task TASK20 on iteration 34124 
12/06/2021 16:33:30 - INFO - volta.train_utils -   Validation [RetrievalWIT]: loss 0.160 score 94.161 
12/06/2021 16:33:30 - INFO - __main__ -   ** ** * Saving model * ** ** 
12/06/2021 16:33:59 - INFO - volta.train_utils -   [RetrievalWIT]: iter 34128 Ep: 1.09 loss 0.007 score 0.234 lr 2.52533e-06 
12/06/2021 16:34:48 - INFO - volta.train_utils -   [RetrievalWIT]: iter 34208 Ep: 1.09 loss 0.009 score 0.235 lr 2.51822e-06 
12/06/2021 16:35:37 - INFO - volta.train_utils -   [RetrievalWIT]: iter 34288 Ep: 1.10 loss 0.013 score 0.233 lr 2.51111e-06 
12/06/2021 16:36:26 - INFO - volta.train_utils -   [RetrievalWIT]: iter 34368 Ep: 1.10 loss 0.011 score 0.234 lr 2.504e-06 
12/06/2021 16:37:15 - INFO - volta.train_utils -   [RetrievalWIT]: iter 34448 Ep: 1.10 loss 0.009 score 0.234 lr 2.49689e-06 
12/06/2021 16:38:04 - INFO - volta.train_utils -   [RetrievalWIT]: iter 34528 Ep: 1.10 loss 0.007 score 0.237 lr 2.48978e-06 
12/06/2021 16:38:53 - INFO - volta.train_utils -   [RetrievalWIT]: iter 34608 Ep: 1.11 loss 0.012 score 0.234 lr 2.48267e-06 
12/06/2021 16:39:42 - INFO - volta.train_utils -   [RetrievalWIT]: iter 34688 Ep: 1.11 loss 0.010 score 0.234 lr 2.47556e-06 
12/06/2021 16:40:32 - INFO - volta.train_utils -   [RetrievalWIT]: iter 34768 Ep: 1.11 loss 0.009 score 0.233 lr 2.46844e-06 
12/06/2021 16:41:21 - INFO - volta.train_utils -   [RetrievalWIT]: iter 34848 Ep: 1.12 loss 0.012 score 0.236 lr 2.46133e-06 
12/06/2021 16:42:10 - INFO - volta.train_utils -   [RetrievalWIT]: iter 34928 Ep: 1.12 loss 0.008 score 0.237 lr 2.45422e-06 
12/06/2021 16:42:59 - INFO - volta.train_utils -   [RetrievalWIT]: iter 35008 Ep: 1.12 loss 0.010 score 0.234 lr 2.44711e-06 
12/06/2021 16:43:48 - INFO - volta.train_utils -   [RetrievalWIT]: iter 35088 Ep: 1.12 loss 0.007 score 0.238 lr 2.44e-06 
12/06/2021 16:44:38 - INFO - volta.train_utils -   [RetrievalWIT]: iter 35168 Ep: 1.13 loss 0.010 score 0.237 lr 2.43289e-06 
12/06/2021 16:45:27 - INFO - volta.train_utils -   [RetrievalWIT]: iter 35248 Ep: 1.13 loss 0.014 score 0.233 lr 2.42578e-06 
12/06/2021 16:46:16 - INFO - volta.train_utils -   [RetrievalWIT]: iter 35328 Ep: 1.13 loss 0.010 score 0.235 lr 2.41867e-06 
12/06/2021 16:47:05 - INFO - volta.train_utils -   [RetrievalWIT]: iter 35408 Ep: 1.13 loss 0.008 score 0.238 lr 2.41156e-06 
12/06/2021 16:47:54 - INFO - volta.train_utils -   [RetrievalWIT]: iter 35488 Ep: 1.14 loss 0.009 score 0.235 lr 2.40444e-06 
12/06/2021 16:48:43 - INFO - volta.train_utils -   [RetrievalWIT]: iter 35568 Ep: 1.14 loss 0.010 score 0.235 lr 2.39733e-06 
12/06/2021 16:49:33 - INFO - volta.train_utils -   [RetrievalWIT]: iter 35648 Ep: 1.14 loss 0.009 score 0.235 lr 2.39022e-06 
12/06/2021 16:50:22 - INFO - volta.train_utils -   [RetrievalWIT]: iter 35728 Ep: 1.14 loss 0.009 score 0.234 lr 2.38311e-06 
12/06/2021 16:51:11 - INFO - volta.train_utils -   [RetrievalWIT]: iter 35808 Ep: 1.15 loss 0.008 score 0.237 lr 2.376e-06 
12/06/2021 16:52:00 - INFO - volta.train_utils -   [RetrievalWIT]: iter 35888 Ep: 1.15 loss 0.010 score 0.236 lr 2.36889e-06 
12/06/2021 16:52:49 - INFO - volta.train_utils -   [RetrievalWIT]: iter 35968 Ep: 1.15 loss 0.008 score 0.236 lr 2.36178e-06 
12/06/2021 16:53:38 - INFO - volta.train_utils -   [RetrievalWIT]: iter 36048 Ep: 1.15 loss 0.009 score 0.232 lr 2.35467e-06 
12/06/2021 16:54:28 - INFO - volta.train_utils -   [RetrievalWIT]: iter 36128 Ep: 1.16 loss 0.008 score 0.236 lr 2.34756e-06 
12/06/2021 16:55:17 - INFO - volta.train_utils -   [RetrievalWIT]: iter 36208 Ep: 1.16 loss 0.009 score 0.236 lr 2.34044e-06 
12/06/2021 16:56:06 - INFO - volta.train_utils -   [RetrievalWIT]: iter 36288 Ep: 1.16 loss 0.012 score 0.236 lr 2.33333e-06 
12/06/2021 16:56:55 - INFO - volta.train_utils -   [RetrievalWIT]: iter 36368 Ep: 1.16 loss 0.008 score 0.237 lr 2.32622e-06 
12/06/2021 16:57:44 - INFO - volta.train_utils -   [RetrievalWIT]: iter 36448 Ep: 1.17 loss 0.009 score 0.237 lr 2.31911e-06 
12/06/2021 16:58:33 - INFO - volta.train_utils -   [RetrievalWIT]: iter 36528 Ep: 1.17 loss 0.006 score 0.235 lr 2.312e-06 
12/06/2021 16:59:22 - INFO - volta.train_utils -   [RetrievalWIT]: iter 36608 Ep: 1.17 loss 0.009 score 0.234 lr 2.30489e-06 
12/06/2021 17:00:11 - INFO - volta.train_utils -   [RetrievalWIT]: iter 36688 Ep: 1.17 loss 0.008 score 0.237 lr 2.29778e-06 
12/06/2021 17:01:00 - INFO - volta.train_utils -   [RetrievalWIT]: iter 36768 Ep: 1.18 loss 0.009 score 0.236 lr 2.29067e-06 
12/06/2021 17:01:50 - INFO - volta.train_utils -   [RetrievalWIT]: iter 36848 Ep: 1.18 loss 0.010 score 0.233 lr 2.28356e-06 
12/06/2021 17:02:39 - INFO - volta.train_utils -   [RetrievalWIT]: iter 36928 Ep: 1.18 loss 0.009 score 0.236 lr 2.27644e-06 
12/06/2021 17:03:28 - INFO - volta.train_utils -   [RetrievalWIT]: iter 37008 Ep: 1.18 loss 0.010 score 0.237 lr 2.26933e-06 
12/06/2021 17:04:17 - INFO - volta.train_utils -   [RetrievalWIT]: iter 37088 Ep: 1.19 loss 0.011 score 0.235 lr 2.26222e-06 
12/06/2021 17:05:06 - INFO - volta.train_utils -   [RetrievalWIT]: iter 37168 Ep: 1.19 loss 0.011 score 0.231 lr 2.25511e-06 
12/06/2021 17:05:55 - INFO - volta.train_utils -   [RetrievalWIT]: iter 37248 Ep: 1.19 loss 0.007 score 0.238 lr 2.248e-06 
12/06/2021 17:06:45 - INFO - volta.train_utils -   [RetrievalWIT]: iter 37328 Ep: 1.19 loss 0.006 score 0.238 lr 2.24089e-06 
12/06/2021 17:07:34 - INFO - volta.train_utils -   [RetrievalWIT]: iter 37408 Ep: 1.20 loss 0.009 score 0.236 lr 2.23378e-06 
12/06/2021 17:08:23 - INFO - volta.train_utils -   [RetrievalWIT]: iter 37488 Ep: 1.20 loss 0.010 score 0.236 lr 2.22667e-06 
12/06/2021 17:09:12 - INFO - volta.train_utils -   [RetrievalWIT]: iter 37568 Ep: 1.20 loss 0.008 score 0.234 lr 2.21956e-06 
12/06/2021 17:10:01 - INFO - volta.train_utils -   [RetrievalWIT]: iter 37648 Ep: 1.20 loss 0.013 score 0.233 lr 2.21244e-06 
12/06/2021 17:10:50 - INFO - volta.train_utils -   [RetrievalWIT]: iter 37728 Ep: 1.21 loss 0.009 score 0.236 lr 2.20533e-06 
12/06/2021 17:11:39 - INFO - volta.train_utils -   [RetrievalWIT]: iter 37808 Ep: 1.21 loss 0.007 score 0.236 lr 2.19822e-06 
12/06/2021 17:12:28 - INFO - volta.train_utils -   [RetrievalWIT]: iter 37888 Ep: 1.21 loss 0.006 score 0.239 lr 2.19111e-06 
12/06/2021 17:13:17 - INFO - volta.train_utils -   [RetrievalWIT]: iter 37968 Ep: 1.21 loss 0.010 score 0.234 lr 2.184e-06 
12/06/2021 17:14:06 - INFO - volta.train_utils -   [RetrievalWIT]: iter 38048 Ep: 1.22 loss 0.006 score 0.237 lr 2.17689e-06 
12/06/2021 17:15:53 - INFO - volta.train_utils -   Eval task TASK20 on iteration 38116 
12/06/2021 17:15:53 - INFO - volta.train_utils -   Validation [RetrievalWIT]: loss 0.167 score 93.728 
12/06/2021 17:16:58 - INFO - volta.train_utils -   Eval task TASK20 on iteration 38116 
12/06/2021 17:16:58 - INFO - volta.train_utils -   Validation [RetrievalWIT]: loss 0.175 score 93.426 
12/06/2021 17:18:03 - INFO - volta.train_utils -   Eval task TASK20 on iteration 38116 
12/06/2021 17:18:03 - INFO - volta.train_utils -   Validation [RetrievalWIT]: loss 0.151 score 94.356 
12/06/2021 17:18:03 - INFO - __main__ -   ** ** * Saving model * ** ** 
12/06/2021 17:19:35 - INFO - volta.train_utils -   Eval task TASK20 on iteration 38120 
12/06/2021 17:19:35 - INFO - volta.train_utils -   Validation [RetrievalWIT]: loss 0.161 score 94.226 
12/06/2021 17:19:41 - INFO - volta.train_utils -   [RetrievalWIT]: iter 38128 Ep: 1.22 loss 0.010 score 0.238 lr 2.16978e-06 
12/06/2021 17:20:30 - INFO - volta.train_utils -   [RetrievalWIT]: iter 38208 Ep: 1.22 loss 0.010 score 0.237 lr 2.16267e-06 
12/06/2021 17:21:19 - INFO - volta.train_utils -   [RetrievalWIT]: iter 38288 Ep: 1.23 loss 0.010 score 0.236 lr 2.15556e-06 
12/06/2021 17:22:09 - INFO - volta.train_utils -   [RetrievalWIT]: iter 38368 Ep: 1.23 loss 0.007 score 0.239 lr 2.14844e-06 
12/06/2021 17:22:58 - INFO - volta.train_utils -   [RetrievalWIT]: iter 38448 Ep: 1.23 loss 0.005 score 0.237 lr 2.14133e-06 
12/06/2021 17:23:47 - INFO - volta.train_utils -   [RetrievalWIT]: iter 38528 Ep: 1.23 loss 0.009 score 0.233 lr 2.13422e-06 
12/06/2021 17:24:36 - INFO - volta.train_utils -   [RetrievalWIT]: iter 38608 Ep: 1.24 loss 0.005 score 0.236 lr 2.12711e-06 
12/06/2021 17:25:26 - INFO - volta.train_utils -   [RetrievalWIT]: iter 38688 Ep: 1.24 loss 0.008 score 0.236 lr 2.12e-06 
12/06/2021 17:26:15 - INFO - volta.train_utils -   [RetrievalWIT]: iter 38768 Ep: 1.24 loss 0.009 score 0.237 lr 2.11289e-06 
12/06/2021 17:27:04 - INFO - volta.train_utils -   [RetrievalWIT]: iter 38848 Ep: 1.24 loss 0.008 score 0.237 lr 2.10578e-06 
12/06/2021 17:27:53 - INFO - volta.train_utils -   [RetrievalWIT]: iter 38928 Ep: 1.25 loss 0.008 score 0.236 lr 2.09867e-06 
12/06/2021 17:28:42 - INFO - volta.train_utils -   [RetrievalWIT]: iter 39008 Ep: 1.25 loss 0.005 score 0.236 lr 2.09156e-06 
12/06/2021 17:29:31 - INFO - volta.train_utils -   [RetrievalWIT]: iter 39088 Ep: 1.25 loss 0.008 score 0.239 lr 2.08444e-06 
12/06/2021 17:30:20 - INFO - volta.train_utils -   [RetrievalWIT]: iter 39168 Ep: 1.25 loss 0.005 score 0.236 lr 2.07733e-06 
12/06/2021 17:31:10 - INFO - volta.train_utils -   [RetrievalWIT]: iter 39248 Ep: 1.26 loss 0.013 score 0.236 lr 2.07022e-06 
12/06/2021 17:31:59 - INFO - volta.train_utils -   [RetrievalWIT]: iter 39328 Ep: 1.26 loss 0.009 score 0.235 lr 2.06311e-06 
12/06/2021 17:32:48 - INFO - volta.train_utils -   [RetrievalWIT]: iter 39408 Ep: 1.26 loss 0.005 score 0.238 lr 2.056e-06 
12/06/2021 17:33:37 - INFO - volta.train_utils -   [RetrievalWIT]: iter 39488 Ep: 1.26 loss 0.010 score 0.237 lr 2.04889e-06 
12/06/2021 17:34:26 - INFO - volta.train_utils -   [RetrievalWIT]: iter 39568 Ep: 1.27 loss 0.010 score 0.236 lr 2.04178e-06 
12/06/2021 17:35:15 - INFO - volta.train_utils -   [RetrievalWIT]: iter 39648 Ep: 1.27 loss 0.008 score 0.235 lr 2.03467e-06 
12/06/2021 17:36:04 - INFO - volta.train_utils -   [RetrievalWIT]: iter 39728 Ep: 1.27 loss 0.011 score 0.233 lr 2.02756e-06 
12/06/2021 17:36:53 - INFO - volta.train_utils -   [RetrievalWIT]: iter 39808 Ep: 1.27 loss 0.008 score 0.237 lr 2.02044e-06 
12/06/2021 17:37:42 - INFO - volta.train_utils -   [RetrievalWIT]: iter 39888 Ep: 1.28 loss 0.010 score 0.238 lr 2.01333e-06 
12/06/2021 17:38:31 - INFO - volta.train_utils -   [RetrievalWIT]: iter 39968 Ep: 1.28 loss 0.011 score 0.236 lr 2.00622e-06 
12/06/2021 17:39:21 - INFO - volta.train_utils -   [RetrievalWIT]: iter 40048 Ep: 1.28 loss 0.008 score 0.237 lr 1.99911e-06 
12/06/2021 17:40:10 - INFO - volta.train_utils -   [RetrievalWIT]: iter 40128 Ep: 1.28 loss 0.007 score 0.236 lr 1.992e-06 
12/06/2021 17:40:59 - INFO - volta.train_utils -   [RetrievalWIT]: iter 40208 Ep: 1.29 loss 0.009 score 0.237 lr 1.98489e-06 
12/06/2021 17:41:48 - INFO - volta.train_utils -   [RetrievalWIT]: iter 40288 Ep: 1.29 loss 0.008 score 0.238 lr 1.97778e-06 
12/06/2021 17:42:37 - INFO - volta.train_utils -   [RetrievalWIT]: iter 40368 Ep: 1.29 loss 0.008 score 0.238 lr 1.97067e-06 
12/06/2021 17:43:26 - INFO - volta.train_utils -   [RetrievalWIT]: iter 40448 Ep: 1.29 loss 0.007 score 0.238 lr 1.96356e-06 
12/06/2021 17:44:15 - INFO - volta.train_utils -   [RetrievalWIT]: iter 40528 Ep: 1.30 loss 0.009 score 0.236 lr 1.95644e-06 
12/06/2021 17:45:05 - INFO - volta.train_utils -   [RetrievalWIT]: iter 40608 Ep: 1.30 loss 0.007 score 0.238 lr 1.94933e-06 
12/06/2021 17:45:54 - INFO - volta.train_utils -   [RetrievalWIT]: iter 40688 Ep: 1.30 loss 0.010 score 0.236 lr 1.94222e-06 
12/06/2021 17:46:43 - INFO - volta.train_utils -   [RetrievalWIT]: iter 40768 Ep: 1.30 loss 0.008 score 0.235 lr 1.93511e-06 
12/06/2021 17:47:32 - INFO - volta.train_utils -   [RetrievalWIT]: iter 40848 Ep: 1.31 loss 0.008 score 0.235 lr 1.928e-06 
12/06/2021 17:48:21 - INFO - volta.train_utils -   [RetrievalWIT]: iter 40928 Ep: 1.31 loss 0.007 score 0.239 lr 1.92089e-06 
12/06/2021 17:49:11 - INFO - volta.train_utils -   [RetrievalWIT]: iter 41008 Ep: 1.31 loss 0.007 score 0.237 lr 1.91378e-06 
12/06/2021 17:50:00 - INFO - volta.train_utils -   [RetrievalWIT]: iter 41088 Ep: 1.31 loss 0.010 score 0.239 lr 1.90667e-06 
12/06/2021 17:50:49 - INFO - volta.train_utils -   [RetrievalWIT]: iter 41168 Ep: 1.32 loss 0.011 score 0.237 lr 1.89956e-06 
12/06/2021 17:51:38 - INFO - volta.train_utils -   [RetrievalWIT]: iter 41248 Ep: 1.32 loss 0.007 score 0.236 lr 1.89244e-06 
12/06/2021 17:52:27 - INFO - volta.train_utils -   [RetrievalWIT]: iter 41328 Ep: 1.32 loss 0.008 score 0.238 lr 1.88533e-06 
12/06/2021 17:53:16 - INFO - volta.train_utils -   [RetrievalWIT]: iter 41408 Ep: 1.33 loss 0.009 score 0.237 lr 1.87822e-06 
12/06/2021 17:54:05 - INFO - volta.train_utils -   [RetrievalWIT]: iter 41488 Ep: 1.33 loss 0.010 score 0.238 lr 1.87111e-06 
12/06/2021 17:54:55 - INFO - volta.train_utils -   [RetrievalWIT]: iter 41568 Ep: 1.33 loss 0.012 score 0.236 lr 1.864e-06 
12/06/2021 17:55:44 - INFO - volta.train_utils -   [RetrievalWIT]: iter 41648 Ep: 1.33 loss 0.011 score 0.235 lr 1.85689e-06 
12/06/2021 17:56:33 - INFO - volta.train_utils -   [RetrievalWIT]: iter 41728 Ep: 1.34 loss 0.009 score 0.237 lr 1.84978e-06 
12/06/2021 17:57:22 - INFO - volta.train_utils -   [RetrievalWIT]: iter 41808 Ep: 1.34 loss 0.007 score 0.238 lr 1.84267e-06 
12/06/2021 17:58:11 - INFO - volta.train_utils -   [RetrievalWIT]: iter 41888 Ep: 1.34 loss 0.009 score 0.237 lr 1.83556e-06 
12/06/2021 17:59:00 - INFO - volta.train_utils -   [RetrievalWIT]: iter 41968 Ep: 1.34 loss 0.010 score 0.233 lr 1.82844e-06 
12/06/2021 17:59:49 - INFO - volta.train_utils -   [RetrievalWIT]: iter 42048 Ep: 1.35 loss 0.006 score 0.238 lr 1.82133e-06 
12/06/2021 18:01:33 - INFO - volta.train_utils -   Eval task TASK20 on iteration 42112 
12/06/2021 18:01:33 - INFO - volta.train_utils -   Validation [RetrievalWIT]: loss 0.169 score 94.031 
12/06/2021 18:02:38 - INFO - volta.train_utils -   Eval task TASK20 on iteration 42112 
12/06/2021 18:02:38 - INFO - volta.train_utils -   Validation [RetrievalWIT]: loss 0.170 score 94.226 
12/06/2021 18:03:43 - INFO - volta.train_utils -   Eval task TASK20 on iteration 42112 
12/06/2021 18:03:43 - INFO - volta.train_utils -   Validation [RetrievalWIT]: loss 0.162 score 93.901 
12/06/2021 18:04:48 - INFO - volta.train_utils -   Eval task TASK20 on iteration 42116 
12/06/2021 18:04:48 - INFO - volta.train_utils -   Validation [RetrievalWIT]: loss 0.168 score 93.837 
12/06/2021 18:04:56 - INFO - volta.train_utils -   [RetrievalWIT]: iter 42128 Ep: 1.35 loss 0.008 score 0.236 lr 1.81422e-06 
12/06/2021 18:05:45 - INFO - volta.train_utils -   [RetrievalWIT]: iter 42208 Ep: 1.35 loss 0.011 score 0.235 lr 1.80711e-06 
12/06/2021 18:06:34 - INFO - volta.train_utils -   [RetrievalWIT]: iter 42288 Ep: 1.35 loss 0.009 score 0.237 lr 1.8e-06 
12/06/2021 18:07:23 - INFO - volta.train_utils -   [RetrievalWIT]: iter 42368 Ep: 1.36 loss 0.009 score 0.239 lr 1.79289e-06 
12/06/2021 18:08:13 - INFO - volta.train_utils -   [RetrievalWIT]: iter 42448 Ep: 1.36 loss 0.009 score 0.237 lr 1.78578e-06 
12/06/2021 18:09:02 - INFO - volta.train_utils -   [RetrievalWIT]: iter 42528 Ep: 1.36 loss 0.010 score 0.236 lr 1.77867e-06 
12/06/2021 18:09:51 - INFO - volta.train_utils -   [RetrievalWIT]: iter 42608 Ep: 1.36 loss 0.008 score 0.239 lr 1.77156e-06 
12/06/2021 18:10:40 - INFO - volta.train_utils -   [RetrievalWIT]: iter 42688 Ep: 1.37 loss 0.008 score 0.235 lr 1.76444e-06 
12/06/2021 18:11:29 - INFO - volta.train_utils -   [RetrievalWIT]: iter 42768 Ep: 1.37 loss 0.009 score 0.236 lr 1.75733e-06 
12/06/2021 18:12:18 - INFO - volta.train_utils -   [RetrievalWIT]: iter 42848 Ep: 1.37 loss 0.011 score 0.235 lr 1.75022e-06 
12/06/2021 18:13:07 - INFO - volta.train_utils -   [RetrievalWIT]: iter 42928 Ep: 1.37 loss 0.009 score 0.237 lr 1.74311e-06 
12/06/2021 18:13:56 - INFO - volta.train_utils -   [RetrievalWIT]: iter 43008 Ep: 1.38 loss 0.009 score 0.237 lr 1.736e-06 
12/06/2021 18:14:45 - INFO - volta.train_utils -   [RetrievalWIT]: iter 43088 Ep: 1.38 loss 0.005 score 0.239 lr 1.72889e-06 
12/06/2021 18:15:35 - INFO - volta.train_utils -   [RetrievalWIT]: iter 43168 Ep: 1.38 loss 0.006 score 0.237 lr 1.72178e-06 
12/06/2021 18:16:24 - INFO - volta.train_utils -   [RetrievalWIT]: iter 43248 Ep: 1.38 loss 0.010 score 0.234 lr 1.71467e-06 
12/06/2021 18:17:13 - INFO - volta.train_utils -   [RetrievalWIT]: iter 43328 Ep: 1.39 loss 0.008 score 0.237 lr 1.70756e-06 
12/06/2021 18:18:02 - INFO - volta.train_utils -   [RetrievalWIT]: iter 43408 Ep: 1.39 loss 0.008 score 0.236 lr 1.70044e-06 
12/06/2021 18:18:51 - INFO - volta.train_utils -   [RetrievalWIT]: iter 43488 Ep: 1.39 loss 0.008 score 0.236 lr 1.69333e-06 
12/06/2021 18:19:40 - INFO - volta.train_utils -   [RetrievalWIT]: iter 43568 Ep: 1.39 loss 0.008 score 0.237 lr 1.68622e-06 
12/06/2021 18:20:29 - INFO - volta.train_utils -   [RetrievalWIT]: iter 43648 Ep: 1.40 loss 0.009 score 0.237 lr 1.67911e-06 
12/06/2021 18:21:19 - INFO - volta.train_utils -   [RetrievalWIT]: iter 43728 Ep: 1.40 loss 0.009 score 0.237 lr 1.672e-06 
12/06/2021 18:22:08 - INFO - volta.train_utils -   [RetrievalWIT]: iter 43808 Ep: 1.40 loss 0.011 score 0.238 lr 1.66489e-06 
12/06/2021 18:22:57 - INFO - volta.train_utils -   [RetrievalWIT]: iter 43888 Ep: 1.40 loss 0.008 score 0.234 lr 1.65778e-06 
12/06/2021 18:23:46 - INFO - volta.train_utils -   [RetrievalWIT]: iter 43968 Ep: 1.41 loss 0.008 score 0.236 lr 1.65067e-06 
12/06/2021 18:24:35 - INFO - volta.train_utils -   [RetrievalWIT]: iter 44048 Ep: 1.41 loss 0.008 score 0.239 lr 1.64356e-06 
12/06/2021 18:25:24 - INFO - volta.train_utils -   [RetrievalWIT]: iter 44128 Ep: 1.41 loss 0.008 score 0.237 lr 1.63644e-06 
12/06/2021 18:26:13 - INFO - volta.train_utils -   [RetrievalWIT]: iter 44208 Ep: 1.41 loss 0.008 score 0.236 lr 1.62933e-06 
12/06/2021 18:27:03 - INFO - volta.train_utils -   [RetrievalWIT]: iter 44288 Ep: 1.42 loss 0.011 score 0.236 lr 1.62222e-06 
12/06/2021 18:27:52 - INFO - volta.train_utils -   [RetrievalWIT]: iter 44368 Ep: 1.42 loss 0.009 score 0.237 lr 1.61511e-06 
12/06/2021 18:28:41 - INFO - volta.train_utils -   [RetrievalWIT]: iter 44448 Ep: 1.42 loss 0.007 score 0.236 lr 1.608e-06 
12/06/2021 18:29:30 - INFO - volta.train_utils -   [RetrievalWIT]: iter 44528 Ep: 1.42 loss 0.010 score 0.234 lr 1.60089e-06 
12/06/2021 18:30:19 - INFO - volta.train_utils -   [RetrievalWIT]: iter 44608 Ep: 1.43 loss 0.010 score 0.235 lr 1.59378e-06 
12/06/2021 18:31:08 - INFO - volta.train_utils -   [RetrievalWIT]: iter 44688 Ep: 1.43 loss 0.007 score 0.238 lr 1.58667e-06 
12/06/2021 18:31:58 - INFO - volta.train_utils -   [RetrievalWIT]: iter 44768 Ep: 1.43 loss 0.007 score 0.238 lr 1.57956e-06 
12/06/2021 18:32:47 - INFO - volta.train_utils -   [RetrievalWIT]: iter 44848 Ep: 1.44 loss 0.011 score 0.237 lr 1.57244e-06 
12/06/2021 18:33:36 - INFO - volta.train_utils -   [RetrievalWIT]: iter 44928 Ep: 1.44 loss 0.008 score 0.235 lr 1.56533e-06 
12/06/2021 18:34:25 - INFO - volta.train_utils -   [RetrievalWIT]: iter 45008 Ep: 1.44 loss 0.011 score 0.238 lr 1.55822e-06 
12/06/2021 18:35:14 - INFO - volta.train_utils -   [RetrievalWIT]: iter 45088 Ep: 1.44 loss 0.006 score 0.237 lr 1.55111e-06 
12/06/2021 18:36:04 - INFO - volta.train_utils -   [RetrievalWIT]: iter 45168 Ep: 1.45 loss 0.011 score 0.236 lr 1.544e-06 
12/06/2021 18:36:53 - INFO - volta.train_utils -   [RetrievalWIT]: iter 45248 Ep: 1.45 loss 0.009 score 0.236 lr 1.53689e-06 
12/06/2021 18:37:42 - INFO - volta.train_utils -   [RetrievalWIT]: iter 45328 Ep: 1.45 loss 0.008 score 0.237 lr 1.52978e-06 
12/06/2021 18:38:31 - INFO - volta.train_utils -   [RetrievalWIT]: iter 45408 Ep: 1.45 loss 0.009 score 0.237 lr 1.52267e-06 
12/06/2021 18:39:20 - INFO - volta.train_utils -   [RetrievalWIT]: iter 45488 Ep: 1.46 loss 0.010 score 0.236 lr 1.51556e-06 
12/06/2021 18:40:09 - INFO - volta.train_utils -   [RetrievalWIT]: iter 45568 Ep: 1.46 loss 0.009 score 0.237 lr 1.50844e-06 
12/06/2021 18:40:58 - INFO - volta.train_utils -   [RetrievalWIT]: iter 45648 Ep: 1.46 loss 0.008 score 0.236 lr 1.50133e-06 
12/06/2021 18:41:47 - INFO - volta.train_utils -   [RetrievalWIT]: iter 45728 Ep: 1.46 loss 0.008 score 0.236 lr 1.49422e-06 
12/06/2021 18:42:36 - INFO - volta.train_utils -   [RetrievalWIT]: iter 45808 Ep: 1.47 loss 0.009 score 0.238 lr 1.48711e-06 
12/06/2021 18:43:25 - INFO - volta.train_utils -   [RetrievalWIT]: iter 45888 Ep: 1.47 loss 0.009 score 0.238 lr 1.48e-06 
12/06/2021 18:44:15 - INFO - volta.train_utils -   [RetrievalWIT]: iter 45968 Ep: 1.47 loss 0.007 score 0.238 lr 1.47289e-06 
12/06/2021 18:45:04 - INFO - volta.train_utils -   [RetrievalWIT]: iter 46048 Ep: 1.47 loss 0.006 score 0.237 lr 1.46578e-06 
12/06/2021 18:46:45 - INFO - volta.train_utils -   Eval task TASK20 on iteration 46108 
12/06/2021 18:46:45 - INFO - volta.train_utils -   Validation [RetrievalWIT]: loss 0.161 score 94.031 
12/06/2021 18:47:50 - INFO - volta.train_utils -   Eval task TASK20 on iteration 46108 
12/06/2021 18:47:50 - INFO - volta.train_utils -   Validation [RetrievalWIT]: loss 0.161 score 93.966 
12/06/2021 18:48:56 - INFO - volta.train_utils -   Eval task TASK20 on iteration 46108 
12/06/2021 18:48:56 - INFO - volta.train_utils -   Validation [RetrievalWIT]: loss 0.171 score 93.555 
12/06/2021 18:50:01 - INFO - volta.train_utils -   Eval task TASK20 on iteration 46112 
12/06/2021 18:50:01 - INFO - volta.train_utils -   Validation [RetrievalWIT]: loss 0.159 score 94.377 
12/06/2021 18:50:01 - INFO - __main__ -   ** ** * Saving model * ** ** 
12/06/2021 18:50:40 - INFO - volta.train_utils -   [RetrievalWIT]: iter 46128 Ep: 1.48 loss 0.009 score 0.236 lr 1.45867e-06 
12/06/2021 18:51:29 - INFO - volta.train_utils -   [RetrievalWIT]: iter 46208 Ep: 1.48 loss 0.011 score 0.237 lr 1.45156e-06 
12/06/2021 18:52:18 - INFO - volta.train_utils -   [RetrievalWIT]: iter 46288 Ep: 1.48 loss 0.008 score 0.237 lr 1.44444e-06 
12/06/2021 18:53:07 - INFO - volta.train_utils -   [RetrievalWIT]: iter 46368 Ep: 1.48 loss 0.008 score 0.237 lr 1.43733e-06 
12/06/2021 18:53:57 - INFO - volta.train_utils -   [RetrievalWIT]: iter 46448 Ep: 1.49 loss 0.009 score 0.237 lr 1.43022e-06 
12/06/2021 18:54:46 - INFO - volta.train_utils -   [RetrievalWIT]: iter 46528 Ep: 1.49 loss 0.006 score 0.239 lr 1.42311e-06 
12/06/2021 18:55:35 - INFO - volta.train_utils -   [RetrievalWIT]: iter 46608 Ep: 1.49 loss 0.011 score 0.239 lr 1.416e-06 
12/06/2021 18:56:24 - INFO - volta.train_utils -   [RetrievalWIT]: iter 46688 Ep: 1.49 loss 0.008 score 0.237 lr 1.40889e-06 
12/06/2021 18:57:14 - INFO - volta.train_utils -   [RetrievalWIT]: iter 46768 Ep: 1.50 loss 0.008 score 0.239 lr 1.40178e-06 
12/06/2021 18:58:03 - INFO - volta.train_utils -   [RetrievalWIT]: iter 46848 Ep: 1.50 loss 0.008 score 0.236 lr 1.39467e-06 
12/06/2021 18:58:52 - INFO - volta.train_utils -   [RetrievalWIT]: iter 46928 Ep: 1.50 loss 0.007 score 0.237 lr 1.38756e-06 
12/06/2021 18:59:41 - INFO - volta.train_utils -   [RetrievalWIT]: iter 47008 Ep: 1.50 loss 0.009 score 0.236 lr 1.38044e-06 
12/06/2021 19:00:30 - INFO - volta.train_utils -   [RetrievalWIT]: iter 47088 Ep: 1.51 loss 0.010 score 0.233 lr 1.37333e-06 
12/06/2021 19:01:19 - INFO - volta.train_utils -   [RetrievalWIT]: iter 47168 Ep: 1.51 loss 0.007 score 0.234 lr 1.36622e-06 
12/06/2021 19:02:09 - INFO - volta.train_utils -   [RetrievalWIT]: iter 47248 Ep: 1.51 loss 0.011 score 0.237 lr 1.35911e-06 
12/06/2021 19:02:58 - INFO - volta.train_utils -   [RetrievalWIT]: iter 47328 Ep: 1.51 loss 0.009 score 0.238 lr 1.352e-06 
12/06/2021 19:03:47 - INFO - volta.train_utils -   [RetrievalWIT]: iter 47408 Ep: 1.52 loss 0.009 score 0.237 lr 1.34489e-06 
12/06/2021 19:04:36 - INFO - volta.train_utils -   [RetrievalWIT]: iter 47488 Ep: 1.52 loss 0.009 score 0.240 lr 1.33778e-06 
12/06/2021 19:05:26 - INFO - volta.train_utils -   [RetrievalWIT]: iter 47568 Ep: 1.52 loss 0.007 score 0.236 lr 1.33067e-06 
12/06/2021 19:06:15 - INFO - volta.train_utils -   [RetrievalWIT]: iter 47648 Ep: 1.52 loss 0.006 score 0.238 lr 1.32356e-06 
12/06/2021 19:07:04 - INFO - volta.train_utils -   [RetrievalWIT]: iter 47728 Ep: 1.53 loss 0.008 score 0.237 lr 1.31644e-06 
12/06/2021 19:07:53 - INFO - volta.train_utils -   [RetrievalWIT]: iter 47808 Ep: 1.53 loss 0.007 score 0.239 lr 1.30933e-06 
12/06/2021 19:08:42 - INFO - volta.train_utils -   [RetrievalWIT]: iter 47888 Ep: 1.53 loss 0.007 score 0.236 lr 1.30222e-06 
12/06/2021 19:09:31 - INFO - volta.train_utils -   [RetrievalWIT]: iter 47968 Ep: 1.53 loss 0.007 score 0.237 lr 1.29511e-06 
12/06/2021 19:10:20 - INFO - volta.train_utils -   [RetrievalWIT]: iter 48048 Ep: 1.54 loss 0.007 score 0.237 lr 1.288e-06 
12/06/2021 19:11:10 - INFO - volta.train_utils -   [RetrievalWIT]: iter 48128 Ep: 1.54 loss 0.008 score 0.238 lr 1.28089e-06 
12/06/2021 19:11:59 - INFO - volta.train_utils -   [RetrievalWIT]: iter 48208 Ep: 1.54 loss 0.008 score 0.235 lr 1.27378e-06 
12/06/2021 19:12:48 - INFO - volta.train_utils -   [RetrievalWIT]: iter 48288 Ep: 1.55 loss 0.007 score 0.239 lr 1.26667e-06 
12/06/2021 19:13:38 - INFO - volta.train_utils -   [RetrievalWIT]: iter 48368 Ep: 1.55 loss 0.009 score 0.238 lr 1.25956e-06 
12/06/2021 19:14:27 - INFO - volta.train_utils -   [RetrievalWIT]: iter 48448 Ep: 1.55 loss 0.010 score 0.239 lr 1.25244e-06 
12/06/2021 19:15:16 - INFO - volta.train_utils -   [RetrievalWIT]: iter 48528 Ep: 1.55 loss 0.007 score 0.239 lr 1.24533e-06 
12/06/2021 19:16:05 - INFO - volta.train_utils -   [RetrievalWIT]: iter 48608 Ep: 1.56 loss 0.007 score 0.236 lr 1.23822e-06 
12/06/2021 19:16:54 - INFO - volta.train_utils -   [RetrievalWIT]: iter 48688 Ep: 1.56 loss 0.008 score 0.240 lr 1.23111e-06 
12/06/2021 19:17:43 - INFO - volta.train_utils -   [RetrievalWIT]: iter 48768 Ep: 1.56 loss 0.006 score 0.238 lr 1.224e-06 
12/06/2021 19:18:32 - INFO - volta.train_utils -   [RetrievalWIT]: iter 48848 Ep: 1.56 loss 0.007 score 0.237 lr 1.21689e-06 
12/06/2021 19:19:21 - INFO - volta.train_utils -   [RetrievalWIT]: iter 48928 Ep: 1.57 loss 0.007 score 0.238 lr 1.20978e-06 
12/06/2021 19:20:11 - INFO - volta.train_utils -   [RetrievalWIT]: iter 49008 Ep: 1.57 loss 0.006 score 0.239 lr 1.20267e-06 
12/06/2021 19:21:00 - INFO - volta.train_utils -   [RetrievalWIT]: iter 49088 Ep: 1.57 loss 0.011 score 0.234 lr 1.19556e-06 
12/06/2021 19:21:49 - INFO - volta.train_utils -   [RetrievalWIT]: iter 49168 Ep: 1.57 loss 0.009 score 0.238 lr 1.18844e-06 
12/06/2021 19:22:38 - INFO - volta.train_utils -   [RetrievalWIT]: iter 49248 Ep: 1.58 loss 0.008 score 0.237 lr 1.18133e-06 
12/06/2021 19:23:27 - INFO - volta.train_utils -   [RetrievalWIT]: iter 49328 Ep: 1.58 loss 0.007 score 0.241 lr 1.17422e-06 
12/06/2021 19:24:16 - INFO - volta.train_utils -   [RetrievalWIT]: iter 49408 Ep: 1.58 loss 0.007 score 0.237 lr 1.16711e-06 
12/06/2021 19:25:05 - INFO - volta.train_utils -   [RetrievalWIT]: iter 49488 Ep: 1.58 loss 0.008 score 0.237 lr 1.16e-06 
12/06/2021 19:25:54 - INFO - volta.train_utils -   [RetrievalWIT]: iter 49568 Ep: 1.59 loss 0.008 score 0.238 lr 1.15289e-06 
12/06/2021 19:26:43 - INFO - volta.train_utils -   [RetrievalWIT]: iter 49648 Ep: 1.59 loss 0.006 score 0.239 lr 1.14578e-06 
12/06/2021 19:27:33 - INFO - volta.train_utils -   [RetrievalWIT]: iter 49728 Ep: 1.59 loss 0.009 score 0.236 lr 1.13867e-06 
12/06/2021 19:28:22 - INFO - volta.train_utils -   [RetrievalWIT]: iter 49808 Ep: 1.59 loss 0.009 score 0.239 lr 1.13156e-06 
12/06/2021 19:29:11 - INFO - volta.train_utils -   [RetrievalWIT]: iter 49888 Ep: 1.60 loss 0.007 score 0.235 lr 1.12444e-06 
12/06/2021 19:30:00 - INFO - volta.train_utils -   [RetrievalWIT]: iter 49968 Ep: 1.60 loss 0.007 score 0.237 lr 1.11733e-06 
12/06/2021 19:30:49 - INFO - volta.train_utils -   [RetrievalWIT]: iter 50048 Ep: 1.60 loss 0.008 score 0.237 lr 1.11022e-06 
12/06/2021 19:32:29 - INFO - volta.train_utils -   Eval task TASK20 on iteration 50104 
12/06/2021 19:32:29 - INFO - volta.train_utils -   Validation [RetrievalWIT]: loss 0.153 score 94.399 
12/06/2021 19:32:29 - INFO - __main__ -   ** ** * Saving model * ** ** 
12/06/2021 19:33:56 - INFO - volta.train_utils -   Eval task TASK20 on iteration 50104 
12/06/2021 19:33:56 - INFO - volta.train_utils -   Validation [RetrievalWIT]: loss 0.169 score 93.966 
12/06/2021 19:35:01 - INFO - volta.train_utils -   Eval task TASK20 on iteration 50104 
12/06/2021 19:35:01 - INFO - volta.train_utils -   Validation [RetrievalWIT]: loss 0.162 score 94.010 
12/06/2021 19:36:05 - INFO - volta.train_utils -   Eval task TASK20 on iteration 50108 
12/06/2021 19:36:05 - INFO - volta.train_utils -   Validation [RetrievalWIT]: loss 0.158 score 94.269 
12/06/2021 19:36:18 - INFO - volta.train_utils -   [RetrievalWIT]: iter 50128 Ep: 1.60 loss 0.010 score 0.237 lr 1.10311e-06 
12/06/2021 19:37:07 - INFO - volta.train_utils -   [RetrievalWIT]: iter 50208 Ep: 1.61 loss 0.007 score 0.240 lr 1.096e-06 
12/06/2021 19:37:57 - INFO - volta.train_utils -   [RetrievalWIT]: iter 50288 Ep: 1.61 loss 0.010 score 0.238 lr 1.08889e-06 
12/06/2021 19:38:46 - INFO - volta.train_utils -   [RetrievalWIT]: iter 50368 Ep: 1.61 loss 0.009 score 0.240 lr 1.08178e-06 
12/06/2021 19:39:36 - INFO - volta.train_utils -   [RetrievalWIT]: iter 50448 Ep: 1.61 loss 0.009 score 0.237 lr 1.07467e-06 
12/06/2021 19:40:25 - INFO - volta.train_utils -   [RetrievalWIT]: iter 50528 Ep: 1.62 loss 0.007 score 0.237 lr 1.06756e-06 
12/06/2021 19:41:14 - INFO - volta.train_utils -   [RetrievalWIT]: iter 50608 Ep: 1.62 loss 0.010 score 0.234 lr 1.06044e-06 
12/06/2021 19:42:03 - INFO - volta.train_utils -   [RetrievalWIT]: iter 50688 Ep: 1.62 loss 0.007 score 0.235 lr 1.05333e-06 
12/06/2021 19:42:53 - INFO - volta.train_utils -   [RetrievalWIT]: iter 50768 Ep: 1.62 loss 0.008 score 0.238 lr 1.04622e-06 
12/06/2021 19:43:42 - INFO - volta.train_utils -   [RetrievalWIT]: iter 50848 Ep: 1.63 loss 0.008 score 0.238 lr 1.03911e-06 
12/06/2021 19:44:31 - INFO - volta.train_utils -   [RetrievalWIT]: iter 50928 Ep: 1.63 loss 0.008 score 0.237 lr 1.032e-06 
12/06/2021 19:45:20 - INFO - volta.train_utils -   [RetrievalWIT]: iter 51008 Ep: 1.63 loss 0.010 score 0.236 lr 1.02489e-06 
12/06/2021 19:46:09 - INFO - volta.train_utils -   [RetrievalWIT]: iter 51088 Ep: 1.63 loss 0.008 score 0.239 lr 1.01778e-06 
12/06/2021 19:46:58 - INFO - volta.train_utils -   [RetrievalWIT]: iter 51168 Ep: 1.64 loss 0.007 score 0.235 lr 1.01067e-06 
12/06/2021 19:47:47 - INFO - volta.train_utils -   [RetrievalWIT]: iter 51248 Ep: 1.64 loss 0.006 score 0.238 lr 1.00356e-06 
12/06/2021 19:48:37 - INFO - volta.train_utils -   [RetrievalWIT]: iter 51328 Ep: 1.64 loss 0.009 score 0.238 lr 9.96444e-07 
12/06/2021 19:49:26 - INFO - volta.train_utils -   [RetrievalWIT]: iter 51408 Ep: 1.65 loss 0.011 score 0.237 lr 9.89333e-07 
12/06/2021 19:50:15 - INFO - volta.train_utils -   [RetrievalWIT]: iter 51488 Ep: 1.65 loss 0.010 score 0.238 lr 9.82222e-07 
12/06/2021 19:51:04 - INFO - volta.train_utils -   [RetrievalWIT]: iter 51568 Ep: 1.65 loss 0.010 score 0.237 lr 9.75111e-07 
12/06/2021 19:51:53 - INFO - volta.train_utils -   [RetrievalWIT]: iter 51648 Ep: 1.65 loss 0.007 score 0.236 lr 9.68e-07 
12/06/2021 19:52:42 - INFO - volta.train_utils -   [RetrievalWIT]: iter 51728 Ep: 1.66 loss 0.006 score 0.235 lr 9.60889e-07 
12/06/2021 19:53:31 - INFO - volta.train_utils -   [RetrievalWIT]: iter 51808 Ep: 1.66 loss 0.010 score 0.236 lr 9.53778e-07 
12/06/2021 19:54:21 - INFO - volta.train_utils -   [RetrievalWIT]: iter 51888 Ep: 1.66 loss 0.009 score 0.237 lr 9.46667e-07 
12/06/2021 19:55:10 - INFO - volta.train_utils -   [RetrievalWIT]: iter 51968 Ep: 1.66 loss 0.007 score 0.239 lr 9.39556e-07 
12/06/2021 19:55:59 - INFO - volta.train_utils -   [RetrievalWIT]: iter 52048 Ep: 1.67 loss 0.008 score 0.241 lr 9.32444e-07 
12/06/2021 19:56:48 - INFO - volta.train_utils -   [RetrievalWIT]: iter 52128 Ep: 1.67 loss 0.011 score 0.238 lr 9.25333e-07 
12/06/2021 19:57:38 - INFO - volta.train_utils -   [RetrievalWIT]: iter 52208 Ep: 1.67 loss 0.008 score 0.237 lr 9.18222e-07 
12/06/2021 19:58:27 - INFO - volta.train_utils -   [RetrievalWIT]: iter 52288 Ep: 1.67 loss 0.009 score 0.236 lr 9.11111e-07 
12/06/2021 19:59:16 - INFO - volta.train_utils -   [RetrievalWIT]: iter 52368 Ep: 1.68 loss 0.009 score 0.234 lr 9.04e-07 
12/06/2021 20:00:05 - INFO - volta.train_utils -   [RetrievalWIT]: iter 52448 Ep: 1.68 loss 0.006 score 0.239 lr 8.96889e-07 
12/06/2021 20:00:54 - INFO - volta.train_utils -   [RetrievalWIT]: iter 52528 Ep: 1.68 loss 0.011 score 0.235 lr 8.89778e-07 
12/06/2021 20:01:43 - INFO - volta.train_utils -   [RetrievalWIT]: iter 52608 Ep: 1.68 loss 0.009 score 0.234 lr 8.82667e-07 
12/06/2021 20:02:32 - INFO - volta.train_utils -   [RetrievalWIT]: iter 52688 Ep: 1.69 loss 0.008 score 0.238 lr 8.75556e-07 
12/06/2021 20:03:22 - INFO - volta.train_utils -   [RetrievalWIT]: iter 52768 Ep: 1.69 loss 0.007 score 0.238 lr 8.68444e-07 
12/06/2021 20:04:11 - INFO - volta.train_utils -   [RetrievalWIT]: iter 52848 Ep: 1.69 loss 0.007 score 0.236 lr 8.61333e-07 
12/06/2021 20:05:00 - INFO - volta.train_utils -   [RetrievalWIT]: iter 52928 Ep: 1.69 loss 0.009 score 0.237 lr 8.54222e-07 
12/06/2021 20:05:49 - INFO - volta.train_utils -   [RetrievalWIT]: iter 53008 Ep: 1.70 loss 0.005 score 0.240 lr 8.47111e-07 
12/06/2021 20:06:38 - INFO - volta.train_utils -   [RetrievalWIT]: iter 53088 Ep: 1.70 loss 0.009 score 0.239 lr 8.4e-07 
12/06/2021 20:07:27 - INFO - volta.train_utils -   [RetrievalWIT]: iter 53168 Ep: 1.70 loss 0.007 score 0.240 lr 8.32889e-07 
12/06/2021 20:08:16 - INFO - volta.train_utils -   [RetrievalWIT]: iter 53248 Ep: 1.70 loss 0.009 score 0.237 lr 8.25778e-07 
12/06/2021 20:09:06 - INFO - volta.train_utils -   [RetrievalWIT]: iter 53328 Ep: 1.71 loss 0.010 score 0.237 lr 8.18667e-07 
12/06/2021 20:09:55 - INFO - volta.train_utils -   [RetrievalWIT]: iter 53408 Ep: 1.71 loss 0.010 score 0.238 lr 8.11556e-07 
12/06/2021 20:10:44 - INFO - volta.train_utils -   [RetrievalWIT]: iter 53488 Ep: 1.71 loss 0.011 score 0.235 lr 8.04444e-07 
12/06/2021 20:11:33 - INFO - volta.train_utils -   [RetrievalWIT]: iter 53568 Ep: 1.71 loss 0.008 score 0.235 lr 7.97333e-07 
12/06/2021 20:12:22 - INFO - volta.train_utils -   [RetrievalWIT]: iter 53648 Ep: 1.72 loss 0.010 score 0.239 lr 7.90222e-07 
12/06/2021 20:13:11 - INFO - volta.train_utils -   [RetrievalWIT]: iter 53728 Ep: 1.72 loss 0.007 score 0.234 lr 7.83111e-07 
12/06/2021 20:14:00 - INFO - volta.train_utils -   [RetrievalWIT]: iter 53808 Ep: 1.72 loss 0.010 score 0.237 lr 7.76e-07 
12/06/2021 20:14:49 - INFO - volta.train_utils -   [RetrievalWIT]: iter 53888 Ep: 1.72 loss 0.009 score 0.237 lr 7.68889e-07 
12/06/2021 20:15:38 - INFO - volta.train_utils -   [RetrievalWIT]: iter 53968 Ep: 1.73 loss 0.009 score 0.237 lr 7.61778e-07 
12/06/2021 20:16:27 - INFO - volta.train_utils -   [RetrievalWIT]: iter 54048 Ep: 1.73 loss 0.008 score 0.238 lr 7.54667e-07 
12/06/2021 20:18:04 - INFO - volta.train_utils -   Eval task TASK20 on iteration 54100 
12/06/2021 20:18:04 - INFO - volta.train_utils -   Validation [RetrievalWIT]: loss 0.150 score 94.420 
12/06/2021 20:18:04 - INFO - __main__ -   ** ** * Saving model * ** ** 
12/06/2021 20:19:30 - INFO - volta.train_utils -   Eval task TASK20 on iteration 54100 
12/06/2021 20:19:30 - INFO - volta.train_utils -   Validation [RetrievalWIT]: loss 0.159 score 94.226 
12/06/2021 20:20:35 - INFO - volta.train_utils -   Eval task TASK20 on iteration 54100 
12/06/2021 20:20:35 - INFO - volta.train_utils -   Validation [RetrievalWIT]: loss 0.157 score 94.269 
12/06/2021 20:21:40 - INFO - volta.train_utils -   Eval task TASK20 on iteration 54104 
12/06/2021 20:21:40 - INFO - volta.train_utils -   Validation [RetrievalWIT]: loss 0.156 score 94.291 
12/06/2021 20:21:55 - INFO - volta.train_utils -   [RetrievalWIT]: iter 54128 Ep: 1.73 loss 0.007 score 0.238 lr 7.47556e-07 
12/06/2021 20:22:45 - INFO - volta.train_utils -   [RetrievalWIT]: iter 54208 Ep: 1.73 loss 0.008 score 0.237 lr 7.40444e-07 
12/06/2021 20:23:34 - INFO - volta.train_utils -   [RetrievalWIT]: iter 54288 Ep: 1.74 loss 0.007 score 0.241 lr 7.33333e-07 
12/06/2021 20:24:23 - INFO - volta.train_utils -   [RetrievalWIT]: iter 54368 Ep: 1.74 loss 0.005 score 0.237 lr 7.26222e-07 
12/06/2021 20:25:12 - INFO - volta.train_utils -   [RetrievalWIT]: iter 54448 Ep: 1.74 loss 0.006 score 0.240 lr 7.19111e-07 
12/06/2021 20:26:01 - INFO - volta.train_utils -   [RetrievalWIT]: iter 54528 Ep: 1.74 loss 0.008 score 0.239 lr 7.12e-07 
12/06/2021 20:26:51 - INFO - volta.train_utils -   [RetrievalWIT]: iter 54608 Ep: 1.75 loss 0.006 score 0.238 lr 7.04889e-07 
12/06/2021 20:27:40 - INFO - volta.train_utils -   [RetrievalWIT]: iter 54688 Ep: 1.75 loss 0.010 score 0.235 lr 6.97778e-07 
12/06/2021 20:28:29 - INFO - volta.train_utils -   [RetrievalWIT]: iter 54768 Ep: 1.75 loss 0.008 score 0.236 lr 6.90667e-07 
12/06/2021 20:29:18 - INFO - volta.train_utils -   [RetrievalWIT]: iter 54848 Ep: 1.76 loss 0.006 score 0.238 lr 6.83556e-07 
12/06/2021 20:30:07 - INFO - volta.train_utils -   [RetrievalWIT]: iter 54928 Ep: 1.76 loss 0.009 score 0.239 lr 6.76444e-07 
12/06/2021 20:30:57 - INFO - volta.train_utils -   [RetrievalWIT]: iter 55008 Ep: 1.76 loss 0.009 score 0.236 lr 6.69333e-07 
12/06/2021 20:31:46 - INFO - volta.train_utils -   [RetrievalWIT]: iter 55088 Ep: 1.76 loss 0.007 score 0.237 lr 6.62222e-07 
12/06/2021 20:32:35 - INFO - volta.train_utils -   [RetrievalWIT]: iter 55168 Ep: 1.77 loss 0.008 score 0.235 lr 6.55111e-07 
12/06/2021 20:33:24 - INFO - volta.train_utils -   [RetrievalWIT]: iter 55248 Ep: 1.77 loss 0.010 score 0.237 lr 6.48e-07 
12/06/2021 20:34:13 - INFO - volta.train_utils -   [RetrievalWIT]: iter 55328 Ep: 1.77 loss 0.006 score 0.238 lr 6.40889e-07 
12/06/2021 20:35:02 - INFO - volta.train_utils -   [RetrievalWIT]: iter 55408 Ep: 1.77 loss 0.012 score 0.237 lr 6.33778e-07 
12/06/2021 20:35:51 - INFO - volta.train_utils -   [RetrievalWIT]: iter 55488 Ep: 1.78 loss 0.008 score 0.236 lr 6.26667e-07 
12/06/2021 20:36:40 - INFO - volta.train_utils -   [RetrievalWIT]: iter 55568 Ep: 1.78 loss 0.009 score 0.237 lr 6.19556e-07 
12/06/2021 20:37:29 - INFO - volta.train_utils -   [RetrievalWIT]: iter 55648 Ep: 1.78 loss 0.006 score 0.237 lr 6.12444e-07 
12/06/2021 20:38:19 - INFO - volta.train_utils -   [RetrievalWIT]: iter 55728 Ep: 1.78 loss 0.008 score 0.238 lr 6.05333e-07 
12/06/2021 20:39:08 - INFO - volta.train_utils -   [RetrievalWIT]: iter 55808 Ep: 1.79 loss 0.009 score 0.234 lr 5.98222e-07 
12/06/2021 20:39:57 - INFO - volta.train_utils -   [RetrievalWIT]: iter 55888 Ep: 1.79 loss 0.009 score 0.232 lr 5.91111e-07 
12/06/2021 20:40:47 - INFO - volta.train_utils -   [RetrievalWIT]: iter 55968 Ep: 1.79 loss 0.008 score 0.239 lr 5.84e-07 
12/06/2021 20:41:36 - INFO - volta.train_utils -   [RetrievalWIT]: iter 56048 Ep: 1.79 loss 0.009 score 0.238 lr 5.76889e-07 
12/06/2021 20:42:25 - INFO - volta.train_utils -   [RetrievalWIT]: iter 56128 Ep: 1.80 loss 0.008 score 0.238 lr 5.69778e-07 
12/06/2021 20:43:14 - INFO - volta.train_utils -   [RetrievalWIT]: iter 56208 Ep: 1.80 loss 0.007 score 0.239 lr 5.62667e-07 
12/06/2021 20:44:03 - INFO - volta.train_utils -   [RetrievalWIT]: iter 56288 Ep: 1.80 loss 0.006 score 0.240 lr 5.55556e-07 
12/06/2021 20:44:52 - INFO - volta.train_utils -   [RetrievalWIT]: iter 56368 Ep: 1.80 loss 0.007 score 0.238 lr 5.48444e-07 
12/06/2021 20:45:42 - INFO - volta.train_utils -   [RetrievalWIT]: iter 56448 Ep: 1.81 loss 0.008 score 0.238 lr 5.41333e-07 
12/06/2021 20:46:31 - INFO - volta.train_utils -   [RetrievalWIT]: iter 56528 Ep: 1.81 loss 0.006 score 0.238 lr 5.34222e-07 
12/06/2021 20:47:20 - INFO - volta.train_utils -   [RetrievalWIT]: iter 56608 Ep: 1.81 loss 0.007 score 0.237 lr 5.27111e-07 
12/06/2021 20:48:09 - INFO - volta.train_utils -   [RetrievalWIT]: iter 56688 Ep: 1.81 loss 0.010 score 0.237 lr 5.2e-07 
12/06/2021 20:48:58 - INFO - volta.train_utils -   [RetrievalWIT]: iter 56768 Ep: 1.82 loss 0.007 score 0.238 lr 5.12889e-07 
12/06/2021 20:49:48 - INFO - volta.train_utils -   [RetrievalWIT]: iter 56848 Ep: 1.82 loss 0.009 score 0.237 lr 5.05778e-07 
12/06/2021 20:50:37 - INFO - volta.train_utils -   [RetrievalWIT]: iter 56928 Ep: 1.82 loss 0.008 score 0.240 lr 4.98667e-07 
12/06/2021 20:51:26 - INFO - volta.train_utils -   [RetrievalWIT]: iter 57008 Ep: 1.82 loss 0.007 score 0.238 lr 4.91556e-07 
12/06/2021 20:52:15 - INFO - volta.train_utils -   [RetrievalWIT]: iter 57088 Ep: 1.83 loss 0.007 score 0.239 lr 4.84444e-07 
12/06/2021 20:53:05 - INFO - volta.train_utils -   [RetrievalWIT]: iter 57168 Ep: 1.83 loss 0.011 score 0.237 lr 4.77333e-07 
12/06/2021 20:53:54 - INFO - volta.train_utils -   [RetrievalWIT]: iter 57248 Ep: 1.83 loss 0.007 score 0.236 lr 4.70222e-07 
12/06/2021 20:54:44 - INFO - volta.train_utils -   [RetrievalWIT]: iter 57328 Ep: 1.83 loss 0.008 score 0.236 lr 4.63111e-07 
12/06/2021 20:55:33 - INFO - volta.train_utils -   [RetrievalWIT]: iter 57408 Ep: 1.84 loss 0.009 score 0.235 lr 4.56e-07 
12/06/2021 20:56:22 - INFO - volta.train_utils -   [RetrievalWIT]: iter 57488 Ep: 1.84 loss 0.006 score 0.237 lr 4.48889e-07 
12/06/2021 20:57:11 - INFO - volta.train_utils -   [RetrievalWIT]: iter 57568 Ep: 1.84 loss 0.011 score 0.237 lr 4.41778e-07 
12/06/2021 20:58:01 - INFO - volta.train_utils -   [RetrievalWIT]: iter 57648 Ep: 1.84 loss 0.010 score 0.239 lr 4.34667e-07 
12/06/2021 20:58:50 - INFO - volta.train_utils -   [RetrievalWIT]: iter 57728 Ep: 1.85 loss 0.007 score 0.238 lr 4.27556e-07 
12/06/2021 20:59:39 - INFO - volta.train_utils -   [RetrievalWIT]: iter 57808 Ep: 1.85 loss 0.008 score 0.238 lr 4.20444e-07 
12/06/2021 21:00:28 - INFO - volta.train_utils -   [RetrievalWIT]: iter 57888 Ep: 1.85 loss 0.008 score 0.237 lr 4.13333e-07 
12/06/2021 21:01:17 - INFO - volta.train_utils -   [RetrievalWIT]: iter 57968 Ep: 1.85 loss 0.008 score 0.238 lr 4.06222e-07 
12/06/2021 21:02:06 - INFO - volta.train_utils -   [RetrievalWIT]: iter 58048 Ep: 1.86 loss 0.009 score 0.234 lr 3.99111e-07 
12/06/2021 21:03:41 - INFO - volta.train_utils -   Eval task TASK20 on iteration 58096 
12/06/2021 21:03:41 - INFO - volta.train_utils -   Validation [RetrievalWIT]: loss 0.155 score 94.312 
12/06/2021 21:04:45 - INFO - volta.train_utils -   Eval task TASK20 on iteration 58096 
12/06/2021 21:04:45 - INFO - volta.train_utils -   Validation [RetrievalWIT]: loss 0.149 score 94.529 
12/06/2021 21:04:45 - INFO - __main__ -   ** ** * Saving model * ** ** 
12/06/2021 21:06:15 - INFO - volta.train_utils -   Eval task TASK20 on iteration 58096 
12/06/2021 21:06:15 - INFO - volta.train_utils -   Validation [RetrievalWIT]: loss 0.146 score 94.745 
12/06/2021 21:06:15 - INFO - __main__ -   ** ** * Saving model * ** ** 
12/06/2021 21:07:44 - INFO - volta.train_utils -   Eval task TASK20 on iteration 58100 
12/06/2021 21:07:44 - INFO - volta.train_utils -   Validation [RetrievalWIT]: loss 0.148 score 94.485 
12/06/2021 21:08:02 - INFO - volta.train_utils -   [RetrievalWIT]: iter 58128 Ep: 1.86 loss 0.008 score 0.239 lr 3.92e-07 
12/06/2021 21:08:51 - INFO - volta.train_utils -   [RetrievalWIT]: iter 58208 Ep: 1.86 loss 0.007 score 0.239 lr 3.84889e-07 
12/06/2021 21:09:40 - INFO - volta.train_utils -   [RetrievalWIT]: iter 58288 Ep: 1.87 loss 0.010 score 0.239 lr 3.77778e-07 
12/06/2021 21:10:30 - INFO - volta.train_utils -   [RetrievalWIT]: iter 58368 Ep: 1.87 loss 0.005 score 0.239 lr 3.70667e-07 
12/06/2021 21:11:19 - INFO - volta.train_utils -   [RetrievalWIT]: iter 58448 Ep: 1.87 loss 0.007 score 0.240 lr 3.63556e-07 
12/06/2021 21:12:08 - INFO - volta.train_utils -   [RetrievalWIT]: iter 58528 Ep: 1.87 loss 0.009 score 0.238 lr 3.56444e-07 
12/06/2021 21:12:57 - INFO - volta.train_utils -   [RetrievalWIT]: iter 58608 Ep: 1.88 loss 0.007 score 0.238 lr 3.49333e-07 
12/06/2021 21:13:46 - INFO - volta.train_utils -   [RetrievalWIT]: iter 58688 Ep: 1.88 loss 0.008 score 0.237 lr 3.42222e-07 
12/06/2021 21:14:35 - INFO - volta.train_utils -   [RetrievalWIT]: iter 58768 Ep: 1.88 loss 0.008 score 0.235 lr 3.35111e-07 
12/06/2021 21:15:24 - INFO - volta.train_utils -   [RetrievalWIT]: iter 58848 Ep: 1.88 loss 0.007 score 0.241 lr 3.28e-07 
12/06/2021 21:16:13 - INFO - volta.train_utils -   [RetrievalWIT]: iter 58928 Ep: 1.89 loss 0.009 score 0.237 lr 3.20889e-07 
12/06/2021 21:17:03 - INFO - volta.train_utils -   [RetrievalWIT]: iter 59008 Ep: 1.89 loss 0.009 score 0.239 lr 3.13778e-07 
12/06/2021 21:17:52 - INFO - volta.train_utils -   [RetrievalWIT]: iter 59088 Ep: 1.89 loss 0.010 score 0.238 lr 3.06667e-07 
12/06/2021 21:18:41 - INFO - volta.train_utils -   [RetrievalWIT]: iter 59168 Ep: 1.89 loss 0.007 score 0.237 lr 2.99556e-07 
12/06/2021 21:19:30 - INFO - volta.train_utils -   [RetrievalWIT]: iter 59248 Ep: 1.90 loss 0.009 score 0.240 lr 2.92444e-07 
12/06/2021 21:20:19 - INFO - volta.train_utils -   [RetrievalWIT]: iter 59328 Ep: 1.90 loss 0.012 score 0.237 lr 2.85333e-07 
12/06/2021 21:21:08 - INFO - volta.train_utils -   [RetrievalWIT]: iter 59408 Ep: 1.90 loss 0.014 score 0.233 lr 2.78222e-07 
12/06/2021 21:21:57 - INFO - volta.train_utils -   [RetrievalWIT]: iter 59488 Ep: 1.90 loss 0.008 score 0.236 lr 2.71111e-07 
12/06/2021 21:22:47 - INFO - volta.train_utils -   [RetrievalWIT]: iter 59568 Ep: 1.91 loss 0.010 score 0.238 lr 2.64e-07 
12/06/2021 21:23:36 - INFO - volta.train_utils -   [RetrievalWIT]: iter 59648 Ep: 1.91 loss 0.009 score 0.236 lr 2.56889e-07 
12/06/2021 21:24:25 - INFO - volta.train_utils -   [RetrievalWIT]: iter 59728 Ep: 1.91 loss 0.007 score 0.238 lr 2.49778e-07 
12/06/2021 21:25:14 - INFO - volta.train_utils -   [RetrievalWIT]: iter 59808 Ep: 1.91 loss 0.006 score 0.239 lr 2.42667e-07 
12/06/2021 21:26:03 - INFO - volta.train_utils -   [RetrievalWIT]: iter 59888 Ep: 1.92 loss 0.009 score 0.237 lr 2.35556e-07 
12/06/2021 21:26:52 - INFO - volta.train_utils -   [RetrievalWIT]: iter 59968 Ep: 1.92 loss 0.008 score 0.239 lr 2.28444e-07 
12/06/2021 21:27:42 - INFO - volta.train_utils -   [RetrievalWIT]: iter 60048 Ep: 1.92 loss 0.006 score 0.238 lr 2.21333e-07 
12/06/2021 21:28:31 - INFO - volta.train_utils -   [RetrievalWIT]: iter 60128 Ep: 1.92 loss 0.007 score 0.238 lr 2.14222e-07 
12/06/2021 21:29:20 - INFO - volta.train_utils -   [RetrievalWIT]: iter 60208 Ep: 1.93 loss 0.008 score 0.240 lr 2.07111e-07 
12/06/2021 21:30:09 - INFO - volta.train_utils -   [RetrievalWIT]: iter 60288 Ep: 1.93 loss 0.006 score 0.237 lr 2e-07 
12/06/2021 21:30:58 - INFO - volta.train_utils -   [RetrievalWIT]: iter 60368 Ep: 1.93 loss 0.007 score 0.239 lr 1.92889e-07 
12/06/2021 21:31:48 - INFO - volta.train_utils -   [RetrievalWIT]: iter 60448 Ep: 1.93 loss 0.006 score 0.240 lr 1.85778e-07 
12/06/2021 21:32:37 - INFO - volta.train_utils -   [RetrievalWIT]: iter 60528 Ep: 1.94 loss 0.008 score 0.239 lr 1.78667e-07 
12/06/2021 21:33:26 - INFO - volta.train_utils -   [RetrievalWIT]: iter 60608 Ep: 1.94 loss 0.007 score 0.239 lr 1.71556e-07 
12/06/2021 21:34:15 - INFO - volta.train_utils -   [RetrievalWIT]: iter 60688 Ep: 1.94 loss 0.007 score 0.239 lr 1.64444e-07 
12/06/2021 21:35:04 - INFO - volta.train_utils -   [RetrievalWIT]: iter 60768 Ep: 1.94 loss 0.005 score 0.242 lr 1.57333e-07 
12/06/2021 21:35:53 - INFO - volta.train_utils -   [RetrievalWIT]: iter 60848 Ep: 1.95 loss 0.007 score 0.238 lr 1.50222e-07 
12/06/2021 21:36:42 - INFO - volta.train_utils -   [RetrievalWIT]: iter 60928 Ep: 1.95 loss 0.006 score 0.240 lr 1.43111e-07 
12/06/2021 21:37:32 - INFO - volta.train_utils -   [RetrievalWIT]: iter 61008 Ep: 1.95 loss 0.008 score 0.241 lr 1.36e-07 
12/06/2021 21:38:21 - INFO - volta.train_utils -   [RetrievalWIT]: iter 61088 Ep: 1.95 loss 0.007 score 0.240 lr 1.28889e-07 
12/06/2021 21:39:10 - INFO - volta.train_utils -   [RetrievalWIT]: iter 61168 Ep: 1.96 loss 0.007 score 0.241 lr 1.21778e-07 
12/06/2021 21:39:59 - INFO - volta.train_utils -   [RetrievalWIT]: iter 61248 Ep: 1.96 loss 0.004 score 0.238 lr 1.14667e-07 
12/06/2021 21:40:48 - INFO - volta.train_utils -   [RetrievalWIT]: iter 61328 Ep: 1.96 loss 0.007 score 0.237 lr 1.07556e-07 
12/06/2021 21:41:38 - INFO - volta.train_utils -   [RetrievalWIT]: iter 61408 Ep: 1.97 loss 0.008 score 0.238 lr 1.00444e-07 
12/06/2021 21:42:27 - INFO - volta.train_utils -   [RetrievalWIT]: iter 61488 Ep: 1.97 loss 0.007 score 0.241 lr 9.33333e-08 
12/06/2021 21:43:16 - INFO - volta.train_utils -   [RetrievalWIT]: iter 61568 Ep: 1.97 loss 0.007 score 0.239 lr 8.62222e-08 
12/06/2021 21:44:05 - INFO - volta.train_utils -   [RetrievalWIT]: iter 61648 Ep: 1.97 loss 0.004 score 0.240 lr 7.91111e-08 
12/06/2021 21:44:55 - INFO - volta.train_utils -   [RetrievalWIT]: iter 61728 Ep: 1.98 loss 0.009 score 0.237 lr 7.2e-08 
12/06/2021 21:45:44 - INFO - volta.train_utils -   [RetrievalWIT]: iter 61808 Ep: 1.98 loss 0.009 score 0.236 lr 6.48889e-08 
12/06/2021 21:46:33 - INFO - volta.train_utils -   [RetrievalWIT]: iter 61888 Ep: 1.98 loss 0.008 score 0.238 lr 5.77778e-08 
12/06/2021 21:47:22 - INFO - volta.train_utils -   [RetrievalWIT]: iter 61968 Ep: 1.98 loss 0.006 score 0.240 lr 5.06667e-08 
12/06/2021 21:48:11 - INFO - volta.train_utils -   [RetrievalWIT]: iter 62048 Ep: 1.99 loss 0.008 score 0.239 lr 4.35556e-08 
12/06/2021 21:49:42 - INFO - volta.train_utils -   Eval task TASK20 on iteration 62092 
12/06/2021 21:49:42 - INFO - volta.train_utils -   Validation [RetrievalWIT]: loss 0.151 score 94.550 
12/06/2021 21:50:47 - INFO - volta.train_utils -   Eval task TASK20 on iteration 62092 
12/06/2021 21:50:47 - INFO - volta.train_utils -   Validation [RetrievalWIT]: loss 0.167 score 94.204 
12/06/2021 21:51:52 - INFO - volta.train_utils -   Eval task TASK20 on iteration 62092 
12/06/2021 21:51:52 - INFO - volta.train_utils -   Validation [RetrievalWIT]: loss 0.158 score 94.399 
12/06/2021 21:52:57 - INFO - volta.train_utils -   Eval task TASK20 on iteration 62096 
12/06/2021 21:52:57 - INFO - volta.train_utils -   Validation [RetrievalWIT]: loss 0.146 score 94.831 
12/06/2021 21:52:57 - INFO - __main__ -   ** ** * Saving model * ** ** 
12/06/2021 21:53:40 - INFO - volta.train_utils -   [RetrievalWIT]: iter 62128 Ep: 1.99 loss 0.006 score 0.239 lr 3.64444e-08 
12/06/2021 21:54:29 - INFO - volta.train_utils -   [RetrievalWIT]: iter 62208 Ep: 1.99 loss 0.011 score 0.236 lr 2.93333e-08 
12/06/2021 21:55:18 - INFO - volta.train_utils -   [RetrievalWIT]: iter 62288 Ep: 1.99 loss 0.005 score 0.241 lr 2.22222e-08 
12/06/2021 21:56:07 - INFO - volta.train_utils -   [RetrievalWIT]: iter 62368 Ep: 2.00 loss 0.006 score 0.239 lr 1.51111e-08 
12/06/2021 21:56:56 - INFO - volta.train_utils -   [RetrievalWIT]: iter 62448 Ep: 2.00 loss 0.007 score 0.237 lr 8e-09 
12/06/2021 21:58:31 - INFO - volta.train_utils -   Eval task TASK20 on iteration 62496 
12/06/2021 21:58:31 - INFO - volta.train_utils -   Validation [RetrievalWIT]: loss 0.148 score 94.485 
Epoch: 100%|██████████| 2/2 [11:53:12<00:00, 21343.08s/it] 
