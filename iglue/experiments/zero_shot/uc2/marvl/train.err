WARNING:tensorflow:From /home/projects/ku_00062/envs/iglue/lib/python3.6/site-packages/tensorpack/callbacks/hooks.py:17: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.

WARNING:tensorflow:From /home/projects/ku_00062/envs/iglue/lib/python3.6/site-packages/tensorpack/tfutils/optimizer.py:18: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

WARNING:tensorflow:From /home/projects/ku_00062/envs/iglue/lib/python3.6/site-packages/tensorpack/tfutils/sesscreate.py:20: The name tf.train.SessionCreator is deprecated. Please use tf.compat.v1.train.SessionCreator instead.

12/02/2021 19:39:25 - INFO - __main__ -   device: cuda n_gpu: 1, distributed training: False
12/02/2021 19:39:26 - INFO - volta.task_utils -   Loading NLVR2 Dataset with batch size 16
12/02/2021 19:39:26 - INFO - volta.train_utils -   logging file at: /home/projects/ku_00062/logs/iglue/marvl/uc2_base/NLVR2_uc2_base
12/02/2021 19:39:26 - INFO - volta.utils -   loading weights file /home/projects/ku_00062/checkpoints/iglue/pretrain/uc2/uc2_base/uc2_checkpoint_200000.bin
12/02/2021 19:39:42 - INFO - volta.utils -   
12/02/2021 19:39:43 - INFO - volta.utils -   Weights of BertForVLTasks not initialized from pretrained model: ['clfs_dict.TASK12.logit_fc.0.weight', 'clfs_dict.TASK12.logit_fc.0.bias', 'clfs_dict.TASK12.logit_fc.2.weight', 'clfs_dict.TASK12.logit_fc.2.bias', 'clfs_dict.TASK12.logit_fc.3.weight', 'clfs_dict.TASK12.logit_fc.3.bias']
12/02/2021 19:39:43 - INFO - volta.utils -   Weights from pretrained model not used in BertForVLTasks: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.bi_seq_relationship.weight', 'cls.bi_seq_relationship.bias', 'cls.imagePredictions.transform.dense.weight', 'cls.imagePredictions.transform.dense.bias', 'cls.imagePredictions.transform.LayerNorm.weight', 'cls.imagePredictions.transform.LayerNorm.bias', 'cls.imagePredictions.decoder_dict.0.weight', 'cls.imagePredictions.decoder_dict.0.bias']
12/02/2021 19:39:48 - INFO - __main__ -   ** ** * Saving model * ** ** 
/home/projects/ku_00062/envs/iglue/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:216: UserWarning: Please also save or load the state of the optimizer when saving or loading the scheduler.
  warnings.warn(SAVE_STATE_WARNING, UserWarning)
12/02/2021 19:39:58 - INFO - __main__ -   >> Parameters:
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |Name                                                       |Dtype            |Shape            |#Params      |Trainable|
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.embeddings.word_embeddings.weight                     |torch.float32    |(250002, 768)    |192001536    |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.embeddings.position_embeddings.weight                 |torch.float32    |(514, 768)       |394752       |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.embeddings.new_token_type_embeddings.weight           |torch.float32    |(2, 768)         |1536         |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.embeddings.LayerNorm.weight                           |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.embeddings.LayerNorm.bias                             |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.embeddings.image_embeddings.weight                    |torch.float32    |(768, 2048)      |1572864      |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.embeddings.image_embeddings.bias                      |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.embeddings.image_location_embeddings.weight           |torch.float32    |(768, 7)         |5376         |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.embeddings.image_location_embeddings.bias             |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.embeddings.image_layer_norm.weight                    |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.embeddings.image_layer_norm.bias                      |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.embeddings.image_location_layer_norm.weight           |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.embeddings.image_location_layer_norm.bias             |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.embeddings.v_LayerNorm.weight                         |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.embeddings.v_LayerNorm.bias                           |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.0.attention_self.query.weight           |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.0.attention_self.query.bias             |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.0.attention_self.key.weight             |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.0.attention_self.key.bias               |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.0.attention_self.value.weight           |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.0.attention_self.value.bias             |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.0.attention_output.dense.weight         |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.0.attention_output.dense.bias           |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.0.attention_output.LayerNorm.weight     |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.0.attention_output.LayerNorm.bias       |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.1.intermediate.dense.weight             |torch.float32    |(3072, 768)      |2359296      |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.1.intermediate.dense.bias               |torch.float32    |(3072,)          |3072         |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.1.output.dense.weight                   |torch.float32    |(768, 3072)      |2359296      |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.1.output.dense.bias                     |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.1.output.LayerNorm.weight               |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.1.output.LayerNorm.bias                 |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.2.attention_self.query.weight           |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.2.attention_self.query.bias             |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.2.attention_self.key.weight             |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.2.attention_self.key.bias               |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.2.attention_self.value.weight           |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.2.attention_self.value.bias             |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.2.attention_output.dense.weight         |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.2.attention_output.dense.bias           |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.2.attention_output.LayerNorm.weight     |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.2.attention_output.LayerNorm.bias       |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.3.intermediate.dense.weight             |torch.float32    |(3072, 768)      |2359296      |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.3.intermediate.dense.bias               |torch.float32    |(3072,)          |3072         |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.3.output.dense.weight                   |torch.float32    |(768, 3072)      |2359296      |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.3.output.dense.bias                     |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.3.output.LayerNorm.weight               |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.3.output.LayerNorm.bias                 |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.4.attention_self.query.weight           |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.4.attention_self.query.bias             |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.4.attention_self.key.weight             |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.4.attention_self.key.bias               |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.4.attention_self.value.weight           |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.4.attention_self.value.bias             |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.4.attention_output.dense.weight         |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.4.attention_output.dense.bias           |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.4.attention_output.LayerNorm.weight     |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.4.attention_output.LayerNorm.bias       |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.5.intermediate.dense.weight             |torch.float32    |(3072, 768)      |2359296      |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.5.intermediate.dense.bias               |torch.float32    |(3072,)          |3072         |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.5.output.dense.weight                   |torch.float32    |(768, 3072)      |2359296      |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.5.output.dense.bias                     |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.5.output.LayerNorm.weight               |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.5.output.LayerNorm.bias                 |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.6.attention_self.query.weight           |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.6.attention_self.query.bias             |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.6.attention_self.key.weight             |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.6.attention_self.key.bias               |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.6.attention_self.value.weight           |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.6.attention_self.value.bias             |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.6.attention_output.dense.weight         |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.6.attention_output.dense.bias           |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.6.attention_output.LayerNorm.weight     |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.6.attention_output.LayerNorm.bias       |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.7.intermediate.dense.weight             |torch.float32    |(3072, 768)      |2359296      |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.7.intermediate.dense.bias               |torch.float32    |(3072,)          |3072         |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.7.output.dense.weight                   |torch.float32    |(768, 3072)      |2359296      |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.7.output.dense.bias                     |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.7.output.LayerNorm.weight               |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.7.output.LayerNorm.bias                 |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.8.attention_self.query.weight           |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.8.attention_self.query.bias             |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.8.attention_self.key.weight             |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.8.attention_self.key.bias               |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.8.attention_self.value.weight           |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.8.attention_self.value.bias             |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.8.attention_output.dense.weight         |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.8.attention_output.dense.bias           |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.8.attention_output.LayerNorm.weight     |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.8.attention_output.LayerNorm.bias       |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.9.intermediate.dense.weight             |torch.float32    |(3072, 768)      |2359296      |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.9.intermediate.dense.bias               |torch.float32    |(3072,)          |3072         |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.9.output.dense.weight                   |torch.float32    |(768, 3072)      |2359296      |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.9.output.dense.bias                     |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.9.output.LayerNorm.weight               |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.9.output.LayerNorm.bias                 |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.10.attention_self.query.weight          |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.10.attention_self.query.bias            |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.10.attention_self.key.weight            |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.10.attention_self.key.bias              |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.10.attention_self.value.weight          |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.10.attention_self.value.bias            |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.10.attention_output.dense.weight        |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.10.attention_output.dense.bias          |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.10.attention_output.LayerNorm.weight    |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.10.attention_output.LayerNorm.bias      |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.11.intermediate.dense.weight            |torch.float32    |(3072, 768)      |2359296      |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.11.intermediate.dense.bias              |torch.float32    |(3072,)          |3072         |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.11.output.dense.weight                  |torch.float32    |(768, 3072)      |2359296      |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.11.output.dense.bias                    |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.11.output.LayerNorm.weight              |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.11.output.LayerNorm.bias                |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.12.attention_self.query.weight          |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.12.attention_self.query.bias            |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.12.attention_self.key.weight            |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.12.attention_self.key.bias              |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.12.attention_self.value.weight          |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.12.attention_self.value.bias            |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.12.attention_output.dense.weight        |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.12.attention_output.dense.bias          |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.12.attention_output.LayerNorm.weight    |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.12.attention_output.LayerNorm.bias      |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.13.intermediate.dense.weight            |torch.float32    |(3072, 768)      |2359296      |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.13.intermediate.dense.bias              |torch.float32    |(3072,)          |3072         |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.13.output.dense.weight                  |torch.float32    |(768, 3072)      |2359296      |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.13.output.dense.bias                    |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.13.output.LayerNorm.weight              |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.13.output.LayerNorm.bias                |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.14.attention_self.query.weight          |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.14.attention_self.query.bias            |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.14.attention_self.key.weight            |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.14.attention_self.key.bias              |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.14.attention_self.value.weight          |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.14.attention_self.value.bias            |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.14.attention_output.dense.weight        |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.14.attention_output.dense.bias          |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.14.attention_output.LayerNorm.weight    |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.14.attention_output.LayerNorm.bias      |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.15.intermediate.dense.weight            |torch.float32    |(3072, 768)      |2359296      |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.15.intermediate.dense.bias              |torch.float32    |(3072,)          |3072         |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.15.output.dense.weight                  |torch.float32    |(768, 3072)      |2359296      |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.15.output.dense.bias                    |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.15.output.LayerNorm.weight              |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.15.output.LayerNorm.bias                |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.16.attention_self.query.weight          |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.16.attention_self.query.bias            |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.16.attention_self.key.weight            |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.16.attention_self.key.bias              |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.16.attention_self.value.weight          |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.16.attention_self.value.bias            |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.16.attention_output.dense.weight        |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.16.attention_output.dense.bias          |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.16.attention_output.LayerNorm.weight    |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.16.attention_output.LayerNorm.bias      |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.17.intermediate.dense.weight            |torch.float32    |(3072, 768)      |2359296      |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.17.intermediate.dense.bias              |torch.float32    |(3072,)          |3072         |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.17.output.dense.weight                  |torch.float32    |(768, 3072)      |2359296      |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.17.output.dense.bias                    |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.17.output.LayerNorm.weight              |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.17.output.LayerNorm.bias                |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.18.attention_self.query.weight          |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.18.attention_self.query.bias            |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.18.attention_self.key.weight            |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.18.attention_self.key.bias              |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.18.attention_self.value.weight          |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.18.attention_self.value.bias            |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.18.attention_output.dense.weight        |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.18.attention_output.dense.bias          |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.18.attention_output.LayerNorm.weight    |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.18.attention_output.LayerNorm.bias      |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.19.intermediate.dense.weight            |torch.float32    |(3072, 768)      |2359296      |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.19.intermediate.dense.bias              |torch.float32    |(3072,)          |3072         |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.19.output.dense.weight                  |torch.float32    |(768, 3072)      |2359296      |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.19.output.dense.bias                    |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.19.output.LayerNorm.weight              |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.19.output.LayerNorm.bias                |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.20.attention_self.query.weight          |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.20.attention_self.query.bias            |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.20.attention_self.key.weight            |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.20.attention_self.key.bias              |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.20.attention_self.value.weight          |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.20.attention_self.value.bias            |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.20.attention_output.dense.weight        |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.20.attention_output.dense.bias          |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.20.attention_output.LayerNorm.weight    |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.20.attention_output.LayerNorm.bias      |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.21.intermediate.dense.weight            |torch.float32    |(3072, 768)      |2359296      |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.21.intermediate.dense.bias              |torch.float32    |(3072,)          |3072         |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.21.output.dense.weight                  |torch.float32    |(768, 3072)      |2359296      |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.21.output.dense.bias                    |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.21.output.LayerNorm.weight              |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.21.output.LayerNorm.bias                |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.22.attention_self.query.weight          |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.22.attention_self.query.bias            |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.22.attention_self.key.weight            |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.22.attention_self.key.bias              |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.22.attention_self.value.weight          |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.22.attention_self.value.bias            |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.22.attention_output.dense.weight        |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.22.attention_output.dense.bias          |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.22.attention_output.LayerNorm.weight    |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.22.attention_output.LayerNorm.bias      |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.23.intermediate.dense.weight            |torch.float32    |(3072, 768)      |2359296      |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.23.intermediate.dense.bias              |torch.float32    |(3072,)          |3072         |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.23.output.dense.weight                  |torch.float32    |(768, 3072)      |2359296      |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.23.output.dense.bias                    |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.23.output.LayerNorm.weight              |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.encoder.layer.23.output.LayerNorm.bias                |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.t_pooler.dense.weight                                 |torch.float32    |(768, 768)       |589824       |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |bert.t_pooler.dense.bias                                   |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |clfs_dict.TASK12.logit_fc.0.weight                         |torch.float32    |(768, 1536)      |1179648      |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |clfs_dict.TASK12.logit_fc.0.bias                           |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |clfs_dict.TASK12.logit_fc.2.weight                         |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |clfs_dict.TASK12.logit_fc.2.bias                           |torch.float32    |(768,)           |768          |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |clfs_dict.TASK12.logit_fc.3.weight                         |torch.float32    |(2, 768)         |1536         |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   |clfs_dict.TASK12.logit_fc.3.bias                           |torch.float32    |(2,)             |2            |True    |
12/02/2021 19:39:58 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
12/02/2021 19:39:58 - INFO - __main__ -   >> # TrainableParams:       	280.81	M
12/02/2021 19:39:58 - INFO - __main__ -   >> # NonTrainableParams:    	0.00	M
12/02/2021 19:39:58 - INFO - __main__ -   >> # TotalParams:           	280.81	M
Epoch:   0%|          | 0/20 [00:00<?, ?it/s]/home/projects/ku_00062/envs/iglue/lib/python3.6/site-packages/pytorch_transformers/optimization.py:166: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
12/02/2021 19:40:21 - INFO - volta.train_utils -   [NLVR2]: iter 80 Ep: 0.01 loss 0.045 score 0.121 lr 9.72582e-09 
12/02/2021 19:40:42 - INFO - volta.train_utils -   [NLVR2]: iter 160 Ep: 0.03 loss 0.045 score 0.124 lr 2.82512e-08 
12/02/2021 19:41:04 - INFO - volta.train_utils -   [NLVR2]: iter 240 Ep: 0.04 loss 0.044 score 0.119 lr 4.67766e-08 
12/02/2021 19:41:26 - INFO - volta.train_utils -   [NLVR2]: iter 320 Ep: 0.06 loss 0.044 score 0.126 lr 6.5302e-08 
12/02/2021 19:41:48 - INFO - volta.train_utils -   [NLVR2]: iter 400 Ep: 0.07 loss 0.044 score 0.125 lr 8.38273e-08 
12/02/2021 19:42:09 - INFO - volta.train_utils -   [NLVR2]: iter 480 Ep: 0.09 loss 0.044 score 0.125 lr 1.02353e-07 
12/02/2021 19:42:31 - INFO - volta.train_utils -   [NLVR2]: iter 560 Ep: 0.10 loss 0.044 score 0.121 lr 1.20878e-07 
12/02/2021 19:42:53 - INFO - volta.train_utils -   [NLVR2]: iter 640 Ep: 0.12 loss 0.044 score 0.122 lr 1.39403e-07 
12/02/2021 19:43:15 - INFO - volta.train_utils -   [NLVR2]: iter 720 Ep: 0.13 loss 0.044 score 0.126 lr 1.57929e-07 
12/02/2021 19:43:37 - INFO - volta.train_utils -   [NLVR2]: iter 800 Ep: 0.15 loss 0.044 score 0.123 lr 1.76454e-07 
12/02/2021 19:43:58 - INFO - volta.train_utils -   [NLVR2]: iter 880 Ep: 0.16 loss 0.044 score 0.124 lr 1.9498e-07 
12/02/2021 19:44:20 - INFO - volta.train_utils -   [NLVR2]: iter 960 Ep: 0.18 loss 0.044 score 0.127 lr 2.13505e-07 
12/02/2021 19:44:42 - INFO - volta.train_utils -   [NLVR2]: iter 1040 Ep: 0.19 loss 0.044 score 0.130 lr 2.3203e-07 
12/02/2021 19:45:04 - INFO - volta.train_utils -   [NLVR2]: iter 1120 Ep: 0.21 loss 0.044 score 0.118 lr 2.50556e-07 
12/02/2021 19:45:25 - INFO - volta.train_utils -   [NLVR2]: iter 1200 Ep: 0.22 loss 0.044 score 0.123 lr 2.69081e-07 
12/02/2021 19:45:47 - INFO - volta.train_utils -   [NLVR2]: iter 1280 Ep: 0.24 loss 0.044 score 0.130 lr 2.87607e-07 
12/02/2021 19:46:09 - INFO - volta.train_utils -   [NLVR2]: iter 1360 Ep: 0.25 loss 0.044 score 0.125 lr 3.06132e-07 
12/02/2021 19:46:31 - INFO - volta.train_utils -   [NLVR2]: iter 1440 Ep: 0.27 loss 0.044 score 0.122 lr 3.24657e-07 
12/02/2021 19:46:52 - INFO - volta.train_utils -   [NLVR2]: iter 1520 Ep: 0.28 loss 0.044 score 0.130 lr 3.43183e-07 
12/02/2021 19:47:14 - INFO - volta.train_utils -   [NLVR2]: iter 1600 Ep: 0.30 loss 0.044 score 0.128 lr 3.61708e-07 
12/02/2021 19:47:36 - INFO - volta.train_utils -   [NLVR2]: iter 1680 Ep: 0.31 loss 0.043 score 0.121 lr 3.80233e-07 
12/02/2021 19:47:57 - INFO - volta.train_utils -   [NLVR2]: iter 1760 Ep: 0.33 loss 0.044 score 0.130 lr 3.98759e-07 
12/02/2021 19:48:19 - INFO - volta.train_utils -   [NLVR2]: iter 1840 Ep: 0.34 loss 0.043 score 0.130 lr 4.17284e-07 
12/02/2021 19:48:41 - INFO - volta.train_utils -   [NLVR2]: iter 1920 Ep: 0.36 loss 0.044 score 0.126 lr 4.3581e-07 
12/02/2021 19:49:02 - INFO - volta.train_utils -   [NLVR2]: iter 2000 Ep: 0.37 loss 0.044 score 0.125 lr 4.54335e-07 
12/02/2021 19:49:24 - INFO - volta.train_utils -   [NLVR2]: iter 2080 Ep: 0.39 loss 0.044 score 0.120 lr 4.7286e-07 
12/02/2021 19:49:46 - INFO - volta.train_utils -   [NLVR2]: iter 2160 Ep: 0.40 loss 0.044 score 0.124 lr 4.91386e-07 
12/02/2021 19:50:08 - INFO - volta.train_utils -   [NLVR2]: iter 2240 Ep: 0.41 loss 0.044 score 0.121 lr 5.09911e-07 
12/02/2021 19:50:29 - INFO - volta.train_utils -   [NLVR2]: iter 2320 Ep: 0.43 loss 0.044 score 0.126 lr 5.28436e-07 
12/02/2021 19:50:51 - INFO - volta.train_utils -   [NLVR2]: iter 2400 Ep: 0.44 loss 0.044 score 0.125 lr 5.46962e-07 
12/02/2021 19:51:13 - INFO - volta.train_utils -   [NLVR2]: iter 2480 Ep: 0.46 loss 0.044 score 0.122 lr 5.65487e-07 
12/02/2021 19:51:35 - INFO - volta.train_utils -   [NLVR2]: iter 2560 Ep: 0.47 loss 0.044 score 0.130 lr 5.84013e-07 
12/02/2021 19:51:56 - INFO - volta.train_utils -   [NLVR2]: iter 2640 Ep: 0.49 loss 0.044 score 0.128 lr 6.02538e-07 
12/02/2021 19:52:18 - INFO - volta.train_utils -   [NLVR2]: iter 2720 Ep: 0.50 loss 0.043 score 0.126 lr 6.21063e-07 
12/02/2021 19:52:40 - INFO - volta.train_utils -   [NLVR2]: iter 2800 Ep: 0.52 loss 0.044 score 0.127 lr 6.39589e-07 
12/02/2021 19:53:01 - INFO - volta.train_utils -   [NLVR2]: iter 2880 Ep: 0.53 loss 0.044 score 0.121 lr 6.58114e-07 
12/02/2021 19:53:23 - INFO - volta.train_utils -   [NLVR2]: iter 2960 Ep: 0.55 loss 0.044 score 0.129 lr 6.76639e-07 
12/02/2021 19:53:45 - INFO - volta.train_utils -   [NLVR2]: iter 3040 Ep: 0.56 loss 0.044 score 0.130 lr 6.95165e-07 
12/02/2021 19:54:07 - INFO - volta.train_utils -   [NLVR2]: iter 3120 Ep: 0.58 loss 0.043 score 0.127 lr 7.1369e-07 
12/02/2021 19:54:28 - INFO - volta.train_utils -   [NLVR2]: iter 3200 Ep: 0.59 loss 0.043 score 0.123 lr 7.32216e-07 
12/02/2021 19:54:50 - INFO - volta.train_utils -   [NLVR2]: iter 3280 Ep: 0.61 loss 0.043 score 0.123 lr 7.50741e-07 
12/02/2021 19:55:12 - INFO - volta.train_utils -   [NLVR2]: iter 3360 Ep: 0.62 loss 0.044 score 0.129 lr 7.69266e-07 
12/02/2021 19:55:34 - INFO - volta.train_utils -   [NLVR2]: iter 3440 Ep: 0.64 loss 0.044 score 0.125 lr 7.87792e-07 
12/02/2021 19:55:55 - INFO - volta.train_utils -   [NLVR2]: iter 3520 Ep: 0.65 loss 0.043 score 0.129 lr 8.06317e-07 
12/02/2021 19:56:17 - INFO - volta.train_utils -   [NLVR2]: iter 3600 Ep: 0.67 loss 0.044 score 0.130 lr 8.24843e-07 
12/02/2021 19:56:39 - INFO - volta.train_utils -   [NLVR2]: iter 3680 Ep: 0.68 loss 0.043 score 0.130 lr 8.43368e-07 
12/02/2021 19:57:00 - INFO - volta.train_utils -   [NLVR2]: iter 3760 Ep: 0.70 loss 0.044 score 0.128 lr 8.61893e-07 
12/02/2021 19:57:22 - INFO - volta.train_utils -   [NLVR2]: iter 3840 Ep: 0.71 loss 0.044 score 0.129 lr 8.80419e-07 
12/02/2021 19:57:44 - INFO - volta.train_utils -   [NLVR2]: iter 3920 Ep: 0.73 loss 0.043 score 0.140 lr 8.98944e-07 
12/02/2021 19:58:06 - INFO - volta.train_utils -   [NLVR2]: iter 4000 Ep: 0.74 loss 0.043 score 0.137 lr 9.17469e-07 
12/02/2021 19:58:27 - INFO - volta.train_utils -   [NLVR2]: iter 4080 Ep: 0.76 loss 0.043 score 0.136 lr 9.35995e-07 
12/02/2021 19:58:49 - INFO - volta.train_utils -   [NLVR2]: iter 4160 Ep: 0.77 loss 0.044 score 0.133 lr 9.5452e-07 
12/02/2021 19:59:11 - INFO - volta.train_utils -   [NLVR2]: iter 4240 Ep: 0.79 loss 0.042 score 0.140 lr 9.73046e-07 
12/02/2021 19:59:32 - INFO - volta.train_utils -   [NLVR2]: iter 4320 Ep: 0.80 loss 0.044 score 0.133 lr 9.91571e-07 
12/02/2021 19:59:54 - INFO - volta.train_utils -   [NLVR2]: iter 4400 Ep: 0.82 loss 0.041 score 0.143 lr 1.0101e-06 
12/02/2021 20:00:16 - INFO - volta.train_utils -   [NLVR2]: iter 4480 Ep: 0.83 loss 0.043 score 0.135 lr 1.02862e-06 
12/02/2021 20:00:38 - INFO - volta.train_utils -   [NLVR2]: iter 4560 Ep: 0.84 loss 0.042 score 0.142 lr 1.04715e-06 
12/02/2021 20:00:59 - INFO - volta.train_utils -   [NLVR2]: iter 4640 Ep: 0.86 loss 0.043 score 0.139 lr 1.06567e-06 
12/02/2021 20:01:21 - INFO - volta.train_utils -   [NLVR2]: iter 4720 Ep: 0.87 loss 0.043 score 0.135 lr 1.0842e-06 
12/02/2021 20:01:43 - INFO - volta.train_utils -   [NLVR2]: iter 4800 Ep: 0.89 loss 0.043 score 0.139 lr 1.10272e-06 
12/02/2021 20:02:05 - INFO - volta.train_utils -   [NLVR2]: iter 4880 Ep: 0.90 loss 0.043 score 0.132 lr 1.12125e-06 
12/02/2021 20:02:26 - INFO - volta.train_utils -   [NLVR2]: iter 4960 Ep: 0.92 loss 0.043 score 0.138 lr 1.13977e-06 
12/02/2021 20:02:48 - INFO - volta.train_utils -   [NLVR2]: iter 5040 Ep: 0.93 loss 0.042 score 0.140 lr 1.1583e-06 
12/02/2021 20:03:10 - INFO - volta.train_utils -   [NLVR2]: iter 5120 Ep: 0.95 loss 0.042 score 0.142 lr 1.17682e-06 
12/02/2021 20:03:31 - INFO - volta.train_utils -   [NLVR2]: iter 5200 Ep: 0.96 loss 0.042 score 0.148 lr 1.19535e-06 
12/02/2021 20:03:53 - INFO - volta.train_utils -   [NLVR2]: iter 5280 Ep: 0.98 loss 0.042 score 0.142 lr 1.21388e-06 
12/02/2021 20:04:15 - INFO - volta.train_utils -   [NLVR2]: iter 5360 Ep: 0.99 loss 0.042 score 0.140 lr 1.2324e-06 
12/02/2021 20:05:08 - INFO - volta.train_utils -   Eval task TASK12 on iteration 5396 
12/02/2021 20:05:08 - INFO - volta.train_utils -   Validation [NLVR2]: loss 0.663 score 59.246 
12/02/2021 20:05:08 - INFO - __main__ -   ** ** * Saving model * ** ** 
Epoch:   5%|▌         | 1/20 [25:47<8:09:57, 1547.25s/it]12/02/2021 20:06:08 - INFO - volta.train_utils -   [NLVR2]: iter 5476 Ep: 1.01 loss 0.042 score 0.144 lr 1.25509e-06 
12/02/2021 20:06:29 - INFO - volta.train_utils -   [NLVR2]: iter 5556 Ep: 1.03 loss 0.040 score 0.145 lr 1.27779e-06 
12/02/2021 20:06:51 - INFO - volta.train_utils -   [NLVR2]: iter 5636 Ep: 1.04 loss 0.042 score 0.142 lr 1.29631e-06 
12/02/2021 20:07:13 - INFO - volta.train_utils -   [NLVR2]: iter 5716 Ep: 1.06 loss 0.042 score 0.141 lr 1.31484e-06 
12/02/2021 20:07:34 - INFO - volta.train_utils -   [NLVR2]: iter 5796 Ep: 1.07 loss 0.043 score 0.141 lr 1.33336e-06 
12/02/2021 20:07:56 - INFO - volta.train_utils -   [NLVR2]: iter 5876 Ep: 1.09 loss 0.043 score 0.145 lr 1.35189e-06 
12/02/2021 20:08:18 - INFO - volta.train_utils -   [NLVR2]: iter 5956 Ep: 1.10 loss 0.043 score 0.145 lr 1.37041e-06 
12/02/2021 20:08:40 - INFO - volta.train_utils -   [NLVR2]: iter 6036 Ep: 1.12 loss 0.041 score 0.141 lr 1.38894e-06 
12/02/2021 20:09:01 - INFO - volta.train_utils -   [NLVR2]: iter 6116 Ep: 1.13 loss 0.041 score 0.144 lr 1.40747e-06 
12/02/2021 20:09:23 - INFO - volta.train_utils -   [NLVR2]: iter 6196 Ep: 1.15 loss 0.042 score 0.141 lr 1.42599e-06 
12/02/2021 20:09:45 - INFO - volta.train_utils -   [NLVR2]: iter 6276 Ep: 1.16 loss 0.041 score 0.153 lr 1.44452e-06 
12/02/2021 20:10:07 - INFO - volta.train_utils -   [NLVR2]: iter 6356 Ep: 1.18 loss 0.042 score 0.142 lr 1.46304e-06 
12/02/2021 20:10:28 - INFO - volta.train_utils -   [NLVR2]: iter 6436 Ep: 1.19 loss 0.041 score 0.143 lr 1.48157e-06 
12/02/2021 20:10:50 - INFO - volta.train_utils -   [NLVR2]: iter 6516 Ep: 1.21 loss 0.042 score 0.151 lr 1.50009e-06 
12/02/2021 20:11:12 - INFO - volta.train_utils -   [NLVR2]: iter 6596 Ep: 1.22 loss 0.041 score 0.146 lr 1.51862e-06 
12/02/2021 20:11:33 - INFO - volta.train_utils -   [NLVR2]: iter 6676 Ep: 1.24 loss 0.041 score 0.150 lr 1.53714e-06 
12/02/2021 20:11:55 - INFO - volta.train_utils -   [NLVR2]: iter 6756 Ep: 1.25 loss 0.040 score 0.154 lr 1.55567e-06 
12/02/2021 20:12:17 - INFO - volta.train_utils -   [NLVR2]: iter 6836 Ep: 1.27 loss 0.043 score 0.144 lr 1.57419e-06 
12/02/2021 20:12:39 - INFO - volta.train_utils -   [NLVR2]: iter 6916 Ep: 1.28 loss 0.040 score 0.152 lr 1.59272e-06 
12/02/2021 20:13:00 - INFO - volta.train_utils -   [NLVR2]: iter 6996 Ep: 1.30 loss 0.041 score 0.150 lr 1.61124e-06 
12/02/2021 20:13:22 - INFO - volta.train_utils -   [NLVR2]: iter 7076 Ep: 1.31 loss 0.042 score 0.146 lr 1.62977e-06 
12/02/2021 20:13:44 - INFO - volta.train_utils -   [NLVR2]: iter 7156 Ep: 1.33 loss 0.041 score 0.147 lr 1.6483e-06 
12/02/2021 20:14:06 - INFO - volta.train_utils -   [NLVR2]: iter 7236 Ep: 1.34 loss 0.041 score 0.146 lr 1.66682e-06 
12/02/2021 20:14:27 - INFO - volta.train_utils -   [NLVR2]: iter 7316 Ep: 1.36 loss 0.041 score 0.148 lr 1.68535e-06 
12/02/2021 20:14:49 - INFO - volta.train_utils -   [NLVR2]: iter 7396 Ep: 1.37 loss 0.040 score 0.152 lr 1.70387e-06 
12/02/2021 20:15:11 - INFO - volta.train_utils -   [NLVR2]: iter 7476 Ep: 1.38 loss 0.042 score 0.148 lr 1.7224e-06 
12/02/2021 20:15:33 - INFO - volta.train_utils -   [NLVR2]: iter 7556 Ep: 1.40 loss 0.041 score 0.144 lr 1.74092e-06 
12/02/2021 20:15:54 - INFO - volta.train_utils -   [NLVR2]: iter 7636 Ep: 1.41 loss 0.041 score 0.146 lr 1.75945e-06 
12/02/2021 20:16:16 - INFO - volta.train_utils -   [NLVR2]: iter 7716 Ep: 1.43 loss 0.042 score 0.148 lr 1.77797e-06 
12/02/2021 20:16:38 - INFO - volta.train_utils -   [NLVR2]: iter 7796 Ep: 1.44 loss 0.041 score 0.149 lr 1.7965e-06 
12/02/2021 20:17:00 - INFO - volta.train_utils -   [NLVR2]: iter 7876 Ep: 1.46 loss 0.040 score 0.155 lr 1.81502e-06 
12/02/2021 20:17:21 - INFO - volta.train_utils -   [NLVR2]: iter 7956 Ep: 1.47 loss 0.041 score 0.152 lr 1.83355e-06 
12/02/2021 20:17:43 - INFO - volta.train_utils -   [NLVR2]: iter 8036 Ep: 1.49 loss 0.039 score 0.150 lr 1.85207e-06 
12/02/2021 20:18:05 - INFO - volta.train_utils -   [NLVR2]: iter 8116 Ep: 1.50 loss 0.042 score 0.146 lr 1.8706e-06 
12/02/2021 20:18:26 - INFO - volta.train_utils -   [NLVR2]: iter 8196 Ep: 1.52 loss 0.041 score 0.150 lr 1.88913e-06 
12/02/2021 20:18:48 - INFO - volta.train_utils -   [NLVR2]: iter 8276 Ep: 1.53 loss 0.041 score 0.161 lr 1.90765e-06 
12/02/2021 20:19:10 - INFO - volta.train_utils -   [NLVR2]: iter 8356 Ep: 1.55 loss 0.040 score 0.149 lr 1.92618e-06 
12/02/2021 20:19:32 - INFO - volta.train_utils -   [NLVR2]: iter 8436 Ep: 1.56 loss 0.040 score 0.155 lr 1.9447e-06 
12/02/2021 20:19:53 - INFO - volta.train_utils -   [NLVR2]: iter 8516 Ep: 1.58 loss 0.040 score 0.148 lr 1.96323e-06 
12/02/2021 20:20:15 - INFO - volta.train_utils -   [NLVR2]: iter 8596 Ep: 1.59 loss 0.041 score 0.153 lr 1.98175e-06 
12/02/2021 20:20:37 - INFO - volta.train_utils -   [NLVR2]: iter 8676 Ep: 1.61 loss 0.041 score 0.149 lr 2.00028e-06 
12/02/2021 20:20:58 - INFO - volta.train_utils -   [NLVR2]: iter 8756 Ep: 1.62 loss 0.038 score 0.158 lr 2.0188e-06 
12/02/2021 20:21:20 - INFO - volta.train_utils -   [NLVR2]: iter 8836 Ep: 1.64 loss 0.040 score 0.146 lr 2.03733e-06 
12/02/2021 20:21:42 - INFO - volta.train_utils -   [NLVR2]: iter 8916 Ep: 1.65 loss 0.042 score 0.158 lr 2.05585e-06 
12/02/2021 20:22:04 - INFO - volta.train_utils -   [NLVR2]: iter 8996 Ep: 1.67 loss 0.040 score 0.153 lr 2.07438e-06 
12/02/2021 20:22:25 - INFO - volta.train_utils -   [NLVR2]: iter 9076 Ep: 1.68 loss 0.040 score 0.151 lr 2.0929e-06 
12/02/2021 20:22:47 - INFO - volta.train_utils -   [NLVR2]: iter 9156 Ep: 1.70 loss 0.040 score 0.154 lr 2.11143e-06 
12/02/2021 20:23:09 - INFO - volta.train_utils -   [NLVR2]: iter 9236 Ep: 1.71 loss 0.041 score 0.149 lr 2.12996e-06 
12/02/2021 20:23:30 - INFO - volta.train_utils -   [NLVR2]: iter 9316 Ep: 1.73 loss 0.040 score 0.164 lr 2.14848e-06 
12/02/2021 20:23:52 - INFO - volta.train_utils -   [NLVR2]: iter 9396 Ep: 1.74 loss 0.041 score 0.150 lr 2.16701e-06 
12/02/2021 20:24:15 - INFO - volta.train_utils -   [NLVR2]: iter 9476 Ep: 1.76 loss 0.039 score 0.158 lr 2.18553e-06 
12/02/2021 20:24:37 - INFO - volta.train_utils -   [NLVR2]: iter 9556 Ep: 1.77 loss 0.040 score 0.154 lr 2.20406e-06 
12/02/2021 20:24:59 - INFO - volta.train_utils -   [NLVR2]: iter 9636 Ep: 1.79 loss 0.041 score 0.156 lr 2.22258e-06 
12/02/2021 20:25:21 - INFO - volta.train_utils -   [NLVR2]: iter 9716 Ep: 1.80 loss 0.042 score 0.155 lr 2.24111e-06 
12/02/2021 20:25:42 - INFO - volta.train_utils -   [NLVR2]: iter 9796 Ep: 1.81 loss 0.040 score 0.152 lr 2.25963e-06 
12/02/2021 20:26:04 - INFO - volta.train_utils -   [NLVR2]: iter 9876 Ep: 1.83 loss 0.041 score 0.155 lr 2.27816e-06 
12/02/2021 20:26:26 - INFO - volta.train_utils -   [NLVR2]: iter 9956 Ep: 1.84 loss 0.039 score 0.167 lr 2.29668e-06 
12/02/2021 20:26:47 - INFO - volta.train_utils -   [NLVR2]: iter 10036 Ep: 1.86 loss 0.037 score 0.164 lr 2.31521e-06 
12/02/2021 20:27:09 - INFO - volta.train_utils -   [NLVR2]: iter 10116 Ep: 1.87 loss 0.037 score 0.158 lr 2.33373e-06 
12/02/2021 20:27:31 - INFO - volta.train_utils -   [NLVR2]: iter 10196 Ep: 1.89 loss 0.040 score 0.154 lr 2.35226e-06 
12/02/2021 20:27:53 - INFO - volta.train_utils -   [NLVR2]: iter 10276 Ep: 1.90 loss 0.041 score 0.152 lr 2.37079e-06 
12/02/2021 20:28:14 - INFO - volta.train_utils -   [NLVR2]: iter 10356 Ep: 1.92 loss 0.040 score 0.155 lr 2.38931e-06 
12/02/2021 20:28:36 - INFO - volta.train_utils -   [NLVR2]: iter 10436 Ep: 1.93 loss 0.039 score 0.156 lr 2.40784e-06 
12/02/2021 20:28:58 - INFO - volta.train_utils -   [NLVR2]: iter 10516 Ep: 1.95 loss 0.039 score 0.158 lr 2.42636e-06 
12/02/2021 20:29:20 - INFO - volta.train_utils -   [NLVR2]: iter 10596 Ep: 1.96 loss 0.037 score 0.163 lr 2.44489e-06 
12/02/2021 20:29:41 - INFO - volta.train_utils -   [NLVR2]: iter 10676 Ep: 1.98 loss 0.040 score 0.159 lr 2.46341e-06 
12/02/2021 20:30:03 - INFO - volta.train_utils -   [NLVR2]: iter 10756 Ep: 1.99 loss 0.038 score 0.158 lr 2.48194e-06 
12/02/2021 20:30:56 - INFO - volta.train_utils -   Eval task TASK12 on iteration 10792 
12/02/2021 20:30:56 - INFO - volta.train_utils -   Validation [NLVR2]: loss 0.623 score 64.521 
12/02/2021 20:30:56 - INFO - __main__ -   ** ** * Saving model * ** ** 
Epoch:  10%|█         | 2/20 [51:33<7:44:06, 1547.01s/it]12/02/2021 20:31:54 - INFO - volta.train_utils -   [NLVR2]: iter 10872 Ep: 2.01 loss 0.038 score 0.160 lr 2.49789e-06 
12/02/2021 20:32:16 - INFO - volta.train_utils -   [NLVR2]: iter 10952 Ep: 2.03 loss 0.040 score 0.157 lr 2.49696e-06 
12/02/2021 20:32:38 - INFO - volta.train_utils -   [NLVR2]: iter 11032 Ep: 2.04 loss 0.039 score 0.163 lr 2.49491e-06 
12/02/2021 20:32:59 - INFO - volta.train_utils -   [NLVR2]: iter 11112 Ep: 2.06 loss 0.042 score 0.154 lr 2.49285e-06 
12/02/2021 20:33:21 - INFO - volta.train_utils -   [NLVR2]: iter 11192 Ep: 2.07 loss 0.039 score 0.160 lr 2.49079e-06 
12/02/2021 20:33:43 - INFO - volta.train_utils -   [NLVR2]: iter 11272 Ep: 2.09 loss 0.040 score 0.156 lr 2.48873e-06 
12/02/2021 20:34:04 - INFO - volta.train_utils -   [NLVR2]: iter 11352 Ep: 2.10 loss 0.039 score 0.159 lr 2.48667e-06 
12/02/2021 20:34:26 - INFO - volta.train_utils -   [NLVR2]: iter 11432 Ep: 2.12 loss 0.040 score 0.161 lr 2.48461e-06 
12/02/2021 20:34:48 - INFO - volta.train_utils -   [NLVR2]: iter 11512 Ep: 2.13 loss 0.039 score 0.156 lr 2.48256e-06 
12/02/2021 20:35:09 - INFO - volta.train_utils -   [NLVR2]: iter 11592 Ep: 2.15 loss 0.040 score 0.161 lr 2.4805e-06 
12/02/2021 20:35:31 - INFO - volta.train_utils -   [NLVR2]: iter 11672 Ep: 2.16 loss 0.041 score 0.151 lr 2.47844e-06 
12/02/2021 20:35:53 - INFO - volta.train_utils -   [NLVR2]: iter 11752 Ep: 2.18 loss 0.039 score 0.159 lr 2.47638e-06 
12/02/2021 20:36:15 - INFO - volta.train_utils -   [NLVR2]: iter 11832 Ep: 2.19 loss 0.038 score 0.162 lr 2.47432e-06 
12/02/2021 20:36:37 - INFO - volta.train_utils -   [NLVR2]: iter 11912 Ep: 2.21 loss 0.040 score 0.158 lr 2.47226e-06 
12/02/2021 20:36:58 - INFO - volta.train_utils -   [NLVR2]: iter 11992 Ep: 2.22 loss 0.038 score 0.163 lr 2.47021e-06 
12/02/2021 20:37:20 - INFO - volta.train_utils -   [NLVR2]: iter 12072 Ep: 2.24 loss 0.039 score 0.160 lr 2.46815e-06 
12/02/2021 20:37:42 - INFO - volta.train_utils -   [NLVR2]: iter 12152 Ep: 2.25 loss 0.039 score 0.165 lr 2.46609e-06 
12/02/2021 20:38:04 - INFO - volta.train_utils -   [NLVR2]: iter 12232 Ep: 2.27 loss 0.038 score 0.166 lr 2.46403e-06 
12/02/2021 20:38:25 - INFO - volta.train_utils -   [NLVR2]: iter 12312 Ep: 2.28 loss 0.036 score 0.159 lr 2.46197e-06 
12/02/2021 20:38:47 - INFO - volta.train_utils -   [NLVR2]: iter 12392 Ep: 2.30 loss 0.037 score 0.158 lr 2.45991e-06 
12/02/2021 20:39:09 - INFO - volta.train_utils -   [NLVR2]: iter 12472 Ep: 2.31 loss 0.040 score 0.161 lr 2.45785e-06 
12/02/2021 20:39:30 - INFO - volta.train_utils -   [NLVR2]: iter 12552 Ep: 2.33 loss 0.038 score 0.162 lr 2.4558e-06 
12/02/2021 20:39:52 - INFO - volta.train_utils -   [NLVR2]: iter 12632 Ep: 2.34 loss 0.038 score 0.165 lr 2.45374e-06 
12/02/2021 20:40:14 - INFO - volta.train_utils -   [NLVR2]: iter 12712 Ep: 2.35 loss 0.036 score 0.162 lr 2.45168e-06 
12/02/2021 20:40:35 - INFO - volta.train_utils -   [NLVR2]: iter 12792 Ep: 2.37 loss 0.039 score 0.168 lr 2.44962e-06 
12/02/2021 20:40:57 - INFO - volta.train_utils -   [NLVR2]: iter 12872 Ep: 2.38 loss 0.038 score 0.159 lr 2.44756e-06 
12/02/2021 20:41:19 - INFO - volta.train_utils -   [NLVR2]: iter 12952 Ep: 2.40 loss 0.039 score 0.163 lr 2.4455e-06 
12/02/2021 20:41:41 - INFO - volta.train_utils -   [NLVR2]: iter 13032 Ep: 2.41 loss 0.040 score 0.164 lr 2.44345e-06 
12/02/2021 20:42:02 - INFO - volta.train_utils -   [NLVR2]: iter 13112 Ep: 2.43 loss 0.039 score 0.160 lr 2.44139e-06 
12/02/2021 20:42:24 - INFO - volta.train_utils -   [NLVR2]: iter 13192 Ep: 2.44 loss 0.037 score 0.160 lr 2.43933e-06 
12/02/2021 20:42:46 - INFO - volta.train_utils -   [NLVR2]: iter 13272 Ep: 2.46 loss 0.036 score 0.168 lr 2.43727e-06 
12/02/2021 20:43:08 - INFO - volta.train_utils -   [NLVR2]: iter 13352 Ep: 2.47 loss 0.037 score 0.160 lr 2.43521e-06 
12/02/2021 20:43:29 - INFO - volta.train_utils -   [NLVR2]: iter 13432 Ep: 2.49 loss 0.038 score 0.154 lr 2.43315e-06 
12/02/2021 20:43:51 - INFO - volta.train_utils -   [NLVR2]: iter 13512 Ep: 2.50 loss 0.039 score 0.166 lr 2.4311e-06 
12/02/2021 20:44:13 - INFO - volta.train_utils -   [NLVR2]: iter 13592 Ep: 2.52 loss 0.039 score 0.169 lr 2.42904e-06 
12/02/2021 20:44:34 - INFO - volta.train_utils -   [NLVR2]: iter 13672 Ep: 2.53 loss 0.037 score 0.166 lr 2.42698e-06 
12/02/2021 20:44:56 - INFO - volta.train_utils -   [NLVR2]: iter 13752 Ep: 2.55 loss 0.038 score 0.166 lr 2.42492e-06 
12/02/2021 20:45:18 - INFO - volta.train_utils -   [NLVR2]: iter 13832 Ep: 2.56 loss 0.038 score 0.163 lr 2.42286e-06 
12/02/2021 20:45:40 - INFO - volta.train_utils -   [NLVR2]: iter 13912 Ep: 2.58 loss 0.040 score 0.168 lr 2.4208e-06 
12/02/2021 20:46:01 - INFO - volta.train_utils -   [NLVR2]: iter 13992 Ep: 2.59 loss 0.035 score 0.163 lr 2.41875e-06 
12/02/2021 20:46:23 - INFO - volta.train_utils -   [NLVR2]: iter 14072 Ep: 2.61 loss 0.037 score 0.159 lr 2.41669e-06 
12/02/2021 20:46:45 - INFO - volta.train_utils -   [NLVR2]: iter 14152 Ep: 2.62 loss 0.037 score 0.163 lr 2.41463e-06 
12/02/2021 20:47:07 - INFO - volta.train_utils -   [NLVR2]: iter 14232 Ep: 2.64 loss 0.039 score 0.159 lr 2.41257e-06 
12/02/2021 20:47:28 - INFO - volta.train_utils -   [NLVR2]: iter 14312 Ep: 2.65 loss 0.039 score 0.163 lr 2.41051e-06 
12/02/2021 20:47:50 - INFO - volta.train_utils -   [NLVR2]: iter 14392 Ep: 2.67 loss 0.038 score 0.161 lr 2.40845e-06 
12/02/2021 20:48:12 - INFO - volta.train_utils -   [NLVR2]: iter 14472 Ep: 2.68 loss 0.039 score 0.163 lr 2.4064e-06 
12/02/2021 20:48:34 - INFO - volta.train_utils -   [NLVR2]: iter 14552 Ep: 2.70 loss 0.036 score 0.167 lr 2.40434e-06 
12/02/2021 20:48:55 - INFO - volta.train_utils -   [NLVR2]: iter 14632 Ep: 2.71 loss 0.038 score 0.169 lr 2.40228e-06 
12/02/2021 20:49:17 - INFO - volta.train_utils -   [NLVR2]: iter 14712 Ep: 2.73 loss 0.037 score 0.166 lr 2.40022e-06 
12/02/2021 20:49:39 - INFO - volta.train_utils -   [NLVR2]: iter 14792 Ep: 2.74 loss 0.037 score 0.166 lr 2.39816e-06 
12/02/2021 20:50:00 - INFO - volta.train_utils -   [NLVR2]: iter 14872 Ep: 2.76 loss 0.038 score 0.162 lr 2.3961e-06 
12/02/2021 20:50:22 - INFO - volta.train_utils -   [NLVR2]: iter 14952 Ep: 2.77 loss 0.036 score 0.168 lr 2.39405e-06 
12/02/2021 20:50:44 - INFO - volta.train_utils -   [NLVR2]: iter 15032 Ep: 2.78 loss 0.038 score 0.163 lr 2.39199e-06 
12/02/2021 20:51:06 - INFO - volta.train_utils -   [NLVR2]: iter 15112 Ep: 2.80 loss 0.038 score 0.162 lr 2.38993e-06 
12/02/2021 20:51:27 - INFO - volta.train_utils -   [NLVR2]: iter 15192 Ep: 2.81 loss 0.036 score 0.170 lr 2.38787e-06 
12/02/2021 20:51:49 - INFO - volta.train_utils -   [NLVR2]: iter 15272 Ep: 2.83 loss 0.037 score 0.167 lr 2.38581e-06 
12/02/2021 20:52:11 - INFO - volta.train_utils -   [NLVR2]: iter 15352 Ep: 2.84 loss 0.037 score 0.171 lr 2.38375e-06 
12/02/2021 20:52:33 - INFO - volta.train_utils -   [NLVR2]: iter 15432 Ep: 2.86 loss 0.038 score 0.169 lr 2.38169e-06 
12/02/2021 20:52:54 - INFO - volta.train_utils -   [NLVR2]: iter 15512 Ep: 2.87 loss 0.036 score 0.180 lr 2.37964e-06 
12/02/2021 20:53:16 - INFO - volta.train_utils -   [NLVR2]: iter 15592 Ep: 2.89 loss 0.035 score 0.172 lr 2.37758e-06 
12/02/2021 20:53:38 - INFO - volta.train_utils -   [NLVR2]: iter 15672 Ep: 2.90 loss 0.038 score 0.164 lr 2.37552e-06 
12/02/2021 20:53:59 - INFO - volta.train_utils -   [NLVR2]: iter 15752 Ep: 2.92 loss 0.038 score 0.168 lr 2.37346e-06 
12/02/2021 20:54:21 - INFO - volta.train_utils -   [NLVR2]: iter 15832 Ep: 2.93 loss 0.036 score 0.168 lr 2.3714e-06 
12/02/2021 20:54:43 - INFO - volta.train_utils -   [NLVR2]: iter 15912 Ep: 2.95 loss 0.038 score 0.168 lr 2.36934e-06 
12/02/2021 20:55:05 - INFO - volta.train_utils -   [NLVR2]: iter 15992 Ep: 2.96 loss 0.035 score 0.171 lr 2.36729e-06 
12/02/2021 20:55:26 - INFO - volta.train_utils -   [NLVR2]: iter 16072 Ep: 2.98 loss 0.037 score 0.167 lr 2.36523e-06 
12/02/2021 20:55:48 - INFO - volta.train_utils -   [NLVR2]: iter 16152 Ep: 2.99 loss 0.037 score 0.171 lr 2.36317e-06 
12/02/2021 20:56:41 - INFO - volta.train_utils -   Eval task TASK12 on iteration 16188 
12/02/2021 20:56:41 - INFO - volta.train_utils -   Validation [NLVR2]: loss 0.616 score 66.643 
12/02/2021 20:56:41 - INFO - __main__ -   ** ** * Saving model * ** ** 
Epoch:  15%|█▌        | 3/20 [1:17:17<7:18:03, 1546.11s/it]12/02/2021 20:57:38 - INFO - volta.train_utils -   [NLVR2]: iter 16268 Ep: 3.01 loss 0.038 score 0.174 lr 2.36065e-06 
12/02/2021 20:58:00 - INFO - volta.train_utils -   [NLVR2]: iter 16348 Ep: 3.03 loss 0.036 score 0.171 lr 2.35813e-06 
12/02/2021 20:58:22 - INFO - volta.train_utils -   [NLVR2]: iter 16428 Ep: 3.04 loss 0.037 score 0.168 lr 2.35607e-06 
12/02/2021 20:58:43 - INFO - volta.train_utils -   [NLVR2]: iter 16508 Ep: 3.06 loss 0.036 score 0.167 lr 2.35401e-06 
12/02/2021 20:59:05 - INFO - volta.train_utils -   [NLVR2]: iter 16588 Ep: 3.07 loss 0.034 score 0.171 lr 2.35195e-06 
12/02/2021 20:59:27 - INFO - volta.train_utils -   [NLVR2]: iter 16668 Ep: 3.09 loss 0.037 score 0.168 lr 2.34989e-06 
12/02/2021 20:59:49 - INFO - volta.train_utils -   [NLVR2]: iter 16748 Ep: 3.10 loss 0.036 score 0.167 lr 2.34783e-06 
12/02/2021 21:00:11 - INFO - volta.train_utils -   [NLVR2]: iter 16828 Ep: 3.12 loss 0.039 score 0.166 lr 2.34578e-06 
12/02/2021 21:00:33 - INFO - volta.train_utils -   [NLVR2]: iter 16908 Ep: 3.13 loss 0.035 score 0.166 lr 2.34372e-06 
12/02/2021 21:00:55 - INFO - volta.train_utils -   [NLVR2]: iter 16988 Ep: 3.15 loss 0.037 score 0.165 lr 2.34166e-06 
12/02/2021 21:01:16 - INFO - volta.train_utils -   [NLVR2]: iter 17068 Ep: 3.16 loss 0.034 score 0.170 lr 2.3396e-06 
12/02/2021 21:01:38 - INFO - volta.train_utils -   [NLVR2]: iter 17148 Ep: 3.18 loss 0.037 score 0.169 lr 2.33754e-06 
12/02/2021 21:02:00 - INFO - volta.train_utils -   [NLVR2]: iter 17228 Ep: 3.19 loss 0.036 score 0.166 lr 2.33548e-06 
12/02/2021 21:02:21 - INFO - volta.train_utils -   [NLVR2]: iter 17308 Ep: 3.21 loss 0.035 score 0.171 lr 2.33343e-06 
12/02/2021 21:02:43 - INFO - volta.train_utils -   [NLVR2]: iter 17388 Ep: 3.22 loss 0.035 score 0.174 lr 2.33137e-06 
12/02/2021 21:03:05 - INFO - volta.train_utils -   [NLVR2]: iter 17468 Ep: 3.24 loss 0.036 score 0.174 lr 2.32931e-06 
12/02/2021 21:03:27 - INFO - volta.train_utils -   [NLVR2]: iter 17548 Ep: 3.25 loss 0.039 score 0.170 lr 2.32725e-06 
12/02/2021 21:03:48 - INFO - volta.train_utils -   [NLVR2]: iter 17628 Ep: 3.27 loss 0.038 score 0.174 lr 2.32519e-06 
12/02/2021 21:04:10 - INFO - volta.train_utils -   [NLVR2]: iter 17708 Ep: 3.28 loss 0.036 score 0.168 lr 2.32313e-06 
12/02/2021 21:04:32 - INFO - volta.train_utils -   [NLVR2]: iter 17788 Ep: 3.30 loss 0.037 score 0.170 lr 2.32108e-06 
12/02/2021 21:04:54 - INFO - volta.train_utils -   [NLVR2]: iter 17868 Ep: 3.31 loss 0.036 score 0.169 lr 2.31902e-06 
12/02/2021 21:05:15 - INFO - volta.train_utils -   [NLVR2]: iter 17948 Ep: 3.32 loss 0.037 score 0.171 lr 2.31696e-06 
12/02/2021 21:05:37 - INFO - volta.train_utils -   [NLVR2]: iter 18028 Ep: 3.34 loss 0.034 score 0.178 lr 2.3149e-06 
12/02/2021 21:05:59 - INFO - volta.train_utils -   [NLVR2]: iter 18108 Ep: 3.35 loss 0.035 score 0.170 lr 2.31284e-06 
12/02/2021 21:06:20 - INFO - volta.train_utils -   [NLVR2]: iter 18188 Ep: 3.37 loss 0.037 score 0.176 lr 2.31078e-06 
12/02/2021 21:06:42 - INFO - volta.train_utils -   [NLVR2]: iter 18268 Ep: 3.38 loss 0.035 score 0.172 lr 2.30873e-06 
12/02/2021 21:07:04 - INFO - volta.train_utils -   [NLVR2]: iter 18348 Ep: 3.40 loss 0.035 score 0.171 lr 2.30667e-06 
12/02/2021 21:07:26 - INFO - volta.train_utils -   [NLVR2]: iter 18428 Ep: 3.41 loss 0.033 score 0.177 lr 2.30461e-06 
12/02/2021 21:07:47 - INFO - volta.train_utils -   [NLVR2]: iter 18508 Ep: 3.43 loss 0.035 score 0.170 lr 2.30255e-06 
12/02/2021 21:08:09 - INFO - volta.train_utils -   [NLVR2]: iter 18588 Ep: 3.44 loss 0.032 score 0.172 lr 2.30049e-06 
12/02/2021 21:08:31 - INFO - volta.train_utils -   [NLVR2]: iter 18668 Ep: 3.46 loss 0.037 score 0.166 lr 2.29843e-06 
12/02/2021 21:08:53 - INFO - volta.train_utils -   [NLVR2]: iter 18748 Ep: 3.47 loss 0.037 score 0.162 lr 2.29638e-06 
12/02/2021 21:09:14 - INFO - volta.train_utils -   [NLVR2]: iter 18828 Ep: 3.49 loss 0.036 score 0.173 lr 2.29432e-06 
12/02/2021 21:09:36 - INFO - volta.train_utils -   [NLVR2]: iter 18908 Ep: 3.50 loss 0.035 score 0.179 lr 2.29226e-06 
12/02/2021 21:09:58 - INFO - volta.train_utils -   [NLVR2]: iter 18988 Ep: 3.52 loss 0.034 score 0.175 lr 2.2902e-06 
12/02/2021 21:10:20 - INFO - volta.train_utils -   [NLVR2]: iter 19068 Ep: 3.53 loss 0.037 score 0.175 lr 2.28814e-06 
12/02/2021 21:10:41 - INFO - volta.train_utils -   [NLVR2]: iter 19148 Ep: 3.55 loss 0.035 score 0.174 lr 2.28608e-06 
12/02/2021 21:11:03 - INFO - volta.train_utils -   [NLVR2]: iter 19228 Ep: 3.56 loss 0.035 score 0.175 lr 2.28402e-06 
12/02/2021 21:11:25 - INFO - volta.train_utils -   [NLVR2]: iter 19308 Ep: 3.58 loss 0.033 score 0.173 lr 2.28197e-06 
12/02/2021 21:11:46 - INFO - volta.train_utils -   [NLVR2]: iter 19388 Ep: 3.59 loss 0.034 score 0.172 lr 2.27991e-06 
12/02/2021 21:12:08 - INFO - volta.train_utils -   [NLVR2]: iter 19468 Ep: 3.61 loss 0.034 score 0.176 lr 2.27785e-06 
12/02/2021 21:12:30 - INFO - volta.train_utils -   [NLVR2]: iter 19548 Ep: 3.62 loss 0.038 score 0.169 lr 2.27579e-06 
12/02/2021 21:12:52 - INFO - volta.train_utils -   [NLVR2]: iter 19628 Ep: 3.64 loss 0.038 score 0.170 lr 2.27373e-06 
12/02/2021 21:13:13 - INFO - volta.train_utils -   [NLVR2]: iter 19708 Ep: 3.65 loss 0.037 score 0.171 lr 2.27167e-06 
12/02/2021 21:13:35 - INFO - volta.train_utils -   [NLVR2]: iter 19788 Ep: 3.67 loss 0.037 score 0.169 lr 2.26962e-06 
12/02/2021 21:13:57 - INFO - volta.train_utils -   [NLVR2]: iter 19868 Ep: 3.68 loss 0.037 score 0.174 lr 2.26756e-06 
12/02/2021 21:14:19 - INFO - volta.train_utils -   [NLVR2]: iter 19948 Ep: 3.70 loss 0.032 score 0.175 lr 2.2655e-06 
12/02/2021 21:14:40 - INFO - volta.train_utils -   [NLVR2]: iter 20028 Ep: 3.71 loss 0.033 score 0.174 lr 2.26344e-06 
12/02/2021 21:15:02 - INFO - volta.train_utils -   [NLVR2]: iter 20108 Ep: 3.73 loss 0.036 score 0.173 lr 2.26138e-06 
12/02/2021 21:15:24 - INFO - volta.train_utils -   [NLVR2]: iter 20188 Ep: 3.74 loss 0.034 score 0.173 lr 2.25932e-06 
12/02/2021 21:15:45 - INFO - volta.train_utils -   [NLVR2]: iter 20268 Ep: 3.75 loss 0.036 score 0.171 lr 2.25727e-06 
12/02/2021 21:16:07 - INFO - volta.train_utils -   [NLVR2]: iter 20348 Ep: 3.77 loss 0.034 score 0.177 lr 2.25521e-06 
12/02/2021 21:16:29 - INFO - volta.train_utils -   [NLVR2]: iter 20428 Ep: 3.78 loss 0.036 score 0.172 lr 2.25315e-06 
12/02/2021 21:16:51 - INFO - volta.train_utils -   [NLVR2]: iter 20508 Ep: 3.80 loss 0.035 score 0.179 lr 2.25109e-06 
12/02/2021 21:17:13 - INFO - volta.train_utils -   [NLVR2]: iter 20588 Ep: 3.81 loss 0.033 score 0.180 lr 2.24903e-06 
12/02/2021 21:17:35 - INFO - volta.train_utils -   [NLVR2]: iter 20668 Ep: 3.83 loss 0.034 score 0.177 lr 2.24697e-06 
12/02/2021 21:17:56 - INFO - volta.train_utils -   [NLVR2]: iter 20748 Ep: 3.84 loss 0.037 score 0.174 lr 2.24492e-06 
12/02/2021 21:18:18 - INFO - volta.train_utils -   [NLVR2]: iter 20828 Ep: 3.86 loss 0.034 score 0.177 lr 2.24286e-06 
12/02/2021 21:18:40 - INFO - volta.train_utils -   [NLVR2]: iter 20908 Ep: 3.87 loss 0.035 score 0.171 lr 2.2408e-06 
12/02/2021 21:19:02 - INFO - volta.train_utils -   [NLVR2]: iter 20988 Ep: 3.89 loss 0.038 score 0.173 lr 2.23874e-06 
12/02/2021 21:19:24 - INFO - volta.train_utils -   [NLVR2]: iter 21068 Ep: 3.90 loss 0.034 score 0.174 lr 2.23668e-06 
12/02/2021 21:19:46 - INFO - volta.train_utils -   [NLVR2]: iter 21148 Ep: 3.92 loss 0.032 score 0.182 lr 2.23462e-06 
12/02/2021 21:20:07 - INFO - volta.train_utils -   [NLVR2]: iter 21228 Ep: 3.93 loss 0.033 score 0.174 lr 2.23257e-06 
12/02/2021 21:20:29 - INFO - volta.train_utils -   [NLVR2]: iter 21308 Ep: 3.95 loss 0.035 score 0.177 lr 2.23051e-06 
12/02/2021 21:20:51 - INFO - volta.train_utils -   [NLVR2]: iter 21388 Ep: 3.96 loss 0.033 score 0.177 lr 2.22845e-06 
12/02/2021 21:21:12 - INFO - volta.train_utils -   [NLVR2]: iter 21468 Ep: 3.98 loss 0.034 score 0.174 lr 2.22639e-06 
12/02/2021 21:21:34 - INFO - volta.train_utils -   [NLVR2]: iter 21548 Ep: 3.99 loss 0.037 score 0.176 lr 2.22433e-06 
12/02/2021 21:22:27 - INFO - volta.train_utils -   Eval task TASK12 on iteration 21584 
12/02/2021 21:22:27 - INFO - volta.train_utils -   Validation [NLVR2]: loss 0.610 score 67.288 
12/02/2021 21:22:27 - INFO - __main__ -   ** ** * Saving model * ** ** 
Epoch:  20%|██        | 4/20 [1:43:01<6:52:05, 1545.34s/it]12/02/2021 21:23:22 - INFO - volta.train_utils -   [NLVR2]: iter 21664 Ep: 4.01 loss 0.036 score 0.180 lr 2.22181e-06 
12/02/2021 21:23:43 - INFO - volta.train_utils -   [NLVR2]: iter 21744 Ep: 4.03 loss 0.035 score 0.177 lr 2.21929e-06 
12/02/2021 21:24:05 - INFO - volta.train_utils -   [NLVR2]: iter 21824 Ep: 4.04 loss 0.033 score 0.178 lr 2.21723e-06 
12/02/2021 21:24:27 - INFO - volta.train_utils -   [NLVR2]: iter 21904 Ep: 4.06 loss 0.032 score 0.174 lr 2.21517e-06 
12/02/2021 21:24:48 - INFO - volta.train_utils -   [NLVR2]: iter 21984 Ep: 4.07 loss 0.034 score 0.179 lr 2.21311e-06 
12/02/2021 21:25:10 - INFO - volta.train_utils -   [NLVR2]: iter 22064 Ep: 4.09 loss 0.036 score 0.173 lr 2.21106e-06 
12/02/2021 21:25:32 - INFO - volta.train_utils -   [NLVR2]: iter 22144 Ep: 4.10 loss 0.031 score 0.180 lr 2.209e-06 
12/02/2021 21:25:54 - INFO - volta.train_utils -   [NLVR2]: iter 22224 Ep: 4.12 loss 0.037 score 0.175 lr 2.20694e-06 
12/02/2021 21:26:15 - INFO - volta.train_utils -   [NLVR2]: iter 22304 Ep: 4.13 loss 0.035 score 0.179 lr 2.20488e-06 
12/02/2021 21:26:37 - INFO - volta.train_utils -   [NLVR2]: iter 22384 Ep: 4.15 loss 0.034 score 0.177 lr 2.20282e-06 
12/02/2021 21:26:59 - INFO - volta.train_utils -   [NLVR2]: iter 22464 Ep: 4.16 loss 0.033 score 0.175 lr 2.20076e-06 
12/02/2021 21:27:20 - INFO - volta.train_utils -   [NLVR2]: iter 22544 Ep: 4.18 loss 0.036 score 0.175 lr 2.19871e-06 
12/02/2021 21:27:42 - INFO - volta.train_utils -   [NLVR2]: iter 22624 Ep: 4.19 loss 0.032 score 0.173 lr 2.19665e-06 
12/02/2021 21:28:04 - INFO - volta.train_utils -   [NLVR2]: iter 22704 Ep: 4.21 loss 0.035 score 0.177 lr 2.19459e-06 
12/02/2021 21:28:26 - INFO - volta.train_utils -   [NLVR2]: iter 22784 Ep: 4.22 loss 0.035 score 0.172 lr 2.19253e-06 
12/02/2021 21:28:47 - INFO - volta.train_utils -   [NLVR2]: iter 22864 Ep: 4.24 loss 0.034 score 0.175 lr 2.19047e-06 
12/02/2021 21:29:09 - INFO - volta.train_utils -   [NLVR2]: iter 22944 Ep: 4.25 loss 0.034 score 0.176 lr 2.18841e-06 
12/02/2021 21:29:31 - INFO - volta.train_utils -   [NLVR2]: iter 23024 Ep: 4.27 loss 0.036 score 0.177 lr 2.18636e-06 
12/02/2021 21:29:53 - INFO - volta.train_utils -   [NLVR2]: iter 23104 Ep: 4.28 loss 0.034 score 0.183 lr 2.1843e-06 
12/02/2021 21:30:14 - INFO - volta.train_utils -   [NLVR2]: iter 23184 Ep: 4.29 loss 0.033 score 0.184 lr 2.18224e-06 
12/02/2021 21:30:36 - INFO - volta.train_utils -   [NLVR2]: iter 23264 Ep: 4.31 loss 0.033 score 0.176 lr 2.18018e-06 
12/02/2021 21:30:58 - INFO - volta.train_utils -   [NLVR2]: iter 23344 Ep: 4.32 loss 0.034 score 0.182 lr 2.17812e-06 
12/02/2021 21:31:20 - INFO - volta.train_utils -   [NLVR2]: iter 23424 Ep: 4.34 loss 0.032 score 0.183 lr 2.17606e-06 
12/02/2021 21:31:41 - INFO - volta.train_utils -   [NLVR2]: iter 23504 Ep: 4.35 loss 0.036 score 0.181 lr 2.174e-06 
12/02/2021 21:32:03 - INFO - volta.train_utils -   [NLVR2]: iter 23584 Ep: 4.37 loss 0.031 score 0.180 lr 2.17195e-06 
12/02/2021 21:32:25 - INFO - volta.train_utils -   [NLVR2]: iter 23664 Ep: 4.38 loss 0.033 score 0.182 lr 2.16989e-06 
12/02/2021 21:32:46 - INFO - volta.train_utils -   [NLVR2]: iter 23744 Ep: 4.40 loss 0.032 score 0.181 lr 2.16783e-06 
12/02/2021 21:33:08 - INFO - volta.train_utils -   [NLVR2]: iter 23824 Ep: 4.41 loss 0.035 score 0.172 lr 2.16577e-06 
12/02/2021 21:33:30 - INFO - volta.train_utils -   [NLVR2]: iter 23904 Ep: 4.43 loss 0.033 score 0.179 lr 2.16371e-06 
12/02/2021 21:33:52 - INFO - volta.train_utils -   [NLVR2]: iter 23984 Ep: 4.44 loss 0.035 score 0.177 lr 2.16165e-06 
12/02/2021 21:34:14 - INFO - volta.train_utils -   [NLVR2]: iter 24064 Ep: 4.46 loss 0.034 score 0.179 lr 2.1596e-06 
12/02/2021 21:34:36 - INFO - volta.train_utils -   [NLVR2]: iter 24144 Ep: 4.47 loss 0.032 score 0.179 lr 2.15754e-06 
12/02/2021 21:34:58 - INFO - volta.train_utils -   [NLVR2]: iter 24224 Ep: 4.49 loss 0.034 score 0.177 lr 2.15548e-06 
12/02/2021 21:35:20 - INFO - volta.train_utils -   [NLVR2]: iter 24304 Ep: 4.50 loss 0.034 score 0.177 lr 2.15342e-06 
12/02/2021 21:35:41 - INFO - volta.train_utils -   [NLVR2]: iter 24384 Ep: 4.52 loss 0.034 score 0.175 lr 2.15136e-06 
12/02/2021 21:36:03 - INFO - volta.train_utils -   [NLVR2]: iter 24464 Ep: 4.53 loss 0.029 score 0.185 lr 2.1493e-06 
12/02/2021 21:36:25 - INFO - volta.train_utils -   [NLVR2]: iter 24544 Ep: 4.55 loss 0.033 score 0.175 lr 2.14725e-06 
12/02/2021 21:36:47 - INFO - volta.train_utils -   [NLVR2]: iter 24624 Ep: 4.56 loss 0.034 score 0.184 lr 2.14519e-06 
12/02/2021 21:37:08 - INFO - volta.train_utils -   [NLVR2]: iter 24704 Ep: 4.58 loss 0.032 score 0.179 lr 2.14313e-06 
12/02/2021 21:37:30 - INFO - volta.train_utils -   [NLVR2]: iter 24784 Ep: 4.59 loss 0.034 score 0.177 lr 2.14107e-06 
12/02/2021 21:37:52 - INFO - volta.train_utils -   [NLVR2]: iter 24864 Ep: 4.61 loss 0.034 score 0.177 lr 2.13901e-06 
12/02/2021 21:38:13 - INFO - volta.train_utils -   [NLVR2]: iter 24944 Ep: 4.62 loss 0.033 score 0.178 lr 2.13695e-06 
12/02/2021 21:38:35 - INFO - volta.train_utils -   [NLVR2]: iter 25024 Ep: 4.64 loss 0.033 score 0.177 lr 2.1349e-06 
12/02/2021 21:38:57 - INFO - volta.train_utils -   [NLVR2]: iter 25104 Ep: 4.65 loss 0.032 score 0.181 lr 2.13284e-06 
12/02/2021 21:39:19 - INFO - volta.train_utils -   [NLVR2]: iter 25184 Ep: 4.67 loss 0.031 score 0.186 lr 2.13078e-06 
12/02/2021 21:39:40 - INFO - volta.train_utils -   [NLVR2]: iter 25264 Ep: 4.68 loss 0.033 score 0.180 lr 2.12872e-06 
12/02/2021 21:40:02 - INFO - volta.train_utils -   [NLVR2]: iter 25344 Ep: 4.70 loss 0.033 score 0.175 lr 2.12666e-06 
12/02/2021 21:40:24 - INFO - volta.train_utils -   [NLVR2]: iter 25424 Ep: 4.71 loss 0.032 score 0.180 lr 2.1246e-06 
12/02/2021 21:40:46 - INFO - volta.train_utils -   [NLVR2]: iter 25504 Ep: 4.72 loss 0.030 score 0.180 lr 2.12255e-06 
12/02/2021 21:41:07 - INFO - volta.train_utils -   [NLVR2]: iter 25584 Ep: 4.74 loss 0.034 score 0.174 lr 2.12049e-06 
12/02/2021 21:41:29 - INFO - volta.train_utils -   [NLVR2]: iter 25664 Ep: 4.75 loss 0.033 score 0.181 lr 2.11843e-06 
12/02/2021 21:41:51 - INFO - volta.train_utils -   [NLVR2]: iter 25744 Ep: 4.77 loss 0.034 score 0.181 lr 2.11637e-06 
12/02/2021 21:42:13 - INFO - volta.train_utils -   [NLVR2]: iter 25824 Ep: 4.78 loss 0.032 score 0.181 lr 2.11431e-06 
12/02/2021 21:42:34 - INFO - volta.train_utils -   [NLVR2]: iter 25904 Ep: 4.80 loss 0.029 score 0.186 lr 2.11225e-06 
12/02/2021 21:42:56 - INFO - volta.train_utils -   [NLVR2]: iter 25984 Ep: 4.81 loss 0.031 score 0.187 lr 2.1102e-06 
12/02/2021 21:43:18 - INFO - volta.train_utils -   [NLVR2]: iter 26064 Ep: 4.83 loss 0.031 score 0.182 lr 2.10814e-06 
12/02/2021 21:43:40 - INFO - volta.train_utils -   [NLVR2]: iter 26144 Ep: 4.84 loss 0.033 score 0.178 lr 2.10608e-06 
12/02/2021 21:44:01 - INFO - volta.train_utils -   [NLVR2]: iter 26224 Ep: 4.86 loss 0.028 score 0.187 lr 2.10402e-06 
12/02/2021 21:44:23 - INFO - volta.train_utils -   [NLVR2]: iter 26304 Ep: 4.87 loss 0.028 score 0.188 lr 2.10196e-06 
12/02/2021 21:44:45 - INFO - volta.train_utils -   [NLVR2]: iter 26384 Ep: 4.89 loss 0.033 score 0.180 lr 2.0999e-06 
12/02/2021 21:45:06 - INFO - volta.train_utils -   [NLVR2]: iter 26464 Ep: 4.90 loss 0.031 score 0.185 lr 2.09784e-06 
12/02/2021 21:45:28 - INFO - volta.train_utils -   [NLVR2]: iter 26544 Ep: 4.92 loss 0.033 score 0.186 lr 2.09579e-06 
12/02/2021 21:45:50 - INFO - volta.train_utils -   [NLVR2]: iter 26624 Ep: 4.93 loss 0.031 score 0.186 lr 2.09373e-06 
12/02/2021 21:46:12 - INFO - volta.train_utils -   [NLVR2]: iter 26704 Ep: 4.95 loss 0.035 score 0.181 lr 2.09167e-06 
12/02/2021 21:46:33 - INFO - volta.train_utils -   [NLVR2]: iter 26784 Ep: 4.96 loss 0.033 score 0.183 lr 2.08961e-06 
12/02/2021 21:46:55 - INFO - volta.train_utils -   [NLVR2]: iter 26864 Ep: 4.98 loss 0.030 score 0.186 lr 2.08755e-06 
12/02/2021 21:47:17 - INFO - volta.train_utils -   [NLVR2]: iter 26944 Ep: 4.99 loss 0.029 score 0.190 lr 2.08549e-06 
12/02/2021 21:48:10 - INFO - volta.train_utils -   Eval task TASK12 on iteration 26980 
12/02/2021 21:48:10 - INFO - volta.train_utils -   Validation [NLVR2]: loss 0.684 score 66.901 
Epoch:  25%|██▌       | 5/20 [2:08:11<6:23:43, 1534.92s/it]12/02/2021 21:48:32 - INFO - volta.train_utils -   [NLVR2]: iter 27060 Ep: 5.01 loss 0.027 score 0.189 lr 2.08297e-06 
12/02/2021 21:48:54 - INFO - volta.train_utils -   [NLVR2]: iter 27140 Ep: 5.03 loss 0.032 score 0.179 lr 2.08045e-06 
12/02/2021 21:49:16 - INFO - volta.train_utils -   [NLVR2]: iter 27220 Ep: 5.04 loss 0.030 score 0.185 lr 2.07839e-06 
12/02/2021 21:49:37 - INFO - volta.train_utils -   [NLVR2]: iter 27300 Ep: 5.06 loss 0.031 score 0.182 lr 2.07633e-06 
12/02/2021 21:49:59 - INFO - volta.train_utils -   [NLVR2]: iter 27380 Ep: 5.07 loss 0.030 score 0.183 lr 2.07428e-06 
12/02/2021 21:50:21 - INFO - volta.train_utils -   [NLVR2]: iter 27460 Ep: 5.09 loss 0.035 score 0.179 lr 2.07222e-06 
12/02/2021 21:50:42 - INFO - volta.train_utils -   [NLVR2]: iter 27540 Ep: 5.10 loss 0.038 score 0.177 lr 2.07016e-06 
12/02/2021 21:51:04 - INFO - volta.train_utils -   [NLVR2]: iter 27620 Ep: 5.12 loss 0.033 score 0.179 lr 2.0681e-06 
12/02/2021 21:51:26 - INFO - volta.train_utils -   [NLVR2]: iter 27700 Ep: 5.13 loss 0.035 score 0.180 lr 2.06604e-06 
12/02/2021 21:51:48 - INFO - volta.train_utils -   [NLVR2]: iter 27780 Ep: 5.15 loss 0.030 score 0.185 lr 2.06398e-06 
12/02/2021 21:52:09 - INFO - volta.train_utils -   [NLVR2]: iter 27860 Ep: 5.16 loss 0.031 score 0.183 lr 2.06193e-06 
12/02/2021 21:52:31 - INFO - volta.train_utils -   [NLVR2]: iter 27940 Ep: 5.18 loss 0.033 score 0.183 lr 2.05987e-06 
12/02/2021 21:52:53 - INFO - volta.train_utils -   [NLVR2]: iter 28020 Ep: 5.19 loss 0.030 score 0.180 lr 2.05781e-06 
12/02/2021 21:53:15 - INFO - volta.train_utils -   [NLVR2]: iter 28100 Ep: 5.21 loss 0.030 score 0.187 lr 2.05575e-06 
12/02/2021 21:53:36 - INFO - volta.train_utils -   [NLVR2]: iter 28180 Ep: 5.22 loss 0.035 score 0.179 lr 2.05369e-06 
12/02/2021 21:53:58 - INFO - volta.train_utils -   [NLVR2]: iter 28260 Ep: 5.24 loss 0.033 score 0.183 lr 2.05163e-06 
12/02/2021 21:54:20 - INFO - volta.train_utils -   [NLVR2]: iter 28340 Ep: 5.25 loss 0.030 score 0.189 lr 2.04958e-06 
12/02/2021 21:54:42 - INFO - volta.train_utils -   [NLVR2]: iter 28420 Ep: 5.26 loss 0.029 score 0.184 lr 2.04752e-06 
12/02/2021 21:55:03 - INFO - volta.train_utils -   [NLVR2]: iter 28500 Ep: 5.28 loss 0.030 score 0.187 lr 2.04546e-06 
12/02/2021 21:55:25 - INFO - volta.train_utils -   [NLVR2]: iter 28580 Ep: 5.29 loss 0.034 score 0.184 lr 2.0434e-06 
12/02/2021 21:55:47 - INFO - volta.train_utils -   [NLVR2]: iter 28660 Ep: 5.31 loss 0.030 score 0.187 lr 2.04134e-06 
12/02/2021 21:56:08 - INFO - volta.train_utils -   [NLVR2]: iter 28740 Ep: 5.32 loss 0.032 score 0.182 lr 2.03928e-06 
12/02/2021 21:56:30 - INFO - volta.train_utils -   [NLVR2]: iter 28820 Ep: 5.34 loss 0.028 score 0.190 lr 2.03723e-06 
12/02/2021 21:56:52 - INFO - volta.train_utils -   [NLVR2]: iter 28900 Ep: 5.35 loss 0.034 score 0.188 lr 2.03517e-06 
12/02/2021 21:57:14 - INFO - volta.train_utils -   [NLVR2]: iter 28980 Ep: 5.37 loss 0.030 score 0.187 lr 2.03311e-06 
12/02/2021 21:57:35 - INFO - volta.train_utils -   [NLVR2]: iter 29060 Ep: 5.38 loss 0.030 score 0.186 lr 2.03105e-06 
12/02/2021 21:57:57 - INFO - volta.train_utils -   [NLVR2]: iter 29140 Ep: 5.40 loss 0.030 score 0.188 lr 2.02899e-06 
12/02/2021 21:58:19 - INFO - volta.train_utils -   [NLVR2]: iter 29220 Ep: 5.41 loss 0.032 score 0.184 lr 2.02693e-06 
12/02/2021 21:58:41 - INFO - volta.train_utils -   [NLVR2]: iter 29300 Ep: 5.43 loss 0.032 score 0.184 lr 2.02488e-06 
12/02/2021 21:59:02 - INFO - volta.train_utils -   [NLVR2]: iter 29380 Ep: 5.44 loss 0.033 score 0.183 lr 2.02282e-06 
12/02/2021 21:59:24 - INFO - volta.train_utils -   [NLVR2]: iter 29460 Ep: 5.46 loss 0.032 score 0.179 lr 2.02076e-06 
12/02/2021 21:59:46 - INFO - volta.train_utils -   [NLVR2]: iter 29540 Ep: 5.47 loss 0.028 score 0.185 lr 2.0187e-06 
12/02/2021 22:00:08 - INFO - volta.train_utils -   [NLVR2]: iter 29620 Ep: 5.49 loss 0.035 score 0.184 lr 2.01664e-06 
12/02/2021 22:00:29 - INFO - volta.train_utils -   [NLVR2]: iter 29700 Ep: 5.50 loss 0.032 score 0.185 lr 2.01458e-06 
12/02/2021 22:00:51 - INFO - volta.train_utils -   [NLVR2]: iter 29780 Ep: 5.52 loss 0.029 score 0.184 lr 2.01253e-06 
12/02/2021 22:01:13 - INFO - volta.train_utils -   [NLVR2]: iter 29860 Ep: 5.53 loss 0.029 score 0.186 lr 2.01047e-06 
12/02/2021 22:01:34 - INFO - volta.train_utils -   [NLVR2]: iter 29940 Ep: 5.55 loss 0.030 score 0.189 lr 2.00841e-06 
12/02/2021 22:01:56 - INFO - volta.train_utils -   [NLVR2]: iter 30020 Ep: 5.56 loss 0.031 score 0.188 lr 2.00635e-06 
12/02/2021 22:02:18 - INFO - volta.train_utils -   [NLVR2]: iter 30100 Ep: 5.58 loss 0.031 score 0.185 lr 2.00429e-06 
12/02/2021 22:02:40 - INFO - volta.train_utils -   [NLVR2]: iter 30180 Ep: 5.59 loss 0.030 score 0.182 lr 2.00223e-06 
12/02/2021 22:03:01 - INFO - volta.train_utils -   [NLVR2]: iter 30260 Ep: 5.61 loss 0.034 score 0.187 lr 2.00017e-06 
12/02/2021 22:03:23 - INFO - volta.train_utils -   [NLVR2]: iter 30340 Ep: 5.62 loss 0.030 score 0.182 lr 1.99812e-06 
12/02/2021 22:03:45 - INFO - volta.train_utils -   [NLVR2]: iter 30420 Ep: 5.64 loss 0.033 score 0.181 lr 1.99606e-06 
12/02/2021 22:04:07 - INFO - volta.train_utils -   [NLVR2]: iter 30500 Ep: 5.65 loss 0.029 score 0.187 lr 1.994e-06 
12/02/2021 22:04:28 - INFO - volta.train_utils -   [NLVR2]: iter 30580 Ep: 5.67 loss 0.031 score 0.186 lr 1.99194e-06 
12/02/2021 22:04:50 - INFO - volta.train_utils -   [NLVR2]: iter 30660 Ep: 5.68 loss 0.033 score 0.183 lr 1.98988e-06 
12/02/2021 22:05:12 - INFO - volta.train_utils -   [NLVR2]: iter 30740 Ep: 5.69 loss 0.033 score 0.184 lr 1.98782e-06 
12/02/2021 22:05:34 - INFO - volta.train_utils -   [NLVR2]: iter 30820 Ep: 5.71 loss 0.030 score 0.185 lr 1.98577e-06 
12/02/2021 22:05:55 - INFO - volta.train_utils -   [NLVR2]: iter 30900 Ep: 5.72 loss 0.033 score 0.187 lr 1.98371e-06 
12/02/2021 22:06:17 - INFO - volta.train_utils -   [NLVR2]: iter 30980 Ep: 5.74 loss 0.030 score 0.189 lr 1.98165e-06 
12/02/2021 22:06:39 - INFO - volta.train_utils -   [NLVR2]: iter 31060 Ep: 5.75 loss 0.033 score 0.187 lr 1.97959e-06 
12/02/2021 22:07:01 - INFO - volta.train_utils -   [NLVR2]: iter 31140 Ep: 5.77 loss 0.030 score 0.191 lr 1.97753e-06 
12/02/2021 22:07:22 - INFO - volta.train_utils -   [NLVR2]: iter 31220 Ep: 5.78 loss 0.031 score 0.185 lr 1.97547e-06 
12/02/2021 22:07:44 - INFO - volta.train_utils -   [NLVR2]: iter 31300 Ep: 5.80 loss 0.029 score 0.189 lr 1.97342e-06 
12/02/2021 22:08:06 - INFO - volta.train_utils -   [NLVR2]: iter 31380 Ep: 5.81 loss 0.030 score 0.189 lr 1.97136e-06 
12/02/2021 22:08:28 - INFO - volta.train_utils -   [NLVR2]: iter 31460 Ep: 5.83 loss 0.034 score 0.189 lr 1.9693e-06 
12/02/2021 22:08:50 - INFO - volta.train_utils -   [NLVR2]: iter 31540 Ep: 5.84 loss 0.031 score 0.187 lr 1.96724e-06 
12/02/2021 22:09:12 - INFO - volta.train_utils -   [NLVR2]: iter 31620 Ep: 5.86 loss 0.029 score 0.193 lr 1.96518e-06 
12/02/2021 22:09:33 - INFO - volta.train_utils -   [NLVR2]: iter 31700 Ep: 5.87 loss 0.028 score 0.192 lr 1.96312e-06 
12/02/2021 22:09:55 - INFO - volta.train_utils -   [NLVR2]: iter 31780 Ep: 5.89 loss 0.029 score 0.189 lr 1.96107e-06 
12/02/2021 22:10:17 - INFO - volta.train_utils -   [NLVR2]: iter 31860 Ep: 5.90 loss 0.029 score 0.189 lr 1.95901e-06 
12/02/2021 22:10:39 - INFO - volta.train_utils -   [NLVR2]: iter 31940 Ep: 5.92 loss 0.031 score 0.189 lr 1.95695e-06 
12/02/2021 22:11:00 - INFO - volta.train_utils -   [NLVR2]: iter 32020 Ep: 5.93 loss 0.029 score 0.192 lr 1.95489e-06 
12/02/2021 22:11:22 - INFO - volta.train_utils -   [NLVR2]: iter 32100 Ep: 5.95 loss 0.031 score 0.191 lr 1.95283e-06 
12/02/2021 22:11:44 - INFO - volta.train_utils -   [NLVR2]: iter 32180 Ep: 5.96 loss 0.029 score 0.191 lr 1.95077e-06 
12/02/2021 22:12:06 - INFO - volta.train_utils -   [NLVR2]: iter 32260 Ep: 5.98 loss 0.028 score 0.193 lr 1.94872e-06 
12/02/2021 22:12:27 - INFO - volta.train_utils -   [NLVR2]: iter 32340 Ep: 5.99 loss 0.029 score 0.185 lr 1.94666e-06 
12/02/2021 22:13:20 - INFO - volta.train_utils -   Eval task TASK12 on iteration 32376 
12/02/2021 22:13:20 - INFO - volta.train_utils -   Validation [NLVR2]: loss 0.657 score 66.213 
Epoch:  30%|███       | 6/20 [2:33:22<5:56:25, 1527.52s/it]12/02/2021 22:13:43 - INFO - volta.train_utils -   [NLVR2]: iter 32456 Ep: 6.01 loss 0.030 score 0.190 lr 1.94414e-06 
12/02/2021 22:14:04 - INFO - volta.train_utils -   [NLVR2]: iter 32536 Ep: 6.03 loss 0.028 score 0.189 lr 1.94161e-06 
12/02/2021 22:14:26 - INFO - volta.train_utils -   [NLVR2]: iter 32616 Ep: 6.04 loss 0.028 score 0.190 lr 1.93956e-06 
12/02/2021 22:14:48 - INFO - volta.train_utils -   [NLVR2]: iter 32696 Ep: 6.06 loss 0.032 score 0.191 lr 1.9375e-06 
12/02/2021 22:15:10 - INFO - volta.train_utils -   [NLVR2]: iter 32776 Ep: 6.07 loss 0.030 score 0.188 lr 1.93544e-06 
12/02/2021 22:15:31 - INFO - volta.train_utils -   [NLVR2]: iter 32856 Ep: 6.09 loss 0.031 score 0.186 lr 1.93338e-06 
12/02/2021 22:15:53 - INFO - volta.train_utils -   [NLVR2]: iter 32936 Ep: 6.10 loss 0.032 score 0.185 lr 1.93132e-06 
12/02/2021 22:16:15 - INFO - volta.train_utils -   [NLVR2]: iter 33016 Ep: 6.12 loss 0.027 score 0.194 lr 1.92926e-06 
12/02/2021 22:16:36 - INFO - volta.train_utils -   [NLVR2]: iter 33096 Ep: 6.13 loss 0.027 score 0.187 lr 1.92721e-06 
12/02/2021 22:16:58 - INFO - volta.train_utils -   [NLVR2]: iter 33176 Ep: 6.15 loss 0.029 score 0.194 lr 1.92515e-06 
12/02/2021 22:17:20 - INFO - volta.train_utils -   [NLVR2]: iter 33256 Ep: 6.16 loss 0.032 score 0.192 lr 1.92309e-06 
12/02/2021 22:17:42 - INFO - volta.train_utils -   [NLVR2]: iter 33336 Ep: 6.18 loss 0.032 score 0.188 lr 1.92103e-06 
12/02/2021 22:18:03 - INFO - volta.train_utils -   [NLVR2]: iter 33416 Ep: 6.19 loss 0.030 score 0.191 lr 1.91897e-06 
12/02/2021 22:18:25 - INFO - volta.train_utils -   [NLVR2]: iter 33496 Ep: 6.21 loss 0.028 score 0.192 lr 1.91691e-06 
12/02/2021 22:18:47 - INFO - volta.train_utils -   [NLVR2]: iter 33576 Ep: 6.22 loss 0.029 score 0.191 lr 1.91486e-06 
12/02/2021 22:19:09 - INFO - volta.train_utils -   [NLVR2]: iter 33656 Ep: 6.23 loss 0.033 score 0.188 lr 1.9128e-06 
12/02/2021 22:19:31 - INFO - volta.train_utils -   [NLVR2]: iter 33736 Ep: 6.25 loss 0.031 score 0.189 lr 1.91074e-06 
12/02/2021 22:19:53 - INFO - volta.train_utils -   [NLVR2]: iter 33816 Ep: 6.26 loss 0.028 score 0.195 lr 1.90868e-06 
12/02/2021 22:20:14 - INFO - volta.train_utils -   [NLVR2]: iter 33896 Ep: 6.28 loss 0.027 score 0.191 lr 1.90662e-06 
12/02/2021 22:20:36 - INFO - volta.train_utils -   [NLVR2]: iter 33976 Ep: 6.29 loss 0.027 score 0.191 lr 1.90456e-06 
12/02/2021 22:20:58 - INFO - volta.train_utils -   [NLVR2]: iter 34056 Ep: 6.31 loss 0.029 score 0.190 lr 1.90251e-06 
12/02/2021 22:21:20 - INFO - volta.train_utils -   [NLVR2]: iter 34136 Ep: 6.32 loss 0.029 score 0.191 lr 1.90045e-06 
12/02/2021 22:21:41 - INFO - volta.train_utils -   [NLVR2]: iter 34216 Ep: 6.34 loss 0.029 score 0.192 lr 1.89839e-06 
12/02/2021 22:22:03 - INFO - volta.train_utils -   [NLVR2]: iter 34296 Ep: 6.35 loss 0.030 score 0.190 lr 1.89633e-06 
12/02/2021 22:22:25 - INFO - volta.train_utils -   [NLVR2]: iter 34376 Ep: 6.37 loss 0.029 score 0.194 lr 1.89427e-06 
12/02/2021 22:22:47 - INFO - volta.train_utils -   [NLVR2]: iter 34456 Ep: 6.38 loss 0.032 score 0.189 lr 1.89221e-06 
12/02/2021 22:23:08 - INFO - volta.train_utils -   [NLVR2]: iter 34536 Ep: 6.40 loss 0.030 score 0.190 lr 1.89015e-06 
12/02/2021 22:23:30 - INFO - volta.train_utils -   [NLVR2]: iter 34616 Ep: 6.41 loss 0.027 score 0.191 lr 1.8881e-06 
12/02/2021 22:23:52 - INFO - volta.train_utils -   [NLVR2]: iter 34696 Ep: 6.43 loss 0.031 score 0.192 lr 1.88604e-06 
12/02/2021 22:24:14 - INFO - volta.train_utils -   [NLVR2]: iter 34776 Ep: 6.44 loss 0.028 score 0.195 lr 1.88398e-06 
12/02/2021 22:24:36 - INFO - volta.train_utils -   [NLVR2]: iter 34856 Ep: 6.46 loss 0.032 score 0.186 lr 1.88192e-06 
12/02/2021 22:24:58 - INFO - volta.train_utils -   [NLVR2]: iter 34936 Ep: 6.47 loss 0.029 score 0.193 lr 1.87986e-06 
12/02/2021 22:25:19 - INFO - volta.train_utils -   [NLVR2]: iter 35016 Ep: 6.49 loss 0.030 score 0.190 lr 1.8778e-06 
12/02/2021 22:25:41 - INFO - volta.train_utils -   [NLVR2]: iter 35096 Ep: 6.50 loss 0.029 score 0.193 lr 1.87575e-06 
12/02/2021 22:26:03 - INFO - volta.train_utils -   [NLVR2]: iter 35176 Ep: 6.52 loss 0.031 score 0.190 lr 1.87369e-06 
12/02/2021 22:26:25 - INFO - volta.train_utils -   [NLVR2]: iter 35256 Ep: 6.53 loss 0.031 score 0.196 lr 1.87163e-06 
12/02/2021 22:26:46 - INFO - volta.train_utils -   [NLVR2]: iter 35336 Ep: 6.55 loss 0.029 score 0.189 lr 1.86957e-06 
12/02/2021 22:27:08 - INFO - volta.train_utils -   [NLVR2]: iter 35416 Ep: 6.56 loss 0.031 score 0.186 lr 1.86751e-06 
12/02/2021 22:27:30 - INFO - volta.train_utils -   [NLVR2]: iter 35496 Ep: 6.58 loss 0.028 score 0.194 lr 1.86545e-06 
12/02/2021 22:27:52 - INFO - volta.train_utils -   [NLVR2]: iter 35576 Ep: 6.59 loss 0.030 score 0.186 lr 1.8634e-06 
12/02/2021 22:28:13 - INFO - volta.train_utils -   [NLVR2]: iter 35656 Ep: 6.61 loss 0.029 score 0.189 lr 1.86134e-06 
12/02/2021 22:28:35 - INFO - volta.train_utils -   [NLVR2]: iter 35736 Ep: 6.62 loss 0.028 score 0.189 lr 1.85928e-06 
12/02/2021 22:28:57 - INFO - volta.train_utils -   [NLVR2]: iter 35816 Ep: 6.64 loss 0.029 score 0.190 lr 1.85722e-06 
12/02/2021 22:29:19 - INFO - volta.train_utils -   [NLVR2]: iter 35896 Ep: 6.65 loss 0.032 score 0.188 lr 1.85516e-06 
12/02/2021 22:29:40 - INFO - volta.train_utils -   [NLVR2]: iter 35976 Ep: 6.66 loss 0.030 score 0.193 lr 1.8531e-06 
12/02/2021 22:30:02 - INFO - volta.train_utils -   [NLVR2]: iter 36056 Ep: 6.68 loss 0.032 score 0.188 lr 1.85105e-06 
12/02/2021 22:30:24 - INFO - volta.train_utils -   [NLVR2]: iter 36136 Ep: 6.69 loss 0.029 score 0.192 lr 1.84899e-06 
12/02/2021 22:30:45 - INFO - volta.train_utils -   [NLVR2]: iter 36216 Ep: 6.71 loss 0.033 score 0.188 lr 1.84693e-06 
12/02/2021 22:31:07 - INFO - volta.train_utils -   [NLVR2]: iter 36296 Ep: 6.72 loss 0.031 score 0.191 lr 1.84487e-06 
12/02/2021 22:31:29 - INFO - volta.train_utils -   [NLVR2]: iter 36376 Ep: 6.74 loss 0.023 score 0.198 lr 1.84281e-06 
12/02/2021 22:31:51 - INFO - volta.train_utils -   [NLVR2]: iter 36456 Ep: 6.75 loss 0.031 score 0.190 lr 1.84075e-06 
12/02/2021 22:32:12 - INFO - volta.train_utils -   [NLVR2]: iter 36536 Ep: 6.77 loss 0.030 score 0.192 lr 1.8387e-06 
12/02/2021 22:32:34 - INFO - volta.train_utils -   [NLVR2]: iter 36616 Ep: 6.78 loss 0.028 score 0.199 lr 1.83664e-06 
12/02/2021 22:32:56 - INFO - volta.train_utils -   [NLVR2]: iter 36696 Ep: 6.80 loss 0.028 score 0.195 lr 1.83458e-06 
12/02/2021 22:33:17 - INFO - volta.train_utils -   [NLVR2]: iter 36776 Ep: 6.81 loss 0.025 score 0.195 lr 1.83252e-06 
12/02/2021 22:33:39 - INFO - volta.train_utils -   [NLVR2]: iter 36856 Ep: 6.83 loss 0.027 score 0.197 lr 1.83046e-06 
12/02/2021 22:34:01 - INFO - volta.train_utils -   [NLVR2]: iter 36936 Ep: 6.84 loss 0.028 score 0.194 lr 1.8284e-06 
12/02/2021 22:34:23 - INFO - volta.train_utils -   [NLVR2]: iter 37016 Ep: 6.86 loss 0.029 score 0.196 lr 1.82635e-06 
12/02/2021 22:34:44 - INFO - volta.train_utils -   [NLVR2]: iter 37096 Ep: 6.87 loss 0.026 score 0.200 lr 1.82429e-06 
12/02/2021 22:35:06 - INFO - volta.train_utils -   [NLVR2]: iter 37176 Ep: 6.89 loss 0.027 score 0.200 lr 1.82223e-06 
12/02/2021 22:35:28 - INFO - volta.train_utils -   [NLVR2]: iter 37256 Ep: 6.90 loss 0.027 score 0.195 lr 1.82017e-06 
12/02/2021 22:35:49 - INFO - volta.train_utils -   [NLVR2]: iter 37336 Ep: 6.92 loss 0.029 score 0.195 lr 1.81811e-06 
12/02/2021 22:36:11 - INFO - volta.train_utils -   [NLVR2]: iter 37416 Ep: 6.93 loss 0.028 score 0.199 lr 1.81605e-06 
12/02/2021 22:36:33 - INFO - volta.train_utils -   [NLVR2]: iter 37496 Ep: 6.95 loss 0.029 score 0.199 lr 1.81399e-06 
12/02/2021 22:36:55 - INFO - volta.train_utils -   [NLVR2]: iter 37576 Ep: 6.96 loss 0.028 score 0.197 lr 1.81194e-06 
12/02/2021 22:37:16 - INFO - volta.train_utils -   [NLVR2]: iter 37656 Ep: 6.98 loss 0.025 score 0.200 lr 1.80988e-06 
12/02/2021 22:37:38 - INFO - volta.train_utils -   [NLVR2]: iter 37736 Ep: 6.99 loss 0.028 score 0.194 lr 1.80782e-06 
12/02/2021 22:38:32 - INFO - volta.train_utils -   Eval task TASK12 on iteration 37772 
12/02/2021 22:38:32 - INFO - volta.train_utils -   Validation [NLVR2]: loss 0.683 score 68.048 
12/02/2021 22:38:32 - INFO - __main__ -   ** ** * Saving model * ** ** 
Epoch:  35%|███▌      | 7/20 [2:59:07<5:32:08, 1532.95s/it]12/02/2021 22:39:28 - INFO - volta.train_utils -   [NLVR2]: iter 37852 Ep: 7.01 loss 0.026 score 0.197 lr 1.8053e-06 
12/02/2021 22:39:50 - INFO - volta.train_utils -   [NLVR2]: iter 37932 Ep: 7.03 loss 0.029 score 0.193 lr 1.80278e-06 
12/02/2021 22:40:12 - INFO - volta.train_utils -   [NLVR2]: iter 38012 Ep: 7.04 loss 0.027 score 0.188 lr 1.80072e-06 
12/02/2021 22:40:33 - INFO - volta.train_utils -   [NLVR2]: iter 38092 Ep: 7.06 loss 0.030 score 0.201 lr 1.79866e-06 
12/02/2021 22:40:55 - INFO - volta.train_utils -   [NLVR2]: iter 38172 Ep: 7.07 loss 0.027 score 0.197 lr 1.7966e-06 
12/02/2021 22:41:17 - INFO - volta.train_utils -   [NLVR2]: iter 38252 Ep: 7.09 loss 0.027 score 0.196 lr 1.79454e-06 
12/02/2021 22:41:39 - INFO - volta.train_utils -   [NLVR2]: iter 38332 Ep: 7.10 loss 0.025 score 0.196 lr 1.79248e-06 
12/02/2021 22:42:00 - INFO - volta.train_utils -   [NLVR2]: iter 38412 Ep: 7.12 loss 0.024 score 0.194 lr 1.79043e-06 
12/02/2021 22:42:22 - INFO - volta.train_utils -   [NLVR2]: iter 38492 Ep: 7.13 loss 0.028 score 0.193 lr 1.78837e-06 
12/02/2021 22:42:44 - INFO - volta.train_utils -   [NLVR2]: iter 38572 Ep: 7.15 loss 0.025 score 0.197 lr 1.78631e-06 
12/02/2021 22:43:06 - INFO - volta.train_utils -   [NLVR2]: iter 38652 Ep: 7.16 loss 0.027 score 0.202 lr 1.78425e-06 
12/02/2021 22:43:27 - INFO - volta.train_utils -   [NLVR2]: iter 38732 Ep: 7.18 loss 0.030 score 0.198 lr 1.78219e-06 
12/02/2021 22:43:49 - INFO - volta.train_utils -   [NLVR2]: iter 38812 Ep: 7.19 loss 0.027 score 0.198 lr 1.78013e-06 
12/02/2021 22:44:11 - INFO - volta.train_utils -   [NLVR2]: iter 38892 Ep: 7.20 loss 0.026 score 0.196 lr 1.77808e-06 
12/02/2021 22:44:33 - INFO - volta.train_utils -   [NLVR2]: iter 38972 Ep: 7.22 loss 0.026 score 0.197 lr 1.77602e-06 
12/02/2021 22:44:54 - INFO - volta.train_utils -   [NLVR2]: iter 39052 Ep: 7.23 loss 0.024 score 0.203 lr 1.77396e-06 
12/02/2021 22:45:16 - INFO - volta.train_utils -   [NLVR2]: iter 39132 Ep: 7.25 loss 0.026 score 0.196 lr 1.7719e-06 
12/02/2021 22:45:38 - INFO - volta.train_utils -   [NLVR2]: iter 39212 Ep: 7.26 loss 0.022 score 0.199 lr 1.76984e-06 
12/02/2021 22:46:00 - INFO - volta.train_utils -   [NLVR2]: iter 39292 Ep: 7.28 loss 0.029 score 0.199 lr 1.76778e-06 
12/02/2021 22:46:21 - INFO - volta.train_utils -   [NLVR2]: iter 39372 Ep: 7.29 loss 0.029 score 0.194 lr 1.76573e-06 
12/02/2021 22:46:43 - INFO - volta.train_utils -   [NLVR2]: iter 39452 Ep: 7.31 loss 0.029 score 0.195 lr 1.76367e-06 
12/02/2021 22:47:05 - INFO - volta.train_utils -   [NLVR2]: iter 39532 Ep: 7.32 loss 0.025 score 0.203 lr 1.76161e-06 
12/02/2021 22:47:27 - INFO - volta.train_utils -   [NLVR2]: iter 39612 Ep: 7.34 loss 0.027 score 0.197 lr 1.75955e-06 
12/02/2021 22:47:48 - INFO - volta.train_utils -   [NLVR2]: iter 39692 Ep: 7.35 loss 0.022 score 0.199 lr 1.75749e-06 
12/02/2021 22:48:10 - INFO - volta.train_utils -   [NLVR2]: iter 39772 Ep: 7.37 loss 0.026 score 0.198 lr 1.75543e-06 
12/02/2021 22:48:32 - INFO - volta.train_utils -   [NLVR2]: iter 39852 Ep: 7.38 loss 0.025 score 0.197 lr 1.75338e-06 
12/02/2021 22:48:54 - INFO - volta.train_utils -   [NLVR2]: iter 39932 Ep: 7.40 loss 0.025 score 0.194 lr 1.75132e-06 
12/02/2021 22:49:15 - INFO - volta.train_utils -   [NLVR2]: iter 40012 Ep: 7.41 loss 0.027 score 0.196 lr 1.74926e-06 
12/02/2021 22:49:37 - INFO - volta.train_utils -   [NLVR2]: iter 40092 Ep: 7.43 loss 0.030 score 0.193 lr 1.7472e-06 
12/02/2021 22:49:59 - INFO - volta.train_utils -   [NLVR2]: iter 40172 Ep: 7.44 loss 0.022 score 0.199 lr 1.74514e-06 
12/02/2021 22:50:21 - INFO - volta.train_utils -   [NLVR2]: iter 40252 Ep: 7.46 loss 0.026 score 0.197 lr 1.74308e-06 
12/02/2021 22:50:42 - INFO - volta.train_utils -   [NLVR2]: iter 40332 Ep: 7.47 loss 0.027 score 0.198 lr 1.74103e-06 
12/02/2021 22:51:04 - INFO - volta.train_utils -   [NLVR2]: iter 40412 Ep: 7.49 loss 0.029 score 0.197 lr 1.73897e-06 
12/02/2021 22:51:26 - INFO - volta.train_utils -   [NLVR2]: iter 40492 Ep: 7.50 loss 0.025 score 0.201 lr 1.73691e-06 
12/02/2021 22:51:47 - INFO - volta.train_utils -   [NLVR2]: iter 40572 Ep: 7.52 loss 0.025 score 0.204 lr 1.73485e-06 
12/02/2021 22:52:09 - INFO - volta.train_utils -   [NLVR2]: iter 40652 Ep: 7.53 loss 0.024 score 0.202 lr 1.73279e-06 
12/02/2021 22:52:31 - INFO - volta.train_utils -   [NLVR2]: iter 40732 Ep: 7.55 loss 0.024 score 0.201 lr 1.73073e-06 
12/02/2021 22:52:53 - INFO - volta.train_utils -   [NLVR2]: iter 40812 Ep: 7.56 loss 0.027 score 0.195 lr 1.72868e-06 
12/02/2021 22:53:14 - INFO - volta.train_utils -   [NLVR2]: iter 40892 Ep: 7.58 loss 0.027 score 0.200 lr 1.72662e-06 
12/02/2021 22:53:36 - INFO - volta.train_utils -   [NLVR2]: iter 40972 Ep: 7.59 loss 0.026 score 0.197 lr 1.72456e-06 
12/02/2021 22:53:58 - INFO - volta.train_utils -   [NLVR2]: iter 41052 Ep: 7.61 loss 0.026 score 0.196 lr 1.7225e-06 
12/02/2021 22:54:19 - INFO - volta.train_utils -   [NLVR2]: iter 41132 Ep: 7.62 loss 0.023 score 0.201 lr 1.72044e-06 
12/02/2021 22:54:41 - INFO - volta.train_utils -   [NLVR2]: iter 41212 Ep: 7.63 loss 0.028 score 0.196 lr 1.71838e-06 
12/02/2021 22:55:03 - INFO - volta.train_utils -   [NLVR2]: iter 41292 Ep: 7.65 loss 0.026 score 0.199 lr 1.71632e-06 
12/02/2021 22:55:24 - INFO - volta.train_utils -   [NLVR2]: iter 41372 Ep: 7.66 loss 0.026 score 0.196 lr 1.71427e-06 
12/02/2021 22:55:46 - INFO - volta.train_utils -   [NLVR2]: iter 41452 Ep: 7.68 loss 0.026 score 0.192 lr 1.71221e-06 
12/02/2021 22:56:08 - INFO - volta.train_utils -   [NLVR2]: iter 41532 Ep: 7.69 loss 0.028 score 0.196 lr 1.71015e-06 
12/02/2021 22:56:30 - INFO - volta.train_utils -   [NLVR2]: iter 41612 Ep: 7.71 loss 0.029 score 0.190 lr 1.70809e-06 
12/02/2021 22:56:52 - INFO - volta.train_utils -   [NLVR2]: iter 41692 Ep: 7.72 loss 0.023 score 0.197 lr 1.70603e-06 
12/02/2021 22:57:13 - INFO - volta.train_utils -   [NLVR2]: iter 41772 Ep: 7.74 loss 0.026 score 0.199 lr 1.70397e-06 
12/02/2021 22:57:35 - INFO - volta.train_utils -   [NLVR2]: iter 41852 Ep: 7.75 loss 0.026 score 0.197 lr 1.70192e-06 
12/02/2021 22:57:57 - INFO - volta.train_utils -   [NLVR2]: iter 41932 Ep: 7.77 loss 0.030 score 0.195 lr 1.69986e-06 
12/02/2021 22:58:19 - INFO - volta.train_utils -   [NLVR2]: iter 42012 Ep: 7.78 loss 0.024 score 0.203 lr 1.6978e-06 
12/02/2021 22:58:40 - INFO - volta.train_utils -   [NLVR2]: iter 42092 Ep: 7.80 loss 0.024 score 0.202 lr 1.69574e-06 
12/02/2021 22:59:02 - INFO - volta.train_utils -   [NLVR2]: iter 42172 Ep: 7.81 loss 0.027 score 0.200 lr 1.69368e-06 
12/02/2021 22:59:24 - INFO - volta.train_utils -   [NLVR2]: iter 42252 Ep: 7.83 loss 0.024 score 0.202 lr 1.69162e-06 
12/02/2021 22:59:46 - INFO - volta.train_utils -   [NLVR2]: iter 42332 Ep: 7.84 loss 0.025 score 0.202 lr 1.68957e-06 
12/02/2021 23:00:07 - INFO - volta.train_utils -   [NLVR2]: iter 42412 Ep: 7.86 loss 0.021 score 0.206 lr 1.68751e-06 
12/02/2021 23:00:29 - INFO - volta.train_utils -   [NLVR2]: iter 42492 Ep: 7.87 loss 0.022 score 0.204 lr 1.68545e-06 
12/02/2021 23:00:51 - INFO - volta.train_utils -   [NLVR2]: iter 42572 Ep: 7.89 loss 0.024 score 0.200 lr 1.68339e-06 
12/02/2021 23:01:13 - INFO - volta.train_utils -   [NLVR2]: iter 42652 Ep: 7.90 loss 0.022 score 0.204 lr 1.68133e-06 
12/02/2021 23:01:35 - INFO - volta.train_utils -   [NLVR2]: iter 42732 Ep: 7.92 loss 0.025 score 0.204 lr 1.67927e-06 
12/02/2021 23:01:56 - INFO - volta.train_utils -   [NLVR2]: iter 42812 Ep: 7.93 loss 0.023 score 0.199 lr 1.67722e-06 
12/02/2021 23:02:18 - INFO - volta.train_utils -   [NLVR2]: iter 42892 Ep: 7.95 loss 0.026 score 0.201 lr 1.67516e-06 
12/02/2021 23:02:40 - INFO - volta.train_utils -   [NLVR2]: iter 42972 Ep: 7.96 loss 0.027 score 0.199 lr 1.6731e-06 
12/02/2021 23:03:01 - INFO - volta.train_utils -   [NLVR2]: iter 43052 Ep: 7.98 loss 0.023 score 0.199 lr 1.67104e-06 
12/02/2021 23:03:23 - INFO - volta.train_utils -   [NLVR2]: iter 43132 Ep: 7.99 loss 0.026 score 0.199 lr 1.66898e-06 
12/02/2021 23:04:17 - INFO - volta.train_utils -   Eval task TASK12 on iteration 43168 
12/02/2021 23:04:17 - INFO - volta.train_utils -   Validation [NLVR2]: loss 0.708 score 68.850 
12/02/2021 23:04:17 - INFO - __main__ -   ** ** * Saving model * ** ** 
Epoch:  40%|████      | 8/20 [3:24:48<5:07:03, 1535.27s/it]12/02/2021 23:05:09 - INFO - volta.train_utils -   [NLVR2]: iter 43248 Ep: 8.01 loss 0.026 score 0.207 lr 1.66646e-06 
12/02/2021 23:05:31 - INFO - volta.train_utils -   [NLVR2]: iter 43328 Ep: 8.03 loss 0.024 score 0.205 lr 1.66394e-06 
12/02/2021 23:05:52 - INFO - volta.train_utils -   [NLVR2]: iter 43408 Ep: 8.04 loss 0.030 score 0.201 lr 1.66188e-06 
12/02/2021 23:06:14 - INFO - volta.train_utils -   [NLVR2]: iter 43488 Ep: 8.06 loss 0.021 score 0.207 lr 1.65982e-06 
12/02/2021 23:06:36 - INFO - volta.train_utils -   [NLVR2]: iter 43568 Ep: 8.07 loss 0.023 score 0.204 lr 1.65776e-06 
12/02/2021 23:06:57 - INFO - volta.train_utils -   [NLVR2]: iter 43648 Ep: 8.09 loss 0.026 score 0.204 lr 1.65571e-06 
12/02/2021 23:07:19 - INFO - volta.train_utils -   [NLVR2]: iter 43728 Ep: 8.10 loss 0.027 score 0.202 lr 1.65365e-06 
12/02/2021 23:07:41 - INFO - volta.train_utils -   [NLVR2]: iter 43808 Ep: 8.12 loss 0.028 score 0.201 lr 1.65159e-06 
12/02/2021 23:08:03 - INFO - volta.train_utils -   [NLVR2]: iter 43888 Ep: 8.13 loss 0.028 score 0.200 lr 1.64953e-06 
12/02/2021 23:08:24 - INFO - volta.train_utils -   [NLVR2]: iter 43968 Ep: 8.15 loss 0.023 score 0.207 lr 1.64747e-06 
12/02/2021 23:08:46 - INFO - volta.train_utils -   [NLVR2]: iter 44048 Ep: 8.16 loss 0.026 score 0.198 lr 1.64541e-06 
12/02/2021 23:09:08 - INFO - volta.train_utils -   [NLVR2]: iter 44128 Ep: 8.17 loss 0.024 score 0.200 lr 1.64336e-06 
12/02/2021 23:09:29 - INFO - volta.train_utils -   [NLVR2]: iter 44208 Ep: 8.19 loss 0.026 score 0.201 lr 1.6413e-06 
12/02/2021 23:09:51 - INFO - volta.train_utils -   [NLVR2]: iter 44288 Ep: 8.20 loss 0.024 score 0.208 lr 1.63924e-06 
12/02/2021 23:10:13 - INFO - volta.train_utils -   [NLVR2]: iter 44368 Ep: 8.22 loss 0.027 score 0.204 lr 1.63718e-06 
12/02/2021 23:10:35 - INFO - volta.train_utils -   [NLVR2]: iter 44448 Ep: 8.23 loss 0.024 score 0.205 lr 1.63512e-06 
12/02/2021 23:10:56 - INFO - volta.train_utils -   [NLVR2]: iter 44528 Ep: 8.25 loss 0.023 score 0.203 lr 1.63306e-06 
12/02/2021 23:11:18 - INFO - volta.train_utils -   [NLVR2]: iter 44608 Ep: 8.26 loss 0.024 score 0.201 lr 1.63101e-06 
12/02/2021 23:11:40 - INFO - volta.train_utils -   [NLVR2]: iter 44688 Ep: 8.28 loss 0.027 score 0.201 lr 1.62895e-06 
12/02/2021 23:12:02 - INFO - volta.train_utils -   [NLVR2]: iter 44768 Ep: 8.29 loss 0.026 score 0.203 lr 1.62689e-06 
12/02/2021 23:12:24 - INFO - volta.train_utils -   [NLVR2]: iter 44848 Ep: 8.31 loss 0.023 score 0.206 lr 1.62483e-06 
12/02/2021 23:12:46 - INFO - volta.train_utils -   [NLVR2]: iter 44928 Ep: 8.32 loss 0.026 score 0.203 lr 1.62277e-06 
12/02/2021 23:13:07 - INFO - volta.train_utils -   [NLVR2]: iter 45008 Ep: 8.34 loss 0.020 score 0.207 lr 1.62071e-06 
12/02/2021 23:13:29 - INFO - volta.train_utils -   [NLVR2]: iter 45088 Ep: 8.35 loss 0.020 score 0.204 lr 1.61866e-06 
12/02/2021 23:13:51 - INFO - volta.train_utils -   [NLVR2]: iter 45168 Ep: 8.37 loss 0.027 score 0.198 lr 1.6166e-06 
12/02/2021 23:14:13 - INFO - volta.train_utils -   [NLVR2]: iter 45248 Ep: 8.38 loss 0.024 score 0.203 lr 1.61454e-06 
12/02/2021 23:14:34 - INFO - volta.train_utils -   [NLVR2]: iter 45328 Ep: 8.40 loss 0.026 score 0.205 lr 1.61248e-06 
12/02/2021 23:14:56 - INFO - volta.train_utils -   [NLVR2]: iter 45408 Ep: 8.41 loss 0.024 score 0.204 lr 1.61042e-06 
12/02/2021 23:15:18 - INFO - volta.train_utils -   [NLVR2]: iter 45488 Ep: 8.43 loss 0.024 score 0.204 lr 1.60836e-06 
12/02/2021 23:15:39 - INFO - volta.train_utils -   [NLVR2]: iter 45568 Ep: 8.44 loss 0.026 score 0.201 lr 1.6063e-06 
12/02/2021 23:16:01 - INFO - volta.train_utils -   [NLVR2]: iter 45648 Ep: 8.46 loss 0.025 score 0.198 lr 1.60425e-06 
12/02/2021 23:16:23 - INFO - volta.train_utils -   [NLVR2]: iter 45728 Ep: 8.47 loss 0.025 score 0.204 lr 1.60219e-06 
12/02/2021 23:16:45 - INFO - volta.train_utils -   [NLVR2]: iter 45808 Ep: 8.49 loss 0.021 score 0.206 lr 1.60013e-06 
12/02/2021 23:17:06 - INFO - volta.train_utils -   [NLVR2]: iter 45888 Ep: 8.50 loss 0.023 score 0.204 lr 1.59807e-06 
12/02/2021 23:17:28 - INFO - volta.train_utils -   [NLVR2]: iter 45968 Ep: 8.52 loss 0.024 score 0.205 lr 1.59601e-06 
12/02/2021 23:17:50 - INFO - volta.train_utils -   [NLVR2]: iter 46048 Ep: 8.53 loss 0.026 score 0.204 lr 1.59395e-06 
12/02/2021 23:18:11 - INFO - volta.train_utils -   [NLVR2]: iter 46128 Ep: 8.55 loss 0.023 score 0.209 lr 1.5919e-06 
12/02/2021 23:18:33 - INFO - volta.train_utils -   [NLVR2]: iter 46208 Ep: 8.56 loss 0.026 score 0.204 lr 1.58984e-06 
12/02/2021 23:18:55 - INFO - volta.train_utils -   [NLVR2]: iter 46288 Ep: 8.58 loss 0.022 score 0.204 lr 1.58778e-06 
12/02/2021 23:19:17 - INFO - volta.train_utils -   [NLVR2]: iter 46368 Ep: 8.59 loss 0.022 score 0.203 lr 1.58572e-06 
12/02/2021 23:19:38 - INFO - volta.train_utils -   [NLVR2]: iter 46448 Ep: 8.60 loss 0.021 score 0.202 lr 1.58366e-06 
12/02/2021 23:20:00 - INFO - volta.train_utils -   [NLVR2]: iter 46528 Ep: 8.62 loss 0.026 score 0.203 lr 1.5816e-06 
12/02/2021 23:20:22 - INFO - volta.train_utils -   [NLVR2]: iter 46608 Ep: 8.63 loss 0.026 score 0.203 lr 1.57955e-06 
12/02/2021 23:20:44 - INFO - volta.train_utils -   [NLVR2]: iter 46688 Ep: 8.65 loss 0.026 score 0.200 lr 1.57749e-06 
12/02/2021 23:21:05 - INFO - volta.train_utils -   [NLVR2]: iter 46768 Ep: 8.66 loss 0.023 score 0.201 lr 1.57543e-06 
12/02/2021 23:21:27 - INFO - volta.train_utils -   [NLVR2]: iter 46848 Ep: 8.68 loss 0.024 score 0.201 lr 1.57337e-06 
12/02/2021 23:21:49 - INFO - volta.train_utils -   [NLVR2]: iter 46928 Ep: 8.69 loss 0.023 score 0.206 lr 1.57131e-06 
12/02/2021 23:22:11 - INFO - volta.train_utils -   [NLVR2]: iter 47008 Ep: 8.71 loss 0.022 score 0.208 lr 1.56925e-06 
12/02/2021 23:22:32 - INFO - volta.train_utils -   [NLVR2]: iter 47088 Ep: 8.72 loss 0.025 score 0.199 lr 1.5672e-06 
12/02/2021 23:22:54 - INFO - volta.train_utils -   [NLVR2]: iter 47168 Ep: 8.74 loss 0.022 score 0.207 lr 1.56514e-06 
12/02/2021 23:23:16 - INFO - volta.train_utils -   [NLVR2]: iter 47248 Ep: 8.75 loss 0.024 score 0.205 lr 1.56308e-06 
12/02/2021 23:23:38 - INFO - volta.train_utils -   [NLVR2]: iter 47328 Ep: 8.77 loss 0.019 score 0.204 lr 1.56102e-06 
12/02/2021 23:23:59 - INFO - volta.train_utils -   [NLVR2]: iter 47408 Ep: 8.78 loss 0.021 score 0.207 lr 1.55896e-06 
12/02/2021 23:24:21 - INFO - volta.train_utils -   [NLVR2]: iter 47488 Ep: 8.80 loss 0.025 score 0.207 lr 1.5569e-06 
12/02/2021 23:24:43 - INFO - volta.train_utils -   [NLVR2]: iter 47568 Ep: 8.81 loss 0.024 score 0.202 lr 1.55485e-06 
12/02/2021 23:25:05 - INFO - volta.train_utils -   [NLVR2]: iter 47648 Ep: 8.83 loss 0.027 score 0.205 lr 1.55279e-06 
12/02/2021 23:25:26 - INFO - volta.train_utils -   [NLVR2]: iter 47728 Ep: 8.84 loss 0.019 score 0.209 lr 1.55073e-06 
12/02/2021 23:25:48 - INFO - volta.train_utils -   [NLVR2]: iter 47808 Ep: 8.86 loss 0.021 score 0.204 lr 1.54867e-06 
12/02/2021 23:26:10 - INFO - volta.train_utils -   [NLVR2]: iter 47888 Ep: 8.87 loss 0.023 score 0.205 lr 1.54661e-06 
12/02/2021 23:26:32 - INFO - volta.train_utils -   [NLVR2]: iter 47968 Ep: 8.89 loss 0.022 score 0.210 lr 1.54455e-06 
12/02/2021 23:26:53 - INFO - volta.train_utils -   [NLVR2]: iter 48048 Ep: 8.90 loss 0.021 score 0.212 lr 1.5425e-06 
12/02/2021 23:27:15 - INFO - volta.train_utils -   [NLVR2]: iter 48128 Ep: 8.92 loss 0.022 score 0.209 lr 1.54044e-06 
12/02/2021 23:27:37 - INFO - volta.train_utils -   [NLVR2]: iter 48208 Ep: 8.93 loss 0.023 score 0.211 lr 1.53838e-06 
12/02/2021 23:27:59 - INFO - volta.train_utils -   [NLVR2]: iter 48288 Ep: 8.95 loss 0.022 score 0.207 lr 1.53632e-06 
12/02/2021 23:28:20 - INFO - volta.train_utils -   [NLVR2]: iter 48368 Ep: 8.96 loss 0.023 score 0.208 lr 1.53426e-06 
12/02/2021 23:28:42 - INFO - volta.train_utils -   [NLVR2]: iter 48448 Ep: 8.98 loss 0.021 score 0.205 lr 1.5322e-06 
12/02/2021 23:29:04 - INFO - volta.train_utils -   [NLVR2]: iter 48528 Ep: 8.99 loss 0.025 score 0.206 lr 1.53014e-06 
12/02/2021 23:29:57 - INFO - volta.train_utils -   Eval task TASK12 on iteration 48564 
12/02/2021 23:29:57 - INFO - volta.train_utils -   Validation [NLVR2]: loss 0.812 score 67.689 
Epoch:  45%|████▌     | 9/20 [3:49:58<4:40:05, 1527.75s/it]12/02/2021 23:30:19 - INFO - volta.train_utils -   [NLVR2]: iter 48644 Ep: 9.01 loss 0.022 score 0.211 lr 1.52762e-06 
12/02/2021 23:30:41 - INFO - volta.train_utils -   [NLVR2]: iter 48724 Ep: 9.03 loss 0.018 score 0.210 lr 1.5251e-06 
12/02/2021 23:31:02 - INFO - volta.train_utils -   [NLVR2]: iter 48804 Ep: 9.04 loss 0.021 score 0.208 lr 1.52304e-06 
12/02/2021 23:31:24 - INFO - volta.train_utils -   [NLVR2]: iter 48884 Ep: 9.06 loss 0.024 score 0.205 lr 1.52099e-06 
12/02/2021 23:31:46 - INFO - volta.train_utils -   [NLVR2]: iter 48964 Ep: 9.07 loss 0.022 score 0.210 lr 1.51893e-06 
12/02/2021 23:32:08 - INFO - volta.train_utils -   [NLVR2]: iter 49044 Ep: 9.09 loss 0.021 score 0.206 lr 1.51687e-06 
12/02/2021 23:32:29 - INFO - volta.train_utils -   [NLVR2]: iter 49124 Ep: 9.10 loss 0.022 score 0.212 lr 1.51481e-06 
12/02/2021 23:32:51 - INFO - volta.train_utils -   [NLVR2]: iter 49204 Ep: 9.12 loss 0.020 score 0.208 lr 1.51275e-06 
12/02/2021 23:33:13 - INFO - volta.train_utils -   [NLVR2]: iter 49284 Ep: 9.13 loss 0.024 score 0.205 lr 1.51069e-06 
12/02/2021 23:33:34 - INFO - volta.train_utils -   [NLVR2]: iter 49364 Ep: 9.14 loss 0.023 score 0.209 lr 1.50863e-06 
12/02/2021 23:33:56 - INFO - volta.train_utils -   [NLVR2]: iter 49444 Ep: 9.16 loss 0.022 score 0.205 lr 1.50658e-06 
12/02/2021 23:34:18 - INFO - volta.train_utils -   [NLVR2]: iter 49524 Ep: 9.17 loss 0.026 score 0.206 lr 1.50452e-06 
12/02/2021 23:34:40 - INFO - volta.train_utils -   [NLVR2]: iter 49604 Ep: 9.19 loss 0.023 score 0.209 lr 1.50246e-06 
12/02/2021 23:35:01 - INFO - volta.train_utils -   [NLVR2]: iter 49684 Ep: 9.20 loss 0.023 score 0.206 lr 1.5004e-06 
12/02/2021 23:35:23 - INFO - volta.train_utils -   [NLVR2]: iter 49764 Ep: 9.22 loss 0.021 score 0.212 lr 1.49834e-06 
12/02/2021 23:35:45 - INFO - volta.train_utils -   [NLVR2]: iter 49844 Ep: 9.23 loss 0.021 score 0.209 lr 1.49628e-06 
12/02/2021 23:36:06 - INFO - volta.train_utils -   [NLVR2]: iter 49924 Ep: 9.25 loss 0.020 score 0.210 lr 1.49423e-06 
12/02/2021 23:36:28 - INFO - volta.train_utils -   [NLVR2]: iter 50004 Ep: 9.26 loss 0.020 score 0.212 lr 1.49217e-06 
12/02/2021 23:36:50 - INFO - volta.train_utils -   [NLVR2]: iter 50084 Ep: 9.28 loss 0.023 score 0.213 lr 1.49011e-06 
12/02/2021 23:37:12 - INFO - volta.train_utils -   [NLVR2]: iter 50164 Ep: 9.29 loss 0.023 score 0.204 lr 1.48805e-06 
12/02/2021 23:37:33 - INFO - volta.train_utils -   [NLVR2]: iter 50244 Ep: 9.31 loss 0.019 score 0.210 lr 1.48599e-06 
12/02/2021 23:37:55 - INFO - volta.train_utils -   [NLVR2]: iter 50324 Ep: 9.32 loss 0.020 score 0.209 lr 1.48393e-06 
12/02/2021 23:38:17 - INFO - volta.train_utils -   [NLVR2]: iter 50404 Ep: 9.34 loss 0.022 score 0.209 lr 1.48188e-06 
12/02/2021 23:38:39 - INFO - volta.train_utils -   [NLVR2]: iter 50484 Ep: 9.35 loss 0.020 score 0.212 lr 1.47982e-06 
12/02/2021 23:39:01 - INFO - volta.train_utils -   [NLVR2]: iter 50564 Ep: 9.37 loss 0.021 score 0.213 lr 1.47776e-06 
12/02/2021 23:39:22 - INFO - volta.train_utils -   [NLVR2]: iter 50644 Ep: 9.38 loss 0.025 score 0.207 lr 1.4757e-06 
12/02/2021 23:39:44 - INFO - volta.train_utils -   [NLVR2]: iter 50724 Ep: 9.40 loss 0.022 score 0.212 lr 1.47364e-06 
12/02/2021 23:40:06 - INFO - volta.train_utils -   [NLVR2]: iter 50804 Ep: 9.41 loss 0.024 score 0.206 lr 1.47158e-06 
12/02/2021 23:40:28 - INFO - volta.train_utils -   [NLVR2]: iter 50884 Ep: 9.43 loss 0.021 score 0.208 lr 1.46953e-06 
12/02/2021 23:40:49 - INFO - volta.train_utils -   [NLVR2]: iter 50964 Ep: 9.44 loss 0.020 score 0.209 lr 1.46747e-06 
12/02/2021 23:41:11 - INFO - volta.train_utils -   [NLVR2]: iter 51044 Ep: 9.46 loss 0.018 score 0.209 lr 1.46541e-06 
12/02/2021 23:41:33 - INFO - volta.train_utils -   [NLVR2]: iter 51124 Ep: 9.47 loss 0.023 score 0.208 lr 1.46335e-06 
12/02/2021 23:41:54 - INFO - volta.train_utils -   [NLVR2]: iter 51204 Ep: 9.49 loss 0.020 score 0.208 lr 1.46129e-06 
12/02/2021 23:42:16 - INFO - volta.train_utils -   [NLVR2]: iter 51284 Ep: 9.50 loss 0.022 score 0.210 lr 1.45923e-06 
12/02/2021 23:42:38 - INFO - volta.train_utils -   [NLVR2]: iter 51364 Ep: 9.52 loss 0.023 score 0.209 lr 1.45718e-06 
12/02/2021 23:43:00 - INFO - volta.train_utils -   [NLVR2]: iter 51444 Ep: 9.53 loss 0.025 score 0.206 lr 1.45512e-06 
12/02/2021 23:43:21 - INFO - volta.train_utils -   [NLVR2]: iter 51524 Ep: 9.55 loss 0.016 score 0.217 lr 1.45306e-06 
12/02/2021 23:43:43 - INFO - volta.train_utils -   [NLVR2]: iter 51604 Ep: 9.56 loss 0.019 score 0.210 lr 1.451e-06 
12/02/2021 23:44:05 - INFO - volta.train_utils -   [NLVR2]: iter 51684 Ep: 9.57 loss 0.023 score 0.211 lr 1.44894e-06 
12/02/2021 23:44:27 - INFO - volta.train_utils -   [NLVR2]: iter 51764 Ep: 9.59 loss 0.021 score 0.207 lr 1.44688e-06 
12/02/2021 23:44:48 - INFO - volta.train_utils -   [NLVR2]: iter 51844 Ep: 9.60 loss 0.023 score 0.204 lr 1.44483e-06 
12/02/2021 23:45:10 - INFO - volta.train_utils -   [NLVR2]: iter 51924 Ep: 9.62 loss 0.021 score 0.209 lr 1.44277e-06 
12/02/2021 23:45:32 - INFO - volta.train_utils -   [NLVR2]: iter 52004 Ep: 9.63 loss 0.025 score 0.206 lr 1.44071e-06 
12/02/2021 23:45:54 - INFO - volta.train_utils -   [NLVR2]: iter 52084 Ep: 9.65 loss 0.019 score 0.206 lr 1.43865e-06 
12/02/2021 23:46:15 - INFO - volta.train_utils -   [NLVR2]: iter 52164 Ep: 9.66 loss 0.022 score 0.205 lr 1.43659e-06 
12/02/2021 23:46:37 - INFO - volta.train_utils -   [NLVR2]: iter 52244 Ep: 9.68 loss 0.022 score 0.206 lr 1.43453e-06 
12/02/2021 23:46:59 - INFO - volta.train_utils -   [NLVR2]: iter 52324 Ep: 9.69 loss 0.022 score 0.208 lr 1.43247e-06 
12/02/2021 23:47:20 - INFO - volta.train_utils -   [NLVR2]: iter 52404 Ep: 9.71 loss 0.025 score 0.208 lr 1.43042e-06 
12/02/2021 23:47:42 - INFO - volta.train_utils -   [NLVR2]: iter 52484 Ep: 9.72 loss 0.023 score 0.205 lr 1.42836e-06 
12/02/2021 23:48:04 - INFO - volta.train_utils -   [NLVR2]: iter 52564 Ep: 9.74 loss 0.023 score 0.204 lr 1.4263e-06 
12/02/2021 23:48:26 - INFO - volta.train_utils -   [NLVR2]: iter 52644 Ep: 9.75 loss 0.021 score 0.209 lr 1.42424e-06 
12/02/2021 23:48:47 - INFO - volta.train_utils -   [NLVR2]: iter 52724 Ep: 9.77 loss 0.022 score 0.207 lr 1.42218e-06 
12/02/2021 23:49:09 - INFO - volta.train_utils -   [NLVR2]: iter 52804 Ep: 9.78 loss 0.020 score 0.210 lr 1.42012e-06 
12/02/2021 23:49:31 - INFO - volta.train_utils -   [NLVR2]: iter 52884 Ep: 9.80 loss 0.025 score 0.205 lr 1.41807e-06 
12/02/2021 23:49:53 - INFO - volta.train_utils -   [NLVR2]: iter 52964 Ep: 9.81 loss 0.019 score 0.214 lr 1.41601e-06 
12/02/2021 23:50:14 - INFO - volta.train_utils -   [NLVR2]: iter 53044 Ep: 9.83 loss 0.018 score 0.212 lr 1.41395e-06 
12/02/2021 23:50:36 - INFO - volta.train_utils -   [NLVR2]: iter 53124 Ep: 9.84 loss 0.020 score 0.214 lr 1.41189e-06 
12/02/2021 23:50:58 - INFO - volta.train_utils -   [NLVR2]: iter 53204 Ep: 9.86 loss 0.021 score 0.210 lr 1.40983e-06 
12/02/2021 23:51:20 - INFO - volta.train_utils -   [NLVR2]: iter 53284 Ep: 9.87 loss 0.019 score 0.212 lr 1.40777e-06 
12/02/2021 23:51:41 - INFO - volta.train_utils -   [NLVR2]: iter 53364 Ep: 9.89 loss 0.020 score 0.212 lr 1.40572e-06 
12/02/2021 23:52:03 - INFO - volta.train_utils -   [NLVR2]: iter 53444 Ep: 9.90 loss 0.018 score 0.216 lr 1.40366e-06 
12/02/2021 23:52:25 - INFO - volta.train_utils -   [NLVR2]: iter 53524 Ep: 9.92 loss 0.020 score 0.213 lr 1.4016e-06 
12/02/2021 23:52:47 - INFO - volta.train_utils -   [NLVR2]: iter 53604 Ep: 9.93 loss 0.019 score 0.211 lr 1.39954e-06 
12/02/2021 23:53:08 - INFO - volta.train_utils -   [NLVR2]: iter 53684 Ep: 9.95 loss 0.020 score 0.213 lr 1.39748e-06 
12/02/2021 23:53:30 - INFO - volta.train_utils -   [NLVR2]: iter 53764 Ep: 9.96 loss 0.022 score 0.214 lr 1.39542e-06 
12/02/2021 23:53:52 - INFO - volta.train_utils -   [NLVR2]: iter 53844 Ep: 9.97 loss 0.021 score 0.216 lr 1.39337e-06 
12/02/2021 23:54:13 - INFO - volta.train_utils -   [NLVR2]: iter 53924 Ep: 9.99 loss 0.019 score 0.215 lr 1.39131e-06 
12/02/2021 23:55:07 - INFO - volta.train_utils -   Eval task TASK12 on iteration 53960 
12/02/2021 23:55:07 - INFO - volta.train_utils -   Validation [NLVR2]: loss 0.840 score 68.263 
Epoch:  50%|█████     | 10/20 [4:15:08<4:13:44, 1522.43s/it]12/02/2021 23:55:29 - INFO - volta.train_utils -   [NLVR2]: iter 54040 Ep: 10.01 loss 0.020 score 0.216 lr 1.38879e-06 
12/02/2021 23:55:51 - INFO - volta.train_utils -   [NLVR2]: iter 54120 Ep: 10.03 loss 0.020 score 0.210 lr 1.38626e-06 
12/02/2021 23:56:13 - INFO - volta.train_utils -   [NLVR2]: iter 54200 Ep: 10.04 loss 0.022 score 0.212 lr 1.38421e-06 
12/02/2021 23:56:34 - INFO - volta.train_utils -   [NLVR2]: iter 54280 Ep: 10.06 loss 0.021 score 0.212 lr 1.38215e-06 
12/02/2021 23:56:56 - INFO - volta.train_utils -   [NLVR2]: iter 54360 Ep: 10.07 loss 0.023 score 0.214 lr 1.38009e-06 
12/02/2021 23:57:18 - INFO - volta.train_utils -   [NLVR2]: iter 54440 Ep: 10.09 loss 0.020 score 0.213 lr 1.37803e-06 
12/02/2021 23:57:39 - INFO - volta.train_utils -   [NLVR2]: iter 54520 Ep: 10.10 loss 0.020 score 0.217 lr 1.37597e-06 
12/02/2021 23:58:01 - INFO - volta.train_utils -   [NLVR2]: iter 54600 Ep: 10.11 loss 0.023 score 0.210 lr 1.37391e-06 
12/02/2021 23:58:23 - INFO - volta.train_utils -   [NLVR2]: iter 54680 Ep: 10.13 loss 0.018 score 0.210 lr 1.37186e-06 
12/02/2021 23:58:45 - INFO - volta.train_utils -   [NLVR2]: iter 54760 Ep: 10.14 loss 0.022 score 0.212 lr 1.3698e-06 
12/02/2021 23:59:07 - INFO - volta.train_utils -   [NLVR2]: iter 54840 Ep: 10.16 loss 0.021 score 0.215 lr 1.36774e-06 
12/02/2021 23:59:28 - INFO - volta.train_utils -   [NLVR2]: iter 54920 Ep: 10.17 loss 0.020 score 0.212 lr 1.36568e-06 
12/02/2021 23:59:50 - INFO - volta.train_utils -   [NLVR2]: iter 55000 Ep: 10.19 loss 0.022 score 0.212 lr 1.36362e-06 
12/03/2021 00:00:12 - INFO - volta.train_utils -   [NLVR2]: iter 55080 Ep: 10.20 loss 0.021 score 0.210 lr 1.36156e-06 
12/03/2021 00:00:33 - INFO - volta.train_utils -   [NLVR2]: iter 55160 Ep: 10.22 loss 0.021 score 0.208 lr 1.35951e-06 
12/03/2021 00:00:55 - INFO - volta.train_utils -   [NLVR2]: iter 55240 Ep: 10.23 loss 0.021 score 0.212 lr 1.35745e-06 
12/03/2021 00:01:17 - INFO - volta.train_utils -   [NLVR2]: iter 55320 Ep: 10.25 loss 0.018 score 0.216 lr 1.35539e-06 
12/03/2021 00:01:39 - INFO - volta.train_utils -   [NLVR2]: iter 55400 Ep: 10.26 loss 0.022 score 0.211 lr 1.35333e-06 
12/03/2021 00:02:00 - INFO - volta.train_utils -   [NLVR2]: iter 55480 Ep: 10.28 loss 0.024 score 0.213 lr 1.35127e-06 
12/03/2021 00:02:22 - INFO - volta.train_utils -   [NLVR2]: iter 55560 Ep: 10.29 loss 0.019 score 0.214 lr 1.34921e-06 
12/03/2021 00:02:44 - INFO - volta.train_utils -   [NLVR2]: iter 55640 Ep: 10.31 loss 0.020 score 0.214 lr 1.34716e-06 
12/03/2021 00:03:05 - INFO - volta.train_utils -   [NLVR2]: iter 55720 Ep: 10.32 loss 0.020 score 0.217 lr 1.3451e-06 
12/03/2021 00:03:27 - INFO - volta.train_utils -   [NLVR2]: iter 55800 Ep: 10.34 loss 0.019 score 0.215 lr 1.34304e-06 
12/03/2021 00:03:49 - INFO - volta.train_utils -   [NLVR2]: iter 55880 Ep: 10.35 loss 0.024 score 0.208 lr 1.34098e-06 
12/03/2021 00:04:10 - INFO - volta.train_utils -   [NLVR2]: iter 55960 Ep: 10.37 loss 0.020 score 0.213 lr 1.33892e-06 
12/03/2021 00:04:32 - INFO - volta.train_utils -   [NLVR2]: iter 56040 Ep: 10.38 loss 0.020 score 0.215 lr 1.33686e-06 
12/03/2021 00:04:54 - INFO - volta.train_utils -   [NLVR2]: iter 56120 Ep: 10.40 loss 0.020 score 0.210 lr 1.33481e-06 
12/03/2021 00:05:16 - INFO - volta.train_utils -   [NLVR2]: iter 56200 Ep: 10.41 loss 0.020 score 0.213 lr 1.33275e-06 
12/03/2021 00:05:37 - INFO - volta.train_utils -   [NLVR2]: iter 56280 Ep: 10.43 loss 0.022 score 0.209 lr 1.33069e-06 
12/03/2021 00:05:59 - INFO - volta.train_utils -   [NLVR2]: iter 56360 Ep: 10.44 loss 0.018 score 0.211 lr 1.32863e-06 
12/03/2021 00:06:21 - INFO - volta.train_utils -   [NLVR2]: iter 56440 Ep: 10.46 loss 0.019 score 0.212 lr 1.32657e-06 
12/03/2021 00:06:42 - INFO - volta.train_utils -   [NLVR2]: iter 56520 Ep: 10.47 loss 0.017 score 0.215 lr 1.32451e-06 
12/03/2021 00:07:04 - INFO - volta.train_utils -   [NLVR2]: iter 56600 Ep: 10.49 loss 0.020 score 0.211 lr 1.32245e-06 
12/03/2021 00:07:26 - INFO - volta.train_utils -   [NLVR2]: iter 56680 Ep: 10.50 loss 0.018 score 0.214 lr 1.3204e-06 
12/03/2021 00:07:48 - INFO - volta.train_utils -   [NLVR2]: iter 56760 Ep: 10.52 loss 0.017 score 0.215 lr 1.31834e-06 
12/03/2021 00:08:09 - INFO - volta.train_utils -   [NLVR2]: iter 56840 Ep: 10.53 loss 0.021 score 0.212 lr 1.31628e-06 
12/03/2021 00:08:31 - INFO - volta.train_utils -   [NLVR2]: iter 56920 Ep: 10.54 loss 0.020 score 0.214 lr 1.31422e-06 
12/03/2021 00:08:53 - INFO - volta.train_utils -   [NLVR2]: iter 57000 Ep: 10.56 loss 0.019 score 0.212 lr 1.31216e-06 
12/03/2021 00:09:15 - INFO - volta.train_utils -   [NLVR2]: iter 57080 Ep: 10.57 loss 0.020 score 0.210 lr 1.3101e-06 
12/03/2021 00:09:36 - INFO - volta.train_utils -   [NLVR2]: iter 57160 Ep: 10.59 loss 0.020 score 0.213 lr 1.30805e-06 
12/03/2021 00:09:58 - INFO - volta.train_utils -   [NLVR2]: iter 57240 Ep: 10.60 loss 0.020 score 0.214 lr 1.30599e-06 
12/03/2021 00:10:20 - INFO - volta.train_utils -   [NLVR2]: iter 57320 Ep: 10.62 loss 0.020 score 0.214 lr 1.30393e-06 
12/03/2021 00:10:42 - INFO - volta.train_utils -   [NLVR2]: iter 57400 Ep: 10.63 loss 0.021 score 0.210 lr 1.30187e-06 
12/03/2021 00:11:03 - INFO - volta.train_utils -   [NLVR2]: iter 57480 Ep: 10.65 loss 0.019 score 0.215 lr 1.29981e-06 
12/03/2021 00:11:25 - INFO - volta.train_utils -   [NLVR2]: iter 57560 Ep: 10.66 loss 0.019 score 0.214 lr 1.29775e-06 
12/03/2021 00:11:47 - INFO - volta.train_utils -   [NLVR2]: iter 57640 Ep: 10.68 loss 0.020 score 0.208 lr 1.2957e-06 
12/03/2021 00:12:08 - INFO - volta.train_utils -   [NLVR2]: iter 57720 Ep: 10.69 loss 0.021 score 0.212 lr 1.29364e-06 
12/03/2021 00:12:30 - INFO - volta.train_utils -   [NLVR2]: iter 57800 Ep: 10.71 loss 0.018 score 0.215 lr 1.29158e-06 
12/03/2021 00:12:52 - INFO - volta.train_utils -   [NLVR2]: iter 57880 Ep: 10.72 loss 0.019 score 0.215 lr 1.28952e-06 
12/03/2021 00:13:13 - INFO - volta.train_utils -   [NLVR2]: iter 57960 Ep: 10.74 loss 0.018 score 0.208 lr 1.28746e-06 
12/03/2021 00:13:35 - INFO - volta.train_utils -   [NLVR2]: iter 58040 Ep: 10.75 loss 0.019 score 0.213 lr 1.2854e-06 
12/03/2021 00:13:57 - INFO - volta.train_utils -   [NLVR2]: iter 58120 Ep: 10.77 loss 0.019 score 0.211 lr 1.28335e-06 
12/03/2021 00:14:19 - INFO - volta.train_utils -   [NLVR2]: iter 58200 Ep: 10.78 loss 0.017 score 0.219 lr 1.28129e-06 
12/03/2021 00:14:40 - INFO - volta.train_utils -   [NLVR2]: iter 58280 Ep: 10.80 loss 0.021 score 0.213 lr 1.27923e-06 
12/03/2021 00:15:02 - INFO - volta.train_utils -   [NLVR2]: iter 58360 Ep: 10.81 loss 0.018 score 0.214 lr 1.27717e-06 
12/03/2021 00:15:24 - INFO - volta.train_utils -   [NLVR2]: iter 58440 Ep: 10.83 loss 0.019 score 0.217 lr 1.27511e-06 
12/03/2021 00:15:45 - INFO - volta.train_utils -   [NLVR2]: iter 58520 Ep: 10.84 loss 0.020 score 0.216 lr 1.27305e-06 
12/03/2021 00:16:07 - INFO - volta.train_utils -   [NLVR2]: iter 58600 Ep: 10.86 loss 0.022 score 0.214 lr 1.271e-06 
12/03/2021 00:16:29 - INFO - volta.train_utils -   [NLVR2]: iter 58680 Ep: 10.87 loss 0.018 score 0.214 lr 1.26894e-06 
12/03/2021 00:16:51 - INFO - volta.train_utils -   [NLVR2]: iter 58760 Ep: 10.89 loss 0.017 score 0.219 lr 1.26688e-06 
12/03/2021 00:17:12 - INFO - volta.train_utils -   [NLVR2]: iter 58840 Ep: 10.90 loss 0.017 score 0.215 lr 1.26482e-06 
12/03/2021 00:17:34 - INFO - volta.train_utils -   [NLVR2]: iter 58920 Ep: 10.92 loss 0.017 score 0.217 lr 1.26276e-06 
12/03/2021 00:17:56 - INFO - volta.train_utils -   [NLVR2]: iter 59000 Ep: 10.93 loss 0.017 score 0.220 lr 1.2607e-06 
12/03/2021 00:18:18 - INFO - volta.train_utils -   [NLVR2]: iter 59080 Ep: 10.94 loss 0.020 score 0.215 lr 1.25865e-06 
12/03/2021 00:18:39 - INFO - volta.train_utils -   [NLVR2]: iter 59160 Ep: 10.96 loss 0.018 score 0.218 lr 1.25659e-06 
12/03/2021 00:19:01 - INFO - volta.train_utils -   [NLVR2]: iter 59240 Ep: 10.97 loss 0.019 score 0.216 lr 1.25453e-06 
12/03/2021 00:19:23 - INFO - volta.train_utils -   [NLVR2]: iter 59320 Ep: 10.99 loss 0.018 score 0.217 lr 1.25247e-06 
12/03/2021 00:20:16 - INFO - volta.train_utils -   Eval task TASK12 on iteration 59356 
12/03/2021 00:20:16 - INFO - volta.train_utils -   Validation [NLVR2]: loss 0.898 score 67.990 
Epoch:  55%|█████▌    | 11/20 [4:40:17<3:47:45, 1518.43s/it]12/03/2021 00:20:38 - INFO - volta.train_utils -   [NLVR2]: iter 59436 Ep: 11.01 loss 0.017 score 0.218 lr 1.24995e-06 
12/03/2021 00:21:00 - INFO - volta.train_utils -   [NLVR2]: iter 59516 Ep: 11.03 loss 0.016 score 0.218 lr 1.24743e-06 
12/03/2021 00:21:22 - INFO - volta.train_utils -   [NLVR2]: iter 59596 Ep: 11.04 loss 0.019 score 0.219 lr 1.24537e-06 
12/03/2021 00:21:43 - INFO - volta.train_utils -   [NLVR2]: iter 59676 Ep: 11.06 loss 0.019 score 0.216 lr 1.24331e-06 
12/03/2021 00:22:05 - INFO - volta.train_utils -   [NLVR2]: iter 59756 Ep: 11.07 loss 0.015 score 0.216 lr 1.24125e-06 
12/03/2021 00:22:27 - INFO - volta.train_utils -   [NLVR2]: iter 59836 Ep: 11.08 loss 0.020 score 0.217 lr 1.23919e-06 
12/03/2021 00:22:48 - INFO - volta.train_utils -   [NLVR2]: iter 59916 Ep: 11.10 loss 0.019 score 0.215 lr 1.23714e-06 
12/03/2021 00:23:10 - INFO - volta.train_utils -   [NLVR2]: iter 59996 Ep: 11.11 loss 0.021 score 0.214 lr 1.23508e-06 
12/03/2021 00:23:32 - INFO - volta.train_utils -   [NLVR2]: iter 60076 Ep: 11.13 loss 0.018 score 0.217 lr 1.23302e-06 
12/03/2021 00:23:53 - INFO - volta.train_utils -   [NLVR2]: iter 60156 Ep: 11.14 loss 0.020 score 0.214 lr 1.23096e-06 
12/03/2021 00:24:15 - INFO - volta.train_utils -   [NLVR2]: iter 60236 Ep: 11.16 loss 0.019 score 0.220 lr 1.2289e-06 
12/03/2021 00:24:37 - INFO - volta.train_utils -   [NLVR2]: iter 60316 Ep: 11.17 loss 0.018 score 0.216 lr 1.22684e-06 
12/03/2021 00:24:59 - INFO - volta.train_utils -   [NLVR2]: iter 60396 Ep: 11.19 loss 0.018 score 0.213 lr 1.22478e-06 
12/03/2021 00:25:21 - INFO - volta.train_utils -   [NLVR2]: iter 60476 Ep: 11.20 loss 0.020 score 0.220 lr 1.22273e-06 
12/03/2021 00:25:42 - INFO - volta.train_utils -   [NLVR2]: iter 60556 Ep: 11.22 loss 0.017 score 0.219 lr 1.22067e-06 
12/03/2021 00:26:04 - INFO - volta.train_utils -   [NLVR2]: iter 60636 Ep: 11.23 loss 0.016 score 0.218 lr 1.21861e-06 
12/03/2021 00:26:26 - INFO - volta.train_utils -   [NLVR2]: iter 60716 Ep: 11.25 loss 0.020 score 0.219 lr 1.21655e-06 
12/03/2021 00:26:47 - INFO - volta.train_utils -   [NLVR2]: iter 60796 Ep: 11.26 loss 0.020 score 0.214 lr 1.21449e-06 
12/03/2021 00:27:09 - INFO - volta.train_utils -   [NLVR2]: iter 60876 Ep: 11.28 loss 0.020 score 0.218 lr 1.21243e-06 
12/03/2021 00:27:31 - INFO - volta.train_utils -   [NLVR2]: iter 60956 Ep: 11.29 loss 0.015 score 0.215 lr 1.21038e-06 
12/03/2021 00:27:53 - INFO - volta.train_utils -   [NLVR2]: iter 61036 Ep: 11.31 loss 0.018 score 0.221 lr 1.20832e-06 
12/03/2021 00:28:14 - INFO - volta.train_utils -   [NLVR2]: iter 61116 Ep: 11.32 loss 0.018 score 0.222 lr 1.20626e-06 
12/03/2021 00:28:36 - INFO - volta.train_utils -   [NLVR2]: iter 61196 Ep: 11.34 loss 0.016 score 0.218 lr 1.2042e-06 
12/03/2021 00:28:58 - INFO - volta.train_utils -   [NLVR2]: iter 61276 Ep: 11.35 loss 0.017 score 0.218 lr 1.20214e-06 
12/03/2021 00:29:19 - INFO - volta.train_utils -   [NLVR2]: iter 61356 Ep: 11.37 loss 0.018 score 0.220 lr 1.20008e-06 
12/03/2021 00:29:41 - INFO - volta.train_utils -   [NLVR2]: iter 61436 Ep: 11.38 loss 0.022 score 0.217 lr 1.19803e-06 
12/03/2021 00:30:03 - INFO - volta.train_utils -   [NLVR2]: iter 61516 Ep: 11.40 loss 0.014 score 0.219 lr 1.19597e-06 
12/03/2021 00:30:25 - INFO - volta.train_utils -   [NLVR2]: iter 61596 Ep: 11.41 loss 0.019 score 0.215 lr 1.19391e-06 
12/03/2021 00:30:46 - INFO - volta.train_utils -   [NLVR2]: iter 61676 Ep: 11.43 loss 0.018 score 0.213 lr 1.19185e-06 
12/03/2021 00:31:08 - INFO - volta.train_utils -   [NLVR2]: iter 61756 Ep: 11.44 loss 0.020 score 0.217 lr 1.18979e-06 
12/03/2021 00:31:30 - INFO - volta.train_utils -   [NLVR2]: iter 61836 Ep: 11.46 loss 0.018 score 0.214 lr 1.18773e-06 
12/03/2021 00:31:52 - INFO - volta.train_utils -   [NLVR2]: iter 61916 Ep: 11.47 loss 0.017 score 0.217 lr 1.18568e-06 
12/03/2021 00:32:13 - INFO - volta.train_utils -   [NLVR2]: iter 61996 Ep: 11.48 loss 0.020 score 0.214 lr 1.18362e-06 
12/03/2021 00:32:35 - INFO - volta.train_utils -   [NLVR2]: iter 62076 Ep: 11.50 loss 0.017 score 0.214 lr 1.18156e-06 
12/03/2021 00:32:57 - INFO - volta.train_utils -   [NLVR2]: iter 62156 Ep: 11.51 loss 0.018 score 0.217 lr 1.1795e-06 
12/03/2021 00:33:18 - INFO - volta.train_utils -   [NLVR2]: iter 62236 Ep: 11.53 loss 0.018 score 0.217 lr 1.17744e-06 
12/03/2021 00:33:40 - INFO - volta.train_utils -   [NLVR2]: iter 62316 Ep: 11.54 loss 0.020 score 0.215 lr 1.17538e-06 
12/03/2021 00:34:02 - INFO - volta.train_utils -   [NLVR2]: iter 62396 Ep: 11.56 loss 0.019 score 0.216 lr 1.17333e-06 
12/03/2021 00:34:24 - INFO - volta.train_utils -   [NLVR2]: iter 62476 Ep: 11.57 loss 0.017 score 0.218 lr 1.17127e-06 
12/03/2021 00:34:45 - INFO - volta.train_utils -   [NLVR2]: iter 62556 Ep: 11.59 loss 0.017 score 0.216 lr 1.16921e-06 
12/03/2021 00:35:07 - INFO - volta.train_utils -   [NLVR2]: iter 62636 Ep: 11.60 loss 0.020 score 0.216 lr 1.16715e-06 
12/03/2021 00:35:29 - INFO - volta.train_utils -   [NLVR2]: iter 62716 Ep: 11.62 loss 0.017 score 0.217 lr 1.16509e-06 
12/03/2021 00:35:51 - INFO - volta.train_utils -   [NLVR2]: iter 62796 Ep: 11.63 loss 0.017 score 0.221 lr 1.16303e-06 
12/03/2021 00:36:12 - INFO - volta.train_utils -   [NLVR2]: iter 62876 Ep: 11.65 loss 0.020 score 0.214 lr 1.16098e-06 
12/03/2021 00:36:34 - INFO - volta.train_utils -   [NLVR2]: iter 62956 Ep: 11.66 loss 0.018 score 0.215 lr 1.15892e-06 
12/03/2021 00:36:56 - INFO - volta.train_utils -   [NLVR2]: iter 63036 Ep: 11.68 loss 0.015 score 0.220 lr 1.15686e-06 
12/03/2021 00:37:17 - INFO - volta.train_utils -   [NLVR2]: iter 63116 Ep: 11.69 loss 0.020 score 0.213 lr 1.1548e-06 
12/03/2021 00:37:39 - INFO - volta.train_utils -   [NLVR2]: iter 63196 Ep: 11.71 loss 0.021 score 0.215 lr 1.15274e-06 
12/03/2021 00:38:01 - INFO - volta.train_utils -   [NLVR2]: iter 63276 Ep: 11.72 loss 0.020 score 0.214 lr 1.15068e-06 
12/03/2021 00:38:23 - INFO - volta.train_utils -   [NLVR2]: iter 63356 Ep: 11.74 loss 0.017 score 0.216 lr 1.14863e-06 
12/03/2021 00:38:44 - INFO - volta.train_utils -   [NLVR2]: iter 63436 Ep: 11.75 loss 0.018 score 0.221 lr 1.14657e-06 
12/03/2021 00:39:06 - INFO - volta.train_utils -   [NLVR2]: iter 63516 Ep: 11.77 loss 0.018 score 0.221 lr 1.14451e-06 
12/03/2021 00:39:28 - INFO - volta.train_utils -   [NLVR2]: iter 63596 Ep: 11.78 loss 0.015 score 0.218 lr 1.14245e-06 
12/03/2021 00:39:50 - INFO - volta.train_utils -   [NLVR2]: iter 63676 Ep: 11.80 loss 0.020 score 0.217 lr 1.14039e-06 
12/03/2021 00:40:11 - INFO - volta.train_utils -   [NLVR2]: iter 63756 Ep: 11.81 loss 0.016 score 0.215 lr 1.13833e-06 
12/03/2021 00:40:33 - INFO - volta.train_utils -   [NLVR2]: iter 63836 Ep: 11.83 loss 0.017 score 0.221 lr 1.13627e-06 
12/03/2021 00:40:55 - INFO - volta.train_utils -   [NLVR2]: iter 63916 Ep: 11.84 loss 0.018 score 0.220 lr 1.13422e-06 
12/03/2021 00:41:17 - INFO - volta.train_utils -   [NLVR2]: iter 63996 Ep: 11.86 loss 0.017 score 0.220 lr 1.13216e-06 
12/03/2021 00:41:38 - INFO - volta.train_utils -   [NLVR2]: iter 64076 Ep: 11.87 loss 0.017 score 0.218 lr 1.1301e-06 
12/03/2021 00:42:00 - INFO - volta.train_utils -   [NLVR2]: iter 64156 Ep: 11.89 loss 0.016 score 0.218 lr 1.12804e-06 
12/03/2021 00:42:22 - INFO - volta.train_utils -   [NLVR2]: iter 64236 Ep: 11.90 loss 0.015 score 0.222 lr 1.12598e-06 
12/03/2021 00:42:43 - INFO - volta.train_utils -   [NLVR2]: iter 64316 Ep: 11.91 loss 0.017 score 0.224 lr 1.12392e-06 
12/03/2021 00:43:05 - INFO - volta.train_utils -   [NLVR2]: iter 64396 Ep: 11.93 loss 0.019 score 0.217 lr 1.12187e-06 
12/03/2021 00:43:27 - INFO - volta.train_utils -   [NLVR2]: iter 64476 Ep: 11.94 loss 0.019 score 0.218 lr 1.11981e-06 
12/03/2021 00:43:49 - INFO - volta.train_utils -   [NLVR2]: iter 64556 Ep: 11.96 loss 0.018 score 0.220 lr 1.11775e-06 
12/03/2021 00:44:10 - INFO - volta.train_utils -   [NLVR2]: iter 64636 Ep: 11.97 loss 0.014 score 0.225 lr 1.11569e-06 
12/03/2021 00:44:32 - INFO - volta.train_utils -   [NLVR2]: iter 64716 Ep: 11.99 loss 0.015 score 0.219 lr 1.11363e-06 
12/03/2021 00:45:25 - INFO - volta.train_utils -   Eval task TASK12 on iteration 64752 
12/03/2021 00:45:25 - INFO - volta.train_utils -   Validation [NLVR2]: loss 0.998 score 67.661 
Epoch:  60%|██████    | 12/20 [5:05:27<3:22:05, 1515.68s/it]12/03/2021 00:45:47 - INFO - volta.train_utils -   [NLVR2]: iter 64832 Ep: 12.01 loss 0.015 score 0.225 lr 1.11111e-06 
12/03/2021 00:46:09 - INFO - volta.train_utils -   [NLVR2]: iter 64912 Ep: 12.03 loss 0.019 score 0.217 lr 1.10859e-06 
12/03/2021 00:46:31 - INFO - volta.train_utils -   [NLVR2]: iter 64992 Ep: 12.04 loss 0.017 score 0.223 lr 1.10653e-06 
12/03/2021 00:46:53 - INFO - volta.train_utils -   [NLVR2]: iter 65072 Ep: 12.05 loss 0.016 score 0.221 lr 1.10447e-06 
12/03/2021 00:47:14 - INFO - volta.train_utils -   [NLVR2]: iter 65152 Ep: 12.07 loss 0.018 score 0.221 lr 1.10241e-06 
12/03/2021 00:47:36 - INFO - volta.train_utils -   [NLVR2]: iter 65232 Ep: 12.08 loss 0.016 score 0.221 lr 1.10036e-06 
12/03/2021 00:47:58 - INFO - volta.train_utils -   [NLVR2]: iter 65312 Ep: 12.10 loss 0.016 score 0.220 lr 1.0983e-06 
12/03/2021 00:48:19 - INFO - volta.train_utils -   [NLVR2]: iter 65392 Ep: 12.11 loss 0.018 score 0.222 lr 1.09624e-06 
12/03/2021 00:48:41 - INFO - volta.train_utils -   [NLVR2]: iter 65472 Ep: 12.13 loss 0.015 score 0.215 lr 1.09418e-06 
12/03/2021 00:49:03 - INFO - volta.train_utils -   [NLVR2]: iter 65552 Ep: 12.14 loss 0.016 score 0.220 lr 1.09212e-06 
12/03/2021 00:49:25 - INFO - volta.train_utils -   [NLVR2]: iter 65632 Ep: 12.16 loss 0.017 score 0.220 lr 1.09006e-06 
12/03/2021 00:49:46 - INFO - volta.train_utils -   [NLVR2]: iter 65712 Ep: 12.17 loss 0.017 score 0.217 lr 1.08801e-06 
12/03/2021 00:50:08 - INFO - volta.train_utils -   [NLVR2]: iter 65792 Ep: 12.19 loss 0.015 score 0.221 lr 1.08595e-06 
12/03/2021 00:50:30 - INFO - volta.train_utils -   [NLVR2]: iter 65872 Ep: 12.20 loss 0.017 score 0.221 lr 1.08389e-06 
12/03/2021 00:50:52 - INFO - volta.train_utils -   [NLVR2]: iter 65952 Ep: 12.22 loss 0.018 score 0.215 lr 1.08183e-06 
12/03/2021 00:51:13 - INFO - volta.train_utils -   [NLVR2]: iter 66032 Ep: 12.23 loss 0.016 score 0.219 lr 1.07977e-06 
12/03/2021 00:51:35 - INFO - volta.train_utils -   [NLVR2]: iter 66112 Ep: 12.25 loss 0.018 score 0.222 lr 1.07771e-06 
12/03/2021 00:51:57 - INFO - volta.train_utils -   [NLVR2]: iter 66192 Ep: 12.26 loss 0.012 score 0.225 lr 1.07566e-06 
12/03/2021 00:52:19 - INFO - volta.train_utils -   [NLVR2]: iter 66272 Ep: 12.28 loss 0.014 score 0.222 lr 1.0736e-06 
12/03/2021 00:52:40 - INFO - volta.train_utils -   [NLVR2]: iter 66352 Ep: 12.29 loss 0.015 score 0.219 lr 1.07154e-06 
12/03/2021 00:53:02 - INFO - volta.train_utils -   [NLVR2]: iter 66432 Ep: 12.31 loss 0.017 score 0.220 lr 1.06948e-06 
12/03/2021 00:53:24 - INFO - volta.train_utils -   [NLVR2]: iter 66512 Ep: 12.32 loss 0.011 score 0.230 lr 1.06742e-06 
12/03/2021 00:53:46 - INFO - volta.train_utils -   [NLVR2]: iter 66592 Ep: 12.34 loss 0.017 score 0.221 lr 1.06536e-06 
12/03/2021 00:54:07 - INFO - volta.train_utils -   [NLVR2]: iter 66672 Ep: 12.35 loss 0.016 score 0.219 lr 1.06331e-06 
12/03/2021 00:54:29 - INFO - volta.train_utils -   [NLVR2]: iter 66752 Ep: 12.37 loss 0.019 score 0.219 lr 1.06125e-06 
12/03/2021 00:54:51 - INFO - volta.train_utils -   [NLVR2]: iter 66832 Ep: 12.38 loss 0.018 score 0.220 lr 1.05919e-06 
12/03/2021 00:55:12 - INFO - volta.train_utils -   [NLVR2]: iter 66912 Ep: 12.40 loss 0.016 score 0.220 lr 1.05713e-06 
12/03/2021 00:55:34 - INFO - volta.train_utils -   [NLVR2]: iter 66992 Ep: 12.41 loss 0.017 score 0.219 lr 1.05507e-06 
12/03/2021 00:55:56 - INFO - volta.train_utils -   [NLVR2]: iter 67072 Ep: 12.43 loss 0.013 score 0.226 lr 1.05301e-06 
12/03/2021 00:56:18 - INFO - volta.train_utils -   [NLVR2]: iter 67152 Ep: 12.44 loss 0.016 score 0.218 lr 1.05096e-06 
12/03/2021 00:56:39 - INFO - volta.train_utils -   [NLVR2]: iter 67232 Ep: 12.45 loss 0.017 score 0.218 lr 1.0489e-06 
12/03/2021 00:57:01 - INFO - volta.train_utils -   [NLVR2]: iter 67312 Ep: 12.47 loss 0.018 score 0.218 lr 1.04684e-06 
12/03/2021 00:57:23 - INFO - volta.train_utils -   [NLVR2]: iter 67392 Ep: 12.48 loss 0.018 score 0.215 lr 1.04478e-06 
12/03/2021 00:57:45 - INFO - volta.train_utils -   [NLVR2]: iter 67472 Ep: 12.50 loss 0.018 score 0.221 lr 1.04272e-06 
12/03/2021 00:58:06 - INFO - volta.train_utils -   [NLVR2]: iter 67552 Ep: 12.51 loss 0.017 score 0.222 lr 1.04066e-06 
12/03/2021 00:58:28 - INFO - volta.train_utils -   [NLVR2]: iter 67632 Ep: 12.53 loss 0.014 score 0.221 lr 1.0386e-06 
12/03/2021 00:58:50 - INFO - volta.train_utils -   [NLVR2]: iter 67712 Ep: 12.54 loss 0.018 score 0.218 lr 1.03655e-06 
12/03/2021 00:59:12 - INFO - volta.train_utils -   [NLVR2]: iter 67792 Ep: 12.56 loss 0.017 score 0.217 lr 1.03449e-06 
12/03/2021 00:59:33 - INFO - volta.train_utils -   [NLVR2]: iter 67872 Ep: 12.57 loss 0.017 score 0.223 lr 1.03243e-06 
12/03/2021 00:59:55 - INFO - volta.train_utils -   [NLVR2]: iter 67952 Ep: 12.59 loss 0.017 score 0.218 lr 1.03037e-06 
12/03/2021 01:00:17 - INFO - volta.train_utils -   [NLVR2]: iter 68032 Ep: 12.60 loss 0.012 score 0.221 lr 1.02831e-06 
12/03/2021 01:00:38 - INFO - volta.train_utils -   [NLVR2]: iter 68112 Ep: 12.62 loss 0.014 score 0.222 lr 1.02625e-06 
12/03/2021 01:01:00 - INFO - volta.train_utils -   [NLVR2]: iter 68192 Ep: 12.63 loss 0.016 score 0.223 lr 1.0242e-06 
12/03/2021 01:01:22 - INFO - volta.train_utils -   [NLVR2]: iter 68272 Ep: 12.65 loss 0.015 score 0.219 lr 1.02214e-06 
12/03/2021 01:01:44 - INFO - volta.train_utils -   [NLVR2]: iter 68352 Ep: 12.66 loss 0.016 score 0.220 lr 1.02008e-06 
12/03/2021 01:02:05 - INFO - volta.train_utils -   [NLVR2]: iter 68432 Ep: 12.68 loss 0.018 score 0.220 lr 1.01802e-06 
12/03/2021 01:02:27 - INFO - volta.train_utils -   [NLVR2]: iter 68512 Ep: 12.69 loss 0.020 score 0.216 lr 1.01596e-06 
12/03/2021 01:02:49 - INFO - volta.train_utils -   [NLVR2]: iter 68592 Ep: 12.71 loss 0.019 score 0.219 lr 1.0139e-06 
12/03/2021 01:03:10 - INFO - volta.train_utils -   [NLVR2]: iter 68672 Ep: 12.72 loss 0.014 score 0.224 lr 1.01185e-06 
12/03/2021 01:03:32 - INFO - volta.train_utils -   [NLVR2]: iter 68752 Ep: 12.74 loss 0.016 score 0.221 lr 1.00979e-06 
12/03/2021 01:03:54 - INFO - volta.train_utils -   [NLVR2]: iter 68832 Ep: 12.75 loss 0.017 score 0.223 lr 1.00773e-06 
12/03/2021 01:04:16 - INFO - volta.train_utils -   [NLVR2]: iter 68912 Ep: 12.77 loss 0.019 score 0.216 lr 1.00567e-06 
12/03/2021 01:04:38 - INFO - volta.train_utils -   [NLVR2]: iter 68992 Ep: 12.78 loss 0.018 score 0.220 lr 1.00361e-06 
12/03/2021 01:04:59 - INFO - volta.train_utils -   [NLVR2]: iter 69072 Ep: 12.80 loss 0.014 score 0.222 lr 1.00155e-06 
12/03/2021 01:05:21 - INFO - volta.train_utils -   [NLVR2]: iter 69152 Ep: 12.81 loss 0.013 score 0.224 lr 9.99496e-07 
12/03/2021 01:05:43 - INFO - volta.train_utils -   [NLVR2]: iter 69232 Ep: 12.83 loss 0.018 score 0.222 lr 9.97437e-07 
12/03/2021 01:06:05 - INFO - volta.train_utils -   [NLVR2]: iter 69312 Ep: 12.84 loss 0.014 score 0.223 lr 9.95379e-07 
12/03/2021 01:06:26 - INFO - volta.train_utils -   [NLVR2]: iter 69392 Ep: 12.86 loss 0.015 score 0.222 lr 9.93321e-07 
12/03/2021 01:06:48 - INFO - volta.train_utils -   [NLVR2]: iter 69472 Ep: 12.87 loss 0.013 score 0.224 lr 9.91262e-07 
12/03/2021 01:07:10 - INFO - volta.train_utils -   [NLVR2]: iter 69552 Ep: 12.88 loss 0.012 score 0.224 lr 9.89204e-07 
12/03/2021 01:07:31 - INFO - volta.train_utils -   [NLVR2]: iter 69632 Ep: 12.90 loss 0.017 score 0.220 lr 9.87145e-07 
12/03/2021 01:07:53 - INFO - volta.train_utils -   [NLVR2]: iter 69712 Ep: 12.91 loss 0.016 score 0.223 lr 9.85087e-07 
12/03/2021 01:08:15 - INFO - volta.train_utils -   [NLVR2]: iter 69792 Ep: 12.93 loss 0.016 score 0.222 lr 9.83029e-07 
12/03/2021 01:08:37 - INFO - volta.train_utils -   [NLVR2]: iter 69872 Ep: 12.94 loss 0.016 score 0.226 lr 9.8097e-07 
12/03/2021 01:08:59 - INFO - volta.train_utils -   [NLVR2]: iter 69952 Ep: 12.96 loss 0.013 score 0.224 lr 9.78912e-07 
12/03/2021 01:09:20 - INFO - volta.train_utils -   [NLVR2]: iter 70032 Ep: 12.97 loss 0.015 score 0.222 lr 9.76854e-07 
12/03/2021 01:09:42 - INFO - volta.train_utils -   [NLVR2]: iter 70112 Ep: 12.99 loss 0.015 score 0.225 lr 9.74795e-07 
12/03/2021 01:10:35 - INFO - volta.train_utils -   Eval task TASK12 on iteration 70148 
12/03/2021 01:10:35 - INFO - volta.train_utils -   Validation [NLVR2]: loss 1.075 score 67.130 
Epoch:  65%|██████▌   | 13/20 [5:30:36<2:56:37, 1513.94s/it]12/03/2021 01:10:57 - INFO - volta.train_utils -   [NLVR2]: iter 70228 Ep: 13.01 loss 0.015 score 0.227 lr 9.72274e-07 
12/03/2021 01:11:19 - INFO - volta.train_utils -   [NLVR2]: iter 70308 Ep: 13.02 loss 0.015 score 0.225 lr 9.69752e-07 
12/03/2021 01:11:41 - INFO - volta.train_utils -   [NLVR2]: iter 70388 Ep: 13.04 loss 0.012 score 0.224 lr 9.67694e-07 
12/03/2021 01:12:02 - INFO - volta.train_utils -   [NLVR2]: iter 70468 Ep: 13.05 loss 0.013 score 0.221 lr 9.65635e-07 
12/03/2021 01:12:24 - INFO - volta.train_utils -   [NLVR2]: iter 70548 Ep: 13.07 loss 0.015 score 0.223 lr 9.63577e-07 
12/03/2021 01:12:46 - INFO - volta.train_utils -   [NLVR2]: iter 70628 Ep: 13.08 loss 0.013 score 0.223 lr 9.61519e-07 
12/03/2021 01:13:08 - INFO - volta.train_utils -   [NLVR2]: iter 70708 Ep: 13.10 loss 0.013 score 0.222 lr 9.5946e-07 
12/03/2021 01:13:30 - INFO - volta.train_utils -   [NLVR2]: iter 70788 Ep: 13.11 loss 0.016 score 0.223 lr 9.57402e-07 
12/03/2021 01:13:51 - INFO - volta.train_utils -   [NLVR2]: iter 70868 Ep: 13.13 loss 0.017 score 0.224 lr 9.55344e-07 
12/03/2021 01:14:13 - INFO - volta.train_utils -   [NLVR2]: iter 70948 Ep: 13.14 loss 0.015 score 0.221 lr 9.53285e-07 
12/03/2021 01:14:35 - INFO - volta.train_utils -   [NLVR2]: iter 71028 Ep: 13.16 loss 0.014 score 0.225 lr 9.51227e-07 
12/03/2021 01:14:56 - INFO - volta.train_utils -   [NLVR2]: iter 71108 Ep: 13.17 loss 0.015 score 0.222 lr 9.49168e-07 
12/03/2021 01:15:18 - INFO - volta.train_utils -   [NLVR2]: iter 71188 Ep: 13.19 loss 0.017 score 0.226 lr 9.4711e-07 
12/03/2021 01:15:40 - INFO - volta.train_utils -   [NLVR2]: iter 71268 Ep: 13.20 loss 0.018 score 0.221 lr 9.45052e-07 
12/03/2021 01:16:02 - INFO - volta.train_utils -   [NLVR2]: iter 71348 Ep: 13.22 loss 0.016 score 0.221 lr 9.42993e-07 
12/03/2021 01:16:23 - INFO - volta.train_utils -   [NLVR2]: iter 71428 Ep: 13.23 loss 0.015 score 0.222 lr 9.40935e-07 
12/03/2021 01:16:45 - INFO - volta.train_utils -   [NLVR2]: iter 71508 Ep: 13.25 loss 0.013 score 0.225 lr 9.38877e-07 
12/03/2021 01:17:07 - INFO - volta.train_utils -   [NLVR2]: iter 71588 Ep: 13.26 loss 0.016 score 0.222 lr 9.36818e-07 
12/03/2021 01:17:29 - INFO - volta.train_utils -   [NLVR2]: iter 71668 Ep: 13.28 loss 0.016 score 0.225 lr 9.3476e-07 
12/03/2021 01:17:51 - INFO - volta.train_utils -   [NLVR2]: iter 71748 Ep: 13.29 loss 0.012 score 0.224 lr 9.32701e-07 
12/03/2021 01:18:12 - INFO - volta.train_utils -   [NLVR2]: iter 71828 Ep: 13.31 loss 0.016 score 0.226 lr 9.30643e-07 
12/03/2021 01:18:34 - INFO - volta.train_utils -   [NLVR2]: iter 71908 Ep: 13.32 loss 0.016 score 0.225 lr 9.28585e-07 
12/03/2021 01:18:56 - INFO - volta.train_utils -   [NLVR2]: iter 71988 Ep: 13.34 loss 0.014 score 0.222 lr 9.26526e-07 
12/03/2021 01:19:18 - INFO - volta.train_utils -   [NLVR2]: iter 72068 Ep: 13.35 loss 0.014 score 0.224 lr 9.24468e-07 
12/03/2021 01:19:39 - INFO - volta.train_utils -   [NLVR2]: iter 72148 Ep: 13.37 loss 0.014 score 0.220 lr 9.2241e-07 
12/03/2021 01:20:01 - INFO - volta.train_utils -   [NLVR2]: iter 72228 Ep: 13.38 loss 0.012 score 0.223 lr 9.20351e-07 
12/03/2021 01:20:23 - INFO - volta.train_utils -   [NLVR2]: iter 72308 Ep: 13.40 loss 0.014 score 0.224 lr 9.18293e-07 
12/03/2021 01:20:44 - INFO - volta.train_utils -   [NLVR2]: iter 72388 Ep: 13.41 loss 0.015 score 0.225 lr 9.16234e-07 
12/03/2021 01:21:06 - INFO - volta.train_utils -   [NLVR2]: iter 72468 Ep: 13.42 loss 0.015 score 0.227 lr 9.14176e-07 
12/03/2021 01:21:28 - INFO - volta.train_utils -   [NLVR2]: iter 72548 Ep: 13.44 loss 0.016 score 0.225 lr 9.12118e-07 
12/03/2021 01:21:50 - INFO - volta.train_utils -   [NLVR2]: iter 72628 Ep: 13.45 loss 0.015 score 0.219 lr 9.10059e-07 
12/03/2021 01:22:11 - INFO - volta.train_utils -   [NLVR2]: iter 72708 Ep: 13.47 loss 0.017 score 0.223 lr 9.08001e-07 
12/03/2021 01:22:34 - INFO - volta.train_utils -   [NLVR2]: iter 72788 Ep: 13.48 loss 0.015 score 0.224 lr 9.05943e-07 
12/03/2021 01:22:55 - INFO - volta.train_utils -   [NLVR2]: iter 72868 Ep: 13.50 loss 0.015 score 0.223 lr 9.03884e-07 
12/03/2021 01:23:17 - INFO - volta.train_utils -   [NLVR2]: iter 72948 Ep: 13.51 loss 0.013 score 0.225 lr 9.01826e-07 
12/03/2021 01:23:39 - INFO - volta.train_utils -   [NLVR2]: iter 73028 Ep: 13.53 loss 0.016 score 0.222 lr 8.99767e-07 
12/03/2021 01:24:01 - INFO - volta.train_utils -   [NLVR2]: iter 73108 Ep: 13.54 loss 0.014 score 0.222 lr 8.97709e-07 
12/03/2021 01:24:23 - INFO - volta.train_utils -   [NLVR2]: iter 73188 Ep: 13.56 loss 0.016 score 0.223 lr 8.95651e-07 
12/03/2021 01:24:45 - INFO - volta.train_utils -   [NLVR2]: iter 73268 Ep: 13.57 loss 0.017 score 0.226 lr 8.93592e-07 
12/03/2021 01:25:06 - INFO - volta.train_utils -   [NLVR2]: iter 73348 Ep: 13.59 loss 0.015 score 0.225 lr 8.91534e-07 
12/03/2021 01:25:28 - INFO - volta.train_utils -   [NLVR2]: iter 73428 Ep: 13.60 loss 0.011 score 0.221 lr 8.89476e-07 
12/03/2021 01:25:50 - INFO - volta.train_utils -   [NLVR2]: iter 73508 Ep: 13.62 loss 0.015 score 0.224 lr 8.87417e-07 
12/03/2021 01:26:11 - INFO - volta.train_utils -   [NLVR2]: iter 73588 Ep: 13.63 loss 0.015 score 0.222 lr 8.85359e-07 
12/03/2021 01:26:33 - INFO - volta.train_utils -   [NLVR2]: iter 73668 Ep: 13.65 loss 0.017 score 0.223 lr 8.833e-07 
12/03/2021 01:26:55 - INFO - volta.train_utils -   [NLVR2]: iter 73748 Ep: 13.66 loss 0.013 score 0.221 lr 8.81242e-07 
12/03/2021 01:27:16 - INFO - volta.train_utils -   [NLVR2]: iter 73828 Ep: 13.68 loss 0.015 score 0.223 lr 8.79184e-07 
12/03/2021 01:27:39 - INFO - volta.train_utils -   [NLVR2]: iter 73908 Ep: 13.69 loss 0.015 score 0.225 lr 8.77125e-07 
12/03/2021 01:28:01 - INFO - volta.train_utils -   [NLVR2]: iter 73988 Ep: 13.71 loss 0.016 score 0.221 lr 8.75067e-07 
12/03/2021 01:28:23 - INFO - volta.train_utils -   [NLVR2]: iter 74068 Ep: 13.72 loss 0.014 score 0.222 lr 8.73009e-07 
12/03/2021 01:28:44 - INFO - volta.train_utils -   [NLVR2]: iter 74148 Ep: 13.74 loss 0.013 score 0.221 lr 8.7095e-07 
12/03/2021 01:29:07 - INFO - volta.train_utils -   [NLVR2]: iter 74228 Ep: 13.75 loss 0.016 score 0.222 lr 8.68892e-07 
12/03/2021 01:29:29 - INFO - volta.train_utils -   [NLVR2]: iter 74308 Ep: 13.77 loss 0.011 score 0.225 lr 8.66833e-07 
12/03/2021 01:29:50 - INFO - volta.train_utils -   [NLVR2]: iter 74388 Ep: 13.78 loss 0.013 score 0.226 lr 8.64775e-07 
12/03/2021 01:30:12 - INFO - volta.train_utils -   [NLVR2]: iter 74468 Ep: 13.80 loss 0.012 score 0.225 lr 8.62717e-07 
12/03/2021 01:30:34 - INFO - volta.train_utils -   [NLVR2]: iter 74548 Ep: 13.81 loss 0.016 score 0.225 lr 8.60658e-07 
12/03/2021 01:30:55 - INFO - volta.train_utils -   [NLVR2]: iter 74628 Ep: 13.83 loss 0.016 score 0.224 lr 8.586e-07 
12/03/2021 01:31:17 - INFO - volta.train_utils -   [NLVR2]: iter 74708 Ep: 13.84 loss 0.015 score 0.221 lr 8.56542e-07 
12/03/2021 01:31:39 - INFO - volta.train_utils -   [NLVR2]: iter 74788 Ep: 13.85 loss 0.015 score 0.227 lr 8.54483e-07 
12/03/2021 01:32:01 - INFO - volta.train_utils -   [NLVR2]: iter 74868 Ep: 13.87 loss 0.014 score 0.227 lr 8.52425e-07 
12/03/2021 01:32:22 - INFO - volta.train_utils -   [NLVR2]: iter 74948 Ep: 13.88 loss 0.013 score 0.222 lr 8.50366e-07 
12/03/2021 01:32:44 - INFO - volta.train_utils -   [NLVR2]: iter 75028 Ep: 13.90 loss 0.013 score 0.229 lr 8.48308e-07 
12/03/2021 01:33:06 - INFO - volta.train_utils -   [NLVR2]: iter 75108 Ep: 13.91 loss 0.013 score 0.221 lr 8.4625e-07 
12/03/2021 01:33:27 - INFO - volta.train_utils -   [NLVR2]: iter 75188 Ep: 13.93 loss 0.016 score 0.225 lr 8.44191e-07 
12/03/2021 01:33:49 - INFO - volta.train_utils -   [NLVR2]: iter 75268 Ep: 13.94 loss 0.012 score 0.228 lr 8.42133e-07 
12/03/2021 01:34:11 - INFO - volta.train_utils -   [NLVR2]: iter 75348 Ep: 13.96 loss 0.014 score 0.224 lr 8.40075e-07 
12/03/2021 01:34:33 - INFO - volta.train_utils -   [NLVR2]: iter 75428 Ep: 13.97 loss 0.014 score 0.228 lr 8.38016e-07 
12/03/2021 01:34:54 - INFO - volta.train_utils -   [NLVR2]: iter 75508 Ep: 13.99 loss 0.016 score 0.229 lr 8.35958e-07 
12/03/2021 01:35:48 - INFO - volta.train_utils -   Eval task TASK12 on iteration 75544 
12/03/2021 01:35:48 - INFO - volta.train_utils -   Validation [NLVR2]: loss 1.120 score 67.646 
Epoch:  70%|███████   | 14/20 [5:55:49<2:31:20, 1513.48s/it]12/03/2021 01:36:10 - INFO - volta.train_utils -   [NLVR2]: iter 75624 Ep: 14.01 loss 0.013 score 0.231 lr 8.33436e-07 
12/03/2021 01:36:31 - INFO - volta.train_utils -   [NLVR2]: iter 75704 Ep: 14.02 loss 0.014 score 0.225 lr 8.30915e-07 
12/03/2021 01:36:53 - INFO - volta.train_utils -   [NLVR2]: iter 75784 Ep: 14.04 loss 0.019 score 0.224 lr 8.28856e-07 
12/03/2021 01:37:15 - INFO - volta.train_utils -   [NLVR2]: iter 75864 Ep: 14.05 loss 0.015 score 0.226 lr 8.26798e-07 
12/03/2021 01:37:37 - INFO - volta.train_utils -   [NLVR2]: iter 75944 Ep: 14.07 loss 0.015 score 0.230 lr 8.2474e-07 
12/03/2021 01:37:59 - INFO - volta.train_utils -   [NLVR2]: iter 76024 Ep: 14.08 loss 0.012 score 0.227 lr 8.22681e-07 
12/03/2021 01:38:20 - INFO - volta.train_utils -   [NLVR2]: iter 76104 Ep: 14.10 loss 0.016 score 0.224 lr 8.20623e-07 
12/03/2021 01:38:42 - INFO - volta.train_utils -   [NLVR2]: iter 76184 Ep: 14.11 loss 0.011 score 0.228 lr 8.18564e-07 
12/03/2021 01:39:04 - INFO - volta.train_utils -   [NLVR2]: iter 76264 Ep: 14.13 loss 0.013 score 0.227 lr 8.16506e-07 
12/03/2021 01:39:26 - INFO - volta.train_utils -   [NLVR2]: iter 76344 Ep: 14.14 loss 0.019 score 0.224 lr 8.14448e-07 
12/03/2021 01:39:47 - INFO - volta.train_utils -   [NLVR2]: iter 76424 Ep: 14.16 loss 0.014 score 0.228 lr 8.12389e-07 
12/03/2021 01:40:09 - INFO - volta.train_utils -   [NLVR2]: iter 76504 Ep: 14.17 loss 0.016 score 0.227 lr 8.10331e-07 
12/03/2021 01:40:31 - INFO - volta.train_utils -   [NLVR2]: iter 76584 Ep: 14.19 loss 0.015 score 0.227 lr 8.08273e-07 
12/03/2021 01:40:53 - INFO - volta.train_utils -   [NLVR2]: iter 76664 Ep: 14.20 loss 0.014 score 0.226 lr 8.06214e-07 
12/03/2021 01:41:14 - INFO - volta.train_utils -   [NLVR2]: iter 76744 Ep: 14.22 loss 0.011 score 0.226 lr 8.04156e-07 
12/03/2021 01:41:36 - INFO - volta.train_utils -   [NLVR2]: iter 76824 Ep: 14.23 loss 0.011 score 0.226 lr 8.02097e-07 
12/03/2021 01:41:58 - INFO - volta.train_utils -   [NLVR2]: iter 76904 Ep: 14.25 loss 0.014 score 0.223 lr 8.00039e-07 
12/03/2021 01:42:20 - INFO - volta.train_utils -   [NLVR2]: iter 76984 Ep: 14.26 loss 0.011 score 0.228 lr 7.97981e-07 
12/03/2021 01:42:41 - INFO - volta.train_utils -   [NLVR2]: iter 77064 Ep: 14.28 loss 0.012 score 0.231 lr 7.95922e-07 
12/03/2021 01:43:03 - INFO - volta.train_utils -   [NLVR2]: iter 77144 Ep: 14.29 loss 0.012 score 0.224 lr 7.93864e-07 
12/03/2021 01:43:25 - INFO - volta.train_utils -   [NLVR2]: iter 77224 Ep: 14.31 loss 0.015 score 0.228 lr 7.91806e-07 
12/03/2021 01:43:46 - INFO - volta.train_utils -   [NLVR2]: iter 77304 Ep: 14.32 loss 0.017 score 0.225 lr 7.89747e-07 
12/03/2021 01:44:08 - INFO - volta.train_utils -   [NLVR2]: iter 77384 Ep: 14.34 loss 0.015 score 0.227 lr 7.87689e-07 
12/03/2021 01:44:30 - INFO - volta.train_utils -   [NLVR2]: iter 77464 Ep: 14.35 loss 0.010 score 0.228 lr 7.8563e-07 
12/03/2021 01:44:52 - INFO - volta.train_utils -   [NLVR2]: iter 77544 Ep: 14.37 loss 0.016 score 0.227 lr 7.83572e-07 
12/03/2021 01:45:13 - INFO - volta.train_utils -   [NLVR2]: iter 77624 Ep: 14.38 loss 0.017 score 0.223 lr 7.81514e-07 
12/03/2021 01:45:35 - INFO - volta.train_utils -   [NLVR2]: iter 77704 Ep: 14.39 loss 0.013 score 0.227 lr 7.79455e-07 
12/03/2021 01:45:57 - INFO - volta.train_utils -   [NLVR2]: iter 77784 Ep: 14.41 loss 0.012 score 0.228 lr 7.77397e-07 
12/03/2021 01:46:19 - INFO - volta.train_utils -   [NLVR2]: iter 77864 Ep: 14.42 loss 0.015 score 0.228 lr 7.75339e-07 
12/03/2021 01:46:40 - INFO - volta.train_utils -   [NLVR2]: iter 77944 Ep: 14.44 loss 0.013 score 0.226 lr 7.7328e-07 
12/03/2021 01:47:02 - INFO - volta.train_utils -   [NLVR2]: iter 78024 Ep: 14.45 loss 0.013 score 0.227 lr 7.71222e-07 
12/03/2021 01:47:24 - INFO - volta.train_utils -   [NLVR2]: iter 78104 Ep: 14.47 loss 0.014 score 0.228 lr 7.69163e-07 
12/03/2021 01:47:46 - INFO - volta.train_utils -   [NLVR2]: iter 78184 Ep: 14.48 loss 0.015 score 0.223 lr 7.67105e-07 
12/03/2021 01:48:07 - INFO - volta.train_utils -   [NLVR2]: iter 78264 Ep: 14.50 loss 0.014 score 0.223 lr 7.65047e-07 
12/03/2021 01:48:29 - INFO - volta.train_utils -   [NLVR2]: iter 78344 Ep: 14.51 loss 0.013 score 0.228 lr 7.62988e-07 
12/03/2021 01:48:51 - INFO - volta.train_utils -   [NLVR2]: iter 78424 Ep: 14.53 loss 0.013 score 0.227 lr 7.6093e-07 
12/03/2021 01:49:12 - INFO - volta.train_utils -   [NLVR2]: iter 78504 Ep: 14.54 loss 0.011 score 0.226 lr 7.58872e-07 
12/03/2021 01:49:34 - INFO - volta.train_utils -   [NLVR2]: iter 78584 Ep: 14.56 loss 0.014 score 0.226 lr 7.56813e-07 
12/03/2021 01:49:56 - INFO - volta.train_utils -   [NLVR2]: iter 78664 Ep: 14.57 loss 0.014 score 0.225 lr 7.54755e-07 
12/03/2021 01:50:18 - INFO - volta.train_utils -   [NLVR2]: iter 78744 Ep: 14.59 loss 0.015 score 0.224 lr 7.52696e-07 
12/03/2021 01:50:39 - INFO - volta.train_utils -   [NLVR2]: iter 78824 Ep: 14.60 loss 0.013 score 0.227 lr 7.50638e-07 
12/03/2021 01:51:01 - INFO - volta.train_utils -   [NLVR2]: iter 78904 Ep: 14.62 loss 0.012 score 0.228 lr 7.4858e-07 
12/03/2021 01:51:23 - INFO - volta.train_utils -   [NLVR2]: iter 78984 Ep: 14.63 loss 0.015 score 0.224 lr 7.46521e-07 
12/03/2021 01:51:45 - INFO - volta.train_utils -   [NLVR2]: iter 79064 Ep: 14.65 loss 0.015 score 0.226 lr 7.44463e-07 
12/03/2021 01:52:06 - INFO - volta.train_utils -   [NLVR2]: iter 79144 Ep: 14.66 loss 0.013 score 0.227 lr 7.42405e-07 
12/03/2021 01:52:28 - INFO - volta.train_utils -   [NLVR2]: iter 79224 Ep: 14.68 loss 0.014 score 0.223 lr 7.40346e-07 
12/03/2021 01:52:50 - INFO - volta.train_utils -   [NLVR2]: iter 79304 Ep: 14.69 loss 0.013 score 0.225 lr 7.38288e-07 
12/03/2021 01:53:12 - INFO - volta.train_utils -   [NLVR2]: iter 79384 Ep: 14.71 loss 0.014 score 0.228 lr 7.36229e-07 
12/03/2021 01:53:33 - INFO - volta.train_utils -   [NLVR2]: iter 79464 Ep: 14.72 loss 0.015 score 0.226 lr 7.34171e-07 
12/03/2021 01:53:55 - INFO - volta.train_utils -   [NLVR2]: iter 79544 Ep: 14.74 loss 0.012 score 0.227 lr 7.32113e-07 
12/03/2021 01:54:17 - INFO - volta.train_utils -   [NLVR2]: iter 79624 Ep: 14.75 loss 0.013 score 0.228 lr 7.30054e-07 
12/03/2021 01:54:39 - INFO - volta.train_utils -   [NLVR2]: iter 79704 Ep: 14.77 loss 0.018 score 0.225 lr 7.27996e-07 
12/03/2021 01:55:00 - INFO - volta.train_utils -   [NLVR2]: iter 79784 Ep: 14.78 loss 0.012 score 0.228 lr 7.25938e-07 
12/03/2021 01:55:22 - INFO - volta.train_utils -   [NLVR2]: iter 79864 Ep: 14.80 loss 0.013 score 0.226 lr 7.23879e-07 
12/03/2021 01:55:44 - INFO - volta.train_utils -   [NLVR2]: iter 79944 Ep: 14.81 loss 0.011 score 0.224 lr 7.21821e-07 
12/03/2021 01:56:06 - INFO - volta.train_utils -   [NLVR2]: iter 80024 Ep: 14.82 loss 0.012 score 0.229 lr 7.19762e-07 
12/03/2021 01:56:27 - INFO - volta.train_utils -   [NLVR2]: iter 80104 Ep: 14.84 loss 0.011 score 0.227 lr 7.17704e-07 
12/03/2021 01:56:49 - INFO - volta.train_utils -   [NLVR2]: iter 80184 Ep: 14.85 loss 0.011 score 0.230 lr 7.15646e-07 
12/03/2021 01:57:11 - INFO - volta.train_utils -   [NLVR2]: iter 80264 Ep: 14.87 loss 0.011 score 0.225 lr 7.13587e-07 
12/03/2021 01:57:33 - INFO - volta.train_utils -   [NLVR2]: iter 80344 Ep: 14.88 loss 0.014 score 0.226 lr 7.11529e-07 
12/03/2021 01:57:55 - INFO - volta.train_utils -   [NLVR2]: iter 80424 Ep: 14.90 loss 0.013 score 0.228 lr 7.09471e-07 
12/03/2021 01:58:16 - INFO - volta.train_utils -   [NLVR2]: iter 80504 Ep: 14.91 loss 0.017 score 0.227 lr 7.07412e-07 
12/03/2021 01:58:38 - INFO - volta.train_utils -   [NLVR2]: iter 80584 Ep: 14.93 loss 0.013 score 0.231 lr 7.05354e-07 
12/03/2021 01:59:01 - INFO - volta.train_utils -   [NLVR2]: iter 80664 Ep: 14.94 loss 0.011 score 0.229 lr 7.03295e-07 
12/03/2021 01:59:22 - INFO - volta.train_utils -   [NLVR2]: iter 80744 Ep: 14.96 loss 0.016 score 0.229 lr 7.01237e-07 
12/03/2021 01:59:44 - INFO - volta.train_utils -   [NLVR2]: iter 80824 Ep: 14.97 loss 0.013 score 0.230 lr 6.99179e-07 
12/03/2021 02:00:06 - INFO - volta.train_utils -   [NLVR2]: iter 80904 Ep: 14.99 loss 0.015 score 0.225 lr 6.9712e-07 
12/03/2021 02:00:59 - INFO - volta.train_utils -   Eval task TASK12 on iteration 80940 
12/03/2021 02:00:59 - INFO - volta.train_utils -   Validation [NLVR2]: loss 1.120 score 67.489 
Epoch:  75%|███████▌  | 15/20 [6:21:00<2:06:03, 1512.78s/it]12/03/2021 02:01:21 - INFO - volta.train_utils -   [NLVR2]: iter 81020 Ep: 15.01 loss 0.012 score 0.233 lr 6.94599e-07 
12/03/2021 02:01:43 - INFO - volta.train_utils -   [NLVR2]: iter 81100 Ep: 15.02 loss 0.010 score 0.230 lr 6.92077e-07 
12/03/2021 02:02:04 - INFO - volta.train_utils -   [NLVR2]: iter 81180 Ep: 15.04 loss 0.014 score 0.227 lr 6.90019e-07 
12/03/2021 02:02:26 - INFO - volta.train_utils -   [NLVR2]: iter 81260 Ep: 15.05 loss 0.013 score 0.231 lr 6.87961e-07 
12/03/2021 02:02:48 - INFO - volta.train_utils -   [NLVR2]: iter 81340 Ep: 15.07 loss 0.012 score 0.230 lr 6.85902e-07 
12/03/2021 02:03:10 - INFO - volta.train_utils -   [NLVR2]: iter 81420 Ep: 15.08 loss 0.012 score 0.227 lr 6.83844e-07 
12/03/2021 02:03:31 - INFO - volta.train_utils -   [NLVR2]: iter 81500 Ep: 15.10 loss 0.013 score 0.228 lr 6.81785e-07 
12/03/2021 02:03:53 - INFO - volta.train_utils -   [NLVR2]: iter 81580 Ep: 15.11 loss 0.014 score 0.226 lr 6.79727e-07 
12/03/2021 02:04:15 - INFO - volta.train_utils -   [NLVR2]: iter 81660 Ep: 15.13 loss 0.011 score 0.230 lr 6.77669e-07 
12/03/2021 02:04:37 - INFO - volta.train_utils -   [NLVR2]: iter 81740 Ep: 15.14 loss 0.011 score 0.230 lr 6.7561e-07 
12/03/2021 02:04:59 - INFO - volta.train_utils -   [NLVR2]: iter 81820 Ep: 15.16 loss 0.015 score 0.226 lr 6.73552e-07 
12/03/2021 02:05:20 - INFO - volta.train_utils -   [NLVR2]: iter 81900 Ep: 15.17 loss 0.011 score 0.226 lr 6.71494e-07 
12/03/2021 02:05:42 - INFO - volta.train_utils -   [NLVR2]: iter 81980 Ep: 15.19 loss 0.011 score 0.227 lr 6.69435e-07 
12/03/2021 02:06:04 - INFO - volta.train_utils -   [NLVR2]: iter 82060 Ep: 15.20 loss 0.012 score 0.231 lr 6.67377e-07 
12/03/2021 02:06:25 - INFO - volta.train_utils -   [NLVR2]: iter 82140 Ep: 15.22 loss 0.011 score 0.227 lr 6.65318e-07 
12/03/2021 02:06:47 - INFO - volta.train_utils -   [NLVR2]: iter 82220 Ep: 15.23 loss 0.014 score 0.225 lr 6.6326e-07 
12/03/2021 02:07:09 - INFO - volta.train_utils -   [NLVR2]: iter 82300 Ep: 15.25 loss 0.011 score 0.229 lr 6.61202e-07 
12/03/2021 02:07:31 - INFO - volta.train_utils -   [NLVR2]: iter 82380 Ep: 15.26 loss 0.017 score 0.230 lr 6.59143e-07 
12/03/2021 02:07:52 - INFO - volta.train_utils -   [NLVR2]: iter 82460 Ep: 15.28 loss 0.012 score 0.231 lr 6.57085e-07 
12/03/2021 02:08:14 - INFO - volta.train_utils -   [NLVR2]: iter 82540 Ep: 15.29 loss 0.010 score 0.228 lr 6.55027e-07 
12/03/2021 02:08:36 - INFO - volta.train_utils -   [NLVR2]: iter 82620 Ep: 15.31 loss 0.014 score 0.229 lr 6.52968e-07 
12/03/2021 02:08:58 - INFO - volta.train_utils -   [NLVR2]: iter 82700 Ep: 15.32 loss 0.012 score 0.227 lr 6.5091e-07 
12/03/2021 02:09:19 - INFO - volta.train_utils -   [NLVR2]: iter 82780 Ep: 15.34 loss 0.011 score 0.233 lr 6.48851e-07 
12/03/2021 02:09:41 - INFO - volta.train_utils -   [NLVR2]: iter 82860 Ep: 15.35 loss 0.012 score 0.227 lr 6.46793e-07 
12/03/2021 02:10:03 - INFO - volta.train_utils -   [NLVR2]: iter 82940 Ep: 15.36 loss 0.012 score 0.228 lr 6.44735e-07 
12/03/2021 02:10:24 - INFO - volta.train_utils -   [NLVR2]: iter 83020 Ep: 15.38 loss 0.011 score 0.233 lr 6.42676e-07 
12/03/2021 02:10:46 - INFO - volta.train_utils -   [NLVR2]: iter 83100 Ep: 15.39 loss 0.011 score 0.228 lr 6.40618e-07 
12/03/2021 02:11:08 - INFO - volta.train_utils -   [NLVR2]: iter 83180 Ep: 15.41 loss 0.010 score 0.229 lr 6.3856e-07 
12/03/2021 02:11:29 - INFO - volta.train_utils -   [NLVR2]: iter 83260 Ep: 15.42 loss 0.012 score 0.226 lr 6.36501e-07 
12/03/2021 02:11:51 - INFO - volta.train_utils -   [NLVR2]: iter 83340 Ep: 15.44 loss 0.012 score 0.229 lr 6.34443e-07 
12/03/2021 02:12:13 - INFO - volta.train_utils -   [NLVR2]: iter 83420 Ep: 15.45 loss 0.012 score 0.228 lr 6.32384e-07 
12/03/2021 02:12:35 - INFO - volta.train_utils -   [NLVR2]: iter 83500 Ep: 15.47 loss 0.011 score 0.229 lr 6.30326e-07 
12/03/2021 02:12:57 - INFO - volta.train_utils -   [NLVR2]: iter 83580 Ep: 15.48 loss 0.015 score 0.227 lr 6.28268e-07 
12/03/2021 02:13:18 - INFO - volta.train_utils -   [NLVR2]: iter 83660 Ep: 15.50 loss 0.011 score 0.230 lr 6.26209e-07 
12/03/2021 02:13:40 - INFO - volta.train_utils -   [NLVR2]: iter 83740 Ep: 15.51 loss 0.011 score 0.231 lr 6.24151e-07 
12/03/2021 02:14:02 - INFO - volta.train_utils -   [NLVR2]: iter 83820 Ep: 15.53 loss 0.012 score 0.229 lr 6.22093e-07 
12/03/2021 02:14:23 - INFO - volta.train_utils -   [NLVR2]: iter 83900 Ep: 15.54 loss 0.012 score 0.229 lr 6.20034e-07 
12/03/2021 02:14:45 - INFO - volta.train_utils -   [NLVR2]: iter 83980 Ep: 15.56 loss 0.012 score 0.226 lr 6.17976e-07 
12/03/2021 02:15:07 - INFO - volta.train_utils -   [NLVR2]: iter 84060 Ep: 15.57 loss 0.012 score 0.227 lr 6.15917e-07 
12/03/2021 02:15:29 - INFO - volta.train_utils -   [NLVR2]: iter 84140 Ep: 15.59 loss 0.015 score 0.223 lr 6.13859e-07 
12/03/2021 02:15:50 - INFO - volta.train_utils -   [NLVR2]: iter 84220 Ep: 15.60 loss 0.012 score 0.226 lr 6.11801e-07 
12/03/2021 02:16:12 - INFO - volta.train_utils -   [NLVR2]: iter 84300 Ep: 15.62 loss 0.013 score 0.226 lr 6.09742e-07 
12/03/2021 02:16:34 - INFO - volta.train_utils -   [NLVR2]: iter 84380 Ep: 15.63 loss 0.013 score 0.228 lr 6.07684e-07 
12/03/2021 02:16:56 - INFO - volta.train_utils -   [NLVR2]: iter 84460 Ep: 15.65 loss 0.012 score 0.229 lr 6.05626e-07 
12/03/2021 02:17:17 - INFO - volta.train_utils -   [NLVR2]: iter 84540 Ep: 15.66 loss 0.012 score 0.227 lr 6.03567e-07 
12/03/2021 02:17:39 - INFO - volta.train_utils -   [NLVR2]: iter 84620 Ep: 15.68 loss 0.013 score 0.226 lr 6.01509e-07 
12/03/2021 02:18:01 - INFO - volta.train_utils -   [NLVR2]: iter 84700 Ep: 15.69 loss 0.014 score 0.225 lr 5.9945e-07 
12/03/2021 02:18:23 - INFO - volta.train_utils -   [NLVR2]: iter 84780 Ep: 15.71 loss 0.012 score 0.226 lr 5.97392e-07 
12/03/2021 02:18:44 - INFO - volta.train_utils -   [NLVR2]: iter 84860 Ep: 15.72 loss 0.010 score 0.230 lr 5.95334e-07 
12/03/2021 02:19:06 - INFO - volta.train_utils -   [NLVR2]: iter 84940 Ep: 15.74 loss 0.013 score 0.229 lr 5.93275e-07 
12/03/2021 02:19:28 - INFO - volta.train_utils -   [NLVR2]: iter 85020 Ep: 15.75 loss 0.013 score 0.230 lr 5.91217e-07 
12/03/2021 02:19:50 - INFO - volta.train_utils -   [NLVR2]: iter 85100 Ep: 15.77 loss 0.010 score 0.229 lr 5.89159e-07 
12/03/2021 02:20:11 - INFO - volta.train_utils -   [NLVR2]: iter 85180 Ep: 15.78 loss 0.013 score 0.227 lr 5.871e-07 
12/03/2021 02:20:33 - INFO - volta.train_utils -   [NLVR2]: iter 85260 Ep: 15.79 loss 0.012 score 0.230 lr 5.85042e-07 
12/03/2021 02:20:55 - INFO - volta.train_utils -   [NLVR2]: iter 85340 Ep: 15.81 loss 0.013 score 0.228 lr 5.82983e-07 
12/03/2021 02:21:17 - INFO - volta.train_utils -   [NLVR2]: iter 85420 Ep: 15.82 loss 0.012 score 0.228 lr 5.80925e-07 
12/03/2021 02:21:38 - INFO - volta.train_utils -   [NLVR2]: iter 85500 Ep: 15.84 loss 0.013 score 0.227 lr 5.78867e-07 
12/03/2021 02:22:00 - INFO - volta.train_utils -   [NLVR2]: iter 85580 Ep: 15.85 loss 0.013 score 0.231 lr 5.76808e-07 
12/03/2021 02:22:22 - INFO - volta.train_utils -   [NLVR2]: iter 85660 Ep: 15.87 loss 0.010 score 0.227 lr 5.7475e-07 
12/03/2021 02:22:43 - INFO - volta.train_utils -   [NLVR2]: iter 85740 Ep: 15.88 loss 0.010 score 0.233 lr 5.72692e-07 
12/03/2021 02:23:05 - INFO - volta.train_utils -   [NLVR2]: iter 85820 Ep: 15.90 loss 0.010 score 0.228 lr 5.70633e-07 
12/03/2021 02:23:27 - INFO - volta.train_utils -   [NLVR2]: iter 85900 Ep: 15.91 loss 0.012 score 0.232 lr 5.68575e-07 
12/03/2021 02:23:49 - INFO - volta.train_utils -   [NLVR2]: iter 85980 Ep: 15.93 loss 0.011 score 0.231 lr 5.66516e-07 
12/03/2021 02:24:10 - INFO - volta.train_utils -   [NLVR2]: iter 86060 Ep: 15.94 loss 0.011 score 0.226 lr 5.64458e-07 
12/03/2021 02:24:32 - INFO - volta.train_utils -   [NLVR2]: iter 86140 Ep: 15.96 loss 0.014 score 0.229 lr 5.624e-07 
12/03/2021 02:24:54 - INFO - volta.train_utils -   [NLVR2]: iter 86220 Ep: 15.97 loss 0.014 score 0.230 lr 5.60341e-07 
12/03/2021 02:25:16 - INFO - volta.train_utils -   [NLVR2]: iter 86300 Ep: 15.99 loss 0.010 score 0.234 lr 5.58283e-07 
12/03/2021 02:26:09 - INFO - volta.train_utils -   Eval task TASK12 on iteration 86336 
12/03/2021 02:26:09 - INFO - volta.train_utils -   Validation [NLVR2]: loss 1.216 score 67.403 
Epoch:  80%|████████  | 16/20 [6:46:10<1:40:47, 1511.95s/it]12/03/2021 02:26:31 - INFO - volta.train_utils -   [NLVR2]: iter 86416 Ep: 16.01 loss 0.011 score 0.236 lr 5.55761e-07 
12/03/2021 02:26:53 - INFO - volta.train_utils -   [NLVR2]: iter 86496 Ep: 16.02 loss 0.011 score 0.232 lr 5.5324e-07 
12/03/2021 02:27:14 - INFO - volta.train_utils -   [NLVR2]: iter 86576 Ep: 16.04 loss 0.011 score 0.230 lr 5.51182e-07 
12/03/2021 02:27:36 - INFO - volta.train_utils -   [NLVR2]: iter 86656 Ep: 16.05 loss 0.013 score 0.230 lr 5.49123e-07 
12/03/2021 02:27:58 - INFO - volta.train_utils -   [NLVR2]: iter 86736 Ep: 16.07 loss 0.012 score 0.230 lr 5.47065e-07 
12/03/2021 02:28:19 - INFO - volta.train_utils -   [NLVR2]: iter 86816 Ep: 16.08 loss 0.012 score 0.231 lr 5.45006e-07 
12/03/2021 02:28:41 - INFO - volta.train_utils -   [NLVR2]: iter 86896 Ep: 16.10 loss 0.012 score 0.231 lr 5.42948e-07 
12/03/2021 02:29:03 - INFO - volta.train_utils -   [NLVR2]: iter 86976 Ep: 16.11 loss 0.015 score 0.227 lr 5.4089e-07 
12/03/2021 02:29:25 - INFO - volta.train_utils -   [NLVR2]: iter 87056 Ep: 16.13 loss 0.015 score 0.231 lr 5.38831e-07 
12/03/2021 02:29:46 - INFO - volta.train_utils -   [NLVR2]: iter 87136 Ep: 16.14 loss 0.014 score 0.227 lr 5.36773e-07 
12/03/2021 02:30:08 - INFO - volta.train_utils -   [NLVR2]: iter 87216 Ep: 16.16 loss 0.013 score 0.231 lr 5.34715e-07 
12/03/2021 02:30:30 - INFO - volta.train_utils -   [NLVR2]: iter 87296 Ep: 16.17 loss 0.009 score 0.232 lr 5.32656e-07 
12/03/2021 02:30:51 - INFO - volta.train_utils -   [NLVR2]: iter 87376 Ep: 16.19 loss 0.012 score 0.230 lr 5.30598e-07 
12/03/2021 02:31:13 - INFO - volta.train_utils -   [NLVR2]: iter 87456 Ep: 16.20 loss 0.012 score 0.230 lr 5.28539e-07 
12/03/2021 02:31:35 - INFO - volta.train_utils -   [NLVR2]: iter 87536 Ep: 16.22 loss 0.012 score 0.232 lr 5.26481e-07 
12/03/2021 02:31:57 - INFO - volta.train_utils -   [NLVR2]: iter 87616 Ep: 16.23 loss 0.014 score 0.230 lr 5.24423e-07 
12/03/2021 02:32:18 - INFO - volta.train_utils -   [NLVR2]: iter 87696 Ep: 16.25 loss 0.013 score 0.231 lr 5.22364e-07 
12/03/2021 02:32:40 - INFO - volta.train_utils -   [NLVR2]: iter 87776 Ep: 16.26 loss 0.013 score 0.228 lr 5.20306e-07 
12/03/2021 02:33:02 - INFO - volta.train_utils -   [NLVR2]: iter 87856 Ep: 16.28 loss 0.013 score 0.232 lr 5.18247e-07 
12/03/2021 02:33:24 - INFO - volta.train_utils -   [NLVR2]: iter 87936 Ep: 16.29 loss 0.009 score 0.230 lr 5.16189e-07 
12/03/2021 02:33:45 - INFO - volta.train_utils -   [NLVR2]: iter 88016 Ep: 16.31 loss 0.012 score 0.228 lr 5.14131e-07 
12/03/2021 02:34:07 - INFO - volta.train_utils -   [NLVR2]: iter 88096 Ep: 16.32 loss 0.012 score 0.233 lr 5.12072e-07 
12/03/2021 02:34:29 - INFO - volta.train_utils -   [NLVR2]: iter 88176 Ep: 16.33 loss 0.014 score 0.229 lr 5.10014e-07 
12/03/2021 02:34:50 - INFO - volta.train_utils -   [NLVR2]: iter 88256 Ep: 16.35 loss 0.015 score 0.232 lr 5.07956e-07 
12/03/2021 02:35:12 - INFO - volta.train_utils -   [NLVR2]: iter 88336 Ep: 16.36 loss 0.013 score 0.231 lr 5.05897e-07 
12/03/2021 02:35:34 - INFO - volta.train_utils -   [NLVR2]: iter 88416 Ep: 16.38 loss 0.013 score 0.230 lr 5.03839e-07 
12/03/2021 02:35:56 - INFO - volta.train_utils -   [NLVR2]: iter 88496 Ep: 16.39 loss 0.010 score 0.229 lr 5.0178e-07 
12/03/2021 02:36:17 - INFO - volta.train_utils -   [NLVR2]: iter 88576 Ep: 16.41 loss 0.013 score 0.231 lr 4.99722e-07 
12/03/2021 02:36:39 - INFO - volta.train_utils -   [NLVR2]: iter 88656 Ep: 16.42 loss 0.008 score 0.234 lr 4.97664e-07 
12/03/2021 02:37:01 - INFO - volta.train_utils -   [NLVR2]: iter 88736 Ep: 16.44 loss 0.010 score 0.231 lr 4.95605e-07 
12/03/2021 02:37:22 - INFO - volta.train_utils -   [NLVR2]: iter 88816 Ep: 16.45 loss 0.013 score 0.231 lr 4.93547e-07 
12/03/2021 02:37:44 - INFO - volta.train_utils -   [NLVR2]: iter 88896 Ep: 16.47 loss 0.014 score 0.230 lr 4.91489e-07 
12/03/2021 02:38:06 - INFO - volta.train_utils -   [NLVR2]: iter 88976 Ep: 16.48 loss 0.012 score 0.229 lr 4.8943e-07 
12/03/2021 02:38:28 - INFO - volta.train_utils -   [NLVR2]: iter 89056 Ep: 16.50 loss 0.010 score 0.231 lr 4.87372e-07 
12/03/2021 02:38:49 - INFO - volta.train_utils -   [NLVR2]: iter 89136 Ep: 16.51 loss 0.011 score 0.234 lr 4.85313e-07 
12/03/2021 02:39:11 - INFO - volta.train_utils -   [NLVR2]: iter 89216 Ep: 16.53 loss 0.011 score 0.232 lr 4.83255e-07 
12/03/2021 02:39:33 - INFO - volta.train_utils -   [NLVR2]: iter 89296 Ep: 16.54 loss 0.014 score 0.229 lr 4.81197e-07 
12/03/2021 02:39:54 - INFO - volta.train_utils -   [NLVR2]: iter 89376 Ep: 16.56 loss 0.011 score 0.229 lr 4.79138e-07 
12/03/2021 02:40:16 - INFO - volta.train_utils -   [NLVR2]: iter 89456 Ep: 16.57 loss 0.014 score 0.231 lr 4.7708e-07 
12/03/2021 02:40:38 - INFO - volta.train_utils -   [NLVR2]: iter 89536 Ep: 16.59 loss 0.012 score 0.229 lr 4.75022e-07 
12/03/2021 02:41:00 - INFO - volta.train_utils -   [NLVR2]: iter 89616 Ep: 16.60 loss 0.010 score 0.229 lr 4.72963e-07 
12/03/2021 02:41:22 - INFO - volta.train_utils -   [NLVR2]: iter 89696 Ep: 16.62 loss 0.011 score 0.230 lr 4.70905e-07 
12/03/2021 02:41:43 - INFO - volta.train_utils -   [NLVR2]: iter 89776 Ep: 16.63 loss 0.012 score 0.230 lr 4.68846e-07 
12/03/2021 02:42:05 - INFO - volta.train_utils -   [NLVR2]: iter 89856 Ep: 16.65 loss 0.011 score 0.228 lr 4.66788e-07 
12/03/2021 02:42:27 - INFO - volta.train_utils -   [NLVR2]: iter 89936 Ep: 16.66 loss 0.012 score 0.228 lr 4.6473e-07 
12/03/2021 02:42:49 - INFO - volta.train_utils -   [NLVR2]: iter 90016 Ep: 16.68 loss 0.012 score 0.230 lr 4.62671e-07 
12/03/2021 02:43:10 - INFO - volta.train_utils -   [NLVR2]: iter 90096 Ep: 16.69 loss 0.014 score 0.228 lr 4.60613e-07 
12/03/2021 02:43:32 - INFO - volta.train_utils -   [NLVR2]: iter 90176 Ep: 16.71 loss 0.012 score 0.226 lr 4.58555e-07 
12/03/2021 02:43:54 - INFO - volta.train_utils -   [NLVR2]: iter 90256 Ep: 16.72 loss 0.012 score 0.229 lr 4.56496e-07 
12/03/2021 02:44:15 - INFO - volta.train_utils -   [NLVR2]: iter 90336 Ep: 16.74 loss 0.011 score 0.231 lr 4.54438e-07 
12/03/2021 02:44:37 - INFO - volta.train_utils -   [NLVR2]: iter 90416 Ep: 16.75 loss 0.015 score 0.228 lr 4.52379e-07 
12/03/2021 02:44:59 - INFO - volta.train_utils -   [NLVR2]: iter 90496 Ep: 16.76 loss 0.011 score 0.229 lr 4.50321e-07 
12/03/2021 02:45:21 - INFO - volta.train_utils -   [NLVR2]: iter 90576 Ep: 16.78 loss 0.009 score 0.228 lr 4.48263e-07 
12/03/2021 02:45:42 - INFO - volta.train_utils -   [NLVR2]: iter 90656 Ep: 16.79 loss 0.010 score 0.235 lr 4.46204e-07 
12/03/2021 02:46:04 - INFO - volta.train_utils -   [NLVR2]: iter 90736 Ep: 16.81 loss 0.012 score 0.234 lr 4.44146e-07 
12/03/2021 02:46:26 - INFO - volta.train_utils -   [NLVR2]: iter 90816 Ep: 16.82 loss 0.010 score 0.232 lr 4.42088e-07 
12/03/2021 02:46:48 - INFO - volta.train_utils -   [NLVR2]: iter 90896 Ep: 16.84 loss 0.010 score 0.232 lr 4.40029e-07 
12/03/2021 02:47:09 - INFO - volta.train_utils -   [NLVR2]: iter 90976 Ep: 16.85 loss 0.011 score 0.228 lr 4.37971e-07 
12/03/2021 02:47:31 - INFO - volta.train_utils -   [NLVR2]: iter 91056 Ep: 16.87 loss 0.011 score 0.231 lr 4.35912e-07 
12/03/2021 02:47:53 - INFO - volta.train_utils -   [NLVR2]: iter 91136 Ep: 16.88 loss 0.011 score 0.232 lr 4.33854e-07 
12/03/2021 02:48:14 - INFO - volta.train_utils -   [NLVR2]: iter 91216 Ep: 16.90 loss 0.009 score 0.235 lr 4.31796e-07 
12/03/2021 02:48:36 - INFO - volta.train_utils -   [NLVR2]: iter 91296 Ep: 16.91 loss 0.010 score 0.237 lr 4.29737e-07 
12/03/2021 02:48:58 - INFO - volta.train_utils -   [NLVR2]: iter 91376 Ep: 16.93 loss 0.011 score 0.235 lr 4.27679e-07 
12/03/2021 02:49:20 - INFO - volta.train_utils -   [NLVR2]: iter 91456 Ep: 16.94 loss 0.009 score 0.231 lr 4.25621e-07 
12/03/2021 02:49:41 - INFO - volta.train_utils -   [NLVR2]: iter 91536 Ep: 16.96 loss 0.010 score 0.235 lr 4.23562e-07 
12/03/2021 02:50:04 - INFO - volta.train_utils -   [NLVR2]: iter 91616 Ep: 16.97 loss 0.014 score 0.233 lr 4.21504e-07 
12/03/2021 02:50:26 - INFO - volta.train_utils -   [NLVR2]: iter 91696 Ep: 16.99 loss 0.010 score 0.233 lr 4.19445e-07 
12/03/2021 02:51:19 - INFO - volta.train_utils -   Eval task TASK12 on iteration 91732 
12/03/2021 02:51:19 - INFO - volta.train_utils -   Validation [NLVR2]: loss 1.327 score 66.585 
Epoch:  85%|████████▌ | 17/20 [7:11:20<1:15:34, 1511.37s/it]12/03/2021 02:51:41 - INFO - volta.train_utils -   [NLVR2]: iter 91812 Ep: 17.01 loss 0.011 score 0.237 lr 4.16924e-07 
12/03/2021 02:52:03 - INFO - volta.train_utils -   [NLVR2]: iter 91892 Ep: 17.02 loss 0.007 score 0.234 lr 4.14402e-07 
12/03/2021 02:52:24 - INFO - volta.train_utils -   [NLVR2]: iter 91972 Ep: 17.04 loss 0.010 score 0.232 lr 4.12344e-07 
12/03/2021 02:52:46 - INFO - volta.train_utils -   [NLVR2]: iter 92052 Ep: 17.05 loss 0.015 score 0.231 lr 4.10286e-07 
12/03/2021 02:53:08 - INFO - volta.train_utils -   [NLVR2]: iter 92132 Ep: 17.07 loss 0.011 score 0.230 lr 4.08227e-07 
12/03/2021 02:53:29 - INFO - volta.train_utils -   [NLVR2]: iter 92212 Ep: 17.08 loss 0.011 score 0.233 lr 4.06169e-07 
12/03/2021 02:53:51 - INFO - volta.train_utils -   [NLVR2]: iter 92292 Ep: 17.10 loss 0.013 score 0.231 lr 4.04111e-07 
12/03/2021 02:54:13 - INFO - volta.train_utils -   [NLVR2]: iter 92372 Ep: 17.11 loss 0.011 score 0.229 lr 4.02052e-07 
12/03/2021 02:54:35 - INFO - volta.train_utils -   [NLVR2]: iter 92452 Ep: 17.13 loss 0.013 score 0.230 lr 3.99994e-07 
12/03/2021 02:54:56 - INFO - volta.train_utils -   [NLVR2]: iter 92532 Ep: 17.14 loss 0.008 score 0.234 lr 3.97935e-07 
12/03/2021 02:55:18 - INFO - volta.train_utils -   [NLVR2]: iter 92612 Ep: 17.16 loss 0.009 score 0.233 lr 3.95877e-07 
12/03/2021 02:55:40 - INFO - volta.train_utils -   [NLVR2]: iter 92692 Ep: 17.17 loss 0.013 score 0.231 lr 3.93819e-07 
12/03/2021 02:56:02 - INFO - volta.train_utils -   [NLVR2]: iter 92772 Ep: 17.19 loss 0.011 score 0.232 lr 3.9176e-07 
12/03/2021 02:56:23 - INFO - volta.train_utils -   [NLVR2]: iter 92852 Ep: 17.20 loss 0.012 score 0.229 lr 3.89702e-07 
12/03/2021 02:56:45 - INFO - volta.train_utils -   [NLVR2]: iter 92932 Ep: 17.22 loss 0.011 score 0.233 lr 3.87644e-07 
12/03/2021 02:57:07 - INFO - volta.train_utils -   [NLVR2]: iter 93012 Ep: 17.23 loss 0.010 score 0.232 lr 3.85585e-07 
12/03/2021 02:57:29 - INFO - volta.train_utils -   [NLVR2]: iter 93092 Ep: 17.25 loss 0.011 score 0.230 lr 3.83527e-07 
12/03/2021 02:57:50 - INFO - volta.train_utils -   [NLVR2]: iter 93172 Ep: 17.26 loss 0.011 score 0.231 lr 3.81468e-07 
12/03/2021 02:58:12 - INFO - volta.train_utils -   [NLVR2]: iter 93252 Ep: 17.28 loss 0.009 score 0.232 lr 3.7941e-07 
12/03/2021 02:58:34 - INFO - volta.train_utils -   [NLVR2]: iter 93332 Ep: 17.29 loss 0.010 score 0.232 lr 3.77352e-07 
12/03/2021 02:58:56 - INFO - volta.train_utils -   [NLVR2]: iter 93412 Ep: 17.30 loss 0.011 score 0.233 lr 3.75293e-07 
12/03/2021 02:59:17 - INFO - volta.train_utils -   [NLVR2]: iter 93492 Ep: 17.32 loss 0.011 score 0.233 lr 3.73235e-07 
12/03/2021 02:59:39 - INFO - volta.train_utils -   [NLVR2]: iter 93572 Ep: 17.33 loss 0.010 score 0.233 lr 3.71177e-07 
12/03/2021 03:00:01 - INFO - volta.train_utils -   [NLVR2]: iter 93652 Ep: 17.35 loss 0.008 score 0.231 lr 3.69118e-07 
12/03/2021 03:00:23 - INFO - volta.train_utils -   [NLVR2]: iter 93732 Ep: 17.36 loss 0.010 score 0.231 lr 3.6706e-07 
12/03/2021 03:00:44 - INFO - volta.train_utils -   [NLVR2]: iter 93812 Ep: 17.38 loss 0.009 score 0.231 lr 3.65001e-07 
12/03/2021 03:01:06 - INFO - volta.train_utils -   [NLVR2]: iter 93892 Ep: 17.39 loss 0.010 score 0.234 lr 3.62943e-07 
12/03/2021 03:01:28 - INFO - volta.train_utils -   [NLVR2]: iter 93972 Ep: 17.41 loss 0.013 score 0.229 lr 3.60885e-07 
12/03/2021 03:01:50 - INFO - volta.train_utils -   [NLVR2]: iter 94052 Ep: 17.42 loss 0.011 score 0.234 lr 3.58826e-07 
12/03/2021 03:02:11 - INFO - volta.train_utils -   [NLVR2]: iter 94132 Ep: 17.44 loss 0.013 score 0.230 lr 3.56768e-07 
12/03/2021 03:02:33 - INFO - volta.train_utils -   [NLVR2]: iter 94212 Ep: 17.45 loss 0.012 score 0.228 lr 3.5471e-07 
12/03/2021 03:02:55 - INFO - volta.train_utils -   [NLVR2]: iter 94292 Ep: 17.47 loss 0.011 score 0.232 lr 3.52651e-07 
12/03/2021 03:03:16 - INFO - volta.train_utils -   [NLVR2]: iter 94372 Ep: 17.48 loss 0.010 score 0.231 lr 3.50593e-07 
12/03/2021 03:03:38 - INFO - volta.train_utils -   [NLVR2]: iter 94452 Ep: 17.50 loss 0.012 score 0.230 lr 3.48534e-07 
12/03/2021 03:04:00 - INFO - volta.train_utils -   [NLVR2]: iter 94532 Ep: 17.51 loss 0.009 score 0.233 lr 3.46476e-07 
12/03/2021 03:04:22 - INFO - volta.train_utils -   [NLVR2]: iter 94612 Ep: 17.53 loss 0.009 score 0.232 lr 3.44418e-07 
12/03/2021 03:04:43 - INFO - volta.train_utils -   [NLVR2]: iter 94692 Ep: 17.54 loss 0.010 score 0.233 lr 3.42359e-07 
12/03/2021 03:05:05 - INFO - volta.train_utils -   [NLVR2]: iter 94772 Ep: 17.56 loss 0.008 score 0.233 lr 3.40301e-07 
12/03/2021 03:05:27 - INFO - volta.train_utils -   [NLVR2]: iter 94852 Ep: 17.57 loss 0.013 score 0.231 lr 3.38243e-07 
12/03/2021 03:05:48 - INFO - volta.train_utils -   [NLVR2]: iter 94932 Ep: 17.59 loss 0.011 score 0.231 lr 3.36184e-07 
12/03/2021 03:06:10 - INFO - volta.train_utils -   [NLVR2]: iter 95012 Ep: 17.60 loss 0.011 score 0.230 lr 3.34126e-07 
12/03/2021 03:06:32 - INFO - volta.train_utils -   [NLVR2]: iter 95092 Ep: 17.62 loss 0.010 score 0.234 lr 3.32067e-07 
12/03/2021 03:06:54 - INFO - volta.train_utils -   [NLVR2]: iter 95172 Ep: 17.63 loss 0.011 score 0.229 lr 3.30009e-07 
12/03/2021 03:07:15 - INFO - volta.train_utils -   [NLVR2]: iter 95252 Ep: 17.65 loss 0.011 score 0.230 lr 3.27951e-07 
12/03/2021 03:07:37 - INFO - volta.train_utils -   [NLVR2]: iter 95332 Ep: 17.66 loss 0.009 score 0.230 lr 3.25892e-07 
12/03/2021 03:07:59 - INFO - volta.train_utils -   [NLVR2]: iter 95412 Ep: 17.68 loss 0.010 score 0.231 lr 3.23834e-07 
12/03/2021 03:08:21 - INFO - volta.train_utils -   [NLVR2]: iter 95492 Ep: 17.69 loss 0.011 score 0.231 lr 3.21776e-07 
12/03/2021 03:08:42 - INFO - volta.train_utils -   [NLVR2]: iter 95572 Ep: 17.71 loss 0.010 score 0.234 lr 3.19717e-07 
12/03/2021 03:09:04 - INFO - volta.train_utils -   [NLVR2]: iter 95652 Ep: 17.72 loss 0.011 score 0.232 lr 3.17659e-07 
12/03/2021 03:09:26 - INFO - volta.train_utils -   [NLVR2]: iter 95732 Ep: 17.73 loss 0.011 score 0.229 lr 3.156e-07 
12/03/2021 03:09:48 - INFO - volta.train_utils -   [NLVR2]: iter 95812 Ep: 17.75 loss 0.010 score 0.234 lr 3.13542e-07 
12/03/2021 03:10:09 - INFO - volta.train_utils -   [NLVR2]: iter 95892 Ep: 17.76 loss 0.011 score 0.233 lr 3.11484e-07 
12/03/2021 03:10:31 - INFO - volta.train_utils -   [NLVR2]: iter 95972 Ep: 17.78 loss 0.007 score 0.234 lr 3.09425e-07 
12/03/2021 03:10:53 - INFO - volta.train_utils -   [NLVR2]: iter 96052 Ep: 17.79 loss 0.009 score 0.230 lr 3.07367e-07 
12/03/2021 03:11:14 - INFO - volta.train_utils -   [NLVR2]: iter 96132 Ep: 17.81 loss 0.009 score 0.233 lr 3.05309e-07 
12/03/2021 03:11:36 - INFO - volta.train_utils -   [NLVR2]: iter 96212 Ep: 17.82 loss 0.010 score 0.234 lr 3.0325e-07 
12/03/2021 03:11:58 - INFO - volta.train_utils -   [NLVR2]: iter 96292 Ep: 17.84 loss 0.008 score 0.236 lr 3.01192e-07 
12/03/2021 03:12:20 - INFO - volta.train_utils -   [NLVR2]: iter 96372 Ep: 17.85 loss 0.009 score 0.232 lr 2.99133e-07 
12/03/2021 03:12:41 - INFO - volta.train_utils -   [NLVR2]: iter 96452 Ep: 17.87 loss 0.011 score 0.232 lr 2.97075e-07 
12/03/2021 03:13:03 - INFO - volta.train_utils -   [NLVR2]: iter 96532 Ep: 17.88 loss 0.012 score 0.232 lr 2.95017e-07 
12/03/2021 03:13:25 - INFO - volta.train_utils -   [NLVR2]: iter 96612 Ep: 17.90 loss 0.012 score 0.232 lr 2.92958e-07 
12/03/2021 03:13:47 - INFO - volta.train_utils -   [NLVR2]: iter 96692 Ep: 17.91 loss 0.009 score 0.233 lr 2.909e-07 
12/03/2021 03:14:08 - INFO - volta.train_utils -   [NLVR2]: iter 96772 Ep: 17.93 loss 0.010 score 0.234 lr 2.88842e-07 
12/03/2021 03:14:30 - INFO - volta.train_utils -   [NLVR2]: iter 96852 Ep: 17.94 loss 0.010 score 0.232 lr 2.86783e-07 
12/03/2021 03:14:52 - INFO - volta.train_utils -   [NLVR2]: iter 96932 Ep: 17.96 loss 0.009 score 0.236 lr 2.84725e-07 
12/03/2021 03:15:14 - INFO - volta.train_utils -   [NLVR2]: iter 97012 Ep: 17.97 loss 0.013 score 0.232 lr 2.82666e-07 
12/03/2021 03:15:35 - INFO - volta.train_utils -   [NLVR2]: iter 97092 Ep: 17.99 loss 0.011 score 0.233 lr 2.80608e-07 
12/03/2021 03:16:28 - INFO - volta.train_utils -   Eval task TASK12 on iteration 97128 
12/03/2021 03:16:28 - INFO - volta.train_utils -   Validation [NLVR2]: loss 1.295 score 67.087 
Epoch:  90%|█████████ | 18/20 [7:36:30<50:21, 1510.87s/it]  12/03/2021 03:16:51 - INFO - volta.train_utils -   [NLVR2]: iter 97208 Ep: 18.01 loss 0.010 score 0.239 lr 2.78087e-07 
12/03/2021 03:17:12 - INFO - volta.train_utils -   [NLVR2]: iter 97288 Ep: 18.02 loss 0.008 score 0.234 lr 2.75565e-07 
12/03/2021 03:17:34 - INFO - volta.train_utils -   [NLVR2]: iter 97368 Ep: 18.04 loss 0.009 score 0.234 lr 2.73507e-07 
12/03/2021 03:17:56 - INFO - volta.train_utils -   [NLVR2]: iter 97448 Ep: 18.05 loss 0.010 score 0.231 lr 2.71448e-07 
12/03/2021 03:18:17 - INFO - volta.train_utils -   [NLVR2]: iter 97528 Ep: 18.07 loss 0.010 score 0.232 lr 2.6939e-07 
12/03/2021 03:18:39 - INFO - volta.train_utils -   [NLVR2]: iter 97608 Ep: 18.08 loss 0.010 score 0.232 lr 2.67332e-07 
12/03/2021 03:19:01 - INFO - volta.train_utils -   [NLVR2]: iter 97688 Ep: 18.10 loss 0.009 score 0.232 lr 2.65273e-07 
12/03/2021 03:19:23 - INFO - volta.train_utils -   [NLVR2]: iter 97768 Ep: 18.11 loss 0.008 score 0.235 lr 2.63215e-07 
12/03/2021 03:19:45 - INFO - volta.train_utils -   [NLVR2]: iter 97848 Ep: 18.13 loss 0.011 score 0.234 lr 2.61156e-07 
12/03/2021 03:20:07 - INFO - volta.train_utils -   [NLVR2]: iter 97928 Ep: 18.14 loss 0.009 score 0.234 lr 2.59098e-07 
12/03/2021 03:20:28 - INFO - volta.train_utils -   [NLVR2]: iter 98008 Ep: 18.16 loss 0.007 score 0.235 lr 2.5704e-07 
12/03/2021 03:20:50 - INFO - volta.train_utils -   [NLVR2]: iter 98088 Ep: 18.17 loss 0.011 score 0.233 lr 2.54981e-07 
12/03/2021 03:21:12 - INFO - volta.train_utils -   [NLVR2]: iter 98168 Ep: 18.19 loss 0.011 score 0.233 lr 2.52923e-07 
12/03/2021 03:21:33 - INFO - volta.train_utils -   [NLVR2]: iter 98248 Ep: 18.20 loss 0.013 score 0.227 lr 2.50865e-07 
12/03/2021 03:21:55 - INFO - volta.train_utils -   [NLVR2]: iter 98328 Ep: 18.22 loss 0.010 score 0.234 lr 2.48806e-07 
12/03/2021 03:22:17 - INFO - volta.train_utils -   [NLVR2]: iter 98408 Ep: 18.23 loss 0.011 score 0.233 lr 2.46748e-07 
12/03/2021 03:22:38 - INFO - volta.train_utils -   [NLVR2]: iter 98488 Ep: 18.25 loss 0.011 score 0.232 lr 2.44689e-07 
12/03/2021 03:23:00 - INFO - volta.train_utils -   [NLVR2]: iter 98568 Ep: 18.26 loss 0.009 score 0.233 lr 2.42631e-07 
12/03/2021 03:23:22 - INFO - volta.train_utils -   [NLVR2]: iter 98648 Ep: 18.27 loss 0.011 score 0.232 lr 2.40573e-07 
12/03/2021 03:23:44 - INFO - volta.train_utils -   [NLVR2]: iter 98728 Ep: 18.29 loss 0.008 score 0.235 lr 2.38514e-07 
12/03/2021 03:24:05 - INFO - volta.train_utils -   [NLVR2]: iter 98808 Ep: 18.30 loss 0.013 score 0.229 lr 2.36456e-07 
12/03/2021 03:24:27 - INFO - volta.train_utils -   [NLVR2]: iter 98888 Ep: 18.32 loss 0.008 score 0.234 lr 2.34398e-07 
12/03/2021 03:24:49 - INFO - volta.train_utils -   [NLVR2]: iter 98968 Ep: 18.33 loss 0.010 score 0.235 lr 2.32339e-07 
12/03/2021 03:25:11 - INFO - volta.train_utils -   [NLVR2]: iter 99048 Ep: 18.35 loss 0.009 score 0.235 lr 2.30281e-07 
12/03/2021 03:25:32 - INFO - volta.train_utils -   [NLVR2]: iter 99128 Ep: 18.36 loss 0.012 score 0.232 lr 2.28222e-07 
12/03/2021 03:25:54 - INFO - volta.train_utils -   [NLVR2]: iter 99208 Ep: 18.38 loss 0.006 score 0.233 lr 2.26164e-07 
12/03/2021 03:26:16 - INFO - volta.train_utils -   [NLVR2]: iter 99288 Ep: 18.39 loss 0.010 score 0.236 lr 2.24106e-07 
12/03/2021 03:26:38 - INFO - volta.train_utils -   [NLVR2]: iter 99368 Ep: 18.41 loss 0.009 score 0.233 lr 2.22047e-07 
12/03/2021 03:26:59 - INFO - volta.train_utils -   [NLVR2]: iter 99448 Ep: 18.42 loss 0.013 score 0.232 lr 2.19989e-07 
12/03/2021 03:27:21 - INFO - volta.train_utils -   [NLVR2]: iter 99528 Ep: 18.44 loss 0.011 score 0.232 lr 2.17931e-07 
12/03/2021 03:27:43 - INFO - volta.train_utils -   [NLVR2]: iter 99608 Ep: 18.45 loss 0.012 score 0.229 lr 2.15872e-07 
12/03/2021 03:28:04 - INFO - volta.train_utils -   [NLVR2]: iter 99688 Ep: 18.47 loss 0.010 score 0.231 lr 2.13814e-07 
12/03/2021 03:28:26 - INFO - volta.train_utils -   [NLVR2]: iter 99768 Ep: 18.48 loss 0.012 score 0.231 lr 2.11755e-07 
12/03/2021 03:28:48 - INFO - volta.train_utils -   [NLVR2]: iter 99848 Ep: 18.50 loss 0.011 score 0.234 lr 2.09697e-07 
12/03/2021 03:29:10 - INFO - volta.train_utils -   [NLVR2]: iter 99928 Ep: 18.51 loss 0.008 score 0.233 lr 2.07639e-07 
12/03/2021 03:29:31 - INFO - volta.train_utils -   [NLVR2]: iter 100008 Ep: 18.53 loss 0.012 score 0.236 lr 2.0558e-07 
12/03/2021 03:29:53 - INFO - volta.train_utils -   [NLVR2]: iter 100088 Ep: 18.54 loss 0.010 score 0.233 lr 2.03522e-07 
12/03/2021 03:30:15 - INFO - volta.train_utils -   [NLVR2]: iter 100168 Ep: 18.56 loss 0.011 score 0.233 lr 2.01464e-07 
12/03/2021 03:30:37 - INFO - volta.train_utils -   [NLVR2]: iter 100248 Ep: 18.57 loss 0.008 score 0.237 lr 1.99405e-07 
12/03/2021 03:30:58 - INFO - volta.train_utils -   [NLVR2]: iter 100328 Ep: 18.59 loss 0.012 score 0.234 lr 1.97347e-07 
12/03/2021 03:31:20 - INFO - volta.train_utils -   [NLVR2]: iter 100408 Ep: 18.60 loss 0.011 score 0.231 lr 1.95288e-07 
12/03/2021 03:31:42 - INFO - volta.train_utils -   [NLVR2]: iter 100488 Ep: 18.62 loss 0.015 score 0.230 lr 1.9323e-07 
12/03/2021 03:32:04 - INFO - volta.train_utils -   [NLVR2]: iter 100568 Ep: 18.63 loss 0.009 score 0.231 lr 1.91172e-07 
12/03/2021 03:32:25 - INFO - volta.train_utils -   [NLVR2]: iter 100648 Ep: 18.65 loss 0.009 score 0.233 lr 1.89113e-07 
12/03/2021 03:32:47 - INFO - volta.train_utils -   [NLVR2]: iter 100728 Ep: 18.66 loss 0.011 score 0.230 lr 1.87055e-07 
12/03/2021 03:33:09 - INFO - volta.train_utils -   [NLVR2]: iter 100808 Ep: 18.68 loss 0.011 score 0.232 lr 1.84997e-07 
12/03/2021 03:33:31 - INFO - volta.train_utils -   [NLVR2]: iter 100888 Ep: 18.69 loss 0.011 score 0.234 lr 1.82938e-07 
12/03/2021 03:33:52 - INFO - volta.train_utils -   [NLVR2]: iter 100968 Ep: 18.70 loss 0.012 score 0.229 lr 1.8088e-07 
12/03/2021 03:34:14 - INFO - volta.train_utils -   [NLVR2]: iter 101048 Ep: 18.72 loss 0.014 score 0.232 lr 1.78821e-07 
12/03/2021 03:34:36 - INFO - volta.train_utils -   [NLVR2]: iter 101128 Ep: 18.73 loss 0.010 score 0.234 lr 1.76763e-07 
12/03/2021 03:34:58 - INFO - volta.train_utils -   [NLVR2]: iter 101208 Ep: 18.75 loss 0.010 score 0.233 lr 1.74705e-07 
12/03/2021 03:35:19 - INFO - volta.train_utils -   [NLVR2]: iter 101288 Ep: 18.76 loss 0.010 score 0.235 lr 1.72646e-07 
12/03/2021 03:35:41 - INFO - volta.train_utils -   [NLVR2]: iter 101368 Ep: 18.78 loss 0.011 score 0.232 lr 1.70588e-07 
12/03/2021 03:36:03 - INFO - volta.train_utils -   [NLVR2]: iter 101448 Ep: 18.79 loss 0.007 score 0.236 lr 1.68529e-07 
12/03/2021 03:36:25 - INFO - volta.train_utils -   [NLVR2]: iter 101528 Ep: 18.81 loss 0.010 score 0.234 lr 1.66471e-07 
12/03/2021 03:36:46 - INFO - volta.train_utils -   [NLVR2]: iter 101608 Ep: 18.82 loss 0.011 score 0.232 lr 1.64413e-07 
12/03/2021 03:37:08 - INFO - volta.train_utils -   [NLVR2]: iter 101688 Ep: 18.84 loss 0.011 score 0.235 lr 1.62354e-07 
12/03/2021 03:37:30 - INFO - volta.train_utils -   [NLVR2]: iter 101768 Ep: 18.85 loss 0.011 score 0.232 lr 1.60296e-07 
12/03/2021 03:37:51 - INFO - volta.train_utils -   [NLVR2]: iter 101848 Ep: 18.87 loss 0.012 score 0.233 lr 1.58238e-07 
12/03/2021 03:38:13 - INFO - volta.train_utils -   [NLVR2]: iter 101928 Ep: 18.88 loss 0.013 score 0.233 lr 1.56179e-07 
12/03/2021 03:38:35 - INFO - volta.train_utils -   [NLVR2]: iter 102008 Ep: 18.90 loss 0.009 score 0.234 lr 1.54121e-07 
12/03/2021 03:38:57 - INFO - volta.train_utils -   [NLVR2]: iter 102088 Ep: 18.91 loss 0.007 score 0.234 lr 1.52062e-07 
12/03/2021 03:39:18 - INFO - volta.train_utils -   [NLVR2]: iter 102168 Ep: 18.93 loss 0.010 score 0.236 lr 1.50004e-07 
12/03/2021 03:39:40 - INFO - volta.train_utils -   [NLVR2]: iter 102248 Ep: 18.94 loss 0.011 score 0.236 lr 1.47946e-07 
12/03/2021 03:40:02 - INFO - volta.train_utils -   [NLVR2]: iter 102328 Ep: 18.96 loss 0.009 score 0.234 lr 1.45887e-07 
12/03/2021 03:40:24 - INFO - volta.train_utils -   [NLVR2]: iter 102408 Ep: 18.97 loss 0.009 score 0.232 lr 1.43829e-07 
12/03/2021 03:40:46 - INFO - volta.train_utils -   [NLVR2]: iter 102488 Ep: 18.99 loss 0.011 score 0.235 lr 1.41771e-07 
12/03/2021 03:41:39 - INFO - volta.train_utils -   Eval task TASK12 on iteration 102524 
12/03/2021 03:41:39 - INFO - volta.train_utils -   Validation [NLVR2]: loss 1.310 score 67.173 
Epoch:  95%|█████████▌| 19/20 [8:01:40<25:10, 1510.74s/it]12/03/2021 03:42:01 - INFO - volta.train_utils -   [NLVR2]: iter 102604 Ep: 19.01 loss 0.009 score 0.239 lr 1.39249e-07 
12/03/2021 03:42:23 - INFO - volta.train_utils -   [NLVR2]: iter 102684 Ep: 19.02 loss 0.010 score 0.235 lr 1.36728e-07 
12/03/2021 03:42:44 - INFO - volta.train_utils -   [NLVR2]: iter 102764 Ep: 19.04 loss 0.012 score 0.232 lr 1.34669e-07 
12/03/2021 03:43:06 - INFO - volta.train_utils -   [NLVR2]: iter 102844 Ep: 19.05 loss 0.009 score 0.234 lr 1.32611e-07 
12/03/2021 03:43:28 - INFO - volta.train_utils -   [NLVR2]: iter 102924 Ep: 19.07 loss 0.007 score 0.235 lr 1.30552e-07 
12/03/2021 03:43:50 - INFO - volta.train_utils -   [NLVR2]: iter 103004 Ep: 19.08 loss 0.011 score 0.232 lr 1.28494e-07 
12/03/2021 03:44:11 - INFO - volta.train_utils -   [NLVR2]: iter 103084 Ep: 19.10 loss 0.007 score 0.237 lr 1.26436e-07 
12/03/2021 03:44:33 - INFO - volta.train_utils -   [NLVR2]: iter 103164 Ep: 19.11 loss 0.007 score 0.237 lr 1.24377e-07 
12/03/2021 03:44:55 - INFO - volta.train_utils -   [NLVR2]: iter 103244 Ep: 19.13 loss 0.010 score 0.234 lr 1.22319e-07 
12/03/2021 03:45:17 - INFO - volta.train_utils -   [NLVR2]: iter 103324 Ep: 19.14 loss 0.012 score 0.234 lr 1.20261e-07 
12/03/2021 03:45:38 - INFO - volta.train_utils -   [NLVR2]: iter 103404 Ep: 19.16 loss 0.009 score 0.235 lr 1.18202e-07 
12/03/2021 03:46:00 - INFO - volta.train_utils -   [NLVR2]: iter 103484 Ep: 19.17 loss 0.010 score 0.236 lr 1.16144e-07 
12/03/2021 03:46:22 - INFO - volta.train_utils -   [NLVR2]: iter 103564 Ep: 19.19 loss 0.010 score 0.236 lr 1.14085e-07 
12/03/2021 03:46:43 - INFO - volta.train_utils -   [NLVR2]: iter 103644 Ep: 19.20 loss 0.009 score 0.231 lr 1.12027e-07 
12/03/2021 03:47:05 - INFO - volta.train_utils -   [NLVR2]: iter 103724 Ep: 19.22 loss 0.008 score 0.234 lr 1.09969e-07 
12/03/2021 03:47:27 - INFO - volta.train_utils -   [NLVR2]: iter 103804 Ep: 19.23 loss 0.011 score 0.237 lr 1.0791e-07 
12/03/2021 03:47:49 - INFO - volta.train_utils -   [NLVR2]: iter 103884 Ep: 19.24 loss 0.009 score 0.233 lr 1.05852e-07 
12/03/2021 03:48:10 - INFO - volta.train_utils -   [NLVR2]: iter 103964 Ep: 19.26 loss 0.011 score 0.234 lr 1.03794e-07 
12/03/2021 03:48:32 - INFO - volta.train_utils -   [NLVR2]: iter 104044 Ep: 19.27 loss 0.011 score 0.237 lr 1.01735e-07 
12/03/2021 03:48:54 - INFO - volta.train_utils -   [NLVR2]: iter 104124 Ep: 19.29 loss 0.007 score 0.235 lr 9.96768e-08 
12/03/2021 03:49:16 - INFO - volta.train_utils -   [NLVR2]: iter 104204 Ep: 19.30 loss 0.011 score 0.231 lr 9.76185e-08 
12/03/2021 03:49:38 - INFO - volta.train_utils -   [NLVR2]: iter 104284 Ep: 19.32 loss 0.009 score 0.236 lr 9.55601e-08 
12/03/2021 03:50:00 - INFO - volta.train_utils -   [NLVR2]: iter 104364 Ep: 19.33 loss 0.012 score 0.232 lr 9.35017e-08 
12/03/2021 03:50:21 - INFO - volta.train_utils -   [NLVR2]: iter 104444 Ep: 19.35 loss 0.007 score 0.235 lr 9.14433e-08 
12/03/2021 03:50:43 - INFO - volta.train_utils -   [NLVR2]: iter 104524 Ep: 19.36 loss 0.009 score 0.236 lr 8.9385e-08 
12/03/2021 03:51:05 - INFO - volta.train_utils -   [NLVR2]: iter 104604 Ep: 19.38 loss 0.012 score 0.234 lr 8.73266e-08 
12/03/2021 03:51:27 - INFO - volta.train_utils -   [NLVR2]: iter 104684 Ep: 19.39 loss 0.011 score 0.231 lr 8.52682e-08 
12/03/2021 03:51:48 - INFO - volta.train_utils -   [NLVR2]: iter 104764 Ep: 19.41 loss 0.008 score 0.234 lr 8.32098e-08 
12/03/2021 03:52:10 - INFO - volta.train_utils -   [NLVR2]: iter 104844 Ep: 19.42 loss 0.009 score 0.237 lr 8.11515e-08 
12/03/2021 03:52:32 - INFO - volta.train_utils -   [NLVR2]: iter 104924 Ep: 19.44 loss 0.010 score 0.233 lr 7.90931e-08 
12/03/2021 03:52:53 - INFO - volta.train_utils -   [NLVR2]: iter 105004 Ep: 19.45 loss 0.012 score 0.232 lr 7.70347e-08 
12/03/2021 03:53:15 - INFO - volta.train_utils -   [NLVR2]: iter 105084 Ep: 19.47 loss 0.010 score 0.231 lr 7.49763e-08 
12/03/2021 03:53:37 - INFO - volta.train_utils -   [NLVR2]: iter 105164 Ep: 19.48 loss 0.009 score 0.234 lr 7.2918e-08 
12/03/2021 03:53:59 - INFO - volta.train_utils -   [NLVR2]: iter 105244 Ep: 19.50 loss 0.010 score 0.230 lr 7.08596e-08 
12/03/2021 03:54:20 - INFO - volta.train_utils -   [NLVR2]: iter 105324 Ep: 19.51 loss 0.009 score 0.231 lr 6.88012e-08 
12/03/2021 03:54:42 - INFO - volta.train_utils -   [NLVR2]: iter 105404 Ep: 19.53 loss 0.011 score 0.233 lr 6.67428e-08 
12/03/2021 03:55:04 - INFO - volta.train_utils -   [NLVR2]: iter 105484 Ep: 19.54 loss 0.011 score 0.234 lr 6.46845e-08 
12/03/2021 03:55:26 - INFO - volta.train_utils -   [NLVR2]: iter 105564 Ep: 19.56 loss 0.008 score 0.233 lr 6.26261e-08 
12/03/2021 03:55:47 - INFO - volta.train_utils -   [NLVR2]: iter 105644 Ep: 19.57 loss 0.010 score 0.233 lr 6.05677e-08 
12/03/2021 03:56:09 - INFO - volta.train_utils -   [NLVR2]: iter 105724 Ep: 19.59 loss 0.010 score 0.233 lr 5.85093e-08 
12/03/2021 03:56:31 - INFO - volta.train_utils -   [NLVR2]: iter 105804 Ep: 19.60 loss 0.010 score 0.234 lr 5.64509e-08 
12/03/2021 03:56:52 - INFO - volta.train_utils -   [NLVR2]: iter 105884 Ep: 19.62 loss 0.011 score 0.231 lr 5.43926e-08 
12/03/2021 03:57:14 - INFO - volta.train_utils -   [NLVR2]: iter 105964 Ep: 19.63 loss 0.007 score 0.236 lr 5.23342e-08 
12/03/2021 03:57:36 - INFO - volta.train_utils -   [NLVR2]: iter 106044 Ep: 19.65 loss 0.012 score 0.234 lr 5.02758e-08 
12/03/2021 03:57:58 - INFO - volta.train_utils -   [NLVR2]: iter 106124 Ep: 19.66 loss 0.008 score 0.234 lr 4.82174e-08 
12/03/2021 03:58:19 - INFO - volta.train_utils -   [NLVR2]: iter 106204 Ep: 19.67 loss 0.009 score 0.230 lr 4.61591e-08 
12/03/2021 03:58:41 - INFO - volta.train_utils -   [NLVR2]: iter 106284 Ep: 19.69 loss 0.010 score 0.233 lr 4.41007e-08 
12/03/2021 03:59:03 - INFO - volta.train_utils -   [NLVR2]: iter 106364 Ep: 19.70 loss 0.009 score 0.232 lr 4.20423e-08 
12/03/2021 03:59:25 - INFO - volta.train_utils -   [NLVR2]: iter 106444 Ep: 19.72 loss 0.011 score 0.233 lr 3.99839e-08 
12/03/2021 03:59:46 - INFO - volta.train_utils -   [NLVR2]: iter 106524 Ep: 19.73 loss 0.010 score 0.236 lr 3.79256e-08 
12/03/2021 04:00:08 - INFO - volta.train_utils -   [NLVR2]: iter 106604 Ep: 19.75 loss 0.010 score 0.236 lr 3.58672e-08 
12/03/2021 04:00:30 - INFO - volta.train_utils -   [NLVR2]: iter 106684 Ep: 19.76 loss 0.009 score 0.237 lr 3.38088e-08 
12/03/2021 04:00:51 - INFO - volta.train_utils -   [NLVR2]: iter 106764 Ep: 19.78 loss 0.011 score 0.235 lr 3.17504e-08 
12/03/2021 04:01:13 - INFO - volta.train_utils -   [NLVR2]: iter 106844 Ep: 19.79 loss 0.009 score 0.231 lr 2.96921e-08 
12/03/2021 04:01:35 - INFO - volta.train_utils -   [NLVR2]: iter 106924 Ep: 19.81 loss 0.010 score 0.233 lr 2.76337e-08 
12/03/2021 04:01:57 - INFO - volta.train_utils -   [NLVR2]: iter 107004 Ep: 19.82 loss 0.011 score 0.231 lr 2.55753e-08 
12/03/2021 04:02:19 - INFO - volta.train_utils -   [NLVR2]: iter 107084 Ep: 19.84 loss 0.010 score 0.234 lr 2.35169e-08 
12/03/2021 04:02:40 - INFO - volta.train_utils -   [NLVR2]: iter 107164 Ep: 19.85 loss 0.010 score 0.233 lr 2.14586e-08 
12/03/2021 04:03:02 - INFO - volta.train_utils -   [NLVR2]: iter 107244 Ep: 19.87 loss 0.010 score 0.234 lr 1.94002e-08 
12/03/2021 04:03:24 - INFO - volta.train_utils -   [NLVR2]: iter 107324 Ep: 19.88 loss 0.008 score 0.234 lr 1.73418e-08 
12/03/2021 04:03:46 - INFO - volta.train_utils -   [NLVR2]: iter 107404 Ep: 19.90 loss 0.010 score 0.236 lr 1.52834e-08 
12/03/2021 04:04:07 - INFO - volta.train_utils -   [NLVR2]: iter 107484 Ep: 19.91 loss 0.008 score 0.235 lr 1.32251e-08 
12/03/2021 04:04:29 - INFO - volta.train_utils -   [NLVR2]: iter 107564 Ep: 19.93 loss 0.011 score 0.235 lr 1.11667e-08 
12/03/2021 04:04:51 - INFO - volta.train_utils -   [NLVR2]: iter 107644 Ep: 19.94 loss 0.011 score 0.232 lr 9.10831e-09 
12/03/2021 04:05:13 - INFO - volta.train_utils -   [NLVR2]: iter 107724 Ep: 19.96 loss 0.011 score 0.233 lr 7.04994e-09 
12/03/2021 04:05:35 - INFO - volta.train_utils -   [NLVR2]: iter 107804 Ep: 19.97 loss 0.009 score 0.237 lr 4.99156e-09 
12/03/2021 04:05:56 - INFO - volta.train_utils -   [NLVR2]: iter 107884 Ep: 19.99 loss 0.009 score 0.235 lr 2.93319e-09 
12/03/2021 04:06:50 - INFO - volta.train_utils -   Eval task TASK12 on iteration 107920 
12/03/2021 04:06:50 - INFO - volta.train_utils -   Validation [NLVR2]: loss 1.303 score 67.231 
Epoch: 100%|██████████| 20/20 [8:26:51<00:00, 1510.73s/it]
