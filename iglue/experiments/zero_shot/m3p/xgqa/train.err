WARNING:tensorflow:From /home/projects/ku_00062/envs/iglue/lib/python3.6/site-packages/tensorpack/callbacks/hooks.py:17: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.

WARNING:tensorflow:From /home/projects/ku_00062/envs/iglue/lib/python3.6/site-packages/tensorpack/tfutils/optimizer.py:18: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

WARNING:tensorflow:From /home/projects/ku_00062/envs/iglue/lib/python3.6/site-packages/tensorpack/tfutils/sesscreate.py:20: The name tf.train.SessionCreator is deprecated. Please use tf.compat.v1.train.SessionCreator instead.

12/05/2021 00:13:23 - INFO - __main__ -   device: cuda n_gpu: 1, distributed training: False
12/05/2021 00:13:23 - INFO - volta.task_utils -   Loading GQA Dataset with batch size 32
12/05/2021 00:13:24 - INFO - volta.train_utils -   logging file at: /home/projects/ku_00062/logs/iglue/xgqa/m3p_base/GQA_m3p_base
12/05/2021 00:13:24 - INFO - volta.utils -   loading weights file /home/projects/ku_00062/checkpoints/iglue/pretrain/m3p/m3p_base/m3p_checkpoint_22.bin
12/05/2021 00:14:17 - INFO - volta.utils -   
12/05/2021 00:14:33 - INFO - volta.utils -   Weights of M3PForVLTasks not initialized from pretrained model: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'clfs_dict.TASK15.logit_fc.0.weight', 'clfs_dict.TASK15.logit_fc.0.bias', 'clfs_dict.TASK15.logit_fc.2.weight', 'clfs_dict.TASK15.logit_fc.2.bias', 'clfs_dict.TASK15.logit_fc.3.weight', 'clfs_dict.TASK15.logit_fc.3.bias']
12/05/2021 00:14:33 - INFO - volta.utils -   Weights from pretrained model not used in M3PForVLTasks: ['bert.encoder.pred_layer.proj.weight', 'bert.encoder.pred_layer.proj.bias', 'bert.encoder.pred_obj_layer.proj.weight', 'bert.encoder.pred_obj_layer.proj.bias']
12/05/2021 00:14:47 - INFO - __main__ -   ** ** * Saving model * ** ** 
/home/projects/ku_00062/envs/iglue/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:216: UserWarning: Please also save or load the state of the optimizer when saving or loading the scheduler.
  warnings.warn(SAVE_STATE_WARNING, UserWarning)
12/05/2021 00:15:04 - INFO - __main__ -   >> Parameters:
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |Name                                                                    |Dtype            |Shape            |#Params      |Trainable|
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.position_embeddings.weight                                 |torch.float32    |(514, 768)       |394752       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.cross_lang_embeddings.weight                               |torch.float32    |(100, 768)       |76800        |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.embeddings.weight                                          |torch.float32    |(250002, 768)    |192001536    |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.layer_norm_emb.weight                                      |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.layer_norm_emb.bias                                        |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.image_embeddings.image_embeddings.weight                   |torch.float32    |(768, 2048)      |1572864      |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.image_embeddings.image_embeddings.bias                     |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.image_embeddings.image_distbution_embeddings.weight        |torch.float32    |(768, 1600)      |1228800      |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.image_embeddings.image_distbution_embeddings.bias          |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.image_embeddings.image_location_embeddings.weight          |torch.float32    |(768, 5)         |3840         |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.image_embeddings.image_location_embeddings.bias            |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.image_embeddings.LayerNorm.weight                          |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.image_embeddings.LayerNorm.bias                            |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.0.self_attn.linears.0.weight      |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.0.self_attn.linears.0.bias        |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.0.self_attn.linears.1.weight      |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.0.self_attn.linears.1.bias        |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.0.self_attn.linears.2.weight      |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.0.self_attn.linears.2.bias        |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.0.self_attn.aoa_layer.0.weight    |torch.float32    |(1536, 1536)     |2359296      |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.0.self_attn.aoa_layer.0.bias      |torch.float32    |(1536,)          |1536         |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.0.feed_forward.lin1.weight        |torch.float32    |(3072, 768)      |2359296      |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.0.feed_forward.lin1.bias          |torch.float32    |(3072,)          |3072         |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.0.feed_forward.lin2.weight        |torch.float32    |(768, 3072)      |2359296      |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.0.feed_forward.lin2.bias          |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.0.sublayer.0.norm.weight          |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.0.sublayer.0.norm.bias            |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.0.sublayer.1.norm.weight          |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.0.sublayer.1.norm.bias            |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.1.self_attn.linears.0.weight      |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.1.self_attn.linears.0.bias        |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.1.self_attn.linears.1.weight      |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.1.self_attn.linears.1.bias        |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.1.self_attn.linears.2.weight      |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.1.self_attn.linears.2.bias        |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.1.self_attn.aoa_layer.0.weight    |torch.float32    |(1536, 1536)     |2359296      |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.1.self_attn.aoa_layer.0.bias      |torch.float32    |(1536,)          |1536         |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.1.feed_forward.lin1.weight        |torch.float32    |(3072, 768)      |2359296      |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.1.feed_forward.lin1.bias          |torch.float32    |(3072,)          |3072         |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.1.feed_forward.lin2.weight        |torch.float32    |(768, 3072)      |2359296      |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.1.feed_forward.lin2.bias          |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.1.sublayer.0.norm.weight          |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.1.sublayer.0.norm.bias            |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.1.sublayer.1.norm.weight          |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.1.sublayer.1.norm.bias            |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.2.self_attn.linears.0.weight      |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.2.self_attn.linears.0.bias        |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.2.self_attn.linears.1.weight      |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.2.self_attn.linears.1.bias        |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.2.self_attn.linears.2.weight      |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.2.self_attn.linears.2.bias        |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.2.self_attn.aoa_layer.0.weight    |torch.float32    |(1536, 1536)     |2359296      |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.2.self_attn.aoa_layer.0.bias      |torch.float32    |(1536,)          |1536         |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.2.feed_forward.lin1.weight        |torch.float32    |(3072, 768)      |2359296      |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.2.feed_forward.lin1.bias          |torch.float32    |(3072,)          |3072         |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.2.feed_forward.lin2.weight        |torch.float32    |(768, 3072)      |2359296      |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.2.feed_forward.lin2.bias          |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.2.sublayer.0.norm.weight          |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.2.sublayer.0.norm.bias            |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.2.sublayer.1.norm.weight          |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.2.sublayer.1.norm.bias            |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.3.self_attn.linears.0.weight      |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.3.self_attn.linears.0.bias        |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.3.self_attn.linears.1.weight      |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.3.self_attn.linears.1.bias        |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.3.self_attn.linears.2.weight      |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.3.self_attn.linears.2.bias        |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.3.self_attn.aoa_layer.0.weight    |torch.float32    |(1536, 1536)     |2359296      |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.3.self_attn.aoa_layer.0.bias      |torch.float32    |(1536,)          |1536         |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.3.feed_forward.lin1.weight        |torch.float32    |(3072, 768)      |2359296      |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.3.feed_forward.lin1.bias          |torch.float32    |(3072,)          |3072         |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.3.feed_forward.lin2.weight        |torch.float32    |(768, 3072)      |2359296      |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.3.feed_forward.lin2.bias          |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.3.sublayer.0.norm.weight          |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.3.sublayer.0.norm.bias            |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.3.sublayer.1.norm.weight          |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.3.sublayer.1.norm.bias            |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.4.self_attn.linears.0.weight      |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.4.self_attn.linears.0.bias        |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.4.self_attn.linears.1.weight      |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.4.self_attn.linears.1.bias        |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.4.self_attn.linears.2.weight      |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.4.self_attn.linears.2.bias        |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.4.self_attn.aoa_layer.0.weight    |torch.float32    |(1536, 1536)     |2359296      |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.4.self_attn.aoa_layer.0.bias      |torch.float32    |(1536,)          |1536         |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.4.feed_forward.lin1.weight        |torch.float32    |(3072, 768)      |2359296      |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.4.feed_forward.lin1.bias          |torch.float32    |(3072,)          |3072         |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.4.feed_forward.lin2.weight        |torch.float32    |(768, 3072)      |2359296      |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.4.feed_forward.lin2.bias          |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.4.sublayer.0.norm.weight          |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.4.sublayer.0.norm.bias            |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.4.sublayer.1.norm.weight          |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.4.sublayer.1.norm.bias            |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.5.self_attn.linears.0.weight      |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.5.self_attn.linears.0.bias        |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.5.self_attn.linears.1.weight      |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.5.self_attn.linears.1.bias        |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.5.self_attn.linears.2.weight      |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.5.self_attn.linears.2.bias        |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.5.self_attn.aoa_layer.0.weight    |torch.float32    |(1536, 1536)     |2359296      |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.5.self_attn.aoa_layer.0.bias      |torch.float32    |(1536,)          |1536         |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.5.feed_forward.lin1.weight        |torch.float32    |(3072, 768)      |2359296      |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.5.feed_forward.lin1.bias          |torch.float32    |(3072,)          |3072         |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.5.feed_forward.lin2.weight        |torch.float32    |(768, 3072)      |2359296      |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.5.feed_forward.lin2.bias          |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.5.sublayer.0.norm.weight          |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.5.sublayer.0.norm.bias            |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.5.sublayer.1.norm.weight          |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.5.sublayer.1.norm.bias            |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.norm.weight                              |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.refine_embeddings.norm.bias                                |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.cross_alignment.att_weight_c.weight                        |torch.float32    |(1, 768)         |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.cross_alignment.att_weight_c.bias                          |torch.float32    |(1,)             |1            |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.cross_alignment.att_weight_q.weight                        |torch.float32    |(1, 768)         |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.cross_alignment.att_weight_q.bias                          |torch.float32    |(1,)             |1            |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.cross_alignment.att_weight_cq.weight                       |torch.float32    |(1, 768)         |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.cross_alignment.att_weight_cq.bias                         |torch.float32    |(1,)             |1            |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.cross_alignment.align_output.weight                        |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.cross_alignment.align_output.bias                          |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.cross_alignment.layer_norm.weight                          |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.cross_alignment.layer_norm.bias                            |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.0.q_lin.weight                                  |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.0.q_lin.bias                                    |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.0.k_lin.weight                                  |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.0.k_lin.bias                                    |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.0.v_lin.weight                                  |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.0.v_lin.bias                                    |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.0.out_lin.weight                                |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.0.out_lin.bias                                  |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.1.q_lin.weight                                  |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.1.q_lin.bias                                    |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.1.k_lin.weight                                  |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.1.k_lin.bias                                    |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.1.v_lin.weight                                  |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.1.v_lin.bias                                    |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.1.out_lin.weight                                |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.1.out_lin.bias                                  |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.2.q_lin.weight                                  |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.2.q_lin.bias                                    |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.2.k_lin.weight                                  |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.2.k_lin.bias                                    |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.2.v_lin.weight                                  |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.2.v_lin.bias                                    |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.2.out_lin.weight                                |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.2.out_lin.bias                                  |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.3.q_lin.weight                                  |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.3.q_lin.bias                                    |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.3.k_lin.weight                                  |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.3.k_lin.bias                                    |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.3.v_lin.weight                                  |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.3.v_lin.bias                                    |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.3.out_lin.weight                                |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.3.out_lin.bias                                  |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.4.q_lin.weight                                  |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.4.q_lin.bias                                    |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.4.k_lin.weight                                  |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.4.k_lin.bias                                    |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.4.v_lin.weight                                  |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.4.v_lin.bias                                    |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.4.out_lin.weight                                |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.4.out_lin.bias                                  |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.5.q_lin.weight                                  |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.5.q_lin.bias                                    |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.5.k_lin.weight                                  |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.5.k_lin.bias                                    |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.5.v_lin.weight                                  |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.5.v_lin.bias                                    |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.5.out_lin.weight                                |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.5.out_lin.bias                                  |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.6.q_lin.weight                                  |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.6.q_lin.bias                                    |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.6.k_lin.weight                                  |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.6.k_lin.bias                                    |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.6.v_lin.weight                                  |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.6.v_lin.bias                                    |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.6.out_lin.weight                                |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.6.out_lin.bias                                  |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.7.q_lin.weight                                  |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.7.q_lin.bias                                    |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.7.k_lin.weight                                  |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.7.k_lin.bias                                    |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.7.v_lin.weight                                  |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.7.v_lin.bias                                    |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.7.out_lin.weight                                |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.7.out_lin.bias                                  |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.8.q_lin.weight                                  |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.8.q_lin.bias                                    |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.8.k_lin.weight                                  |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.8.k_lin.bias                                    |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.8.v_lin.weight                                  |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.8.v_lin.bias                                    |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.8.out_lin.weight                                |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.8.out_lin.bias                                  |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.9.q_lin.weight                                  |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.9.q_lin.bias                                    |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.9.k_lin.weight                                  |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.9.k_lin.bias                                    |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.9.v_lin.weight                                  |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.9.v_lin.bias                                    |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.9.out_lin.weight                                |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.9.out_lin.bias                                  |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.10.q_lin.weight                                 |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.10.q_lin.bias                                   |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.10.k_lin.weight                                 |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.10.k_lin.bias                                   |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.10.v_lin.weight                                 |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.10.v_lin.bias                                   |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.10.out_lin.weight                               |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.10.out_lin.bias                                 |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.11.q_lin.weight                                 |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.11.q_lin.bias                                   |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.11.k_lin.weight                                 |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.11.k_lin.bias                                   |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.11.v_lin.weight                                 |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.11.v_lin.bias                                   |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.11.out_lin.weight                               |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.attentions.11.out_lin.bias                                 |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.layer_norm1.0.weight                                       |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.layer_norm1.0.bias                                         |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.layer_norm1.1.weight                                       |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.layer_norm1.1.bias                                         |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.layer_norm1.2.weight                                       |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.layer_norm1.2.bias                                         |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.layer_norm1.3.weight                                       |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.layer_norm1.3.bias                                         |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.layer_norm1.4.weight                                       |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.layer_norm1.4.bias                                         |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.layer_norm1.5.weight                                       |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.layer_norm1.5.bias                                         |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.layer_norm1.6.weight                                       |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.layer_norm1.6.bias                                         |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.layer_norm1.7.weight                                       |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.layer_norm1.7.bias                                         |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.layer_norm1.8.weight                                       |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.layer_norm1.8.bias                                         |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.layer_norm1.9.weight                                       |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.layer_norm1.9.bias                                         |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.layer_norm1.10.weight                                      |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.layer_norm1.10.bias                                        |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.layer_norm1.11.weight                                      |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.layer_norm1.11.bias                                        |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.ffns.0.lin1.weight                                         |torch.float32    |(3072, 768)      |2359296      |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.ffns.0.lin1.bias                                           |torch.float32    |(3072,)          |3072         |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.ffns.0.lin2.weight                                         |torch.float32    |(768, 3072)      |2359296      |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.ffns.0.lin2.bias                                           |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.ffns.1.lin1.weight                                         |torch.float32    |(3072, 768)      |2359296      |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.ffns.1.lin1.bias                                           |torch.float32    |(3072,)          |3072         |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.ffns.1.lin2.weight                                         |torch.float32    |(768, 3072)      |2359296      |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.ffns.1.lin2.bias                                           |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.ffns.2.lin1.weight                                         |torch.float32    |(3072, 768)      |2359296      |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.ffns.2.lin1.bias                                           |torch.float32    |(3072,)          |3072         |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.ffns.2.lin2.weight                                         |torch.float32    |(768, 3072)      |2359296      |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.ffns.2.lin2.bias                                           |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.ffns.3.lin1.weight                                         |torch.float32    |(3072, 768)      |2359296      |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.ffns.3.lin1.bias                                           |torch.float32    |(3072,)          |3072         |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.ffns.3.lin2.weight                                         |torch.float32    |(768, 3072)      |2359296      |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.ffns.3.lin2.bias                                           |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.ffns.4.lin1.weight                                         |torch.float32    |(3072, 768)      |2359296      |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.ffns.4.lin1.bias                                           |torch.float32    |(3072,)          |3072         |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.ffns.4.lin2.weight                                         |torch.float32    |(768, 3072)      |2359296      |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.ffns.4.lin2.bias                                           |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.ffns.5.lin1.weight                                         |torch.float32    |(3072, 768)      |2359296      |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.ffns.5.lin1.bias                                           |torch.float32    |(3072,)          |3072         |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.ffns.5.lin2.weight                                         |torch.float32    |(768, 3072)      |2359296      |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.ffns.5.lin2.bias                                           |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.ffns.6.lin1.weight                                         |torch.float32    |(3072, 768)      |2359296      |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.ffns.6.lin1.bias                                           |torch.float32    |(3072,)          |3072         |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.ffns.6.lin2.weight                                         |torch.float32    |(768, 3072)      |2359296      |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.ffns.6.lin2.bias                                           |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.ffns.7.lin1.weight                                         |torch.float32    |(3072, 768)      |2359296      |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.ffns.7.lin1.bias                                           |torch.float32    |(3072,)          |3072         |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.ffns.7.lin2.weight                                         |torch.float32    |(768, 3072)      |2359296      |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.ffns.7.lin2.bias                                           |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.ffns.8.lin1.weight                                         |torch.float32    |(3072, 768)      |2359296      |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.ffns.8.lin1.bias                                           |torch.float32    |(3072,)          |3072         |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.ffns.8.lin2.weight                                         |torch.float32    |(768, 3072)      |2359296      |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.ffns.8.lin2.bias                                           |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.ffns.9.lin1.weight                                         |torch.float32    |(3072, 768)      |2359296      |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.ffns.9.lin1.bias                                           |torch.float32    |(3072,)          |3072         |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.ffns.9.lin2.weight                                         |torch.float32    |(768, 3072)      |2359296      |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.ffns.9.lin2.bias                                           |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.ffns.10.lin1.weight                                        |torch.float32    |(3072, 768)      |2359296      |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.ffns.10.lin1.bias                                          |torch.float32    |(3072,)          |3072         |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.ffns.10.lin2.weight                                        |torch.float32    |(768, 3072)      |2359296      |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.ffns.10.lin2.bias                                          |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.ffns.11.lin1.weight                                        |torch.float32    |(3072, 768)      |2359296      |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.ffns.11.lin1.bias                                          |torch.float32    |(3072,)          |3072         |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.ffns.11.lin2.weight                                        |torch.float32    |(768, 3072)      |2359296      |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.ffns.11.lin2.bias                                          |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.layer_norm2.0.weight                                       |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.layer_norm2.0.bias                                         |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.layer_norm2.1.weight                                       |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.layer_norm2.1.bias                                         |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.layer_norm2.2.weight                                       |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.layer_norm2.2.bias                                         |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.layer_norm2.3.weight                                       |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.layer_norm2.3.bias                                         |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.layer_norm2.4.weight                                       |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.layer_norm2.4.bias                                         |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.layer_norm2.5.weight                                       |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.layer_norm2.5.bias                                         |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.layer_norm2.6.weight                                       |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.layer_norm2.6.bias                                         |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.layer_norm2.7.weight                                       |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.layer_norm2.7.bias                                         |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.layer_norm2.8.weight                                       |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.layer_norm2.8.bias                                         |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.layer_norm2.9.weight                                       |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.layer_norm2.9.bias                                         |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.layer_norm2.10.weight                                      |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.layer_norm2.10.bias                                        |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.layer_norm2.11.weight                                      |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.layer_norm2.11.bias                                        |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.layer_norm15.0.weight                                      |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.layer_norm15.0.bias                                        |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.layer_norm15.1.weight                                      |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.layer_norm15.1.bias                                        |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.layer_norm15.2.weight                                      |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.layer_norm15.2.bias                                        |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.layer_norm15.3.weight                                      |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.layer_norm15.3.bias                                        |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.layer_norm15.4.weight                                      |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.layer_norm15.4.bias                                        |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.layer_norm15.5.weight                                      |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.layer_norm15.5.bias                                        |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.layer_norm15.6.weight                                      |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.layer_norm15.6.bias                                        |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.layer_norm15.7.weight                                      |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.layer_norm15.7.bias                                        |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.layer_norm15.8.weight                                      |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.layer_norm15.8.bias                                        |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.layer_norm15.9.weight                                      |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.layer_norm15.9.bias                                        |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.layer_norm15.10.weight                                     |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.layer_norm15.10.bias                                       |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.layer_norm15.11.weight                                     |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.layer_norm15.11.bias                                       |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.0.q_lin.weight                                |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.0.q_lin.bias                                  |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.0.k_lin.weight                                |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.0.k_lin.bias                                  |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.0.v_lin.weight                                |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.0.v_lin.bias                                  |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.0.out_lin.weight                              |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.0.out_lin.bias                                |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.1.q_lin.weight                                |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.1.q_lin.bias                                  |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.1.k_lin.weight                                |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.1.k_lin.bias                                  |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.1.v_lin.weight                                |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.1.v_lin.bias                                  |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.1.out_lin.weight                              |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.1.out_lin.bias                                |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.2.q_lin.weight                                |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.2.q_lin.bias                                  |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.2.k_lin.weight                                |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.2.k_lin.bias                                  |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.2.v_lin.weight                                |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.2.v_lin.bias                                  |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.2.out_lin.weight                              |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.2.out_lin.bias                                |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.3.q_lin.weight                                |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.3.q_lin.bias                                  |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.3.k_lin.weight                                |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.3.k_lin.bias                                  |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.3.v_lin.weight                                |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.3.v_lin.bias                                  |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.3.out_lin.weight                              |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.3.out_lin.bias                                |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.4.q_lin.weight                                |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.4.q_lin.bias                                  |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.4.k_lin.weight                                |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.4.k_lin.bias                                  |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.4.v_lin.weight                                |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.4.v_lin.bias                                  |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.4.out_lin.weight                              |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.4.out_lin.bias                                |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.5.q_lin.weight                                |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.5.q_lin.bias                                  |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.5.k_lin.weight                                |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.5.k_lin.bias                                  |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.5.v_lin.weight                                |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.5.v_lin.bias                                  |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.5.out_lin.weight                              |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.5.out_lin.bias                                |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.6.q_lin.weight                                |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.6.q_lin.bias                                  |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.6.k_lin.weight                                |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.6.k_lin.bias                                  |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.6.v_lin.weight                                |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.6.v_lin.bias                                  |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.6.out_lin.weight                              |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.6.out_lin.bias                                |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.7.q_lin.weight                                |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.7.q_lin.bias                                  |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.7.k_lin.weight                                |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.7.k_lin.bias                                  |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.7.v_lin.weight                                |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.7.v_lin.bias                                  |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.7.out_lin.weight                              |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.7.out_lin.bias                                |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.8.q_lin.weight                                |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.8.q_lin.bias                                  |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.8.k_lin.weight                                |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.8.k_lin.bias                                  |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.8.v_lin.weight                                |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.8.v_lin.bias                                  |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.8.out_lin.weight                              |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.8.out_lin.bias                                |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.9.q_lin.weight                                |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.9.q_lin.bias                                  |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.9.k_lin.weight                                |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.9.k_lin.bias                                  |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.9.v_lin.weight                                |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.9.v_lin.bias                                  |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.9.out_lin.weight                              |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.9.out_lin.bias                                |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.10.q_lin.weight                               |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.10.q_lin.bias                                 |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.10.k_lin.weight                               |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.10.k_lin.bias                                 |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.10.v_lin.weight                               |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.10.v_lin.bias                                 |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.10.out_lin.weight                             |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.10.out_lin.bias                               |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.11.q_lin.weight                               |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.11.q_lin.bias                                 |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.11.k_lin.weight                               |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.11.k_lin.bias                                 |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.11.v_lin.weight                               |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.11.v_lin.bias                                 |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.11.out_lin.weight                             |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.encoder_attn.11.out_lin.bias                               |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.latent_transforms.0.x_to_mu.weight                         |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.latent_transforms.0.x_to_mu.bias                           |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.latent_transforms.0.x_to_logvar.weight                     |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.latent_transforms.0.x_to_logvar.bias                       |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.latent_transforms.0.out_dense.weight                       |torch.float32    |(768, 1536)      |1179648      |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.latent_transforms.0.out_dense.bias                         |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.latent_transforms.1.x_to_mu.weight                         |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.latent_transforms.1.x_to_mu.bias                           |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.latent_transforms.1.x_to_logvar.weight                     |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.latent_transforms.1.x_to_logvar.bias                       |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.latent_transforms.1.out_dense.weight                       |torch.float32    |(768, 1536)      |1179648      |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.latent_transforms.1.out_dense.bias                         |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.original_transforms.0.dense.weight                         |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.original_transforms.0.dense.bias                           |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.original_transforms.0.dense_mu.weight                      |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.original_transforms.0.dense_mu.bias                        |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.original_transforms.0.LayerNorm.weight                     |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.original_transforms.0.LayerNorm.bias                       |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.original_transforms.1.dense.weight                         |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.original_transforms.1.dense.bias                           |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.original_transforms.1.dense_mu.weight                      |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.original_transforms.1.dense_mu.bias                        |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.original_transforms.1.LayerNorm.weight                     |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.original_transforms.1.LayerNorm.bias                       |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.pooled_layer.dense.weight                                  |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.pooled_layer.dense.bias                                    |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.seq_relationship.weight                                    |torch.float32    |(1, 768)         |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.seq_relationship.bias                                      |torch.float32    |(1,)             |1            |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.pooled_layer2.dense.weight                                 |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.pooled_layer2.dense.bias                                   |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.seq_relationship2.weight                                   |torch.float32    |(1, 768)         |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.seq_relationship2.bias                                     |torch.float32    |(1,)             |1            |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.mrfr_dense.weight                                          |torch.float32    |(2048, 768)      |1572864      |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.mrfr_dense.bias                                            |torch.float32    |(2048,)          |2048         |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.transformer_obj.dense.weight                               |torch.float32    |(768, 768)       |589824       |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.transformer_obj.dense.bias                                 |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.transformer_obj.LayerNorm.weight                           |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |bert.encoder.transformer_obj.LayerNorm.bias                             |torch.float32    |(768,)           |768          |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |clfs_dict.TASK15.logit_fc.0.weight                                      |torch.float32    |(1536, 768)      |1179648      |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |clfs_dict.TASK15.logit_fc.0.bias                                        |torch.float32    |(1536,)          |1536         |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |clfs_dict.TASK15.logit_fc.2.weight                                      |torch.float32    |(1536,)          |1536         |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |clfs_dict.TASK15.logit_fc.2.bias                                        |torch.float32    |(1536,)          |1536         |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |clfs_dict.TASK15.logit_fc.3.weight                                      |torch.float32    |(1842, 1536)     |2829312      |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   |clfs_dict.TASK15.logit_fc.3.bias                                        |torch.float32    |(1842,)          |1842         |True    |
12/05/2021 00:15:04 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/05/2021 00:15:04 - INFO - __main__ -   >> # TrainableParams:       	376.90	M
12/05/2021 00:15:04 - INFO - __main__ -   >> # NonTrainableParams:    	0.00	M
12/05/2021 00:15:04 - INFO - __main__ -   >> # TotalParams:           	376.90	M
Epoch:   0%|          | 0/5 [00:00<?, ?it/s]/home/projects/ku_00062/envs/iglue/lib/python3.6/site-packages/pytorch_transformers/optimization.py:166: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
12/05/2021 00:16:15 - INFO - volta.train_utils -   [GQA]: iter 160 Ep: 0.01 loss 22.072 score 0.000 lr 7.12637e-09 
12/05/2021 00:18:01 - INFO - volta.train_utils -   [GQA]: iter 320 Ep: 0.01 loss 22.008 score 0.000 lr 2.07004e-08 
12/05/2021 00:19:47 - INFO - volta.train_utils -   [GQA]: iter 480 Ep: 0.02 loss 21.897 score 0.000 lr 3.42745e-08 
12/05/2021 00:21:33 - INFO - volta.train_utils -   [GQA]: iter 640 Ep: 0.02 loss 21.729 score 0.000 lr 4.78485e-08 
12/05/2021 00:23:18 - INFO - volta.train_utils -   [GQA]: iter 800 Ep: 0.03 loss 21.484 score 0.000 lr 6.14226e-08 
12/05/2021 00:25:04 - INFO - volta.train_utils -   [GQA]: iter 960 Ep: 0.03 loss 21.161 score 0.000 lr 7.49966e-08 
12/05/2021 00:26:50 - INFO - volta.train_utils -   [GQA]: iter 1120 Ep: 0.04 loss 20.765 score 0.000 lr 8.85707e-08 
12/05/2021 00:28:36 - INFO - volta.train_utils -   [GQA]: iter 1280 Ep: 0.04 loss 20.282 score 0.000 lr 1.02145e-07 
12/05/2021 00:30:22 - INFO - volta.train_utils -   [GQA]: iter 1440 Ep: 0.05 loss 19.707 score 0.000 lr 1.15719e-07 
12/05/2021 00:32:07 - INFO - volta.train_utils -   [GQA]: iter 1600 Ep: 0.05 loss 19.048 score 0.000 lr 1.29293e-07 
12/05/2021 00:33:53 - INFO - volta.train_utils -   [GQA]: iter 1760 Ep: 0.06 loss 18.300 score 0.000 lr 1.42867e-07 
12/05/2021 00:35:39 - INFO - volta.train_utils -   [GQA]: iter 1920 Ep: 0.07 loss 17.470 score 0.000 lr 1.56441e-07 
12/05/2021 00:37:25 - INFO - volta.train_utils -   [GQA]: iter 2080 Ep: 0.07 loss 16.552 score 0.000 lr 1.70015e-07 
12/05/2021 00:39:11 - INFO - volta.train_utils -   [GQA]: iter 2240 Ep: 0.08 loss 15.604 score 0.000 lr 1.83589e-07 
12/05/2021 00:40:56 - INFO - volta.train_utils -   [GQA]: iter 2400 Ep: 0.08 loss 14.663 score 0.000 lr 1.97163e-07 
12/05/2021 00:42:42 - INFO - volta.train_utils -   [GQA]: iter 2560 Ep: 0.09 loss 13.768 score 0.000 lr 2.10737e-07 
12/05/2021 00:44:28 - INFO - volta.train_utils -   [GQA]: iter 2720 Ep: 0.09 loss 12.866 score 0.000 lr 2.24311e-07 
12/05/2021 00:46:14 - INFO - volta.train_utils -   [GQA]: iter 2880 Ep: 0.10 loss 12.047 score 0.000 lr 2.37885e-07 
12/05/2021 00:48:00 - INFO - volta.train_utils -   [GQA]: iter 3040 Ep: 0.10 loss 11.260 score 0.000 lr 2.51459e-07 
12/05/2021 00:49:45 - INFO - volta.train_utils -   [GQA]: iter 3200 Ep: 0.11 loss 10.506 score 0.000 lr 2.65033e-07 
12/05/2021 00:51:31 - INFO - volta.train_utils -   [GQA]: iter 3360 Ep: 0.11 loss 9.744 score 0.000 lr 2.78607e-07 
12/05/2021 00:53:17 - INFO - volta.train_utils -   [GQA]: iter 3520 Ep: 0.12 loss 9.004 score 0.000 lr 2.92181e-07 
12/05/2021 00:55:02 - INFO - volta.train_utils -   [GQA]: iter 3680 Ep: 0.12 loss 8.320 score 0.000 lr 3.05755e-07 
12/05/2021 00:56:48 - INFO - volta.train_utils -   [GQA]: iter 3840 Ep: 0.13 loss 7.669 score 0.000 lr 3.19329e-07 
12/05/2021 00:58:34 - INFO - volta.train_utils -   [GQA]: iter 4000 Ep: 0.14 loss 7.041 score 0.000 lr 3.32903e-07 
12/05/2021 01:00:20 - INFO - volta.train_utils -   [GQA]: iter 4160 Ep: 0.14 loss 6.488 score 0.000 lr 3.46478e-07 
12/05/2021 01:02:06 - INFO - volta.train_utils -   [GQA]: iter 4320 Ep: 0.15 loss 5.924 score 0.000 lr 3.60052e-07 
12/05/2021 01:03:52 - INFO - volta.train_utils -   [GQA]: iter 4480 Ep: 0.15 loss 5.355 score 0.000 lr 3.73626e-07 
12/05/2021 01:05:37 - INFO - volta.train_utils -   [GQA]: iter 4640 Ep: 0.16 loss 4.841 score 0.000 lr 3.872e-07 
12/05/2021 01:07:23 - INFO - volta.train_utils -   [GQA]: iter 4800 Ep: 0.16 loss 4.373 score 0.000 lr 4.00774e-07 
12/05/2021 01:09:09 - INFO - volta.train_utils -   [GQA]: iter 4960 Ep: 0.17 loss 3.921 score 0.000 lr 4.14348e-07 
12/05/2021 01:10:55 - INFO - volta.train_utils -   [GQA]: iter 5120 Ep: 0.17 loss 3.512 score 0.000 lr 4.27922e-07 
12/05/2021 01:12:41 - INFO - volta.train_utils -   [GQA]: iter 5280 Ep: 0.18 loss 3.148 score 0.000 lr 4.41496e-07 
12/05/2021 01:14:26 - INFO - volta.train_utils -   [GQA]: iter 5440 Ep: 0.18 loss 2.830 score 0.000 lr 4.5507e-07 
12/05/2021 01:16:12 - INFO - volta.train_utils -   [GQA]: iter 5600 Ep: 0.19 loss 2.544 score 0.000 lr 4.68644e-07 
12/05/2021 01:17:58 - INFO - volta.train_utils -   [GQA]: iter 5760 Ep: 0.20 loss 2.302 score 0.002 lr 4.82218e-07 
12/05/2021 01:19:43 - INFO - volta.train_utils -   [GQA]: iter 5920 Ep: 0.20 loss 2.082 score 0.006 lr 4.95792e-07 
12/05/2021 01:21:29 - INFO - volta.train_utils -   [GQA]: iter 6080 Ep: 0.21 loss 1.827 score 0.012 lr 5.09366e-07 
12/05/2021 01:23:15 - INFO - volta.train_utils -   [GQA]: iter 6240 Ep: 0.21 loss 1.595 score 0.015 lr 5.2294e-07 
12/05/2021 01:25:01 - INFO - volta.train_utils -   [GQA]: iter 6400 Ep: 0.22 loss 1.392 score 0.019 lr 5.36514e-07 
12/05/2021 01:26:47 - INFO - volta.train_utils -   [GQA]: iter 6560 Ep: 0.22 loss 1.198 score 0.022 lr 5.50088e-07 
12/05/2021 01:28:32 - INFO - volta.train_utils -   [GQA]: iter 6720 Ep: 0.23 loss 1.029 score 0.021 lr 5.63662e-07 
12/05/2021 01:30:18 - INFO - volta.train_utils -   [GQA]: iter 6880 Ep: 0.23 loss 0.886 score 0.023 lr 5.77236e-07 
12/05/2021 01:32:04 - INFO - volta.train_utils -   [GQA]: iter 7040 Ep: 0.24 loss 0.765 score 0.023 lr 5.9081e-07 
12/05/2021 01:33:49 - INFO - volta.train_utils -   [GQA]: iter 7200 Ep: 0.24 loss 0.662 score 0.020 lr 6.04384e-07 
12/05/2021 01:35:35 - INFO - volta.train_utils -   [GQA]: iter 7360 Ep: 0.25 loss 0.568 score 0.022 lr 6.17958e-07 
12/05/2021 01:37:21 - INFO - volta.train_utils -   [GQA]: iter 7520 Ep: 0.26 loss 0.489 score 0.021 lr 6.31533e-07 
12/05/2021 01:39:07 - INFO - volta.train_utils -   [GQA]: iter 7680 Ep: 0.26 loss 0.421 score 0.023 lr 6.45107e-07 
12/05/2021 01:40:52 - INFO - volta.train_utils -   [GQA]: iter 7840 Ep: 0.27 loss 0.368 score 0.021 lr 6.58681e-07 
12/05/2021 01:42:38 - INFO - volta.train_utils -   [GQA]: iter 8000 Ep: 0.27 loss 0.321 score 0.022 lr 6.72255e-07 
12/05/2021 01:44:24 - INFO - volta.train_utils -   [GQA]: iter 8160 Ep: 0.28 loss 0.279 score 0.022 lr 6.85829e-07 
12/05/2021 01:46:10 - INFO - volta.train_utils -   [GQA]: iter 8320 Ep: 0.28 loss 0.244 score 0.022 lr 6.99403e-07 
12/05/2021 01:47:55 - INFO - volta.train_utils -   [GQA]: iter 8480 Ep: 0.29 loss 0.216 score 0.021 lr 7.12977e-07 
12/05/2021 01:49:41 - INFO - volta.train_utils -   [GQA]: iter 8640 Ep: 0.29 loss 0.193 score 0.022 lr 7.26551e-07 
12/05/2021 01:51:27 - INFO - volta.train_utils -   [GQA]: iter 8800 Ep: 0.30 loss 0.178 score 0.023 lr 7.40125e-07 
12/05/2021 01:53:13 - INFO - volta.train_utils -   [GQA]: iter 8960 Ep: 0.30 loss 0.162 score 0.022 lr 7.53699e-07 
12/05/2021 01:54:59 - INFO - volta.train_utils -   [GQA]: iter 9120 Ep: 0.31 loss 0.149 score 0.022 lr 7.67273e-07 
12/05/2021 01:56:45 - INFO - volta.train_utils -   [GQA]: iter 9280 Ep: 0.31 loss 0.139 score 0.022 lr 7.80847e-07 
12/05/2021 01:58:30 - INFO - volta.train_utils -   [GQA]: iter 9440 Ep: 0.32 loss 0.128 score 0.022 lr 7.94421e-07 
12/05/2021 02:00:16 - INFO - volta.train_utils -   [GQA]: iter 9600 Ep: 0.33 loss 0.118 score 0.026 lr 8.07995e-07 
12/05/2021 02:02:02 - INFO - volta.train_utils -   [GQA]: iter 9760 Ep: 0.33 loss 0.115 score 0.027 lr 8.21569e-07 
12/05/2021 02:03:48 - INFO - volta.train_utils -   [GQA]: iter 9920 Ep: 0.34 loss 0.109 score 0.029 lr 8.35143e-07 
12/05/2021 02:05:34 - INFO - volta.train_utils -   [GQA]: iter 10080 Ep: 0.34 loss 0.102 score 0.029 lr 8.48717e-07 
12/05/2021 02:07:20 - INFO - volta.train_utils -   [GQA]: iter 10240 Ep: 0.35 loss 0.101 score 0.026 lr 8.62291e-07 
12/05/2021 02:09:06 - INFO - volta.train_utils -   [GQA]: iter 10400 Ep: 0.35 loss 0.096 score 0.029 lr 8.75865e-07 
12/05/2021 02:10:52 - INFO - volta.train_utils -   [GQA]: iter 10560 Ep: 0.36 loss 0.092 score 0.028 lr 8.89439e-07 
12/05/2021 02:12:38 - INFO - volta.train_utils -   [GQA]: iter 10720 Ep: 0.36 loss 0.092 score 0.028 lr 9.03013e-07 
12/05/2021 02:14:23 - INFO - volta.train_utils -   [GQA]: iter 10880 Ep: 0.37 loss 0.087 score 0.031 lr 9.16587e-07 
12/05/2021 02:16:09 - INFO - volta.train_utils -   [GQA]: iter 11040 Ep: 0.37 loss 0.087 score 0.029 lr 9.30162e-07 
12/05/2021 02:17:55 - INFO - volta.train_utils -   [GQA]: iter 11200 Ep: 0.38 loss 0.084 score 0.029 lr 9.43736e-07 
12/05/2021 02:19:41 - INFO - volta.train_utils -   [GQA]: iter 11360 Ep: 0.39 loss 0.085 score 0.030 lr 9.5731e-07 
12/05/2021 02:21:26 - INFO - volta.train_utils -   [GQA]: iter 11520 Ep: 0.39 loss 0.083 score 0.030 lr 9.70884e-07 
12/05/2021 02:23:12 - INFO - volta.train_utils -   [GQA]: iter 11680 Ep: 0.40 loss 0.085 score 0.030 lr 9.84458e-07 
12/05/2021 02:24:58 - INFO - volta.train_utils -   [GQA]: iter 11840 Ep: 0.40 loss 0.080 score 0.031 lr 9.98032e-07 
12/05/2021 02:26:44 - INFO - volta.train_utils -   [GQA]: iter 12000 Ep: 0.41 loss 0.076 score 0.034 lr 1.01161e-06 
12/05/2021 02:28:30 - INFO - volta.train_utils -   [GQA]: iter 12160 Ep: 0.41 loss 0.081 score 0.032 lr 1.02518e-06 
12/05/2021 02:30:15 - INFO - volta.train_utils -   [GQA]: iter 12320 Ep: 0.42 loss 0.076 score 0.036 lr 1.03875e-06 
12/05/2021 02:32:01 - INFO - volta.train_utils -   [GQA]: iter 12480 Ep: 0.42 loss 0.077 score 0.034 lr 1.05233e-06 
12/05/2021 02:33:47 - INFO - volta.train_utils -   [GQA]: iter 12640 Ep: 0.43 loss 0.078 score 0.033 lr 1.0659e-06 
12/05/2021 02:35:33 - INFO - volta.train_utils -   [GQA]: iter 12800 Ep: 0.43 loss 0.077 score 0.034 lr 1.07948e-06 
12/05/2021 02:37:19 - INFO - volta.train_utils -   [GQA]: iter 12960 Ep: 0.44 loss 0.073 score 0.034 lr 1.09305e-06 
12/05/2021 02:39:04 - INFO - volta.train_utils -   [GQA]: iter 13120 Ep: 0.45 loss 0.075 score 0.036 lr 1.10662e-06 
12/05/2021 02:40:50 - INFO - volta.train_utils -   [GQA]: iter 13280 Ep: 0.45 loss 0.074 score 0.035 lr 1.1202e-06 
12/05/2021 02:42:36 - INFO - volta.train_utils -   [GQA]: iter 13440 Ep: 0.46 loss 0.072 score 0.036 lr 1.13377e-06 
12/05/2021 02:44:21 - INFO - volta.train_utils -   [GQA]: iter 13600 Ep: 0.46 loss 0.072 score 0.037 lr 1.14735e-06 
12/05/2021 02:46:08 - INFO - volta.train_utils -   [GQA]: iter 13760 Ep: 0.47 loss 0.070 score 0.037 lr 1.16092e-06 
12/05/2021 02:47:53 - INFO - volta.train_utils -   [GQA]: iter 13920 Ep: 0.47 loss 0.069 score 0.037 lr 1.17449e-06 
12/05/2021 02:49:39 - INFO - volta.train_utils -   [GQA]: iter 14080 Ep: 0.48 loss 0.067 score 0.036 lr 1.18807e-06 
12/05/2021 02:51:25 - INFO - volta.train_utils -   [GQA]: iter 14240 Ep: 0.48 loss 0.067 score 0.038 lr 1.20164e-06 
12/05/2021 02:53:11 - INFO - volta.train_utils -   [GQA]: iter 14400 Ep: 0.49 loss 0.065 score 0.039 lr 1.21522e-06 
12/05/2021 02:54:57 - INFO - volta.train_utils -   [GQA]: iter 14560 Ep: 0.49 loss 0.063 score 0.039 lr 1.22879e-06 
12/05/2021 02:56:43 - INFO - volta.train_utils -   [GQA]: iter 14720 Ep: 0.50 loss 0.062 score 0.039 lr 1.24236e-06 
12/05/2021 02:58:29 - INFO - volta.train_utils -   [GQA]: iter 14880 Ep: 0.50 loss 0.067 score 0.037 lr 1.25594e-06 
12/05/2021 03:00:14 - INFO - volta.train_utils -   [GQA]: iter 15040 Ep: 0.51 loss 0.063 score 0.040 lr 1.26951e-06 
12/05/2021 03:02:00 - INFO - volta.train_utils -   [GQA]: iter 15200 Ep: 0.52 loss 0.064 score 0.039 lr 1.28309e-06 
12/05/2021 03:03:46 - INFO - volta.train_utils -   [GQA]: iter 15360 Ep: 0.52 loss 0.060 score 0.041 lr 1.29666e-06 
12/05/2021 03:05:32 - INFO - volta.train_utils -   [GQA]: iter 15520 Ep: 0.53 loss 0.061 score 0.041 lr 1.31023e-06 
12/05/2021 03:07:17 - INFO - volta.train_utils -   [GQA]: iter 15680 Ep: 0.53 loss 0.062 score 0.039 lr 1.32381e-06 
12/05/2021 03:09:03 - INFO - volta.train_utils -   [GQA]: iter 15840 Ep: 0.54 loss 0.060 score 0.041 lr 1.33738e-06 
12/05/2021 03:10:49 - INFO - volta.train_utils -   [GQA]: iter 16000 Ep: 0.54 loss 0.063 score 0.041 lr 1.35096e-06 
12/05/2021 03:12:35 - INFO - volta.train_utils -   [GQA]: iter 16160 Ep: 0.55 loss 0.059 score 0.041 lr 1.36453e-06 
12/05/2021 03:14:21 - INFO - volta.train_utils -   [GQA]: iter 16320 Ep: 0.55 loss 0.060 score 0.042 lr 1.37811e-06 
12/05/2021 03:16:07 - INFO - volta.train_utils -   [GQA]: iter 16480 Ep: 0.56 loss 0.059 score 0.041 lr 1.39168e-06 
12/05/2021 03:17:52 - INFO - volta.train_utils -   [GQA]: iter 16640 Ep: 0.56 loss 0.061 score 0.044 lr 1.40525e-06 
12/05/2021 03:19:38 - INFO - volta.train_utils -   [GQA]: iter 16800 Ep: 0.57 loss 0.059 score 0.040 lr 1.41883e-06 
12/05/2021 03:21:24 - INFO - volta.train_utils -   [GQA]: iter 16960 Ep: 0.58 loss 0.059 score 0.040 lr 1.4324e-06 
12/05/2021 03:23:10 - INFO - volta.train_utils -   [GQA]: iter 17120 Ep: 0.58 loss 0.055 score 0.042 lr 1.44598e-06 
12/05/2021 03:24:56 - INFO - volta.train_utils -   [GQA]: iter 17280 Ep: 0.59 loss 0.059 score 0.043 lr 1.45955e-06 
12/05/2021 03:26:41 - INFO - volta.train_utils -   [GQA]: iter 17440 Ep: 0.59 loss 0.055 score 0.044 lr 1.47312e-06 
12/05/2021 03:28:27 - INFO - volta.train_utils -   [GQA]: iter 17600 Ep: 0.60 loss 0.058 score 0.042 lr 1.4867e-06 
12/05/2021 03:30:13 - INFO - volta.train_utils -   [GQA]: iter 17760 Ep: 0.60 loss 0.053 score 0.043 lr 1.50027e-06 
12/05/2021 03:31:59 - INFO - volta.train_utils -   [GQA]: iter 17920 Ep: 0.61 loss 0.057 score 0.040 lr 1.51385e-06 
12/05/2021 03:33:45 - INFO - volta.train_utils -   [GQA]: iter 18080 Ep: 0.61 loss 0.053 score 0.044 lr 1.52742e-06 
12/05/2021 03:35:30 - INFO - volta.train_utils -   [GQA]: iter 18240 Ep: 0.62 loss 0.056 score 0.043 lr 1.54099e-06 
12/05/2021 03:37:16 - INFO - volta.train_utils -   [GQA]: iter 18400 Ep: 0.62 loss 0.055 score 0.043 lr 1.55457e-06 
12/05/2021 03:39:02 - INFO - volta.train_utils -   [GQA]: iter 18560 Ep: 0.63 loss 0.056 score 0.044 lr 1.56814e-06 
12/05/2021 03:40:48 - INFO - volta.train_utils -   [GQA]: iter 18720 Ep: 0.64 loss 0.053 score 0.045 lr 1.58172e-06 
12/05/2021 03:42:34 - INFO - volta.train_utils -   [GQA]: iter 18880 Ep: 0.64 loss 0.053 score 0.042 lr 1.59529e-06 
12/05/2021 03:44:19 - INFO - volta.train_utils -   [GQA]: iter 19040 Ep: 0.65 loss 0.053 score 0.044 lr 1.60886e-06 
12/05/2021 03:46:05 - INFO - volta.train_utils -   [GQA]: iter 19200 Ep: 0.65 loss 0.052 score 0.046 lr 1.62244e-06 
12/05/2021 03:47:51 - INFO - volta.train_utils -   [GQA]: iter 19360 Ep: 0.66 loss 0.054 score 0.045 lr 1.63601e-06 
12/05/2021 03:49:37 - INFO - volta.train_utils -   [GQA]: iter 19520 Ep: 0.66 loss 0.054 score 0.045 lr 1.64959e-06 
12/05/2021 03:51:23 - INFO - volta.train_utils -   [GQA]: iter 19680 Ep: 0.67 loss 0.054 score 0.043 lr 1.66316e-06 
12/05/2021 03:53:09 - INFO - volta.train_utils -   [GQA]: iter 19840 Ep: 0.67 loss 0.051 score 0.044 lr 1.67673e-06 
12/05/2021 03:54:55 - INFO - volta.train_utils -   [GQA]: iter 20000 Ep: 0.68 loss 0.052 score 0.045 lr 1.69031e-06 
12/05/2021 03:56:40 - INFO - volta.train_utils -   [GQA]: iter 20160 Ep: 0.68 loss 0.052 score 0.048 lr 1.70388e-06 
12/05/2021 03:58:26 - INFO - volta.train_utils -   [GQA]: iter 20320 Ep: 0.69 loss 0.051 score 0.046 lr 1.71746e-06 
12/05/2021 04:00:12 - INFO - volta.train_utils -   [GQA]: iter 20480 Ep: 0.69 loss 0.053 score 0.046 lr 1.73103e-06 
12/05/2021 04:01:58 - INFO - volta.train_utils -   [GQA]: iter 20640 Ep: 0.70 loss 0.049 score 0.047 lr 1.7446e-06 
12/05/2021 04:03:44 - INFO - volta.train_utils -   [GQA]: iter 20800 Ep: 0.71 loss 0.051 score 0.046 lr 1.75818e-06 
12/05/2021 04:05:30 - INFO - volta.train_utils -   [GQA]: iter 20960 Ep: 0.71 loss 0.049 score 0.048 lr 1.77175e-06 
12/05/2021 04:07:15 - INFO - volta.train_utils -   [GQA]: iter 21120 Ep: 0.72 loss 0.050 score 0.046 lr 1.78533e-06 
12/05/2021 04:09:01 - INFO - volta.train_utils -   [GQA]: iter 21280 Ep: 0.72 loss 0.051 score 0.046 lr 1.7989e-06 
12/05/2021 04:10:47 - INFO - volta.train_utils -   [GQA]: iter 21440 Ep: 0.73 loss 0.050 score 0.047 lr 1.81247e-06 
12/05/2021 04:12:33 - INFO - volta.train_utils -   [GQA]: iter 21600 Ep: 0.73 loss 0.052 score 0.047 lr 1.82605e-06 
12/05/2021 04:14:19 - INFO - volta.train_utils -   [GQA]: iter 21760 Ep: 0.74 loss 0.052 score 0.047 lr 1.83962e-06 
12/05/2021 04:16:05 - INFO - volta.train_utils -   [GQA]: iter 21920 Ep: 0.74 loss 0.050 score 0.049 lr 1.8532e-06 
12/05/2021 04:17:51 - INFO - volta.train_utils -   [GQA]: iter 22080 Ep: 0.75 loss 0.048 score 0.047 lr 1.86677e-06 
12/05/2021 04:19:36 - INFO - volta.train_utils -   [GQA]: iter 22240 Ep: 0.75 loss 0.049 score 0.049 lr 1.88034e-06 
12/05/2021 04:21:22 - INFO - volta.train_utils -   [GQA]: iter 22400 Ep: 0.76 loss 0.050 score 0.048 lr 1.89392e-06 
12/05/2021 04:23:08 - INFO - volta.train_utils -   [GQA]: iter 22560 Ep: 0.77 loss 0.047 score 0.052 lr 1.90749e-06 
12/05/2021 04:24:54 - INFO - volta.train_utils -   [GQA]: iter 22720 Ep: 0.77 loss 0.049 score 0.048 lr 1.92107e-06 
12/05/2021 04:26:40 - INFO - volta.train_utils -   [GQA]: iter 22880 Ep: 0.78 loss 0.047 score 0.051 lr 1.93464e-06 
12/05/2021 04:28:26 - INFO - volta.train_utils -   [GQA]: iter 23040 Ep: 0.78 loss 0.048 score 0.050 lr 1.94822e-06 
12/05/2021 04:30:12 - INFO - volta.train_utils -   [GQA]: iter 23200 Ep: 0.79 loss 0.052 score 0.049 lr 1.96179e-06 
12/05/2021 04:31:58 - INFO - volta.train_utils -   [GQA]: iter 23360 Ep: 0.79 loss 0.049 score 0.049 lr 1.97536e-06 
12/05/2021 04:33:44 - INFO - volta.train_utils -   [GQA]: iter 23520 Ep: 0.80 loss 0.046 score 0.050 lr 1.98894e-06 
12/05/2021 04:35:29 - INFO - volta.train_utils -   [GQA]: iter 23680 Ep: 0.80 loss 0.049 score 0.051 lr 2.00251e-06 
12/05/2021 04:37:15 - INFO - volta.train_utils -   [GQA]: iter 23840 Ep: 0.81 loss 0.047 score 0.051 lr 2.01609e-06 
12/05/2021 04:39:01 - INFO - volta.train_utils -   [GQA]: iter 24000 Ep: 0.81 loss 0.049 score 0.050 lr 2.02966e-06 
12/05/2021 04:40:47 - INFO - volta.train_utils -   [GQA]: iter 24160 Ep: 0.82 loss 0.045 score 0.052 lr 2.04323e-06 
12/05/2021 04:42:33 - INFO - volta.train_utils -   [GQA]: iter 24320 Ep: 0.83 loss 0.047 score 0.051 lr 2.05681e-06 
12/05/2021 04:44:19 - INFO - volta.train_utils -   [GQA]: iter 24480 Ep: 0.83 loss 0.047 score 0.051 lr 2.07038e-06 
12/05/2021 04:46:04 - INFO - volta.train_utils -   [GQA]: iter 24640 Ep: 0.84 loss 0.048 score 0.050 lr 2.08396e-06 
12/05/2021 04:47:50 - INFO - volta.train_utils -   [GQA]: iter 24800 Ep: 0.84 loss 0.047 score 0.051 lr 2.09753e-06 
12/05/2021 04:49:36 - INFO - volta.train_utils -   [GQA]: iter 24960 Ep: 0.85 loss 0.045 score 0.051 lr 2.1111e-06 
12/05/2021 04:51:22 - INFO - volta.train_utils -   [GQA]: iter 25120 Ep: 0.85 loss 0.046 score 0.052 lr 2.12468e-06 
12/05/2021 04:53:08 - INFO - volta.train_utils -   [GQA]: iter 25280 Ep: 0.86 loss 0.045 score 0.055 lr 2.13825e-06 
12/05/2021 04:54:54 - INFO - volta.train_utils -   [GQA]: iter 25440 Ep: 0.86 loss 0.047 score 0.053 lr 2.15183e-06 
12/05/2021 04:56:39 - INFO - volta.train_utils -   [GQA]: iter 25600 Ep: 0.87 loss 0.045 score 0.053 lr 2.1654e-06 
12/05/2021 04:58:25 - INFO - volta.train_utils -   [GQA]: iter 25760 Ep: 0.87 loss 0.046 score 0.054 lr 2.17897e-06 
12/05/2021 05:00:11 - INFO - volta.train_utils -   [GQA]: iter 25920 Ep: 0.88 loss 0.047 score 0.054 lr 2.19255e-06 
12/05/2021 05:01:57 - INFO - volta.train_utils -   [GQA]: iter 26080 Ep: 0.89 loss 0.042 score 0.056 lr 2.20612e-06 
12/05/2021 05:03:43 - INFO - volta.train_utils -   [GQA]: iter 26240 Ep: 0.89 loss 0.045 score 0.056 lr 2.2197e-06 
12/05/2021 05:05:29 - INFO - volta.train_utils -   [GQA]: iter 26400 Ep: 0.90 loss 0.043 score 0.055 lr 2.23327e-06 
12/05/2021 05:07:15 - INFO - volta.train_utils -   [GQA]: iter 26560 Ep: 0.90 loss 0.043 score 0.054 lr 2.24684e-06 
12/05/2021 05:09:00 - INFO - volta.train_utils -   [GQA]: iter 26720 Ep: 0.91 loss 0.046 score 0.055 lr 2.26042e-06 
12/05/2021 05:10:46 - INFO - volta.train_utils -   [GQA]: iter 26880 Ep: 0.91 loss 0.045 score 0.055 lr 2.27399e-06 
12/05/2021 05:12:32 - INFO - volta.train_utils -   [GQA]: iter 27040 Ep: 0.92 loss 0.042 score 0.056 lr 2.28757e-06 
12/05/2021 05:14:18 - INFO - volta.train_utils -   [GQA]: iter 27200 Ep: 0.92 loss 0.042 score 0.058 lr 2.30114e-06 
12/05/2021 05:16:04 - INFO - volta.train_utils -   [GQA]: iter 27360 Ep: 0.93 loss 0.043 score 0.055 lr 2.31471e-06 
12/05/2021 05:17:50 - INFO - volta.train_utils -   [GQA]: iter 27520 Ep: 0.93 loss 0.045 score 0.055 lr 2.32829e-06 
12/05/2021 05:19:35 - INFO - volta.train_utils -   [GQA]: iter 27680 Ep: 0.94 loss 0.043 score 0.058 lr 2.34186e-06 
12/05/2021 05:21:21 - INFO - volta.train_utils -   [GQA]: iter 27840 Ep: 0.94 loss 0.043 score 0.055 lr 2.35544e-06 
12/05/2021 05:23:07 - INFO - volta.train_utils -   [GQA]: iter 28000 Ep: 0.95 loss 0.038 score 0.060 lr 2.36901e-06 
12/05/2021 05:24:53 - INFO - volta.train_utils -   [GQA]: iter 28160 Ep: 0.96 loss 0.044 score 0.058 lr 2.38258e-06 
12/05/2021 05:26:39 - INFO - volta.train_utils -   [GQA]: iter 28320 Ep: 0.96 loss 0.043 score 0.059 lr 2.39616e-06 
12/05/2021 05:28:25 - INFO - volta.train_utils -   [GQA]: iter 28480 Ep: 0.97 loss 0.043 score 0.058 lr 2.40973e-06 
12/05/2021 05:30:11 - INFO - volta.train_utils -   [GQA]: iter 28640 Ep: 0.97 loss 0.042 score 0.060 lr 2.42331e-06 
12/05/2021 05:31:57 - INFO - volta.train_utils -   [GQA]: iter 28800 Ep: 0.98 loss 0.042 score 0.059 lr 2.43688e-06 
12/05/2021 05:33:42 - INFO - volta.train_utils -   [GQA]: iter 28960 Ep: 0.98 loss 0.038 score 0.060 lr 2.45045e-06 
12/05/2021 05:35:28 - INFO - volta.train_utils -   [GQA]: iter 29120 Ep: 0.99 loss 0.039 score 0.062 lr 2.46403e-06 
12/05/2021 05:37:14 - INFO - volta.train_utils -   [GQA]: iter 29280 Ep: 0.99 loss 0.040 score 0.062 lr 2.4776e-06 
12/05/2021 05:39:00 - INFO - volta.train_utils -   [GQA]: iter 29440 Ep: 1.00 loss 0.038 score 0.065 lr 2.49118e-06 
12/05/2021 06:24:19 - INFO - volta.train_utils -   Eval task TASK15 on iteration 29464 
12/05/2021 06:24:19 - INFO - volta.train_utils -   Validation [GQA]: loss 2.770 score 43.951 
12/05/2021 06:24:19 - INFO - __main__ -   ** ** * Saving model * ** ** 
Epoch:  20%|██        | 1/5 [6:10:11<24:40:45, 22211.42s/it]12/05/2021 06:26:27 - INFO - volta.train_utils -   [GQA]: iter 29624 Ep: 1.01 loss 0.046 score 0.056 lr 2.50577e-06 
12/05/2021 06:28:13 - INFO - volta.train_utils -   [GQA]: iter 29784 Ep: 1.01 loss 0.045 score 0.056 lr 2.52036e-06 
12/05/2021 06:29:58 - INFO - volta.train_utils -   [GQA]: iter 29944 Ep: 1.02 loss 0.046 score 0.054 lr 2.53394e-06 
12/05/2021 06:31:44 - INFO - volta.train_utils -   [GQA]: iter 30104 Ep: 1.02 loss 0.044 score 0.053 lr 2.54751e-06 
12/05/2021 06:33:30 - INFO - volta.train_utils -   [GQA]: iter 30264 Ep: 1.03 loss 0.046 score 0.053 lr 2.56108e-06 
12/05/2021 06:35:15 - INFO - volta.train_utils -   [GQA]: iter 30424 Ep: 1.03 loss 0.042 score 0.054 lr 2.57466e-06 
12/05/2021 06:37:02 - INFO - volta.train_utils -   [GQA]: iter 30584 Ep: 1.04 loss 0.045 score 0.053 lr 2.58823e-06 
12/05/2021 06:38:47 - INFO - volta.train_utils -   [GQA]: iter 30744 Ep: 1.04 loss 0.045 score 0.055 lr 2.60181e-06 
12/05/2021 06:40:33 - INFO - volta.train_utils -   [GQA]: iter 30904 Ep: 1.05 loss 0.044 score 0.054 lr 2.61538e-06 
12/05/2021 06:42:19 - INFO - volta.train_utils -   [GQA]: iter 31064 Ep: 1.05 loss 0.042 score 0.056 lr 2.62895e-06 
12/05/2021 06:44:05 - INFO - volta.train_utils -   [GQA]: iter 31224 Ep: 1.06 loss 0.046 score 0.056 lr 2.64253e-06 
12/05/2021 06:45:51 - INFO - volta.train_utils -   [GQA]: iter 31384 Ep: 1.07 loss 0.041 score 0.054 lr 2.6561e-06 
12/05/2021 06:47:36 - INFO - volta.train_utils -   [GQA]: iter 31544 Ep: 1.07 loss 0.046 score 0.054 lr 2.66968e-06 
12/05/2021 06:49:23 - INFO - volta.train_utils -   [GQA]: iter 31704 Ep: 1.08 loss 0.042 score 0.057 lr 2.68325e-06 
12/05/2021 06:51:08 - INFO - volta.train_utils -   [GQA]: iter 31864 Ep: 1.08 loss 0.043 score 0.056 lr 2.69682e-06 
12/05/2021 06:52:54 - INFO - volta.train_utils -   [GQA]: iter 32024 Ep: 1.09 loss 0.043 score 0.057 lr 2.7104e-06 
12/05/2021 06:54:40 - INFO - volta.train_utils -   [GQA]: iter 32184 Ep: 1.09 loss 0.043 score 0.056 lr 2.72397e-06 
12/05/2021 06:56:26 - INFO - volta.train_utils -   [GQA]: iter 32344 Ep: 1.10 loss 0.044 score 0.055 lr 2.73755e-06 
12/05/2021 06:58:12 - INFO - volta.train_utils -   [GQA]: iter 32504 Ep: 1.10 loss 0.042 score 0.058 lr 2.75112e-06 
12/05/2021 06:59:58 - INFO - volta.train_utils -   [GQA]: iter 32664 Ep: 1.11 loss 0.043 score 0.056 lr 2.76469e-06 
12/05/2021 07:01:44 - INFO - volta.train_utils -   [GQA]: iter 32824 Ep: 1.11 loss 0.043 score 0.054 lr 2.77827e-06 
12/05/2021 07:03:29 - INFO - volta.train_utils -   [GQA]: iter 32984 Ep: 1.12 loss 0.041 score 0.055 lr 2.79184e-06 
12/05/2021 07:05:15 - INFO - volta.train_utils -   [GQA]: iter 33144 Ep: 1.12 loss 0.046 score 0.055 lr 2.80542e-06 
12/05/2021 07:07:01 - INFO - volta.train_utils -   [GQA]: iter 33304 Ep: 1.13 loss 0.040 score 0.055 lr 2.81899e-06 
12/05/2021 07:08:47 - INFO - volta.train_utils -   [GQA]: iter 33464 Ep: 1.14 loss 0.046 score 0.054 lr 2.83256e-06 
12/05/2021 07:10:33 - INFO - volta.train_utils -   [GQA]: iter 33624 Ep: 1.14 loss 0.042 score 0.058 lr 2.84614e-06 
12/05/2021 07:12:19 - INFO - volta.train_utils -   [GQA]: iter 33784 Ep: 1.15 loss 0.046 score 0.058 lr 2.85971e-06 
12/05/2021 07:14:04 - INFO - volta.train_utils -   [GQA]: iter 33944 Ep: 1.15 loss 0.039 score 0.058 lr 2.87329e-06 
12/05/2021 07:15:50 - INFO - volta.train_utils -   [GQA]: iter 34104 Ep: 1.16 loss 0.044 score 0.055 lr 2.88686e-06 
12/05/2021 07:17:36 - INFO - volta.train_utils -   [GQA]: iter 34264 Ep: 1.16 loss 0.041 score 0.058 lr 2.90043e-06 
12/05/2021 07:19:22 - INFO - volta.train_utils -   [GQA]: iter 34424 Ep: 1.17 loss 0.042 score 0.057 lr 2.91401e-06 
12/05/2021 07:21:08 - INFO - volta.train_utils -   [GQA]: iter 34584 Ep: 1.17 loss 0.040 score 0.057 lr 2.92758e-06 
12/05/2021 07:22:54 - INFO - volta.train_utils -   [GQA]: iter 34744 Ep: 1.18 loss 0.043 score 0.055 lr 2.94116e-06 
12/05/2021 07:24:40 - INFO - volta.train_utils -   [GQA]: iter 34904 Ep: 1.18 loss 0.041 score 0.055 lr 2.95473e-06 
12/05/2021 07:26:25 - INFO - volta.train_utils -   [GQA]: iter 35064 Ep: 1.19 loss 0.042 score 0.058 lr 2.9683e-06 
12/05/2021 07:28:12 - INFO - volta.train_utils -   [GQA]: iter 35224 Ep: 1.20 loss 0.042 score 0.058 lr 2.98188e-06 
12/05/2021 07:29:57 - INFO - volta.train_utils -   [GQA]: iter 35384 Ep: 1.20 loss 0.041 score 0.058 lr 2.99545e-06 
12/05/2021 07:31:43 - INFO - volta.train_utils -   [GQA]: iter 35544 Ep: 1.21 loss 0.039 score 0.058 lr 3.00903e-06 
12/05/2021 07:33:29 - INFO - volta.train_utils -   [GQA]: iter 35704 Ep: 1.21 loss 0.043 score 0.057 lr 3.0226e-06 
12/05/2021 07:35:15 - INFO - volta.train_utils -   [GQA]: iter 35864 Ep: 1.22 loss 0.043 score 0.056 lr 3.03617e-06 
12/05/2021 07:37:01 - INFO - volta.train_utils -   [GQA]: iter 36024 Ep: 1.22 loss 0.044 score 0.059 lr 3.04975e-06 
12/05/2021 07:38:47 - INFO - volta.train_utils -   [GQA]: iter 36184 Ep: 1.23 loss 0.043 score 0.057 lr 3.06332e-06 
12/05/2021 07:40:33 - INFO - volta.train_utils -   [GQA]: iter 36344 Ep: 1.23 loss 0.039 score 0.061 lr 3.0769e-06 
12/05/2021 07:42:18 - INFO - volta.train_utils -   [GQA]: iter 36504 Ep: 1.24 loss 0.042 score 0.058 lr 3.09047e-06 
12/05/2021 07:44:04 - INFO - volta.train_utils -   [GQA]: iter 36664 Ep: 1.24 loss 0.041 score 0.058 lr 3.10405e-06 
12/05/2021 07:45:50 - INFO - volta.train_utils -   [GQA]: iter 36824 Ep: 1.25 loss 0.040 score 0.058 lr 3.11762e-06 
12/05/2021 07:47:36 - INFO - volta.train_utils -   [GQA]: iter 36984 Ep: 1.26 loss 0.040 score 0.060 lr 3.13119e-06 
12/05/2021 07:49:22 - INFO - volta.train_utils -   [GQA]: iter 37144 Ep: 1.26 loss 0.044 score 0.057 lr 3.14477e-06 
12/05/2021 07:51:08 - INFO - volta.train_utils -   [GQA]: iter 37304 Ep: 1.27 loss 0.044 score 0.057 lr 3.15834e-06 
12/05/2021 07:52:53 - INFO - volta.train_utils -   [GQA]: iter 37464 Ep: 1.27 loss 0.043 score 0.057 lr 3.17192e-06 
12/05/2021 07:54:39 - INFO - volta.train_utils -   [GQA]: iter 37624 Ep: 1.28 loss 0.041 score 0.059 lr 3.18549e-06 
12/05/2021 07:56:25 - INFO - volta.train_utils -   [GQA]: iter 37784 Ep: 1.28 loss 0.040 score 0.059 lr 3.19906e-06 
12/05/2021 07:58:11 - INFO - volta.train_utils -   [GQA]: iter 37944 Ep: 1.29 loss 0.040 score 0.058 lr 3.21264e-06 
12/05/2021 07:59:57 - INFO - volta.train_utils -   [GQA]: iter 38104 Ep: 1.29 loss 0.039 score 0.059 lr 3.22621e-06 
12/05/2021 08:01:43 - INFO - volta.train_utils -   [GQA]: iter 38264 Ep: 1.30 loss 0.041 score 0.059 lr 3.23979e-06 
12/05/2021 08:03:29 - INFO - volta.train_utils -   [GQA]: iter 38424 Ep: 1.30 loss 0.044 score 0.056 lr 3.25336e-06 
12/05/2021 08:05:15 - INFO - volta.train_utils -   [GQA]: iter 38584 Ep: 1.31 loss 0.041 score 0.061 lr 3.26693e-06 
12/05/2021 08:07:01 - INFO - volta.train_utils -   [GQA]: iter 38744 Ep: 1.31 loss 0.037 score 0.060 lr 3.28051e-06 
12/05/2021 08:08:47 - INFO - volta.train_utils -   [GQA]: iter 38904 Ep: 1.32 loss 0.042 score 0.059 lr 3.29408e-06 
12/05/2021 08:10:32 - INFO - volta.train_utils -   [GQA]: iter 39064 Ep: 1.33 loss 0.040 score 0.060 lr 3.30766e-06 
12/05/2021 08:12:18 - INFO - volta.train_utils -   [GQA]: iter 39224 Ep: 1.33 loss 0.040 score 0.058 lr 3.32123e-06 
12/05/2021 08:14:04 - INFO - volta.train_utils -   [GQA]: iter 39384 Ep: 1.34 loss 0.041 score 0.061 lr 3.3348e-06 
12/05/2021 08:15:50 - INFO - volta.train_utils -   [GQA]: iter 39544 Ep: 1.34 loss 0.038 score 0.059 lr 3.34838e-06 
12/05/2021 08:17:36 - INFO - volta.train_utils -   [GQA]: iter 39704 Ep: 1.35 loss 0.042 score 0.057 lr 3.36195e-06 
12/05/2021 08:19:22 - INFO - volta.train_utils -   [GQA]: iter 39864 Ep: 1.35 loss 0.038 score 0.060 lr 3.37553e-06 
12/05/2021 08:21:08 - INFO - volta.train_utils -   [GQA]: iter 40024 Ep: 1.36 loss 0.040 score 0.060 lr 3.3891e-06 
12/05/2021 08:22:54 - INFO - volta.train_utils -   [GQA]: iter 40184 Ep: 1.36 loss 0.041 score 0.059 lr 3.40267e-06 
12/05/2021 08:24:39 - INFO - volta.train_utils -   [GQA]: iter 40344 Ep: 1.37 loss 0.038 score 0.061 lr 3.41625e-06 
12/05/2021 08:26:25 - INFO - volta.train_utils -   [GQA]: iter 40504 Ep: 1.37 loss 0.038 score 0.062 lr 3.42982e-06 
12/05/2021 08:28:11 - INFO - volta.train_utils -   [GQA]: iter 40664 Ep: 1.38 loss 0.044 score 0.060 lr 3.4434e-06 
12/05/2021 08:29:57 - INFO - volta.train_utils -   [GQA]: iter 40824 Ep: 1.39 loss 0.040 score 0.058 lr 3.45697e-06 
12/05/2021 08:31:43 - INFO - volta.train_utils -   [GQA]: iter 40984 Ep: 1.39 loss 0.040 score 0.062 lr 3.47054e-06 
12/05/2021 08:33:29 - INFO - volta.train_utils -   [GQA]: iter 41144 Ep: 1.40 loss 0.040 score 0.062 lr 3.48412e-06 
12/05/2021 08:35:15 - INFO - volta.train_utils -   [GQA]: iter 41304 Ep: 1.40 loss 0.038 score 0.062 lr 3.49769e-06 
12/05/2021 08:37:01 - INFO - volta.train_utils -   [GQA]: iter 41464 Ep: 1.41 loss 0.036 score 0.062 lr 3.51127e-06 
12/05/2021 08:38:47 - INFO - volta.train_utils -   [GQA]: iter 41624 Ep: 1.41 loss 0.039 score 0.062 lr 3.52484e-06 
12/05/2021 08:40:33 - INFO - volta.train_utils -   [GQA]: iter 41784 Ep: 1.42 loss 0.037 score 0.061 lr 3.53841e-06 
12/05/2021 08:42:18 - INFO - volta.train_utils -   [GQA]: iter 41944 Ep: 1.42 loss 0.040 score 0.061 lr 3.55199e-06 
12/05/2021 08:44:04 - INFO - volta.train_utils -   [GQA]: iter 42104 Ep: 1.43 loss 0.038 score 0.059 lr 3.56556e-06 
12/05/2021 08:45:51 - INFO - volta.train_utils -   [GQA]: iter 42264 Ep: 1.43 loss 0.036 score 0.060 lr 3.57914e-06 
12/05/2021 08:47:36 - INFO - volta.train_utils -   [GQA]: iter 42424 Ep: 1.44 loss 0.042 score 0.060 lr 3.59271e-06 
12/05/2021 08:49:22 - INFO - volta.train_utils -   [GQA]: iter 42584 Ep: 1.45 loss 0.038 score 0.064 lr 3.60628e-06 
12/05/2021 08:51:08 - INFO - volta.train_utils -   [GQA]: iter 42744 Ep: 1.45 loss 0.039 score 0.064 lr 3.61986e-06 
12/05/2021 08:52:54 - INFO - volta.train_utils -   [GQA]: iter 42904 Ep: 1.46 loss 0.039 score 0.063 lr 3.63343e-06 
12/05/2021 08:54:40 - INFO - volta.train_utils -   [GQA]: iter 43064 Ep: 1.46 loss 0.036 score 0.062 lr 3.64701e-06 
12/05/2021 08:56:26 - INFO - volta.train_utils -   [GQA]: iter 43224 Ep: 1.47 loss 0.039 score 0.062 lr 3.66058e-06 
12/05/2021 08:58:12 - INFO - volta.train_utils -   [GQA]: iter 43384 Ep: 1.47 loss 0.036 score 0.062 lr 3.67416e-06 
12/05/2021 08:59:58 - INFO - volta.train_utils -   [GQA]: iter 43544 Ep: 1.48 loss 0.038 score 0.062 lr 3.68773e-06 
12/05/2021 09:01:44 - INFO - volta.train_utils -   [GQA]: iter 43704 Ep: 1.48 loss 0.037 score 0.063 lr 3.7013e-06 
12/05/2021 09:03:30 - INFO - volta.train_utils -   [GQA]: iter 43864 Ep: 1.49 loss 0.039 score 0.061 lr 3.71488e-06 
12/05/2021 09:05:16 - INFO - volta.train_utils -   [GQA]: iter 44024 Ep: 1.49 loss 0.037 score 0.062 lr 3.72845e-06 
12/05/2021 09:07:01 - INFO - volta.train_utils -   [GQA]: iter 44184 Ep: 1.50 loss 0.039 score 0.062 lr 3.74203e-06 
12/05/2021 09:08:47 - INFO - volta.train_utils -   [GQA]: iter 44344 Ep: 1.50 loss 0.041 score 0.062 lr 3.7556e-06 
12/05/2021 09:10:33 - INFO - volta.train_utils -   [GQA]: iter 44504 Ep: 1.51 loss 0.037 score 0.062 lr 3.76917e-06 
12/05/2021 09:12:19 - INFO - volta.train_utils -   [GQA]: iter 44664 Ep: 1.52 loss 0.038 score 0.064 lr 3.78275e-06 
12/05/2021 09:14:05 - INFO - volta.train_utils -   [GQA]: iter 44824 Ep: 1.52 loss 0.036 score 0.065 lr 3.79632e-06 
12/05/2021 09:15:51 - INFO - volta.train_utils -   [GQA]: iter 44984 Ep: 1.53 loss 0.039 score 0.063 lr 3.8099e-06 
12/05/2021 09:17:37 - INFO - volta.train_utils -   [GQA]: iter 45144 Ep: 1.53 loss 0.036 score 0.064 lr 3.82347e-06 
12/05/2021 09:19:23 - INFO - volta.train_utils -   [GQA]: iter 45304 Ep: 1.54 loss 0.040 score 0.064 lr 3.83704e-06 
12/05/2021 09:21:08 - INFO - volta.train_utils -   [GQA]: iter 45464 Ep: 1.54 loss 0.035 score 0.063 lr 3.85062e-06 
12/05/2021 09:22:54 - INFO - volta.train_utils -   [GQA]: iter 45624 Ep: 1.55 loss 0.037 score 0.064 lr 3.86419e-06 
12/05/2021 09:24:40 - INFO - volta.train_utils -   [GQA]: iter 45784 Ep: 1.55 loss 0.036 score 0.064 lr 3.87777e-06 
12/05/2021 09:26:26 - INFO - volta.train_utils -   [GQA]: iter 45944 Ep: 1.56 loss 0.036 score 0.065 lr 3.89134e-06 
12/05/2021 09:28:12 - INFO - volta.train_utils -   [GQA]: iter 46104 Ep: 1.56 loss 0.037 score 0.064 lr 3.90491e-06 
12/05/2021 09:29:57 - INFO - volta.train_utils -   [GQA]: iter 46264 Ep: 1.57 loss 0.037 score 0.065 lr 3.91849e-06 
12/05/2021 09:31:43 - INFO - volta.train_utils -   [GQA]: iter 46424 Ep: 1.58 loss 0.034 score 0.065 lr 3.93206e-06 
12/05/2021 09:33:29 - INFO - volta.train_utils -   [GQA]: iter 46584 Ep: 1.58 loss 0.038 score 0.068 lr 3.94564e-06 
12/05/2021 09:35:15 - INFO - volta.train_utils -   [GQA]: iter 46744 Ep: 1.59 loss 0.036 score 0.065 lr 3.95921e-06 
12/05/2021 09:37:01 - INFO - volta.train_utils -   [GQA]: iter 46904 Ep: 1.59 loss 0.037 score 0.064 lr 3.97278e-06 
12/05/2021 09:38:47 - INFO - volta.train_utils -   [GQA]: iter 47064 Ep: 1.60 loss 0.038 score 0.065 lr 3.98636e-06 
12/05/2021 09:40:33 - INFO - volta.train_utils -   [GQA]: iter 47224 Ep: 1.60 loss 0.035 score 0.065 lr 3.99993e-06 
12/05/2021 09:42:19 - INFO - volta.train_utils -   [GQA]: iter 47384 Ep: 1.61 loss 0.036 score 0.064 lr 4.01351e-06 
12/05/2021 09:44:05 - INFO - volta.train_utils -   [GQA]: iter 47544 Ep: 1.61 loss 0.034 score 0.066 lr 4.02708e-06 
12/05/2021 09:45:50 - INFO - volta.train_utils -   [GQA]: iter 47704 Ep: 1.62 loss 0.036 score 0.067 lr 4.04065e-06 
12/05/2021 09:47:37 - INFO - volta.train_utils -   [GQA]: iter 47864 Ep: 1.62 loss 0.034 score 0.066 lr 4.05423e-06 
12/05/2021 09:49:23 - INFO - volta.train_utils -   [GQA]: iter 48024 Ep: 1.63 loss 0.035 score 0.065 lr 4.0678e-06 
12/05/2021 09:51:08 - INFO - volta.train_utils -   [GQA]: iter 48184 Ep: 1.64 loss 0.033 score 0.067 lr 4.08138e-06 
12/05/2021 09:52:54 - INFO - volta.train_utils -   [GQA]: iter 48344 Ep: 1.64 loss 0.038 score 0.067 lr 4.09495e-06 
12/05/2021 09:54:40 - INFO - volta.train_utils -   [GQA]: iter 48504 Ep: 1.65 loss 0.035 score 0.066 lr 4.10852e-06 
12/05/2021 09:56:26 - INFO - volta.train_utils -   [GQA]: iter 48664 Ep: 1.65 loss 0.035 score 0.070 lr 4.1221e-06 
12/05/2021 09:58:11 - INFO - volta.train_utils -   [GQA]: iter 48824 Ep: 1.66 loss 0.035 score 0.068 lr 4.13567e-06 
12/05/2021 09:59:57 - INFO - volta.train_utils -   [GQA]: iter 48984 Ep: 1.66 loss 0.034 score 0.069 lr 4.14925e-06 
12/05/2021 10:01:43 - INFO - volta.train_utils -   [GQA]: iter 49144 Ep: 1.67 loss 0.035 score 0.065 lr 4.16282e-06 
12/05/2021 10:03:29 - INFO - volta.train_utils -   [GQA]: iter 49304 Ep: 1.67 loss 0.033 score 0.068 lr 4.17639e-06 
12/05/2021 10:05:15 - INFO - volta.train_utils -   [GQA]: iter 49464 Ep: 1.68 loss 0.033 score 0.069 lr 4.18997e-06 
12/05/2021 10:07:01 - INFO - volta.train_utils -   [GQA]: iter 49624 Ep: 1.68 loss 0.034 score 0.069 lr 4.20354e-06 
12/05/2021 10:08:47 - INFO - volta.train_utils -   [GQA]: iter 49784 Ep: 1.69 loss 0.035 score 0.068 lr 4.21712e-06 
12/05/2021 10:10:33 - INFO - volta.train_utils -   [GQA]: iter 49944 Ep: 1.69 loss 0.034 score 0.067 lr 4.23069e-06 
12/05/2021 10:12:19 - INFO - volta.train_utils -   [GQA]: iter 50104 Ep: 1.70 loss 0.034 score 0.068 lr 4.24426e-06 
12/05/2021 10:14:05 - INFO - volta.train_utils -   [GQA]: iter 50264 Ep: 1.71 loss 0.034 score 0.069 lr 4.25784e-06 
12/05/2021 10:15:51 - INFO - volta.train_utils -   [GQA]: iter 50424 Ep: 1.71 loss 0.036 score 0.068 lr 4.27141e-06 
12/05/2021 10:17:36 - INFO - volta.train_utils -   [GQA]: iter 50584 Ep: 1.72 loss 0.034 score 0.068 lr 4.28499e-06 
12/05/2021 10:19:22 - INFO - volta.train_utils -   [GQA]: iter 50744 Ep: 1.72 loss 0.037 score 0.066 lr 4.29856e-06 
12/05/2021 10:21:08 - INFO - volta.train_utils -   [GQA]: iter 50904 Ep: 1.73 loss 0.035 score 0.069 lr 4.31214e-06 
12/05/2021 10:22:54 - INFO - volta.train_utils -   [GQA]: iter 51064 Ep: 1.73 loss 0.033 score 0.068 lr 4.32571e-06 
12/05/2021 10:24:40 - INFO - volta.train_utils -   [GQA]: iter 51224 Ep: 1.74 loss 0.035 score 0.068 lr 4.33928e-06 
12/05/2021 10:26:26 - INFO - volta.train_utils -   [GQA]: iter 51384 Ep: 1.74 loss 0.034 score 0.070 lr 4.35286e-06 
12/05/2021 10:28:12 - INFO - volta.train_utils -   [GQA]: iter 51544 Ep: 1.75 loss 0.033 score 0.071 lr 4.36643e-06 
12/05/2021 10:29:58 - INFO - volta.train_utils -   [GQA]: iter 51704 Ep: 1.75 loss 0.034 score 0.070 lr 4.38001e-06 
12/05/2021 10:31:44 - INFO - volta.train_utils -   [GQA]: iter 51864 Ep: 1.76 loss 0.032 score 0.070 lr 4.39358e-06 
12/05/2021 10:33:30 - INFO - volta.train_utils -   [GQA]: iter 52024 Ep: 1.77 loss 0.032 score 0.073 lr 4.40715e-06 
12/05/2021 10:35:15 - INFO - volta.train_utils -   [GQA]: iter 52184 Ep: 1.77 loss 0.034 score 0.068 lr 4.42073e-06 
12/05/2021 10:37:01 - INFO - volta.train_utils -   [GQA]: iter 52344 Ep: 1.78 loss 0.033 score 0.071 lr 4.4343e-06 
12/05/2021 10:38:47 - INFO - volta.train_utils -   [GQA]: iter 52504 Ep: 1.78 loss 0.033 score 0.070 lr 4.44788e-06 
12/05/2021 10:40:33 - INFO - volta.train_utils -   [GQA]: iter 52664 Ep: 1.79 loss 0.034 score 0.070 lr 4.46145e-06 
12/05/2021 10:42:19 - INFO - volta.train_utils -   [GQA]: iter 52824 Ep: 1.79 loss 0.034 score 0.070 lr 4.47502e-06 
12/05/2021 10:44:05 - INFO - volta.train_utils -   [GQA]: iter 52984 Ep: 1.80 loss 0.037 score 0.069 lr 4.4886e-06 
12/05/2021 10:45:51 - INFO - volta.train_utils -   [GQA]: iter 53144 Ep: 1.80 loss 0.033 score 0.071 lr 4.50217e-06 
12/05/2021 10:47:37 - INFO - volta.train_utils -   [GQA]: iter 53304 Ep: 1.81 loss 0.032 score 0.073 lr 4.51575e-06 
12/05/2021 10:49:23 - INFO - volta.train_utils -   [GQA]: iter 53464 Ep: 1.81 loss 0.034 score 0.072 lr 4.52932e-06 
12/05/2021 10:51:09 - INFO - volta.train_utils -   [GQA]: iter 53624 Ep: 1.82 loss 0.032 score 0.070 lr 4.54289e-06 
12/05/2021 10:52:54 - INFO - volta.train_utils -   [GQA]: iter 53784 Ep: 1.83 loss 0.033 score 0.070 lr 4.55647e-06 
12/05/2021 10:54:40 - INFO - volta.train_utils -   [GQA]: iter 53944 Ep: 1.83 loss 0.031 score 0.073 lr 4.57004e-06 
12/05/2021 10:56:26 - INFO - volta.train_utils -   [GQA]: iter 54104 Ep: 1.84 loss 0.033 score 0.071 lr 4.58362e-06 
12/05/2021 10:58:12 - INFO - volta.train_utils -   [GQA]: iter 54264 Ep: 1.84 loss 0.032 score 0.070 lr 4.59719e-06 
12/05/2021 10:59:58 - INFO - volta.train_utils -   [GQA]: iter 54424 Ep: 1.85 loss 0.033 score 0.071 lr 4.61076e-06 
12/05/2021 11:01:44 - INFO - volta.train_utils -   [GQA]: iter 54584 Ep: 1.85 loss 0.033 score 0.073 lr 4.62434e-06 
12/05/2021 11:03:30 - INFO - volta.train_utils -   [GQA]: iter 54744 Ep: 1.86 loss 0.032 score 0.073 lr 4.63791e-06 
12/05/2021 11:05:16 - INFO - volta.train_utils -   [GQA]: iter 54904 Ep: 1.86 loss 0.032 score 0.072 lr 4.65149e-06 
12/05/2021 11:07:02 - INFO - volta.train_utils -   [GQA]: iter 55064 Ep: 1.87 loss 0.035 score 0.072 lr 4.66506e-06 
12/05/2021 11:08:48 - INFO - volta.train_utils -   [GQA]: iter 55224 Ep: 1.87 loss 0.034 score 0.072 lr 4.67863e-06 
12/05/2021 11:10:34 - INFO - volta.train_utils -   [GQA]: iter 55384 Ep: 1.88 loss 0.030 score 0.074 lr 4.69221e-06 
12/05/2021 11:12:20 - INFO - volta.train_utils -   [GQA]: iter 55544 Ep: 1.88 loss 0.033 score 0.072 lr 4.70578e-06 
12/05/2021 11:14:05 - INFO - volta.train_utils -   [GQA]: iter 55704 Ep: 1.89 loss 0.033 score 0.072 lr 4.71936e-06 
12/05/2021 11:15:51 - INFO - volta.train_utils -   [GQA]: iter 55864 Ep: 1.90 loss 0.032 score 0.074 lr 4.73293e-06 
12/05/2021 11:17:37 - INFO - volta.train_utils -   [GQA]: iter 56024 Ep: 1.90 loss 0.030 score 0.074 lr 4.7465e-06 
12/05/2021 11:19:23 - INFO - volta.train_utils -   [GQA]: iter 56184 Ep: 1.91 loss 0.031 score 0.073 lr 4.76008e-06 
12/05/2021 11:21:09 - INFO - volta.train_utils -   [GQA]: iter 56344 Ep: 1.91 loss 0.032 score 0.072 lr 4.77365e-06 
12/05/2021 11:22:55 - INFO - volta.train_utils -   [GQA]: iter 56504 Ep: 1.92 loss 0.033 score 0.074 lr 4.78723e-06 
12/05/2021 11:24:40 - INFO - volta.train_utils -   [GQA]: iter 56664 Ep: 1.92 loss 0.029 score 0.075 lr 4.8008e-06 
12/05/2021 11:26:26 - INFO - volta.train_utils -   [GQA]: iter 56824 Ep: 1.93 loss 0.031 score 0.072 lr 4.81437e-06 
12/05/2021 11:28:12 - INFO - volta.train_utils -   [GQA]: iter 56984 Ep: 1.93 loss 0.032 score 0.075 lr 4.82795e-06 
12/05/2021 11:29:58 - INFO - volta.train_utils -   [GQA]: iter 57144 Ep: 1.94 loss 0.029 score 0.074 lr 4.84152e-06 
12/05/2021 11:31:44 - INFO - volta.train_utils -   [GQA]: iter 57304 Ep: 1.94 loss 0.033 score 0.072 lr 4.8551e-06 
12/05/2021 11:33:30 - INFO - volta.train_utils -   [GQA]: iter 57464 Ep: 1.95 loss 0.030 score 0.076 lr 4.86867e-06 
12/05/2021 11:35:16 - INFO - volta.train_utils -   [GQA]: iter 57624 Ep: 1.96 loss 0.031 score 0.075 lr 4.88225e-06 
12/05/2021 11:37:02 - INFO - volta.train_utils -   [GQA]: iter 57784 Ep: 1.96 loss 0.030 score 0.077 lr 4.89582e-06 
12/05/2021 11:38:48 - INFO - volta.train_utils -   [GQA]: iter 57944 Ep: 1.97 loss 0.030 score 0.077 lr 4.90939e-06 
12/05/2021 11:40:34 - INFO - volta.train_utils -   [GQA]: iter 58104 Ep: 1.97 loss 0.030 score 0.075 lr 4.92297e-06 
12/05/2021 11:42:20 - INFO - volta.train_utils -   [GQA]: iter 58264 Ep: 1.98 loss 0.028 score 0.075 lr 4.93654e-06 
12/05/2021 11:44:05 - INFO - volta.train_utils -   [GQA]: iter 58424 Ep: 1.98 loss 0.031 score 0.075 lr 4.95012e-06 
12/05/2021 11:45:51 - INFO - volta.train_utils -   [GQA]: iter 58584 Ep: 1.99 loss 0.030 score 0.078 lr 4.96369e-06 
12/05/2021 11:47:37 - INFO - volta.train_utils -   [GQA]: iter 58744 Ep: 1.99 loss 0.027 score 0.080 lr 4.97726e-06 
12/05/2021 11:49:23 - INFO - volta.train_utils -   [GQA]: iter 58904 Ep: 2.00 loss 0.028 score 0.082 lr 4.99084e-06 
12/05/2021 12:34:50 - INFO - volta.train_utils -   Eval task TASK15 on iteration 58928 
12/05/2021 12:34:50 - INFO - volta.train_utils -   Validation [GQA]: loss 2.105 score 57.288 
12/05/2021 12:34:50 - INFO - __main__ -   ** ** * Saving model * ** ** 
Epoch:  40%|████      | 2/5 [12:20:40<18:30:50, 22216.69s/it]12/05/2021 12:36:57 - INFO - volta.train_utils -   [GQA]: iter 59088 Ep: 2.01 loss 0.033 score 0.073 lr 4.9992e-06 
12/05/2021 12:38:42 - INFO - volta.train_utils -   [GQA]: iter 59248 Ep: 2.01 loss 0.036 score 0.071 lr 4.99778e-06 
12/05/2021 12:40:28 - INFO - volta.train_utils -   [GQA]: iter 59408 Ep: 2.02 loss 0.035 score 0.069 lr 4.99627e-06 
12/05/2021 12:42:14 - INFO - volta.train_utils -   [GQA]: iter 59568 Ep: 2.02 loss 0.036 score 0.068 lr 4.99476e-06 
12/05/2021 12:44:00 - INFO - volta.train_utils -   [GQA]: iter 59728 Ep: 2.03 loss 0.035 score 0.067 lr 4.99325e-06 
12/05/2021 12:45:45 - INFO - volta.train_utils -   [GQA]: iter 59888 Ep: 2.03 loss 0.034 score 0.071 lr 4.99174e-06 
12/05/2021 12:47:31 - INFO - volta.train_utils -   [GQA]: iter 60048 Ep: 2.04 loss 0.035 score 0.068 lr 4.99023e-06 
12/05/2021 12:49:17 - INFO - volta.train_utils -   [GQA]: iter 60208 Ep: 2.04 loss 0.035 score 0.069 lr 4.98873e-06 
12/05/2021 12:51:03 - INFO - volta.train_utils -   [GQA]: iter 60368 Ep: 2.05 loss 0.036 score 0.068 lr 4.98722e-06 
12/05/2021 12:52:49 - INFO - volta.train_utils -   [GQA]: iter 60528 Ep: 2.05 loss 0.034 score 0.070 lr 4.98571e-06 
12/05/2021 12:54:35 - INFO - volta.train_utils -   [GQA]: iter 60688 Ep: 2.06 loss 0.033 score 0.070 lr 4.9842e-06 
12/05/2021 12:56:21 - INFO - volta.train_utils -   [GQA]: iter 60848 Ep: 2.06 loss 0.035 score 0.070 lr 4.98269e-06 
12/05/2021 12:58:07 - INFO - volta.train_utils -   [GQA]: iter 61008 Ep: 2.07 loss 0.035 score 0.069 lr 4.98118e-06 
12/05/2021 12:59:53 - INFO - volta.train_utils -   [GQA]: iter 61168 Ep: 2.08 loss 0.031 score 0.070 lr 4.97968e-06 
12/05/2021 13:01:39 - INFO - volta.train_utils -   [GQA]: iter 61328 Ep: 2.08 loss 0.035 score 0.069 lr 4.97817e-06 
12/05/2021 13:03:25 - INFO - volta.train_utils -   [GQA]: iter 61488 Ep: 2.09 loss 0.035 score 0.070 lr 4.97666e-06 
12/05/2021 13:05:10 - INFO - volta.train_utils -   [GQA]: iter 61648 Ep: 2.09 loss 0.033 score 0.071 lr 4.97515e-06 
12/05/2021 13:06:56 - INFO - volta.train_utils -   [GQA]: iter 61808 Ep: 2.10 loss 0.036 score 0.071 lr 4.97364e-06 
12/05/2021 13:08:42 - INFO - volta.train_utils -   [GQA]: iter 61968 Ep: 2.10 loss 0.033 score 0.071 lr 4.97214e-06 
12/05/2021 13:10:28 - INFO - volta.train_utils -   [GQA]: iter 62128 Ep: 2.11 loss 0.033 score 0.070 lr 4.97063e-06 
12/05/2021 13:12:14 - INFO - volta.train_utils -   [GQA]: iter 62288 Ep: 2.11 loss 0.034 score 0.069 lr 4.96912e-06 
12/05/2021 13:14:00 - INFO - volta.train_utils -   [GQA]: iter 62448 Ep: 2.12 loss 0.034 score 0.070 lr 4.96761e-06 
12/05/2021 13:15:46 - INFO - volta.train_utils -   [GQA]: iter 62608 Ep: 2.12 loss 0.033 score 0.069 lr 4.9661e-06 
12/05/2021 13:17:32 - INFO - volta.train_utils -   [GQA]: iter 62768 Ep: 2.13 loss 0.034 score 0.071 lr 4.96459e-06 
12/05/2021 13:19:17 - INFO - volta.train_utils -   [GQA]: iter 62928 Ep: 2.14 loss 0.034 score 0.068 lr 4.96309e-06 
12/05/2021 13:21:03 - INFO - volta.train_utils -   [GQA]: iter 63088 Ep: 2.14 loss 0.032 score 0.071 lr 4.96158e-06 
12/05/2021 13:22:49 - INFO - volta.train_utils -   [GQA]: iter 63248 Ep: 2.15 loss 0.036 score 0.070 lr 4.96007e-06 
12/05/2021 13:24:35 - INFO - volta.train_utils -   [GQA]: iter 63408 Ep: 2.15 loss 0.030 score 0.072 lr 4.95856e-06 
12/05/2021 13:26:21 - INFO - volta.train_utils -   [GQA]: iter 63568 Ep: 2.16 loss 0.034 score 0.070 lr 4.95705e-06 
12/05/2021 13:28:07 - INFO - volta.train_utils -   [GQA]: iter 63728 Ep: 2.16 loss 0.033 score 0.073 lr 4.95554e-06 
12/05/2021 13:29:53 - INFO - volta.train_utils -   [GQA]: iter 63888 Ep: 2.17 loss 0.034 score 0.071 lr 4.95404e-06 
12/05/2021 13:31:39 - INFO - volta.train_utils -   [GQA]: iter 64048 Ep: 2.17 loss 0.033 score 0.071 lr 4.95253e-06 
12/05/2021 13:33:25 - INFO - volta.train_utils -   [GQA]: iter 64208 Ep: 2.18 loss 0.033 score 0.071 lr 4.95102e-06 
12/05/2021 13:35:11 - INFO - volta.train_utils -   [GQA]: iter 64368 Ep: 2.18 loss 0.035 score 0.071 lr 4.94951e-06 
12/05/2021 13:36:57 - INFO - volta.train_utils -   [GQA]: iter 64528 Ep: 2.19 loss 0.034 score 0.071 lr 4.948e-06 
12/05/2021 13:38:43 - INFO - volta.train_utils -   [GQA]: iter 64688 Ep: 2.20 loss 0.032 score 0.073 lr 4.9465e-06 
12/05/2021 13:40:28 - INFO - volta.train_utils -   [GQA]: iter 64848 Ep: 2.20 loss 0.034 score 0.071 lr 4.94499e-06 
12/05/2021 13:42:14 - INFO - volta.train_utils -   [GQA]: iter 65008 Ep: 2.21 loss 0.033 score 0.070 lr 4.94348e-06 
12/05/2021 13:44:00 - INFO - volta.train_utils -   [GQA]: iter 65168 Ep: 2.21 loss 0.033 score 0.070 lr 4.94197e-06 
12/05/2021 13:45:46 - INFO - volta.train_utils -   [GQA]: iter 65328 Ep: 2.22 loss 0.032 score 0.071 lr 4.94046e-06 
12/05/2021 13:47:32 - INFO - volta.train_utils -   [GQA]: iter 65488 Ep: 2.22 loss 0.033 score 0.072 lr 4.93895e-06 
12/05/2021 13:49:18 - INFO - volta.train_utils -   [GQA]: iter 65648 Ep: 2.23 loss 0.034 score 0.071 lr 4.93745e-06 
12/05/2021 13:51:04 - INFO - volta.train_utils -   [GQA]: iter 65808 Ep: 2.23 loss 0.032 score 0.073 lr 4.93594e-06 
12/05/2021 13:52:50 - INFO - volta.train_utils -   [GQA]: iter 65968 Ep: 2.24 loss 0.033 score 0.072 lr 4.93443e-06 
12/05/2021 13:54:36 - INFO - volta.train_utils -   [GQA]: iter 66128 Ep: 2.24 loss 0.034 score 0.071 lr 4.93292e-06 
12/05/2021 13:56:22 - INFO - volta.train_utils -   [GQA]: iter 66288 Ep: 2.25 loss 0.032 score 0.072 lr 4.93141e-06 
12/05/2021 13:58:08 - INFO - volta.train_utils -   [GQA]: iter 66448 Ep: 2.25 loss 0.032 score 0.074 lr 4.92991e-06 
12/05/2021 13:59:54 - INFO - volta.train_utils -   [GQA]: iter 66608 Ep: 2.26 loss 0.032 score 0.071 lr 4.9284e-06 
12/05/2021 14:01:40 - INFO - volta.train_utils -   [GQA]: iter 66768 Ep: 2.27 loss 0.032 score 0.071 lr 4.92689e-06 
12/05/2021 14:03:25 - INFO - volta.train_utils -   [GQA]: iter 66928 Ep: 2.27 loss 0.032 score 0.071 lr 4.92538e-06 
12/05/2021 14:05:12 - INFO - volta.train_utils -   [GQA]: iter 67088 Ep: 2.28 loss 0.033 score 0.072 lr 4.92387e-06 
12/05/2021 14:06:58 - INFO - volta.train_utils -   [GQA]: iter 67248 Ep: 2.28 loss 0.031 score 0.073 lr 4.92236e-06 
12/05/2021 14:08:43 - INFO - volta.train_utils -   [GQA]: iter 67408 Ep: 2.29 loss 0.034 score 0.072 lr 4.92086e-06 
12/05/2021 14:10:30 - INFO - volta.train_utils -   [GQA]: iter 67568 Ep: 2.29 loss 0.030 score 0.074 lr 4.91935e-06 
12/05/2021 14:12:15 - INFO - volta.train_utils -   [GQA]: iter 67728 Ep: 2.30 loss 0.033 score 0.074 lr 4.91784e-06 
12/05/2021 14:14:01 - INFO - volta.train_utils -   [GQA]: iter 67888 Ep: 2.30 loss 0.034 score 0.070 lr 4.91633e-06 
12/05/2021 14:15:47 - INFO - volta.train_utils -   [GQA]: iter 68048 Ep: 2.31 loss 0.031 score 0.073 lr 4.91482e-06 
12/05/2021 14:17:33 - INFO - volta.train_utils -   [GQA]: iter 68208 Ep: 2.31 loss 0.032 score 0.073 lr 4.91331e-06 
12/05/2021 14:19:19 - INFO - volta.train_utils -   [GQA]: iter 68368 Ep: 2.32 loss 0.034 score 0.073 lr 4.91181e-06 
12/05/2021 14:21:05 - INFO - volta.train_utils -   [GQA]: iter 68528 Ep: 2.33 loss 0.033 score 0.075 lr 4.9103e-06 
12/05/2021 14:22:50 - INFO - volta.train_utils -   [GQA]: iter 68688 Ep: 2.33 loss 0.033 score 0.072 lr 4.90879e-06 
12/05/2021 14:24:36 - INFO - volta.train_utils -   [GQA]: iter 68848 Ep: 2.34 loss 0.029 score 0.075 lr 4.90728e-06 
12/05/2021 14:26:22 - INFO - volta.train_utils -   [GQA]: iter 69008 Ep: 2.34 loss 0.032 score 0.072 lr 4.90577e-06 
12/05/2021 14:28:08 - INFO - volta.train_utils -   [GQA]: iter 69168 Ep: 2.35 loss 0.033 score 0.071 lr 4.90427e-06 
12/05/2021 14:29:54 - INFO - volta.train_utils -   [GQA]: iter 69328 Ep: 2.35 loss 0.032 score 0.073 lr 4.90276e-06 
12/05/2021 14:31:40 - INFO - volta.train_utils -   [GQA]: iter 69488 Ep: 2.36 loss 0.030 score 0.074 lr 4.90125e-06 
12/05/2021 14:33:26 - INFO - volta.train_utils -   [GQA]: iter 69648 Ep: 2.36 loss 0.035 score 0.073 lr 4.89974e-06 
12/05/2021 14:35:12 - INFO - volta.train_utils -   [GQA]: iter 69808 Ep: 2.37 loss 0.032 score 0.073 lr 4.89823e-06 
12/05/2021 14:36:58 - INFO - volta.train_utils -   [GQA]: iter 69968 Ep: 2.37 loss 0.031 score 0.073 lr 4.89672e-06 
12/05/2021 14:38:44 - INFO - volta.train_utils -   [GQA]: iter 70128 Ep: 2.38 loss 0.031 score 0.074 lr 4.89522e-06 
12/05/2021 14:40:30 - INFO - volta.train_utils -   [GQA]: iter 70288 Ep: 2.39 loss 0.035 score 0.073 lr 4.89371e-06 
12/05/2021 14:42:16 - INFO - volta.train_utils -   [GQA]: iter 70448 Ep: 2.39 loss 0.030 score 0.073 lr 4.8922e-06 
12/05/2021 14:44:02 - INFO - volta.train_utils -   [GQA]: iter 70608 Ep: 2.40 loss 0.031 score 0.073 lr 4.89069e-06 
12/05/2021 14:45:48 - INFO - volta.train_utils -   [GQA]: iter 70768 Ep: 2.40 loss 0.030 score 0.074 lr 4.88918e-06 
12/05/2021 14:47:34 - INFO - volta.train_utils -   [GQA]: iter 70928 Ep: 2.41 loss 0.033 score 0.074 lr 4.88767e-06 
12/05/2021 14:49:20 - INFO - volta.train_utils -   [GQA]: iter 71088 Ep: 2.41 loss 0.031 score 0.073 lr 4.88617e-06 
12/05/2021 14:51:06 - INFO - volta.train_utils -   [GQA]: iter 71248 Ep: 2.42 loss 0.029 score 0.075 lr 4.88466e-06 
12/05/2021 14:52:51 - INFO - volta.train_utils -   [GQA]: iter 71408 Ep: 2.42 loss 0.033 score 0.074 lr 4.88315e-06 
12/05/2021 14:54:37 - INFO - volta.train_utils -   [GQA]: iter 71568 Ep: 2.43 loss 0.033 score 0.073 lr 4.88164e-06 
12/05/2021 14:56:23 - INFO - volta.train_utils -   [GQA]: iter 71728 Ep: 2.43 loss 0.031 score 0.073 lr 4.88013e-06 
12/05/2021 14:58:09 - INFO - volta.train_utils -   [GQA]: iter 71888 Ep: 2.44 loss 0.030 score 0.074 lr 4.87863e-06 
12/05/2021 14:59:55 - INFO - volta.train_utils -   [GQA]: iter 72048 Ep: 2.44 loss 0.032 score 0.076 lr 4.87712e-06 
12/05/2021 15:01:41 - INFO - volta.train_utils -   [GQA]: iter 72208 Ep: 2.45 loss 0.032 score 0.073 lr 4.87561e-06 
12/05/2021 15:03:27 - INFO - volta.train_utils -   [GQA]: iter 72368 Ep: 2.46 loss 0.030 score 0.074 lr 4.8741e-06 
12/05/2021 15:05:12 - INFO - volta.train_utils -   [GQA]: iter 72528 Ep: 2.46 loss 0.030 score 0.074 lr 4.87259e-06 
12/05/2021 15:06:58 - INFO - volta.train_utils -   [GQA]: iter 72688 Ep: 2.47 loss 0.030 score 0.075 lr 4.87108e-06 
12/05/2021 15:08:44 - INFO - volta.train_utils -   [GQA]: iter 72848 Ep: 2.47 loss 0.031 score 0.074 lr 4.86958e-06 
12/05/2021 15:10:30 - INFO - volta.train_utils -   [GQA]: iter 73008 Ep: 2.48 loss 0.033 score 0.073 lr 4.86807e-06 
12/05/2021 15:12:16 - INFO - volta.train_utils -   [GQA]: iter 73168 Ep: 2.48 loss 0.030 score 0.075 lr 4.86656e-06 
12/05/2021 15:14:02 - INFO - volta.train_utils -   [GQA]: iter 73328 Ep: 2.49 loss 0.031 score 0.075 lr 4.86505e-06 
12/05/2021 15:15:48 - INFO - volta.train_utils -   [GQA]: iter 73488 Ep: 2.49 loss 0.032 score 0.075 lr 4.86354e-06 
12/05/2021 15:17:34 - INFO - volta.train_utils -   [GQA]: iter 73648 Ep: 2.50 loss 0.031 score 0.075 lr 4.86203e-06 
12/05/2021 15:19:20 - INFO - volta.train_utils -   [GQA]: iter 73808 Ep: 2.50 loss 0.031 score 0.074 lr 4.86053e-06 
12/05/2021 15:21:06 - INFO - volta.train_utils -   [GQA]: iter 73968 Ep: 2.51 loss 0.031 score 0.074 lr 4.85902e-06 
12/05/2021 15:22:52 - INFO - volta.train_utils -   [GQA]: iter 74128 Ep: 2.52 loss 0.031 score 0.075 lr 4.85751e-06 
12/05/2021 15:24:38 - INFO - volta.train_utils -   [GQA]: iter 74288 Ep: 2.52 loss 0.031 score 0.078 lr 4.856e-06 
12/05/2021 15:26:23 - INFO - volta.train_utils -   [GQA]: iter 74448 Ep: 2.53 loss 0.030 score 0.074 lr 4.85449e-06 
12/05/2021 15:28:09 - INFO - volta.train_utils -   [GQA]: iter 74608 Ep: 2.53 loss 0.031 score 0.074 lr 4.85299e-06 
12/05/2021 15:29:55 - INFO - volta.train_utils -   [GQA]: iter 74768 Ep: 2.54 loss 0.031 score 0.075 lr 4.85148e-06 
12/05/2021 15:31:41 - INFO - volta.train_utils -   [GQA]: iter 74928 Ep: 2.54 loss 0.031 score 0.075 lr 4.84997e-06 
12/05/2021 15:33:27 - INFO - volta.train_utils -   [GQA]: iter 75088 Ep: 2.55 loss 0.031 score 0.074 lr 4.84846e-06 
12/05/2021 15:35:13 - INFO - volta.train_utils -   [GQA]: iter 75248 Ep: 2.55 loss 0.030 score 0.076 lr 4.84695e-06 
12/05/2021 15:36:59 - INFO - volta.train_utils -   [GQA]: iter 75408 Ep: 2.56 loss 0.030 score 0.077 lr 4.84544e-06 
12/05/2021 15:38:45 - INFO - volta.train_utils -   [GQA]: iter 75568 Ep: 2.56 loss 0.029 score 0.075 lr 4.84394e-06 
12/05/2021 15:40:31 - INFO - volta.train_utils -   [GQA]: iter 75728 Ep: 2.57 loss 0.029 score 0.077 lr 4.84243e-06 
12/05/2021 15:42:17 - INFO - volta.train_utils -   [GQA]: iter 75888 Ep: 2.58 loss 0.028 score 0.076 lr 4.84092e-06 
12/05/2021 15:44:03 - INFO - volta.train_utils -   [GQA]: iter 76048 Ep: 2.58 loss 0.030 score 0.078 lr 4.83941e-06 
12/05/2021 15:45:49 - INFO - volta.train_utils -   [GQA]: iter 76208 Ep: 2.59 loss 0.030 score 0.075 lr 4.8379e-06 
12/05/2021 15:47:34 - INFO - volta.train_utils -   [GQA]: iter 76368 Ep: 2.59 loss 0.030 score 0.074 lr 4.8364e-06 
12/05/2021 15:49:20 - INFO - volta.train_utils -   [GQA]: iter 76528 Ep: 2.60 loss 0.031 score 0.075 lr 4.83489e-06 
12/05/2021 15:51:06 - INFO - volta.train_utils -   [GQA]: iter 76688 Ep: 2.60 loss 0.030 score 0.076 lr 4.83338e-06 
12/05/2021 15:52:52 - INFO - volta.train_utils -   [GQA]: iter 76848 Ep: 2.61 loss 0.029 score 0.074 lr 4.83187e-06 
12/05/2021 15:54:38 - INFO - volta.train_utils -   [GQA]: iter 77008 Ep: 2.61 loss 0.031 score 0.078 lr 4.83036e-06 
12/05/2021 15:56:24 - INFO - volta.train_utils -   [GQA]: iter 77168 Ep: 2.62 loss 0.031 score 0.076 lr 4.82885e-06 
12/05/2021 15:58:10 - INFO - volta.train_utils -   [GQA]: iter 77328 Ep: 2.62 loss 0.029 score 0.076 lr 4.82735e-06 
12/05/2021 15:59:56 - INFO - volta.train_utils -   [GQA]: iter 77488 Ep: 2.63 loss 0.032 score 0.076 lr 4.82584e-06 
12/05/2021 16:01:41 - INFO - volta.train_utils -   [GQA]: iter 77648 Ep: 2.63 loss 0.029 score 0.078 lr 4.82433e-06 
12/05/2021 16:03:27 - INFO - volta.train_utils -   [GQA]: iter 77808 Ep: 2.64 loss 0.029 score 0.077 lr 4.82282e-06 
12/05/2021 16:05:13 - INFO - volta.train_utils -   [GQA]: iter 77968 Ep: 2.65 loss 0.029 score 0.076 lr 4.82131e-06 
12/05/2021 16:06:59 - INFO - volta.train_utils -   [GQA]: iter 78128 Ep: 2.65 loss 0.027 score 0.079 lr 4.8198e-06 
12/05/2021 16:08:45 - INFO - volta.train_utils -   [GQA]: iter 78288 Ep: 2.66 loss 0.030 score 0.077 lr 4.8183e-06 
12/05/2021 16:10:31 - INFO - volta.train_utils -   [GQA]: iter 78448 Ep: 2.66 loss 0.028 score 0.078 lr 4.81679e-06 
12/05/2021 16:12:17 - INFO - volta.train_utils -   [GQA]: iter 78608 Ep: 2.67 loss 0.029 score 0.075 lr 4.81528e-06 
12/05/2021 16:14:03 - INFO - volta.train_utils -   [GQA]: iter 78768 Ep: 2.67 loss 0.027 score 0.080 lr 4.81377e-06 
12/05/2021 16:15:49 - INFO - volta.train_utils -   [GQA]: iter 78928 Ep: 2.68 loss 0.026 score 0.079 lr 4.81226e-06 
12/05/2021 16:17:35 - INFO - volta.train_utils -   [GQA]: iter 79088 Ep: 2.68 loss 0.027 score 0.080 lr 4.81076e-06 
12/05/2021 16:19:21 - INFO - volta.train_utils -   [GQA]: iter 79248 Ep: 2.69 loss 0.030 score 0.076 lr 4.80925e-06 
12/05/2021 16:21:07 - INFO - volta.train_utils -   [GQA]: iter 79408 Ep: 2.69 loss 0.030 score 0.077 lr 4.80774e-06 
12/05/2021 16:22:52 - INFO - volta.train_utils -   [GQA]: iter 79568 Ep: 2.70 loss 0.029 score 0.077 lr 4.80623e-06 
12/05/2021 16:24:38 - INFO - volta.train_utils -   [GQA]: iter 79728 Ep: 2.71 loss 0.030 score 0.079 lr 4.80472e-06 
12/05/2021 16:26:24 - INFO - volta.train_utils -   [GQA]: iter 79888 Ep: 2.71 loss 0.031 score 0.077 lr 4.80321e-06 
12/05/2021 16:28:10 - INFO - volta.train_utils -   [GQA]: iter 80048 Ep: 2.72 loss 0.029 score 0.077 lr 4.80171e-06 
12/05/2021 16:29:56 - INFO - volta.train_utils -   [GQA]: iter 80208 Ep: 2.72 loss 0.030 score 0.075 lr 4.8002e-06 
12/05/2021 16:31:42 - INFO - volta.train_utils -   [GQA]: iter 80368 Ep: 2.73 loss 0.029 score 0.077 lr 4.79869e-06 
12/05/2021 16:33:28 - INFO - volta.train_utils -   [GQA]: iter 80528 Ep: 2.73 loss 0.029 score 0.079 lr 4.79718e-06 
12/05/2021 16:35:13 - INFO - volta.train_utils -   [GQA]: iter 80688 Ep: 2.74 loss 0.029 score 0.078 lr 4.79567e-06 
12/05/2021 16:36:59 - INFO - volta.train_utils -   [GQA]: iter 80848 Ep: 2.74 loss 0.030 score 0.077 lr 4.79416e-06 
12/05/2021 16:38:45 - INFO - volta.train_utils -   [GQA]: iter 81008 Ep: 2.75 loss 0.028 score 0.080 lr 4.79266e-06 
12/05/2021 16:40:31 - INFO - volta.train_utils -   [GQA]: iter 81168 Ep: 2.75 loss 0.028 score 0.078 lr 4.79115e-06 
12/05/2021 16:42:17 - INFO - volta.train_utils -   [GQA]: iter 81328 Ep: 2.76 loss 0.032 score 0.079 lr 4.78964e-06 
12/05/2021 16:44:03 - INFO - volta.train_utils -   [GQA]: iter 81488 Ep: 2.77 loss 0.027 score 0.081 lr 4.78813e-06 
12/05/2021 16:45:49 - INFO - volta.train_utils -   [GQA]: iter 81648 Ep: 2.77 loss 0.029 score 0.077 lr 4.78662e-06 
12/05/2021 16:47:35 - INFO - volta.train_utils -   [GQA]: iter 81808 Ep: 2.78 loss 0.028 score 0.081 lr 4.78512e-06 
12/05/2021 16:49:21 - INFO - volta.train_utils -   [GQA]: iter 81968 Ep: 2.78 loss 0.029 score 0.079 lr 4.78361e-06 
12/05/2021 16:51:07 - INFO - volta.train_utils -   [GQA]: iter 82128 Ep: 2.79 loss 0.029 score 0.078 lr 4.7821e-06 
12/05/2021 16:52:53 - INFO - volta.train_utils -   [GQA]: iter 82288 Ep: 2.79 loss 0.028 score 0.077 lr 4.78059e-06 
12/05/2021 16:54:39 - INFO - volta.train_utils -   [GQA]: iter 82448 Ep: 2.80 loss 0.031 score 0.078 lr 4.77908e-06 
12/05/2021 16:56:24 - INFO - volta.train_utils -   [GQA]: iter 82608 Ep: 2.80 loss 0.029 score 0.079 lr 4.77757e-06 
12/05/2021 16:58:10 - INFO - volta.train_utils -   [GQA]: iter 82768 Ep: 2.81 loss 0.026 score 0.082 lr 4.77607e-06 
12/05/2021 16:59:56 - INFO - volta.train_utils -   [GQA]: iter 82928 Ep: 2.81 loss 0.027 score 0.079 lr 4.77456e-06 
12/05/2021 17:01:42 - INFO - volta.train_utils -   [GQA]: iter 83088 Ep: 2.82 loss 0.028 score 0.080 lr 4.77305e-06 
12/05/2021 17:03:28 - INFO - volta.train_utils -   [GQA]: iter 83248 Ep: 2.83 loss 0.028 score 0.078 lr 4.77154e-06 
12/05/2021 17:05:14 - INFO - volta.train_utils -   [GQA]: iter 83408 Ep: 2.83 loss 0.029 score 0.081 lr 4.77003e-06 
12/05/2021 17:07:00 - INFO - volta.train_utils -   [GQA]: iter 83568 Ep: 2.84 loss 0.029 score 0.080 lr 4.76852e-06 
12/05/2021 17:08:46 - INFO - volta.train_utils -   [GQA]: iter 83728 Ep: 2.84 loss 0.027 score 0.078 lr 4.76702e-06 
12/05/2021 17:10:32 - INFO - volta.train_utils -   [GQA]: iter 83888 Ep: 2.85 loss 0.026 score 0.080 lr 4.76551e-06 
12/05/2021 17:12:18 - INFO - volta.train_utils -   [GQA]: iter 84048 Ep: 2.85 loss 0.026 score 0.080 lr 4.764e-06 
12/05/2021 17:14:04 - INFO - volta.train_utils -   [GQA]: iter 84208 Ep: 2.86 loss 0.029 score 0.081 lr 4.76249e-06 
12/05/2021 17:15:50 - INFO - volta.train_utils -   [GQA]: iter 84368 Ep: 2.86 loss 0.028 score 0.081 lr 4.76098e-06 
12/05/2021 17:17:35 - INFO - volta.train_utils -   [GQA]: iter 84528 Ep: 2.87 loss 0.028 score 0.080 lr 4.75948e-06 
12/05/2021 17:19:21 - INFO - volta.train_utils -   [GQA]: iter 84688 Ep: 2.87 loss 0.027 score 0.081 lr 4.75797e-06 
12/05/2021 17:21:07 - INFO - volta.train_utils -   [GQA]: iter 84848 Ep: 2.88 loss 0.026 score 0.081 lr 4.75646e-06 
12/05/2021 17:22:53 - INFO - volta.train_utils -   [GQA]: iter 85008 Ep: 2.88 loss 0.029 score 0.080 lr 4.75495e-06 
12/05/2021 17:24:39 - INFO - volta.train_utils -   [GQA]: iter 85168 Ep: 2.89 loss 0.028 score 0.080 lr 4.75344e-06 
12/05/2021 17:26:25 - INFO - volta.train_utils -   [GQA]: iter 85328 Ep: 2.90 loss 0.026 score 0.080 lr 4.75193e-06 
12/05/2021 17:28:11 - INFO - volta.train_utils -   [GQA]: iter 85488 Ep: 2.90 loss 0.026 score 0.082 lr 4.75043e-06 
12/05/2021 17:29:56 - INFO - volta.train_utils -   [GQA]: iter 85648 Ep: 2.91 loss 0.028 score 0.081 lr 4.74892e-06 
12/05/2021 17:31:42 - INFO - volta.train_utils -   [GQA]: iter 85808 Ep: 2.91 loss 0.029 score 0.080 lr 4.74741e-06 
12/05/2021 17:33:28 - INFO - volta.train_utils -   [GQA]: iter 85968 Ep: 2.92 loss 0.027 score 0.082 lr 4.7459e-06 
12/05/2021 17:35:14 - INFO - volta.train_utils -   [GQA]: iter 86128 Ep: 2.92 loss 0.027 score 0.082 lr 4.74439e-06 
12/05/2021 17:37:00 - INFO - volta.train_utils -   [GQA]: iter 86288 Ep: 2.93 loss 0.030 score 0.079 lr 4.74288e-06 
12/05/2021 17:38:46 - INFO - volta.train_utils -   [GQA]: iter 86448 Ep: 2.93 loss 0.028 score 0.082 lr 4.74138e-06 
12/05/2021 17:40:32 - INFO - volta.train_utils -   [GQA]: iter 86608 Ep: 2.94 loss 0.025 score 0.083 lr 4.73987e-06 
12/05/2021 17:42:17 - INFO - volta.train_utils -   [GQA]: iter 86768 Ep: 2.94 loss 0.027 score 0.080 lr 4.73836e-06 
12/05/2021 17:44:03 - INFO - volta.train_utils -   [GQA]: iter 86928 Ep: 2.95 loss 0.026 score 0.084 lr 4.73685e-06 
12/05/2021 17:45:49 - INFO - volta.train_utils -   [GQA]: iter 87088 Ep: 2.96 loss 0.026 score 0.083 lr 4.73534e-06 
12/05/2021 17:47:35 - INFO - volta.train_utils -   [GQA]: iter 87248 Ep: 2.96 loss 0.026 score 0.084 lr 4.73384e-06 
12/05/2021 17:49:21 - INFO - volta.train_utils -   [GQA]: iter 87408 Ep: 2.97 loss 0.025 score 0.083 lr 4.73233e-06 
12/05/2021 17:51:07 - INFO - volta.train_utils -   [GQA]: iter 87568 Ep: 2.97 loss 0.023 score 0.084 lr 4.73082e-06 
12/05/2021 17:52:53 - INFO - volta.train_utils -   [GQA]: iter 87728 Ep: 2.98 loss 0.027 score 0.083 lr 4.72931e-06 
12/05/2021 17:54:39 - INFO - volta.train_utils -   [GQA]: iter 87888 Ep: 2.98 loss 0.026 score 0.084 lr 4.7278e-06 
12/05/2021 17:56:25 - INFO - volta.train_utils -   [GQA]: iter 88048 Ep: 2.99 loss 0.024 score 0.085 lr 4.72629e-06 
12/05/2021 17:58:11 - INFO - volta.train_utils -   [GQA]: iter 88208 Ep: 2.99 loss 0.025 score 0.086 lr 4.72479e-06 
12/05/2021 17:59:56 - INFO - volta.train_utils -   [GQA]: iter 88368 Ep: 3.00 loss 0.023 score 0.088 lr 4.72328e-06 
12/05/2021 18:45:22 - INFO - volta.train_utils -   Eval task TASK15 on iteration 88392 
12/05/2021 18:45:22 - INFO - volta.train_utils -   Validation [GQA]: loss 1.884 score 62.002 
12/05/2021 18:45:22 - INFO - __main__ -   ** ** * Saving model * ** ** 
Epoch:  60%|██████    | 3/5 [18:31:11<12:20:42, 22221.13s/it]12/05/2021 18:47:28 - INFO - volta.train_utils -   [GQA]: iter 88552 Ep: 3.01 loss 0.030 score 0.081 lr 4.72166e-06 
12/05/2021 18:49:14 - INFO - volta.train_utils -   [GQA]: iter 88712 Ep: 3.01 loss 0.028 score 0.078 lr 4.72004e-06 
12/05/2021 18:51:00 - INFO - volta.train_utils -   [GQA]: iter 88872 Ep: 3.02 loss 0.032 score 0.077 lr 4.71853e-06 
12/05/2021 18:52:46 - INFO - volta.train_utils -   [GQA]: iter 89032 Ep: 3.02 loss 0.029 score 0.076 lr 4.71702e-06 
12/05/2021 18:54:31 - INFO - volta.train_utils -   [GQA]: iter 89192 Ep: 3.03 loss 0.029 score 0.075 lr 4.71551e-06 
12/05/2021 18:56:17 - INFO - volta.train_utils -   [GQA]: iter 89352 Ep: 3.03 loss 0.029 score 0.079 lr 4.714e-06 
12/05/2021 18:58:03 - INFO - volta.train_utils -   [GQA]: iter 89512 Ep: 3.04 loss 0.030 score 0.075 lr 4.71249e-06 
12/05/2021 18:59:49 - INFO - volta.train_utils -   [GQA]: iter 89672 Ep: 3.04 loss 0.028 score 0.077 lr 4.71099e-06 
12/05/2021 19:01:35 - INFO - volta.train_utils -   [GQA]: iter 89832 Ep: 3.05 loss 0.029 score 0.076 lr 4.70948e-06 
12/05/2021 19:03:21 - INFO - volta.train_utils -   [GQA]: iter 89992 Ep: 3.05 loss 0.030 score 0.078 lr 4.70797e-06 
12/05/2021 19:05:07 - INFO - volta.train_utils -   [GQA]: iter 90152 Ep: 3.06 loss 0.029 score 0.078 lr 4.70646e-06 
12/05/2021 19:06:53 - INFO - volta.train_utils -   [GQA]: iter 90312 Ep: 3.06 loss 0.031 score 0.077 lr 4.70495e-06 
12/05/2021 19:08:39 - INFO - volta.train_utils -   [GQA]: iter 90472 Ep: 3.07 loss 0.028 score 0.076 lr 4.70344e-06 
12/05/2021 19:10:25 - INFO - volta.train_utils -   [GQA]: iter 90632 Ep: 3.08 loss 0.029 score 0.076 lr 4.70194e-06 
12/05/2021 19:12:11 - INFO - volta.train_utils -   [GQA]: iter 90792 Ep: 3.08 loss 0.029 score 0.077 lr 4.70043e-06 
12/05/2021 19:13:57 - INFO - volta.train_utils -   [GQA]: iter 90952 Ep: 3.09 loss 0.028 score 0.076 lr 4.69892e-06 
12/05/2021 19:15:43 - INFO - volta.train_utils -   [GQA]: iter 91112 Ep: 3.09 loss 0.028 score 0.078 lr 4.69741e-06 
12/05/2021 19:17:29 - INFO - volta.train_utils -   [GQA]: iter 91272 Ep: 3.10 loss 0.030 score 0.078 lr 4.6959e-06 
12/05/2021 19:19:15 - INFO - volta.train_utils -   [GQA]: iter 91432 Ep: 3.10 loss 0.029 score 0.078 lr 4.6944e-06 
12/05/2021 19:21:01 - INFO - volta.train_utils -   [GQA]: iter 91592 Ep: 3.11 loss 0.029 score 0.077 lr 4.69289e-06 
12/05/2021 19:22:47 - INFO - volta.train_utils -   [GQA]: iter 91752 Ep: 3.11 loss 0.032 score 0.076 lr 4.69138e-06 
12/05/2021 19:24:32 - INFO - volta.train_utils -   [GQA]: iter 91912 Ep: 3.12 loss 0.028 score 0.077 lr 4.68987e-06 
12/05/2021 19:26:19 - INFO - volta.train_utils -   [GQA]: iter 92072 Ep: 3.12 loss 0.033 score 0.076 lr 4.68836e-06 
12/05/2021 19:28:04 - INFO - volta.train_utils -   [GQA]: iter 92232 Ep: 3.13 loss 0.028 score 0.079 lr 4.68685e-06 
12/05/2021 19:29:50 - INFO - volta.train_utils -   [GQA]: iter 92392 Ep: 3.14 loss 0.031 score 0.075 lr 4.68535e-06 
12/05/2021 19:31:36 - INFO - volta.train_utils -   [GQA]: iter 92552 Ep: 3.14 loss 0.027 score 0.078 lr 4.68384e-06 
12/05/2021 19:33:22 - INFO - volta.train_utils -   [GQA]: iter 92712 Ep: 3.15 loss 0.028 score 0.077 lr 4.68233e-06 
12/05/2021 19:35:08 - INFO - volta.train_utils -   [GQA]: iter 92872 Ep: 3.15 loss 0.032 score 0.078 lr 4.68082e-06 
12/05/2021 19:36:54 - INFO - volta.train_utils -   [GQA]: iter 93032 Ep: 3.16 loss 0.028 score 0.078 lr 4.67931e-06 
12/05/2021 19:38:40 - INFO - volta.train_utils -   [GQA]: iter 93192 Ep: 3.16 loss 0.028 score 0.079 lr 4.6778e-06 
12/05/2021 19:40:26 - INFO - volta.train_utils -   [GQA]: iter 93352 Ep: 3.17 loss 0.031 score 0.077 lr 4.6763e-06 
12/05/2021 19:42:12 - INFO - volta.train_utils -   [GQA]: iter 93512 Ep: 3.17 loss 0.028 score 0.078 lr 4.67479e-06 
12/05/2021 19:43:58 - INFO - volta.train_utils -   [GQA]: iter 93672 Ep: 3.18 loss 0.029 score 0.077 lr 4.67328e-06 
12/05/2021 19:45:44 - INFO - volta.train_utils -   [GQA]: iter 93832 Ep: 3.18 loss 0.030 score 0.077 lr 4.67177e-06 
12/05/2021 19:47:30 - INFO - volta.train_utils -   [GQA]: iter 93992 Ep: 3.19 loss 0.029 score 0.078 lr 4.67026e-06 
12/05/2021 19:49:15 - INFO - volta.train_utils -   [GQA]: iter 94152 Ep: 3.20 loss 0.029 score 0.079 lr 4.66876e-06 
12/05/2021 19:51:01 - INFO - volta.train_utils -   [GQA]: iter 94312 Ep: 3.20 loss 0.031 score 0.078 lr 4.66725e-06 
12/05/2021 19:52:47 - INFO - volta.train_utils -   [GQA]: iter 94472 Ep: 3.21 loss 0.027 score 0.077 lr 4.66574e-06 
12/05/2021 19:54:33 - INFO - volta.train_utils -   [GQA]: iter 94632 Ep: 3.21 loss 0.033 score 0.078 lr 4.66423e-06 
12/05/2021 19:56:19 - INFO - volta.train_utils -   [GQA]: iter 94792 Ep: 3.22 loss 0.030 score 0.076 lr 4.66272e-06 
12/05/2021 19:58:05 - INFO - volta.train_utils -   [GQA]: iter 94952 Ep: 3.22 loss 0.030 score 0.078 lr 4.66121e-06 
12/05/2021 19:59:51 - INFO - volta.train_utils -   [GQA]: iter 95112 Ep: 3.23 loss 0.031 score 0.077 lr 4.65971e-06 
12/05/2021 20:01:36 - INFO - volta.train_utils -   [GQA]: iter 95272 Ep: 3.23 loss 0.029 score 0.079 lr 4.6582e-06 
12/05/2021 20:03:22 - INFO - volta.train_utils -   [GQA]: iter 95432 Ep: 3.24 loss 0.028 score 0.078 lr 4.65669e-06 
12/05/2021 20:05:08 - INFO - volta.train_utils -   [GQA]: iter 95592 Ep: 3.24 loss 0.030 score 0.076 lr 4.65518e-06 
12/05/2021 20:06:54 - INFO - volta.train_utils -   [GQA]: iter 95752 Ep: 3.25 loss 0.029 score 0.079 lr 4.65367e-06 
12/05/2021 20:08:40 - INFO - volta.train_utils -   [GQA]: iter 95912 Ep: 3.25 loss 0.029 score 0.081 lr 4.65217e-06 
12/05/2021 20:10:26 - INFO - volta.train_utils -   [GQA]: iter 96072 Ep: 3.26 loss 0.029 score 0.076 lr 4.65066e-06 
12/05/2021 20:12:12 - INFO - volta.train_utils -   [GQA]: iter 96232 Ep: 3.27 loss 0.029 score 0.078 lr 4.64915e-06 
12/05/2021 20:13:58 - INFO - volta.train_utils -   [GQA]: iter 96392 Ep: 3.27 loss 0.032 score 0.078 lr 4.64764e-06 
12/05/2021 20:15:44 - INFO - volta.train_utils -   [GQA]: iter 96552 Ep: 3.28 loss 0.030 score 0.078 lr 4.64613e-06 
12/05/2021 20:17:30 - INFO - volta.train_utils -   [GQA]: iter 96712 Ep: 3.28 loss 0.029 score 0.078 lr 4.64462e-06 
12/05/2021 20:19:16 - INFO - volta.train_utils -   [GQA]: iter 96872 Ep: 3.29 loss 0.029 score 0.079 lr 4.64312e-06 
12/05/2021 20:21:02 - INFO - volta.train_utils -   [GQA]: iter 97032 Ep: 3.29 loss 0.029 score 0.080 lr 4.64161e-06 
12/05/2021 20:22:47 - INFO - volta.train_utils -   [GQA]: iter 97192 Ep: 3.30 loss 0.028 score 0.079 lr 4.6401e-06 
12/05/2021 20:24:34 - INFO - volta.train_utils -   [GQA]: iter 97352 Ep: 3.30 loss 0.031 score 0.076 lr 4.63859e-06 
12/05/2021 20:26:19 - INFO - volta.train_utils -   [GQA]: iter 97512 Ep: 3.31 loss 0.025 score 0.079 lr 4.63708e-06 
12/05/2021 20:28:05 - INFO - volta.train_utils -   [GQA]: iter 97672 Ep: 3.31 loss 0.028 score 0.078 lr 4.63557e-06 
12/05/2021 20:29:51 - INFO - volta.train_utils -   [GQA]: iter 97832 Ep: 3.32 loss 0.029 score 0.078 lr 4.63407e-06 
12/05/2021 20:31:37 - INFO - volta.train_utils -   [GQA]: iter 97992 Ep: 3.33 loss 0.028 score 0.079 lr 4.63256e-06 
12/05/2021 20:33:23 - INFO - volta.train_utils -   [GQA]: iter 98152 Ep: 3.33 loss 0.028 score 0.080 lr 4.63105e-06 
12/05/2021 20:35:09 - INFO - volta.train_utils -   [GQA]: iter 98312 Ep: 3.34 loss 0.030 score 0.080 lr 4.62954e-06 
12/05/2021 20:36:55 - INFO - volta.train_utils -   [GQA]: iter 98472 Ep: 3.34 loss 0.028 score 0.079 lr 4.62803e-06 
12/05/2021 20:38:41 - INFO - volta.train_utils -   [GQA]: iter 98632 Ep: 3.35 loss 0.030 score 0.078 lr 4.62653e-06 
12/05/2021 20:40:27 - INFO - volta.train_utils -   [GQA]: iter 98792 Ep: 3.35 loss 0.028 score 0.079 lr 4.62502e-06 
12/05/2021 20:42:12 - INFO - volta.train_utils -   [GQA]: iter 98952 Ep: 3.36 loss 0.028 score 0.079 lr 4.62351e-06 
12/05/2021 20:43:59 - INFO - volta.train_utils -   [GQA]: iter 99112 Ep: 3.36 loss 0.030 score 0.079 lr 4.622e-06 
12/05/2021 20:45:44 - INFO - volta.train_utils -   [GQA]: iter 99272 Ep: 3.37 loss 0.028 score 0.080 lr 4.62049e-06 
12/05/2021 20:47:30 - INFO - volta.train_utils -   [GQA]: iter 99432 Ep: 3.37 loss 0.027 score 0.079 lr 4.61898e-06 
12/05/2021 20:49:16 - INFO - volta.train_utils -   [GQA]: iter 99592 Ep: 3.38 loss 0.027 score 0.080 lr 4.61748e-06 
12/05/2021 20:51:02 - INFO - volta.train_utils -   [GQA]: iter 99752 Ep: 3.39 loss 0.030 score 0.079 lr 4.61597e-06 
12/05/2021 20:52:48 - INFO - volta.train_utils -   [GQA]: iter 99912 Ep: 3.39 loss 0.025 score 0.080 lr 4.61446e-06 
12/05/2021 20:54:34 - INFO - volta.train_utils -   [GQA]: iter 100072 Ep: 3.40 loss 0.028 score 0.078 lr 4.61295e-06 
12/05/2021 20:56:20 - INFO - volta.train_utils -   [GQA]: iter 100232 Ep: 3.40 loss 0.028 score 0.081 lr 4.61144e-06 
12/05/2021 20:58:06 - INFO - volta.train_utils -   [GQA]: iter 100392 Ep: 3.41 loss 0.026 score 0.080 lr 4.60993e-06 
12/05/2021 20:59:52 - INFO - volta.train_utils -   [GQA]: iter 100552 Ep: 3.41 loss 0.027 score 0.079 lr 4.60843e-06 
12/05/2021 21:01:37 - INFO - volta.train_utils -   [GQA]: iter 100712 Ep: 3.42 loss 0.027 score 0.080 lr 4.60692e-06 
12/05/2021 21:03:23 - INFO - volta.train_utils -   [GQA]: iter 100872 Ep: 3.42 loss 0.029 score 0.079 lr 4.60541e-06 
12/05/2021 21:05:09 - INFO - volta.train_utils -   [GQA]: iter 101032 Ep: 3.43 loss 0.030 score 0.078 lr 4.6039e-06 
12/05/2021 21:06:55 - INFO - volta.train_utils -   [GQA]: iter 101192 Ep: 3.43 loss 0.026 score 0.079 lr 4.60239e-06 
12/05/2021 21:08:41 - INFO - volta.train_utils -   [GQA]: iter 101352 Ep: 3.44 loss 0.029 score 0.080 lr 4.60089e-06 
12/05/2021 21:10:27 - INFO - volta.train_utils -   [GQA]: iter 101512 Ep: 3.44 loss 0.028 score 0.080 lr 4.59938e-06 
12/05/2021 21:12:12 - INFO - volta.train_utils -   [GQA]: iter 101672 Ep: 3.45 loss 0.028 score 0.079 lr 4.59787e-06 
12/05/2021 21:13:58 - INFO - volta.train_utils -   [GQA]: iter 101832 Ep: 3.46 loss 0.026 score 0.081 lr 4.59636e-06 
12/05/2021 21:15:44 - INFO - volta.train_utils -   [GQA]: iter 101992 Ep: 3.46 loss 0.029 score 0.080 lr 4.59485e-06 
12/05/2021 21:17:30 - INFO - volta.train_utils -   [GQA]: iter 102152 Ep: 3.47 loss 0.027 score 0.081 lr 4.59334e-06 
12/05/2021 21:19:16 - INFO - volta.train_utils -   [GQA]: iter 102312 Ep: 3.47 loss 0.028 score 0.080 lr 4.59184e-06 
12/05/2021 21:21:02 - INFO - volta.train_utils -   [GQA]: iter 102472 Ep: 3.48 loss 0.028 score 0.078 lr 4.59033e-06 
12/05/2021 21:22:48 - INFO - volta.train_utils -   [GQA]: iter 102632 Ep: 3.48 loss 0.027 score 0.081 lr 4.58882e-06 
12/05/2021 21:24:34 - INFO - volta.train_utils -   [GQA]: iter 102792 Ep: 3.49 loss 0.026 score 0.079 lr 4.58731e-06 
12/05/2021 21:26:20 - INFO - volta.train_utils -   [GQA]: iter 102952 Ep: 3.49 loss 0.027 score 0.082 lr 4.5858e-06 
12/05/2021 21:28:05 - INFO - volta.train_utils -   [GQA]: iter 103112 Ep: 3.50 loss 0.030 score 0.081 lr 4.58429e-06 
12/05/2021 21:29:51 - INFO - volta.train_utils -   [GQA]: iter 103272 Ep: 3.50 loss 0.028 score 0.079 lr 4.58279e-06 
12/05/2021 21:31:37 - INFO - volta.train_utils -   [GQA]: iter 103432 Ep: 3.51 loss 0.028 score 0.080 lr 4.58128e-06 
12/05/2021 21:33:23 - INFO - volta.train_utils -   [GQA]: iter 103592 Ep: 3.52 loss 0.028 score 0.080 lr 4.57977e-06 
12/05/2021 21:35:09 - INFO - volta.train_utils -   [GQA]: iter 103752 Ep: 3.52 loss 0.027 score 0.083 lr 4.57826e-06 
12/05/2021 21:36:55 - INFO - volta.train_utils -   [GQA]: iter 103912 Ep: 3.53 loss 0.029 score 0.080 lr 4.57675e-06 
12/05/2021 21:38:41 - INFO - volta.train_utils -   [GQA]: iter 104072 Ep: 3.53 loss 0.026 score 0.080 lr 4.57525e-06 
12/05/2021 21:40:27 - INFO - volta.train_utils -   [GQA]: iter 104232 Ep: 3.54 loss 0.029 score 0.081 lr 4.57374e-06 
12/05/2021 21:42:13 - INFO - volta.train_utils -   [GQA]: iter 104392 Ep: 3.54 loss 0.027 score 0.081 lr 4.57223e-06 
12/05/2021 21:43:59 - INFO - volta.train_utils -   [GQA]: iter 104552 Ep: 3.55 loss 0.028 score 0.080 lr 4.57072e-06 
12/05/2021 21:45:44 - INFO - volta.train_utils -   [GQA]: iter 104712 Ep: 3.55 loss 0.026 score 0.080 lr 4.56921e-06 
12/05/2021 21:47:30 - INFO - volta.train_utils -   [GQA]: iter 104872 Ep: 3.56 loss 0.027 score 0.080 lr 4.5677e-06 
12/05/2021 21:49:16 - INFO - volta.train_utils -   [GQA]: iter 105032 Ep: 3.56 loss 0.028 score 0.082 lr 4.5662e-06 
12/05/2021 21:51:02 - INFO - volta.train_utils -   [GQA]: iter 105192 Ep: 3.57 loss 0.025 score 0.082 lr 4.56469e-06 
12/05/2021 21:52:48 - INFO - volta.train_utils -   [GQA]: iter 105352 Ep: 3.58 loss 0.026 score 0.081 lr 4.56318e-06 
12/05/2021 21:54:34 - INFO - volta.train_utils -   [GQA]: iter 105512 Ep: 3.58 loss 0.025 score 0.083 lr 4.56167e-06 
12/05/2021 21:56:20 - INFO - volta.train_utils -   [GQA]: iter 105672 Ep: 3.59 loss 0.027 score 0.082 lr 4.56016e-06 
12/05/2021 21:58:06 - INFO - volta.train_utils -   [GQA]: iter 105832 Ep: 3.59 loss 0.028 score 0.079 lr 4.55865e-06 
12/05/2021 21:59:52 - INFO - volta.train_utils -   [GQA]: iter 105992 Ep: 3.60 loss 0.027 score 0.082 lr 4.55715e-06 
12/05/2021 22:01:38 - INFO - volta.train_utils -   [GQA]: iter 106152 Ep: 3.60 loss 0.027 score 0.081 lr 4.55564e-06 
12/05/2021 22:03:24 - INFO - volta.train_utils -   [GQA]: iter 106312 Ep: 3.61 loss 0.029 score 0.080 lr 4.55413e-06 
12/05/2021 22:05:10 - INFO - volta.train_utils -   [GQA]: iter 106472 Ep: 3.61 loss 0.027 score 0.082 lr 4.55262e-06 
12/05/2021 22:06:55 - INFO - volta.train_utils -   [GQA]: iter 106632 Ep: 3.62 loss 0.025 score 0.082 lr 4.55111e-06 
12/05/2021 22:08:42 - INFO - volta.train_utils -   [GQA]: iter 106792 Ep: 3.62 loss 0.026 score 0.081 lr 4.54961e-06 
12/05/2021 22:10:27 - INFO - volta.train_utils -   [GQA]: iter 106952 Ep: 3.63 loss 0.027 score 0.082 lr 4.5481e-06 
12/05/2021 22:12:13 - INFO - volta.train_utils -   [GQA]: iter 107112 Ep: 3.63 loss 0.026 score 0.084 lr 4.54659e-06 
12/05/2021 22:13:59 - INFO - volta.train_utils -   [GQA]: iter 107272 Ep: 3.64 loss 0.026 score 0.082 lr 4.54508e-06 
12/05/2021 22:15:45 - INFO - volta.train_utils -   [GQA]: iter 107432 Ep: 3.65 loss 0.026 score 0.081 lr 4.54357e-06 
12/05/2021 22:17:31 - INFO - volta.train_utils -   [GQA]: iter 107592 Ep: 3.65 loss 0.023 score 0.084 lr 4.54206e-06 
12/05/2021 22:19:17 - INFO - volta.train_utils -   [GQA]: iter 107752 Ep: 3.66 loss 0.026 score 0.082 lr 4.54056e-06 
12/05/2021 22:21:03 - INFO - volta.train_utils -   [GQA]: iter 107912 Ep: 3.66 loss 0.026 score 0.083 lr 4.53905e-06 
12/05/2021 22:22:48 - INFO - volta.train_utils -   [GQA]: iter 108072 Ep: 3.67 loss 0.027 score 0.080 lr 4.53754e-06 
12/05/2021 22:24:34 - INFO - volta.train_utils -   [GQA]: iter 108232 Ep: 3.67 loss 0.023 score 0.084 lr 4.53603e-06 
12/05/2021 22:26:20 - INFO - volta.train_utils -   [GQA]: iter 108392 Ep: 3.68 loss 0.028 score 0.084 lr 4.53452e-06 
12/05/2021 22:28:06 - INFO - volta.train_utils -   [GQA]: iter 108552 Ep: 3.68 loss 0.026 score 0.084 lr 4.53302e-06 
12/05/2021 22:29:52 - INFO - volta.train_utils -   [GQA]: iter 108712 Ep: 3.69 loss 0.027 score 0.083 lr 4.53151e-06 
12/05/2021 22:31:38 - INFO - volta.train_utils -   [GQA]: iter 108872 Ep: 3.69 loss 0.027 score 0.082 lr 4.53e-06 
12/05/2021 22:33:24 - INFO - volta.train_utils -   [GQA]: iter 109032 Ep: 3.70 loss 0.026 score 0.082 lr 4.52849e-06 
12/05/2021 22:35:10 - INFO - volta.train_utils -   [GQA]: iter 109192 Ep: 3.71 loss 0.026 score 0.085 lr 4.52698e-06 
12/05/2021 22:36:56 - INFO - volta.train_utils -   [GQA]: iter 109352 Ep: 3.71 loss 0.025 score 0.082 lr 4.52547e-06 
12/05/2021 22:38:42 - INFO - volta.train_utils -   [GQA]: iter 109512 Ep: 3.72 loss 0.026 score 0.082 lr 4.52397e-06 
12/05/2021 22:40:28 - INFO - volta.train_utils -   [GQA]: iter 109672 Ep: 3.72 loss 0.029 score 0.081 lr 4.52246e-06 
12/05/2021 22:42:14 - INFO - volta.train_utils -   [GQA]: iter 109832 Ep: 3.73 loss 0.025 score 0.083 lr 4.52095e-06 
12/05/2021 22:44:00 - INFO - volta.train_utils -   [GQA]: iter 109992 Ep: 3.73 loss 0.028 score 0.081 lr 4.51944e-06 
12/05/2021 22:45:46 - INFO - volta.train_utils -   [GQA]: iter 110152 Ep: 3.74 loss 0.026 score 0.083 lr 4.51793e-06 
12/05/2021 22:47:31 - INFO - volta.train_utils -   [GQA]: iter 110312 Ep: 3.74 loss 0.028 score 0.083 lr 4.51642e-06 
12/05/2021 22:49:18 - INFO - volta.train_utils -   [GQA]: iter 110472 Ep: 3.75 loss 0.026 score 0.084 lr 4.51492e-06 
12/05/2021 22:51:03 - INFO - volta.train_utils -   [GQA]: iter 110632 Ep: 3.75 loss 0.026 score 0.084 lr 4.51341e-06 
12/05/2021 22:52:49 - INFO - volta.train_utils -   [GQA]: iter 110792 Ep: 3.76 loss 0.026 score 0.083 lr 4.5119e-06 
12/05/2021 22:54:35 - INFO - volta.train_utils -   [GQA]: iter 110952 Ep: 3.77 loss 0.025 score 0.086 lr 4.51039e-06 
12/05/2021 22:56:21 - INFO - volta.train_utils -   [GQA]: iter 111112 Ep: 3.77 loss 0.027 score 0.083 lr 4.50888e-06 
12/05/2021 22:58:07 - INFO - volta.train_utils -   [GQA]: iter 111272 Ep: 3.78 loss 0.023 score 0.085 lr 4.50738e-06 
12/05/2021 22:59:53 - INFO - volta.train_utils -   [GQA]: iter 111432 Ep: 3.78 loss 0.025 score 0.083 lr 4.50587e-06 
12/05/2021 23:01:39 - INFO - volta.train_utils -   [GQA]: iter 111592 Ep: 3.79 loss 0.028 score 0.084 lr 4.50436e-06 
12/05/2021 23:03:25 - INFO - volta.train_utils -   [GQA]: iter 111752 Ep: 3.79 loss 0.025 score 0.083 lr 4.50285e-06 
12/05/2021 23:05:11 - INFO - volta.train_utils -   [GQA]: iter 111912 Ep: 3.80 loss 0.022 score 0.084 lr 4.50134e-06 
12/05/2021 23:06:57 - INFO - volta.train_utils -   [GQA]: iter 112072 Ep: 3.80 loss 0.028 score 0.084 lr 4.49983e-06 
12/05/2021 23:08:43 - INFO - volta.train_utils -   [GQA]: iter 112232 Ep: 3.81 loss 0.027 score 0.088 lr 4.49833e-06 
12/05/2021 23:10:29 - INFO - volta.train_utils -   [GQA]: iter 112392 Ep: 3.81 loss 0.025 score 0.084 lr 4.49682e-06 
12/05/2021 23:12:15 - INFO - volta.train_utils -   [GQA]: iter 112552 Ep: 3.82 loss 0.026 score 0.084 lr 4.49531e-06 
12/05/2021 23:14:01 - INFO - volta.train_utils -   [GQA]: iter 112712 Ep: 3.82 loss 0.026 score 0.083 lr 4.4938e-06 
12/05/2021 23:15:47 - INFO - volta.train_utils -   [GQA]: iter 112872 Ep: 3.83 loss 0.025 score 0.085 lr 4.49229e-06 
12/05/2021 23:17:33 - INFO - volta.train_utils -   [GQA]: iter 113032 Ep: 3.84 loss 0.023 score 0.085 lr 4.49078e-06 
12/05/2021 23:19:19 - INFO - volta.train_utils -   [GQA]: iter 113192 Ep: 3.84 loss 0.028 score 0.083 lr 4.48928e-06 
12/05/2021 23:21:04 - INFO - volta.train_utils -   [GQA]: iter 113352 Ep: 3.85 loss 0.025 score 0.084 lr 4.48777e-06 
12/05/2021 23:22:50 - INFO - volta.train_utils -   [GQA]: iter 113512 Ep: 3.85 loss 0.025 score 0.085 lr 4.48626e-06 
12/05/2021 23:24:36 - INFO - volta.train_utils -   [GQA]: iter 113672 Ep: 3.86 loss 0.022 score 0.086 lr 4.48475e-06 
12/05/2021 23:26:22 - INFO - volta.train_utils -   [GQA]: iter 113832 Ep: 3.86 loss 0.026 score 0.085 lr 4.48324e-06 
12/05/2021 23:28:08 - INFO - volta.train_utils -   [GQA]: iter 113992 Ep: 3.87 loss 0.025 score 0.085 lr 4.48174e-06 
12/05/2021 23:29:54 - INFO - volta.train_utils -   [GQA]: iter 114152 Ep: 3.87 loss 0.023 score 0.086 lr 4.48023e-06 
12/05/2021 23:31:40 - INFO - volta.train_utils -   [GQA]: iter 114312 Ep: 3.88 loss 0.023 score 0.086 lr 4.47872e-06 
12/05/2021 23:33:26 - INFO - volta.train_utils -   [GQA]: iter 114472 Ep: 3.88 loss 0.024 score 0.085 lr 4.47721e-06 
12/05/2021 23:35:12 - INFO - volta.train_utils -   [GQA]: iter 114632 Ep: 3.89 loss 0.025 score 0.086 lr 4.4757e-06 
12/05/2021 23:36:58 - INFO - volta.train_utils -   [GQA]: iter 114792 Ep: 3.90 loss 0.027 score 0.087 lr 4.47419e-06 
12/05/2021 23:38:44 - INFO - volta.train_utils -   [GQA]: iter 114952 Ep: 3.90 loss 0.025 score 0.086 lr 4.47269e-06 
12/05/2021 23:40:30 - INFO - volta.train_utils -   [GQA]: iter 115112 Ep: 3.91 loss 0.025 score 0.084 lr 4.47118e-06 
12/05/2021 23:42:16 - INFO - volta.train_utils -   [GQA]: iter 115272 Ep: 3.91 loss 0.024 score 0.084 lr 4.46967e-06 
12/05/2021 23:44:02 - INFO - volta.train_utils -   [GQA]: iter 115432 Ep: 3.92 loss 0.025 score 0.086 lr 4.46816e-06 
12/05/2021 23:45:48 - INFO - volta.train_utils -   [GQA]: iter 115592 Ep: 3.92 loss 0.021 score 0.087 lr 4.46665e-06 
12/05/2021 23:47:34 - INFO - volta.train_utils -   [GQA]: iter 115752 Ep: 3.93 loss 0.026 score 0.084 lr 4.46514e-06 
12/05/2021 23:49:20 - INFO - volta.train_utils -   [GQA]: iter 115912 Ep: 3.93 loss 0.024 score 0.086 lr 4.46364e-06 
12/05/2021 23:51:06 - INFO - volta.train_utils -   [GQA]: iter 116072 Ep: 3.94 loss 0.024 score 0.086 lr 4.46213e-06 
12/05/2021 23:52:52 - INFO - volta.train_utils -   [GQA]: iter 116232 Ep: 3.94 loss 0.023 score 0.085 lr 4.46062e-06 
12/05/2021 23:54:38 - INFO - volta.train_utils -   [GQA]: iter 116392 Ep: 3.95 loss 0.024 score 0.087 lr 4.45911e-06 
12/05/2021 23:56:24 - INFO - volta.train_utils -   [GQA]: iter 116552 Ep: 3.96 loss 0.024 score 0.086 lr 4.4576e-06 
12/05/2021 23:58:10 - INFO - volta.train_utils -   [GQA]: iter 116712 Ep: 3.96 loss 0.023 score 0.089 lr 4.4561e-06 
12/05/2021 23:59:56 - INFO - volta.train_utils -   [GQA]: iter 116872 Ep: 3.97 loss 0.023 score 0.087 lr 4.45459e-06 
12/06/2021 00:01:41 - INFO - volta.train_utils -   [GQA]: iter 117032 Ep: 3.97 loss 0.022 score 0.089 lr 4.45308e-06 
12/06/2021 00:03:27 - INFO - volta.train_utils -   [GQA]: iter 117192 Ep: 3.98 loss 0.024 score 0.088 lr 4.45157e-06 
12/06/2021 00:05:13 - INFO - volta.train_utils -   [GQA]: iter 117352 Ep: 3.98 loss 0.024 score 0.089 lr 4.45006e-06 
12/06/2021 00:06:59 - INFO - volta.train_utils -   [GQA]: iter 117512 Ep: 3.99 loss 0.022 score 0.089 lr 4.44855e-06 
12/06/2021 00:08:45 - INFO - volta.train_utils -   [GQA]: iter 117672 Ep: 3.99 loss 0.022 score 0.090 lr 4.44705e-06 
12/06/2021 00:10:31 - INFO - volta.train_utils -   [GQA]: iter 117832 Ep: 4.00 loss 0.020 score 0.091 lr 4.44554e-06 
12/06/2021 00:55:57 - INFO - volta.train_utils -   Eval task TASK15 on iteration 117856 
12/06/2021 00:55:57 - INFO - volta.train_utils -   Validation [GQA]: loss 1.788 score 64.441 
12/06/2021 00:55:57 - INFO - __main__ -   ** ** * Saving model * ** ** 
Epoch:  80%|████████  | 4/5 [24:41:48<6:10:25, 22225.91s/it] 12/06/2021 00:58:06 - INFO - volta.train_utils -   [GQA]: iter 118016 Ep: 4.00 loss 0.027 score 0.085 lr 4.44392e-06 
12/06/2021 00:59:51 - INFO - volta.train_utils -   [GQA]: iter 118176 Ep: 4.01 loss 0.027 score 0.082 lr 4.4423e-06 
12/06/2021 01:01:37 - INFO - volta.train_utils -   [GQA]: iter 118336 Ep: 4.02 loss 0.026 score 0.080 lr 4.44079e-06 
12/06/2021 01:03:23 - INFO - volta.train_utils -   [GQA]: iter 118496 Ep: 4.02 loss 0.025 score 0.081 lr 4.43928e-06 
12/06/2021 01:05:09 - INFO - volta.train_utils -   [GQA]: iter 118656 Ep: 4.03 loss 0.027 score 0.079 lr 4.43777e-06 
12/06/2021 01:06:54 - INFO - volta.train_utils -   [GQA]: iter 118816 Ep: 4.03 loss 0.026 score 0.082 lr 4.43626e-06 
12/06/2021 01:08:40 - INFO - volta.train_utils -   [GQA]: iter 118976 Ep: 4.04 loss 0.027 score 0.080 lr 4.43475e-06 
12/06/2021 01:10:26 - INFO - volta.train_utils -   [GQA]: iter 119136 Ep: 4.04 loss 0.026 score 0.082 lr 4.43325e-06 
12/06/2021 01:12:12 - INFO - volta.train_utils -   [GQA]: iter 119296 Ep: 4.05 loss 0.027 score 0.080 lr 4.43174e-06 
12/06/2021 01:13:58 - INFO - volta.train_utils -   [GQA]: iter 119456 Ep: 4.05 loss 0.026 score 0.082 lr 4.43023e-06 
12/06/2021 01:15:44 - INFO - volta.train_utils -   [GQA]: iter 119616 Ep: 4.06 loss 0.026 score 0.082 lr 4.42872e-06 
12/06/2021 01:17:30 - INFO - volta.train_utils -   [GQA]: iter 119776 Ep: 4.06 loss 0.027 score 0.081 lr 4.42721e-06 
12/06/2021 01:19:16 - INFO - volta.train_utils -   [GQA]: iter 119936 Ep: 4.07 loss 0.028 score 0.081 lr 4.4257e-06 
12/06/2021 01:21:01 - INFO - volta.train_utils -   [GQA]: iter 120096 Ep: 4.08 loss 0.027 score 0.080 lr 4.4242e-06 
12/06/2021 01:22:47 - INFO - volta.train_utils -   [GQA]: iter 120256 Ep: 4.08 loss 0.028 score 0.081 lr 4.42269e-06 
12/06/2021 01:24:33 - INFO - volta.train_utils -   [GQA]: iter 120416 Ep: 4.09 loss 0.024 score 0.080 lr 4.42118e-06 
12/06/2021 01:26:19 - INFO - volta.train_utils -   [GQA]: iter 120576 Ep: 4.09 loss 0.027 score 0.082 lr 4.41967e-06 
12/06/2021 01:28:05 - INFO - volta.train_utils -   [GQA]: iter 120736 Ep: 4.10 loss 0.029 score 0.083 lr 4.41816e-06 
12/06/2021 01:29:50 - INFO - volta.train_utils -   [GQA]: iter 120896 Ep: 4.10 loss 0.025 score 0.081 lr 4.41666e-06 
12/06/2021 01:31:37 - INFO - volta.train_utils -   [GQA]: iter 121056 Ep: 4.11 loss 0.027 score 0.081 lr 4.41515e-06 
12/06/2021 01:33:22 - INFO - volta.train_utils -   [GQA]: iter 121216 Ep: 4.11 loss 0.027 score 0.082 lr 4.41364e-06 
12/06/2021 01:35:08 - INFO - volta.train_utils -   [GQA]: iter 121376 Ep: 4.12 loss 0.026 score 0.081 lr 4.41213e-06 
12/06/2021 01:36:55 - INFO - volta.train_utils -   [GQA]: iter 121536 Ep: 4.12 loss 0.026 score 0.081 lr 4.41062e-06 
12/06/2021 01:38:40 - INFO - volta.train_utils -   [GQA]: iter 121696 Ep: 4.13 loss 0.026 score 0.084 lr 4.40911e-06 
12/06/2021 01:40:26 - INFO - volta.train_utils -   [GQA]: iter 121856 Ep: 4.14 loss 0.028 score 0.080 lr 4.40761e-06 
12/06/2021 01:42:12 - INFO - volta.train_utils -   [GQA]: iter 122016 Ep: 4.14 loss 0.027 score 0.082 lr 4.4061e-06 
12/06/2021 01:43:58 - INFO - volta.train_utils -   [GQA]: iter 122176 Ep: 4.15 loss 0.029 score 0.080 lr 4.40459e-06 
12/06/2021 01:45:44 - INFO - volta.train_utils -   [GQA]: iter 122336 Ep: 4.15 loss 0.027 score 0.082 lr 4.40308e-06 
12/06/2021 01:47:30 - INFO - volta.train_utils -   [GQA]: iter 122496 Ep: 4.16 loss 0.028 score 0.081 lr 4.40157e-06 
12/06/2021 01:49:15 - INFO - volta.train_utils -   [GQA]: iter 122656 Ep: 4.16 loss 0.028 score 0.082 lr 4.40006e-06 
12/06/2021 01:51:01 - INFO - volta.train_utils -   [GQA]: iter 122816 Ep: 4.17 loss 0.028 score 0.082 lr 4.39856e-06 
12/06/2021 01:52:47 - INFO - volta.train_utils -   [GQA]: iter 122976 Ep: 4.17 loss 0.025 score 0.083 lr 4.39705e-06 
12/06/2021 01:54:33 - INFO - volta.train_utils -   [GQA]: iter 123136 Ep: 4.18 loss 0.025 score 0.082 lr 4.39554e-06 
12/06/2021 01:56:19 - INFO - volta.train_utils -   [GQA]: iter 123296 Ep: 4.18 loss 0.028 score 0.081 lr 4.39403e-06 
12/06/2021 01:58:05 - INFO - volta.train_utils -   [GQA]: iter 123456 Ep: 4.19 loss 0.028 score 0.082 lr 4.39252e-06 
12/06/2021 01:59:51 - INFO - volta.train_utils -   [GQA]: iter 123616 Ep: 4.19 loss 0.026 score 0.083 lr 4.39102e-06 
12/06/2021 02:01:36 - INFO - volta.train_utils -   [GQA]: iter 123776 Ep: 4.20 loss 0.026 score 0.083 lr 4.38951e-06 
12/06/2021 02:03:22 - INFO - volta.train_utils -   [GQA]: iter 123936 Ep: 4.21 loss 0.028 score 0.080 lr 4.388e-06 
12/06/2021 02:05:08 - INFO - volta.train_utils -   [GQA]: iter 124096 Ep: 4.21 loss 0.027 score 0.080 lr 4.38649e-06 
12/06/2021 02:06:54 - INFO - volta.train_utils -   [GQA]: iter 124256 Ep: 4.22 loss 0.024 score 0.081 lr 4.38498e-06 
12/06/2021 02:08:40 - INFO - volta.train_utils -   [GQA]: iter 124416 Ep: 4.22 loss 0.026 score 0.084 lr 4.38347e-06 
12/06/2021 02:10:26 - INFO - volta.train_utils -   [GQA]: iter 124576 Ep: 4.23 loss 0.029 score 0.081 lr 4.38197e-06 
12/06/2021 02:12:12 - INFO - volta.train_utils -   [GQA]: iter 124736 Ep: 4.23 loss 0.025 score 0.083 lr 4.38046e-06 
12/06/2021 02:13:58 - INFO - volta.train_utils -   [GQA]: iter 124896 Ep: 4.24 loss 0.027 score 0.083 lr 4.37895e-06 
12/06/2021 02:15:44 - INFO - volta.train_utils -   [GQA]: iter 125056 Ep: 4.24 loss 0.030 score 0.081 lr 4.37744e-06 
12/06/2021 02:17:30 - INFO - volta.train_utils -   [GQA]: iter 125216 Ep: 4.25 loss 0.027 score 0.083 lr 4.37593e-06 
12/06/2021 02:19:16 - INFO - volta.train_utils -   [GQA]: iter 125376 Ep: 4.25 loss 0.024 score 0.084 lr 4.37442e-06 
12/06/2021 02:21:02 - INFO - volta.train_utils -   [GQA]: iter 125536 Ep: 4.26 loss 0.026 score 0.081 lr 4.37292e-06 
12/06/2021 02:22:48 - INFO - volta.train_utils -   [GQA]: iter 125696 Ep: 4.27 loss 0.027 score 0.083 lr 4.37141e-06 
12/06/2021 02:24:33 - INFO - volta.train_utils -   [GQA]: iter 125856 Ep: 4.27 loss 0.026 score 0.083 lr 4.3699e-06 
12/06/2021 02:26:20 - INFO - volta.train_utils -   [GQA]: iter 126016 Ep: 4.28 loss 0.027 score 0.083 lr 4.36839e-06 
12/06/2021 02:28:05 - INFO - volta.train_utils -   [GQA]: iter 126176 Ep: 4.28 loss 0.027 score 0.083 lr 4.36688e-06 
12/06/2021 02:29:51 - INFO - volta.train_utils -   [GQA]: iter 126336 Ep: 4.29 loss 0.029 score 0.082 lr 4.36538e-06 
12/06/2021 02:31:37 - INFO - volta.train_utils -   [GQA]: iter 126496 Ep: 4.29 loss 0.025 score 0.084 lr 4.36387e-06 
12/06/2021 02:33:23 - INFO - volta.train_utils -   [GQA]: iter 126656 Ep: 4.30 loss 0.026 score 0.083 lr 4.36236e-06 
12/06/2021 02:35:09 - INFO - volta.train_utils -   [GQA]: iter 126816 Ep: 4.30 loss 0.026 score 0.080 lr 4.36085e-06 
12/06/2021 02:36:55 - INFO - volta.train_utils -   [GQA]: iter 126976 Ep: 4.31 loss 0.025 score 0.083 lr 4.35934e-06 
12/06/2021 02:38:41 - INFO - volta.train_utils -   [GQA]: iter 127136 Ep: 4.31 loss 0.026 score 0.083 lr 4.35783e-06 
12/06/2021 02:40:27 - INFO - volta.train_utils -   [GQA]: iter 127296 Ep: 4.32 loss 0.026 score 0.083 lr 4.35633e-06 
12/06/2021 02:42:12 - INFO - volta.train_utils -   [GQA]: iter 127456 Ep: 4.33 loss 0.025 score 0.083 lr 4.35482e-06 
12/06/2021 02:43:58 - INFO - volta.train_utils -   [GQA]: iter 127616 Ep: 4.33 loss 0.025 score 0.083 lr 4.35331e-06 
12/06/2021 02:45:44 - INFO - volta.train_utils -   [GQA]: iter 127776 Ep: 4.34 loss 0.025 score 0.083 lr 4.3518e-06 
12/06/2021 02:47:30 - INFO - volta.train_utils -   [GQA]: iter 127936 Ep: 4.34 loss 0.027 score 0.082 lr 4.35029e-06 
12/06/2021 02:49:16 - INFO - volta.train_utils -   [GQA]: iter 128096 Ep: 4.35 loss 0.027 score 0.082 lr 4.34879e-06 
12/06/2021 02:51:02 - INFO - volta.train_utils -   [GQA]: iter 128256 Ep: 4.35 loss 0.026 score 0.084 lr 4.34728e-06 
12/06/2021 02:52:48 - INFO - volta.train_utils -   [GQA]: iter 128416 Ep: 4.36 loss 0.025 score 0.084 lr 4.34577e-06 
12/06/2021 02:54:34 - INFO - volta.train_utils -   [GQA]: iter 128576 Ep: 4.36 loss 0.026 score 0.084 lr 4.34426e-06 
12/06/2021 02:56:20 - INFO - volta.train_utils -   [GQA]: iter 128736 Ep: 4.37 loss 0.026 score 0.083 lr 4.34275e-06 
12/06/2021 02:58:05 - INFO - volta.train_utils -   [GQA]: iter 128896 Ep: 4.37 loss 0.027 score 0.083 lr 4.34124e-06 
12/06/2021 02:59:51 - INFO - volta.train_utils -   [GQA]: iter 129056 Ep: 4.38 loss 0.026 score 0.084 lr 4.33974e-06 
12/06/2021 03:01:37 - INFO - volta.train_utils -   [GQA]: iter 129216 Ep: 4.38 loss 0.026 score 0.081 lr 4.33823e-06 
12/06/2021 03:03:23 - INFO - volta.train_utils -   [GQA]: iter 129376 Ep: 4.39 loss 0.026 score 0.083 lr 4.33672e-06 
12/06/2021 03:05:09 - INFO - volta.train_utils -   [GQA]: iter 129536 Ep: 4.40 loss 0.026 score 0.083 lr 4.33521e-06 
12/06/2021 03:06:56 - INFO - volta.train_utils -   [GQA]: iter 129696 Ep: 4.40 loss 0.025 score 0.086 lr 4.3337e-06 
12/06/2021 03:08:41 - INFO - volta.train_utils -   [GQA]: iter 129856 Ep: 4.41 loss 0.024 score 0.085 lr 4.33219e-06 
12/06/2021 03:10:27 - INFO - volta.train_utils -   [GQA]: iter 130016 Ep: 4.41 loss 0.027 score 0.083 lr 4.33069e-06 
12/06/2021 03:12:13 - INFO - volta.train_utils -   [GQA]: iter 130176 Ep: 4.42 loss 0.025 score 0.084 lr 4.32918e-06 
12/06/2021 03:13:59 - INFO - volta.train_utils -   [GQA]: iter 130336 Ep: 4.42 loss 0.026 score 0.083 lr 4.32767e-06 
12/06/2021 03:15:45 - INFO - volta.train_utils -   [GQA]: iter 130496 Ep: 4.43 loss 0.027 score 0.082 lr 4.32616e-06 
12/06/2021 03:17:31 - INFO - volta.train_utils -   [GQA]: iter 130656 Ep: 4.43 loss 0.024 score 0.084 lr 4.32465e-06 
12/06/2021 03:19:17 - INFO - volta.train_utils -   [GQA]: iter 130816 Ep: 4.44 loss 0.027 score 0.083 lr 4.32315e-06 
12/06/2021 03:21:03 - INFO - volta.train_utils -   [GQA]: iter 130976 Ep: 4.44 loss 0.025 score 0.084 lr 4.32164e-06 
12/06/2021 03:22:49 - INFO - volta.train_utils -   [GQA]: iter 131136 Ep: 4.45 loss 0.023 score 0.083 lr 4.32013e-06 
12/06/2021 03:24:35 - INFO - volta.train_utils -   [GQA]: iter 131296 Ep: 4.46 loss 0.026 score 0.084 lr 4.31862e-06 
12/06/2021 03:26:20 - INFO - volta.train_utils -   [GQA]: iter 131456 Ep: 4.46 loss 0.027 score 0.084 lr 4.31711e-06 
12/06/2021 03:28:06 - INFO - volta.train_utils -   [GQA]: iter 131616 Ep: 4.47 loss 0.024 score 0.085 lr 4.3156e-06 
12/06/2021 03:29:52 - INFO - volta.train_utils -   [GQA]: iter 131776 Ep: 4.47 loss 0.024 score 0.083 lr 4.3141e-06 
12/06/2021 03:31:38 - INFO - volta.train_utils -   [GQA]: iter 131936 Ep: 4.48 loss 0.027 score 0.082 lr 4.31259e-06 
12/06/2021 03:33:24 - INFO - volta.train_utils -   [GQA]: iter 132096 Ep: 4.48 loss 0.024 score 0.086 lr 4.31108e-06 
12/06/2021 03:35:10 - INFO - volta.train_utils -   [GQA]: iter 132256 Ep: 4.49 loss 0.024 score 0.084 lr 4.30957e-06 
12/06/2021 03:36:56 - INFO - volta.train_utils -   [GQA]: iter 132416 Ep: 4.49 loss 0.023 score 0.085 lr 4.30806e-06 
12/06/2021 03:38:42 - INFO - volta.train_utils -   [GQA]: iter 132576 Ep: 4.50 loss 0.025 score 0.084 lr 4.30655e-06 
12/06/2021 03:40:28 - INFO - volta.train_utils -   [GQA]: iter 132736 Ep: 4.50 loss 0.026 score 0.084 lr 4.30505e-06 
12/06/2021 03:42:13 - INFO - volta.train_utils -   [GQA]: iter 132896 Ep: 4.51 loss 0.024 score 0.085 lr 4.30354e-06 
12/06/2021 03:43:59 - INFO - volta.train_utils -   [GQA]: iter 133056 Ep: 4.52 loss 0.024 score 0.085 lr 4.30203e-06 
12/06/2021 03:45:45 - INFO - volta.train_utils -   [GQA]: iter 133216 Ep: 4.52 loss 0.024 score 0.086 lr 4.30052e-06 
12/06/2021 03:47:31 - INFO - volta.train_utils -   [GQA]: iter 133376 Ep: 4.53 loss 0.026 score 0.084 lr 4.29901e-06 
12/06/2021 03:49:17 - INFO - volta.train_utils -   [GQA]: iter 133536 Ep: 4.53 loss 0.025 score 0.085 lr 4.29751e-06 
12/06/2021 03:51:03 - INFO - volta.train_utils -   [GQA]: iter 133696 Ep: 4.54 loss 0.024 score 0.085 lr 4.296e-06 
12/06/2021 03:52:49 - INFO - volta.train_utils -   [GQA]: iter 133856 Ep: 4.54 loss 0.023 score 0.085 lr 4.29449e-06 
12/06/2021 03:54:35 - INFO - volta.train_utils -   [GQA]: iter 134016 Ep: 4.55 loss 0.025 score 0.083 lr 4.29298e-06 
12/06/2021 03:56:21 - INFO - volta.train_utils -   [GQA]: iter 134176 Ep: 4.55 loss 0.023 score 0.085 lr 4.29147e-06 
12/06/2021 03:58:07 - INFO - volta.train_utils -   [GQA]: iter 134336 Ep: 4.56 loss 0.025 score 0.084 lr 4.28996e-06 
12/06/2021 03:59:53 - INFO - volta.train_utils -   [GQA]: iter 134496 Ep: 4.56 loss 0.025 score 0.085 lr 4.28846e-06 
12/06/2021 04:01:38 - INFO - volta.train_utils -   [GQA]: iter 134656 Ep: 4.57 loss 0.024 score 0.086 lr 4.28695e-06 
12/06/2021 04:03:25 - INFO - volta.train_utils -   [GQA]: iter 134816 Ep: 4.57 loss 0.024 score 0.086 lr 4.28544e-06 
12/06/2021 04:05:10 - INFO - volta.train_utils -   [GQA]: iter 134976 Ep: 4.58 loss 0.024 score 0.088 lr 4.28393e-06 
12/06/2021 04:06:56 - INFO - volta.train_utils -   [GQA]: iter 135136 Ep: 4.59 loss 0.025 score 0.084 lr 4.28242e-06 
12/06/2021 04:08:42 - INFO - volta.train_utils -   [GQA]: iter 135296 Ep: 4.59 loss 0.025 score 0.084 lr 4.28091e-06 
12/06/2021 04:10:28 - INFO - volta.train_utils -   [GQA]: iter 135456 Ep: 4.60 loss 0.025 score 0.085 lr 4.27941e-06 
12/06/2021 04:12:14 - INFO - volta.train_utils -   [GQA]: iter 135616 Ep: 4.60 loss 0.025 score 0.084 lr 4.2779e-06 
12/06/2021 04:14:00 - INFO - volta.train_utils -   [GQA]: iter 135776 Ep: 4.61 loss 0.026 score 0.083 lr 4.27639e-06 
12/06/2021 04:15:46 - INFO - volta.train_utils -   [GQA]: iter 135936 Ep: 4.61 loss 0.023 score 0.086 lr 4.27488e-06 
12/06/2021 04:17:32 - INFO - volta.train_utils -   [GQA]: iter 136096 Ep: 4.62 loss 0.024 score 0.085 lr 4.27337e-06 
12/06/2021 04:19:18 - INFO - volta.train_utils -   [GQA]: iter 136256 Ep: 4.62 loss 0.023 score 0.085 lr 4.27187e-06 
12/06/2021 04:21:03 - INFO - volta.train_utils -   [GQA]: iter 136416 Ep: 4.63 loss 0.024 score 0.087 lr 4.27036e-06 
12/06/2021 04:22:49 - INFO - volta.train_utils -   [GQA]: iter 136576 Ep: 4.63 loss 0.023 score 0.087 lr 4.26885e-06 
12/06/2021 04:24:35 - INFO - volta.train_utils -   [GQA]: iter 136736 Ep: 4.64 loss 0.024 score 0.086 lr 4.26734e-06 
12/06/2021 04:26:21 - INFO - volta.train_utils -   [GQA]: iter 136896 Ep: 4.65 loss 0.025 score 0.085 lr 4.26583e-06 
12/06/2021 04:28:07 - INFO - volta.train_utils -   [GQA]: iter 137056 Ep: 4.65 loss 0.023 score 0.087 lr 4.26432e-06 
12/06/2021 04:29:53 - INFO - volta.train_utils -   [GQA]: iter 137216 Ep: 4.66 loss 0.025 score 0.085 lr 4.26282e-06 
12/06/2021 04:31:39 - INFO - volta.train_utils -   [GQA]: iter 137376 Ep: 4.66 loss 0.025 score 0.086 lr 4.26131e-06 
12/06/2021 04:33:25 - INFO - volta.train_utils -   [GQA]: iter 137536 Ep: 4.67 loss 0.026 score 0.085 lr 4.2598e-06 
12/06/2021 04:35:11 - INFO - volta.train_utils -   [GQA]: iter 137696 Ep: 4.67 loss 0.023 score 0.087 lr 4.25829e-06 
12/06/2021 04:36:57 - INFO - volta.train_utils -   [GQA]: iter 137856 Ep: 4.68 loss 0.023 score 0.087 lr 4.25678e-06 
12/06/2021 04:38:43 - INFO - volta.train_utils -   [GQA]: iter 138016 Ep: 4.68 loss 0.023 score 0.088 lr 4.25528e-06 
12/06/2021 04:40:28 - INFO - volta.train_utils -   [GQA]: iter 138176 Ep: 4.69 loss 0.024 score 0.086 lr 4.25377e-06 
12/06/2021 04:42:14 - INFO - volta.train_utils -   [GQA]: iter 138336 Ep: 4.69 loss 0.024 score 0.085 lr 4.25226e-06 
12/06/2021 04:44:00 - INFO - volta.train_utils -   [GQA]: iter 138496 Ep: 4.70 loss 0.025 score 0.085 lr 4.25075e-06 
12/06/2021 04:45:46 - INFO - volta.train_utils -   [GQA]: iter 138656 Ep: 4.71 loss 0.023 score 0.087 lr 4.24924e-06 
12/06/2021 04:47:31 - INFO - volta.train_utils -   [GQA]: iter 138816 Ep: 4.71 loss 0.022 score 0.087 lr 4.24773e-06 
12/06/2021 04:49:17 - INFO - volta.train_utils -   [GQA]: iter 138976 Ep: 4.72 loss 0.026 score 0.084 lr 4.24623e-06 
12/06/2021 04:51:03 - INFO - volta.train_utils -   [GQA]: iter 139136 Ep: 4.72 loss 0.025 score 0.083 lr 4.24472e-06 
12/06/2021 04:52:49 - INFO - volta.train_utils -   [GQA]: iter 139296 Ep: 4.73 loss 0.023 score 0.087 lr 4.24321e-06 
12/06/2021 04:54:35 - INFO - volta.train_utils -   [GQA]: iter 139456 Ep: 4.73 loss 0.024 score 0.086 lr 4.2417e-06 
12/06/2021 04:56:21 - INFO - volta.train_utils -   [GQA]: iter 139616 Ep: 4.74 loss 0.023 score 0.088 lr 4.24019e-06 
12/06/2021 04:58:07 - INFO - volta.train_utils -   [GQA]: iter 139776 Ep: 4.74 loss 0.027 score 0.086 lr 4.23868e-06 
12/06/2021 04:59:53 - INFO - volta.train_utils -   [GQA]: iter 139936 Ep: 4.75 loss 0.025 score 0.088 lr 4.23718e-06 
12/06/2021 05:01:38 - INFO - volta.train_utils -   [GQA]: iter 140096 Ep: 4.75 loss 0.022 score 0.088 lr 4.23567e-06 
12/06/2021 05:03:24 - INFO - volta.train_utils -   [GQA]: iter 140256 Ep: 4.76 loss 0.024 score 0.086 lr 4.23416e-06 
12/06/2021 05:05:10 - INFO - volta.train_utils -   [GQA]: iter 140416 Ep: 4.77 loss 0.023 score 0.089 lr 4.23265e-06 
12/06/2021 05:06:56 - INFO - volta.train_utils -   [GQA]: iter 140576 Ep: 4.77 loss 0.024 score 0.086 lr 4.23114e-06 
12/06/2021 05:08:42 - INFO - volta.train_utils -   [GQA]: iter 140736 Ep: 4.78 loss 0.023 score 0.089 lr 4.22964e-06 
12/06/2021 05:10:28 - INFO - volta.train_utils -   [GQA]: iter 140896 Ep: 4.78 loss 0.024 score 0.086 lr 4.22813e-06 
12/06/2021 05:12:13 - INFO - volta.train_utils -   [GQA]: iter 141056 Ep: 4.79 loss 0.024 score 0.086 lr 4.22662e-06 
12/06/2021 05:13:59 - INFO - volta.train_utils -   [GQA]: iter 141216 Ep: 4.79 loss 0.025 score 0.086 lr 4.22511e-06 
12/06/2021 05:15:45 - INFO - volta.train_utils -   [GQA]: iter 141376 Ep: 4.80 loss 0.024 score 0.088 lr 4.2236e-06 
12/06/2021 05:17:31 - INFO - volta.train_utils -   [GQA]: iter 141536 Ep: 4.80 loss 0.025 score 0.087 lr 4.22209e-06 
12/06/2021 05:19:17 - INFO - volta.train_utils -   [GQA]: iter 141696 Ep: 4.81 loss 0.021 score 0.091 lr 4.22059e-06 
12/06/2021 05:21:03 - INFO - volta.train_utils -   [GQA]: iter 141856 Ep: 4.81 loss 0.025 score 0.088 lr 4.21908e-06 
12/06/2021 05:22:49 - INFO - volta.train_utils -   [GQA]: iter 142016 Ep: 4.82 loss 0.023 score 0.088 lr 4.21757e-06 
12/06/2021 05:24:35 - INFO - volta.train_utils -   [GQA]: iter 142176 Ep: 4.82 loss 0.024 score 0.088 lr 4.21606e-06 
12/06/2021 05:26:21 - INFO - volta.train_utils -   [GQA]: iter 142336 Ep: 4.83 loss 0.024 score 0.088 lr 4.21455e-06 
12/06/2021 05:28:07 - INFO - volta.train_utils -   [GQA]: iter 142496 Ep: 4.84 loss 0.022 score 0.089 lr 4.21304e-06 
12/06/2021 05:29:53 - INFO - volta.train_utils -   [GQA]: iter 142656 Ep: 4.84 loss 0.024 score 0.086 lr 4.21154e-06 
12/06/2021 05:31:39 - INFO - volta.train_utils -   [GQA]: iter 142816 Ep: 4.85 loss 0.022 score 0.089 lr 4.21003e-06 
12/06/2021 05:33:25 - INFO - volta.train_utils -   [GQA]: iter 142976 Ep: 4.85 loss 0.022 score 0.088 lr 4.20852e-06 
12/06/2021 05:35:11 - INFO - volta.train_utils -   [GQA]: iter 143136 Ep: 4.86 loss 0.023 score 0.089 lr 4.20701e-06 
12/06/2021 05:36:56 - INFO - volta.train_utils -   [GQA]: iter 143296 Ep: 4.86 loss 0.024 score 0.088 lr 4.2055e-06 
12/06/2021 05:38:42 - INFO - volta.train_utils -   [GQA]: iter 143456 Ep: 4.87 loss 0.022 score 0.087 lr 4.204e-06 
12/06/2021 05:40:28 - INFO - volta.train_utils -   [GQA]: iter 143616 Ep: 4.87 loss 0.023 score 0.089 lr 4.20249e-06 
12/06/2021 05:42:14 - INFO - volta.train_utils -   [GQA]: iter 143776 Ep: 4.88 loss 0.021 score 0.088 lr 4.20098e-06 
12/06/2021 05:44:00 - INFO - volta.train_utils -   [GQA]: iter 143936 Ep: 4.88 loss 0.023 score 0.088 lr 4.19947e-06 
12/06/2021 05:45:46 - INFO - volta.train_utils -   [GQA]: iter 144096 Ep: 4.89 loss 0.021 score 0.089 lr 4.19796e-06 
12/06/2021 05:47:32 - INFO - volta.train_utils -   [GQA]: iter 144256 Ep: 4.90 loss 0.021 score 0.089 lr 4.19645e-06 
12/06/2021 05:49:18 - INFO - volta.train_utils -   [GQA]: iter 144416 Ep: 4.90 loss 0.023 score 0.089 lr 4.19495e-06 
12/06/2021 05:51:04 - INFO - volta.train_utils -   [GQA]: iter 144576 Ep: 4.91 loss 0.023 score 0.088 lr 4.19344e-06 
12/06/2021 05:52:50 - INFO - volta.train_utils -   [GQA]: iter 144736 Ep: 4.91 loss 0.024 score 0.088 lr 4.19193e-06 
12/06/2021 05:54:36 - INFO - volta.train_utils -   [GQA]: iter 144896 Ep: 4.92 loss 0.022 score 0.089 lr 4.19042e-06 
12/06/2021 05:56:22 - INFO - volta.train_utils -   [GQA]: iter 145056 Ep: 4.92 loss 0.022 score 0.090 lr 4.18891e-06 
12/06/2021 05:58:08 - INFO - volta.train_utils -   [GQA]: iter 145216 Ep: 4.93 loss 0.023 score 0.087 lr 4.1874e-06 
12/06/2021 05:59:54 - INFO - volta.train_utils -   [GQA]: iter 145376 Ep: 4.93 loss 0.021 score 0.089 lr 4.1859e-06 
12/06/2021 06:01:40 - INFO - volta.train_utils -   [GQA]: iter 145536 Ep: 4.94 loss 0.021 score 0.089 lr 4.18439e-06 
12/06/2021 06:03:25 - INFO - volta.train_utils -   [GQA]: iter 145696 Ep: 4.94 loss 0.024 score 0.087 lr 4.18288e-06 
12/06/2021 06:05:11 - INFO - volta.train_utils -   [GQA]: iter 145856 Ep: 4.95 loss 0.023 score 0.090 lr 4.18137e-06 
12/06/2021 06:06:57 - INFO - volta.train_utils -   [GQA]: iter 146016 Ep: 4.96 loss 0.022 score 0.090 lr 4.17986e-06 
12/06/2021 06:08:43 - INFO - volta.train_utils -   [GQA]: iter 146176 Ep: 4.96 loss 0.023 score 0.091 lr 4.17836e-06 
12/06/2021 06:10:29 - INFO - volta.train_utils -   [GQA]: iter 146336 Ep: 4.97 loss 0.021 score 0.090 lr 4.17685e-06 
12/06/2021 06:12:15 - INFO - volta.train_utils -   [GQA]: iter 146496 Ep: 4.97 loss 0.020 score 0.091 lr 4.17534e-06 
12/06/2021 06:14:01 - INFO - volta.train_utils -   [GQA]: iter 146656 Ep: 4.98 loss 0.021 score 0.090 lr 4.17383e-06 
12/06/2021 06:15:46 - INFO - volta.train_utils -   [GQA]: iter 146816 Ep: 4.98 loss 0.021 score 0.092 lr 4.17232e-06 
12/06/2021 06:17:32 - INFO - volta.train_utils -   [GQA]: iter 146976 Ep: 4.99 loss 0.020 score 0.092 lr 4.17081e-06 
12/06/2021 06:19:18 - INFO - volta.train_utils -   [GQA]: iter 147136 Ep: 4.99 loss 0.019 score 0.093 lr 4.16931e-06 
12/06/2021 06:21:04 - INFO - volta.train_utils -   [GQA]: iter 147296 Ep: 5.00 loss 0.020 score 0.093 lr 4.1678e-06 
12/06/2021 07:06:30 - INFO - volta.train_utils -   Eval task TASK15 on iteration 147320 
12/06/2021 07:06:30 - INFO - volta.train_utils -   Validation [GQA]: loss 1.768 score 65.313 
12/06/2021 07:06:30 - INFO - __main__ -   ** ** * Saving model * ** ** 
Epoch: 100%|██████████| 5/5 [30:52:24<00:00, 22228.73s/it]  
