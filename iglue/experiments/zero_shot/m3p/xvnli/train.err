WARNING:tensorflow:From /home/projects/ku_00062/envs/iglue/lib/python3.6/site-packages/tensorpack/callbacks/hooks.py:17: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.

WARNING:tensorflow:From /home/projects/ku_00062/envs/iglue/lib/python3.6/site-packages/tensorpack/tfutils/optimizer.py:18: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

WARNING:tensorflow:From /home/projects/ku_00062/envs/iglue/lib/python3.6/site-packages/tensorpack/tfutils/sesscreate.py:20: The name tf.train.SessionCreator is deprecated. Please use tf.compat.v1.train.SessionCreator instead.

12/04/2021 23:34:55 - INFO - __main__ -   device: cuda n_gpu: 1, distributed training: False
12/04/2021 23:34:56 - INFO - volta.task_utils -   Loading XVNLI Dataset with batch size 16
12/04/2021 23:34:56 - INFO - volta.datasets.visual_entailment_dataset -   Loading from /home/projects/ku_00062/data/XVNLI/annotations/en/cache/XVNLI_train_xlm-roberta-base_80.pkl
12/04/2021 23:37:50 - INFO - volta.datasets.visual_entailment_dataset -   Loading from /home/projects/ku_00062/data/XVNLI/annotations/en/cache/XVNLI_dev_xlm-roberta-base_80.pkl
12/04/2021 23:37:56 - INFO - volta.train_utils -   logging file at: /home/projects/ku_00062/logs/iglue/xvnli/m3p_base/XVNLI_m3p_base
12/04/2021 23:37:56 - INFO - volta.utils -   loading weights file /home/projects/ku_00062/checkpoints/iglue/pretrain/m3p/m3p_base/m3p_checkpoint_22.bin
12/04/2021 23:38:15 - INFO - volta.utils -   
12/04/2021 23:38:15 - INFO - volta.utils -   Weights of M3PForVLTasks not initialized from pretrained model: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'clfs_dict.TASK19.weight', 'clfs_dict.TASK19.bias']
12/04/2021 23:38:15 - INFO - volta.utils -   Weights from pretrained model not used in M3PForVLTasks: ['bert.encoder.pred_layer.proj.weight', 'bert.encoder.pred_layer.proj.bias', 'bert.encoder.pred_obj_layer.proj.weight', 'bert.encoder.pred_obj_layer.proj.bias']
12/04/2021 23:38:20 - INFO - __main__ -   ** ** * Saving model * ** ** 
/home/projects/ku_00062/envs/iglue/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:216: UserWarning: Please also save or load the state of the optimizer when saving or loading the scheduler.
  warnings.warn(SAVE_STATE_WARNING, UserWarning)
12/04/2021 23:38:33 - INFO - __main__ -   >> Parameters:
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |Name                                                                    |Dtype            |Shape            |#Params      |Trainable|
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.position_embeddings.weight                                 |torch.float32    |(514, 768)       |394752       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.cross_lang_embeddings.weight                               |torch.float32    |(100, 768)       |76800        |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.embeddings.weight                                          |torch.float32    |(250002, 768)    |192001536    |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.layer_norm_emb.weight                                      |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.layer_norm_emb.bias                                        |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.image_embeddings.image_embeddings.weight                   |torch.float32    |(768, 2048)      |1572864      |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.image_embeddings.image_embeddings.bias                     |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.image_embeddings.image_distbution_embeddings.weight        |torch.float32    |(768, 1600)      |1228800      |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.image_embeddings.image_distbution_embeddings.bias          |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.image_embeddings.image_location_embeddings.weight          |torch.float32    |(768, 5)         |3840         |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.image_embeddings.image_location_embeddings.bias            |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.image_embeddings.LayerNorm.weight                          |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.image_embeddings.LayerNorm.bias                            |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.0.self_attn.linears.0.weight      |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.0.self_attn.linears.0.bias        |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.0.self_attn.linears.1.weight      |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.0.self_attn.linears.1.bias        |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.0.self_attn.linears.2.weight      |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.0.self_attn.linears.2.bias        |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.0.self_attn.aoa_layer.0.weight    |torch.float32    |(1536, 1536)     |2359296      |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.0.self_attn.aoa_layer.0.bias      |torch.float32    |(1536,)          |1536         |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.0.feed_forward.lin1.weight        |torch.float32    |(3072, 768)      |2359296      |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.0.feed_forward.lin1.bias          |torch.float32    |(3072,)          |3072         |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.0.feed_forward.lin2.weight        |torch.float32    |(768, 3072)      |2359296      |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.0.feed_forward.lin2.bias          |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.0.sublayer.0.norm.weight          |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.0.sublayer.0.norm.bias            |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.0.sublayer.1.norm.weight          |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.0.sublayer.1.norm.bias            |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.1.self_attn.linears.0.weight      |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.1.self_attn.linears.0.bias        |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.1.self_attn.linears.1.weight      |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.1.self_attn.linears.1.bias        |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.1.self_attn.linears.2.weight      |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.1.self_attn.linears.2.bias        |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.1.self_attn.aoa_layer.0.weight    |torch.float32    |(1536, 1536)     |2359296      |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.1.self_attn.aoa_layer.0.bias      |torch.float32    |(1536,)          |1536         |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.1.feed_forward.lin1.weight        |torch.float32    |(3072, 768)      |2359296      |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.1.feed_forward.lin1.bias          |torch.float32    |(3072,)          |3072         |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.1.feed_forward.lin2.weight        |torch.float32    |(768, 3072)      |2359296      |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.1.feed_forward.lin2.bias          |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.1.sublayer.0.norm.weight          |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.1.sublayer.0.norm.bias            |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.1.sublayer.1.norm.weight          |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.1.sublayer.1.norm.bias            |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.2.self_attn.linears.0.weight      |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.2.self_attn.linears.0.bias        |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.2.self_attn.linears.1.weight      |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.2.self_attn.linears.1.bias        |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.2.self_attn.linears.2.weight      |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.2.self_attn.linears.2.bias        |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.2.self_attn.aoa_layer.0.weight    |torch.float32    |(1536, 1536)     |2359296      |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.2.self_attn.aoa_layer.0.bias      |torch.float32    |(1536,)          |1536         |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.2.feed_forward.lin1.weight        |torch.float32    |(3072, 768)      |2359296      |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.2.feed_forward.lin1.bias          |torch.float32    |(3072,)          |3072         |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.2.feed_forward.lin2.weight        |torch.float32    |(768, 3072)      |2359296      |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.2.feed_forward.lin2.bias          |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.2.sublayer.0.norm.weight          |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.2.sublayer.0.norm.bias            |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.2.sublayer.1.norm.weight          |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.2.sublayer.1.norm.bias            |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.3.self_attn.linears.0.weight      |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.3.self_attn.linears.0.bias        |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.3.self_attn.linears.1.weight      |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.3.self_attn.linears.1.bias        |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.3.self_attn.linears.2.weight      |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.3.self_attn.linears.2.bias        |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.3.self_attn.aoa_layer.0.weight    |torch.float32    |(1536, 1536)     |2359296      |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.3.self_attn.aoa_layer.0.bias      |torch.float32    |(1536,)          |1536         |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.3.feed_forward.lin1.weight        |torch.float32    |(3072, 768)      |2359296      |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.3.feed_forward.lin1.bias          |torch.float32    |(3072,)          |3072         |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.3.feed_forward.lin2.weight        |torch.float32    |(768, 3072)      |2359296      |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.3.feed_forward.lin2.bias          |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.3.sublayer.0.norm.weight          |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.3.sublayer.0.norm.bias            |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.3.sublayer.1.norm.weight          |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.3.sublayer.1.norm.bias            |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.4.self_attn.linears.0.weight      |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.4.self_attn.linears.0.bias        |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.4.self_attn.linears.1.weight      |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.4.self_attn.linears.1.bias        |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.4.self_attn.linears.2.weight      |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.4.self_attn.linears.2.bias        |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.4.self_attn.aoa_layer.0.weight    |torch.float32    |(1536, 1536)     |2359296      |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.4.self_attn.aoa_layer.0.bias      |torch.float32    |(1536,)          |1536         |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.4.feed_forward.lin1.weight        |torch.float32    |(3072, 768)      |2359296      |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.4.feed_forward.lin1.bias          |torch.float32    |(3072,)          |3072         |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.4.feed_forward.lin2.weight        |torch.float32    |(768, 3072)      |2359296      |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.4.feed_forward.lin2.bias          |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.4.sublayer.0.norm.weight          |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.4.sublayer.0.norm.bias            |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.4.sublayer.1.norm.weight          |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.4.sublayer.1.norm.bias            |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.5.self_attn.linears.0.weight      |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.5.self_attn.linears.0.bias        |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.5.self_attn.linears.1.weight      |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.5.self_attn.linears.1.bias        |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.5.self_attn.linears.2.weight      |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.5.self_attn.linears.2.bias        |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.5.self_attn.aoa_layer.0.weight    |torch.float32    |(1536, 1536)     |2359296      |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.5.self_attn.aoa_layer.0.bias      |torch.float32    |(1536,)          |1536         |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.5.feed_forward.lin1.weight        |torch.float32    |(3072, 768)      |2359296      |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.5.feed_forward.lin1.bias          |torch.float32    |(3072,)          |3072         |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.5.feed_forward.lin2.weight        |torch.float32    |(768, 3072)      |2359296      |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.5.feed_forward.lin2.bias          |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.5.sublayer.0.norm.weight          |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.5.sublayer.0.norm.bias            |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.5.sublayer.1.norm.weight          |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.layers.5.sublayer.1.norm.bias            |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.norm.weight                              |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.refine_embeddings.norm.bias                                |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.cross_alignment.att_weight_c.weight                        |torch.float32    |(1, 768)         |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.cross_alignment.att_weight_c.bias                          |torch.float32    |(1,)             |1            |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.cross_alignment.att_weight_q.weight                        |torch.float32    |(1, 768)         |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.cross_alignment.att_weight_q.bias                          |torch.float32    |(1,)             |1            |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.cross_alignment.att_weight_cq.weight                       |torch.float32    |(1, 768)         |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.cross_alignment.att_weight_cq.bias                         |torch.float32    |(1,)             |1            |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.cross_alignment.align_output.weight                        |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.cross_alignment.align_output.bias                          |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.cross_alignment.layer_norm.weight                          |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.cross_alignment.layer_norm.bias                            |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.0.q_lin.weight                                  |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.0.q_lin.bias                                    |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.0.k_lin.weight                                  |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.0.k_lin.bias                                    |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.0.v_lin.weight                                  |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.0.v_lin.bias                                    |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.0.out_lin.weight                                |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.0.out_lin.bias                                  |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.1.q_lin.weight                                  |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.1.q_lin.bias                                    |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.1.k_lin.weight                                  |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.1.k_lin.bias                                    |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.1.v_lin.weight                                  |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.1.v_lin.bias                                    |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.1.out_lin.weight                                |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.1.out_lin.bias                                  |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.2.q_lin.weight                                  |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.2.q_lin.bias                                    |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.2.k_lin.weight                                  |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.2.k_lin.bias                                    |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.2.v_lin.weight                                  |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.2.v_lin.bias                                    |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.2.out_lin.weight                                |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.2.out_lin.bias                                  |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.3.q_lin.weight                                  |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.3.q_lin.bias                                    |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.3.k_lin.weight                                  |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.3.k_lin.bias                                    |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.3.v_lin.weight                                  |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.3.v_lin.bias                                    |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.3.out_lin.weight                                |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.3.out_lin.bias                                  |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.4.q_lin.weight                                  |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.4.q_lin.bias                                    |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.4.k_lin.weight                                  |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.4.k_lin.bias                                    |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.4.v_lin.weight                                  |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.4.v_lin.bias                                    |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.4.out_lin.weight                                |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.4.out_lin.bias                                  |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.5.q_lin.weight                                  |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.5.q_lin.bias                                    |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.5.k_lin.weight                                  |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.5.k_lin.bias                                    |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.5.v_lin.weight                                  |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.5.v_lin.bias                                    |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.5.out_lin.weight                                |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.5.out_lin.bias                                  |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.6.q_lin.weight                                  |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.6.q_lin.bias                                    |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.6.k_lin.weight                                  |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.6.k_lin.bias                                    |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.6.v_lin.weight                                  |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.6.v_lin.bias                                    |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.6.out_lin.weight                                |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.6.out_lin.bias                                  |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.7.q_lin.weight                                  |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.7.q_lin.bias                                    |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.7.k_lin.weight                                  |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.7.k_lin.bias                                    |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.7.v_lin.weight                                  |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.7.v_lin.bias                                    |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.7.out_lin.weight                                |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.7.out_lin.bias                                  |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.8.q_lin.weight                                  |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.8.q_lin.bias                                    |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.8.k_lin.weight                                  |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.8.k_lin.bias                                    |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.8.v_lin.weight                                  |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.8.v_lin.bias                                    |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.8.out_lin.weight                                |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.8.out_lin.bias                                  |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.9.q_lin.weight                                  |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.9.q_lin.bias                                    |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.9.k_lin.weight                                  |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.9.k_lin.bias                                    |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.9.v_lin.weight                                  |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.9.v_lin.bias                                    |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.9.out_lin.weight                                |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.9.out_lin.bias                                  |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.10.q_lin.weight                                 |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.10.q_lin.bias                                   |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.10.k_lin.weight                                 |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.10.k_lin.bias                                   |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.10.v_lin.weight                                 |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.10.v_lin.bias                                   |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.10.out_lin.weight                               |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.10.out_lin.bias                                 |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.11.q_lin.weight                                 |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.11.q_lin.bias                                   |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.11.k_lin.weight                                 |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.11.k_lin.bias                                   |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.11.v_lin.weight                                 |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.11.v_lin.bias                                   |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.11.out_lin.weight                               |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.attentions.11.out_lin.bias                                 |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.layer_norm1.0.weight                                       |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.layer_norm1.0.bias                                         |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.layer_norm1.1.weight                                       |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.layer_norm1.1.bias                                         |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.layer_norm1.2.weight                                       |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.layer_norm1.2.bias                                         |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.layer_norm1.3.weight                                       |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.layer_norm1.3.bias                                         |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.layer_norm1.4.weight                                       |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.layer_norm1.4.bias                                         |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.layer_norm1.5.weight                                       |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.layer_norm1.5.bias                                         |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.layer_norm1.6.weight                                       |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.layer_norm1.6.bias                                         |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.layer_norm1.7.weight                                       |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.layer_norm1.7.bias                                         |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.layer_norm1.8.weight                                       |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.layer_norm1.8.bias                                         |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.layer_norm1.9.weight                                       |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.layer_norm1.9.bias                                         |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.layer_norm1.10.weight                                      |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.layer_norm1.10.bias                                        |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.layer_norm1.11.weight                                      |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.layer_norm1.11.bias                                        |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.ffns.0.lin1.weight                                         |torch.float32    |(3072, 768)      |2359296      |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.ffns.0.lin1.bias                                           |torch.float32    |(3072,)          |3072         |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.ffns.0.lin2.weight                                         |torch.float32    |(768, 3072)      |2359296      |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.ffns.0.lin2.bias                                           |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.ffns.1.lin1.weight                                         |torch.float32    |(3072, 768)      |2359296      |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.ffns.1.lin1.bias                                           |torch.float32    |(3072,)          |3072         |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.ffns.1.lin2.weight                                         |torch.float32    |(768, 3072)      |2359296      |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.ffns.1.lin2.bias                                           |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.ffns.2.lin1.weight                                         |torch.float32    |(3072, 768)      |2359296      |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.ffns.2.lin1.bias                                           |torch.float32    |(3072,)          |3072         |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.ffns.2.lin2.weight                                         |torch.float32    |(768, 3072)      |2359296      |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.ffns.2.lin2.bias                                           |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.ffns.3.lin1.weight                                         |torch.float32    |(3072, 768)      |2359296      |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.ffns.3.lin1.bias                                           |torch.float32    |(3072,)          |3072         |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.ffns.3.lin2.weight                                         |torch.float32    |(768, 3072)      |2359296      |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.ffns.3.lin2.bias                                           |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.ffns.4.lin1.weight                                         |torch.float32    |(3072, 768)      |2359296      |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.ffns.4.lin1.bias                                           |torch.float32    |(3072,)          |3072         |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.ffns.4.lin2.weight                                         |torch.float32    |(768, 3072)      |2359296      |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.ffns.4.lin2.bias                                           |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.ffns.5.lin1.weight                                         |torch.float32    |(3072, 768)      |2359296      |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.ffns.5.lin1.bias                                           |torch.float32    |(3072,)          |3072         |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.ffns.5.lin2.weight                                         |torch.float32    |(768, 3072)      |2359296      |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.ffns.5.lin2.bias                                           |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.ffns.6.lin1.weight                                         |torch.float32    |(3072, 768)      |2359296      |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.ffns.6.lin1.bias                                           |torch.float32    |(3072,)          |3072         |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.ffns.6.lin2.weight                                         |torch.float32    |(768, 3072)      |2359296      |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.ffns.6.lin2.bias                                           |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.ffns.7.lin1.weight                                         |torch.float32    |(3072, 768)      |2359296      |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.ffns.7.lin1.bias                                           |torch.float32    |(3072,)          |3072         |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.ffns.7.lin2.weight                                         |torch.float32    |(768, 3072)      |2359296      |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.ffns.7.lin2.bias                                           |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.ffns.8.lin1.weight                                         |torch.float32    |(3072, 768)      |2359296      |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.ffns.8.lin1.bias                                           |torch.float32    |(3072,)          |3072         |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.ffns.8.lin2.weight                                         |torch.float32    |(768, 3072)      |2359296      |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.ffns.8.lin2.bias                                           |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.ffns.9.lin1.weight                                         |torch.float32    |(3072, 768)      |2359296      |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.ffns.9.lin1.bias                                           |torch.float32    |(3072,)          |3072         |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.ffns.9.lin2.weight                                         |torch.float32    |(768, 3072)      |2359296      |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.ffns.9.lin2.bias                                           |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.ffns.10.lin1.weight                                        |torch.float32    |(3072, 768)      |2359296      |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.ffns.10.lin1.bias                                          |torch.float32    |(3072,)          |3072         |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.ffns.10.lin2.weight                                        |torch.float32    |(768, 3072)      |2359296      |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.ffns.10.lin2.bias                                          |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.ffns.11.lin1.weight                                        |torch.float32    |(3072, 768)      |2359296      |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.ffns.11.lin1.bias                                          |torch.float32    |(3072,)          |3072         |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.ffns.11.lin2.weight                                        |torch.float32    |(768, 3072)      |2359296      |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.ffns.11.lin2.bias                                          |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.layer_norm2.0.weight                                       |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.layer_norm2.0.bias                                         |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.layer_norm2.1.weight                                       |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.layer_norm2.1.bias                                         |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.layer_norm2.2.weight                                       |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.layer_norm2.2.bias                                         |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.layer_norm2.3.weight                                       |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.layer_norm2.3.bias                                         |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.layer_norm2.4.weight                                       |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.layer_norm2.4.bias                                         |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.layer_norm2.5.weight                                       |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.layer_norm2.5.bias                                         |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.layer_norm2.6.weight                                       |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.layer_norm2.6.bias                                         |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.layer_norm2.7.weight                                       |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.layer_norm2.7.bias                                         |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.layer_norm2.8.weight                                       |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.layer_norm2.8.bias                                         |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.layer_norm2.9.weight                                       |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.layer_norm2.9.bias                                         |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.layer_norm2.10.weight                                      |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.layer_norm2.10.bias                                        |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.layer_norm2.11.weight                                      |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.layer_norm2.11.bias                                        |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.layer_norm15.0.weight                                      |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.layer_norm15.0.bias                                        |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.layer_norm15.1.weight                                      |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.layer_norm15.1.bias                                        |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.layer_norm15.2.weight                                      |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.layer_norm15.2.bias                                        |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.layer_norm15.3.weight                                      |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.layer_norm15.3.bias                                        |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.layer_norm15.4.weight                                      |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.layer_norm15.4.bias                                        |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.layer_norm15.5.weight                                      |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.layer_norm15.5.bias                                        |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.layer_norm15.6.weight                                      |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.layer_norm15.6.bias                                        |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.layer_norm15.7.weight                                      |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.layer_norm15.7.bias                                        |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.layer_norm15.8.weight                                      |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.layer_norm15.8.bias                                        |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.layer_norm15.9.weight                                      |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.layer_norm15.9.bias                                        |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.layer_norm15.10.weight                                     |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.layer_norm15.10.bias                                       |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.layer_norm15.11.weight                                     |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.layer_norm15.11.bias                                       |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.0.q_lin.weight                                |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.0.q_lin.bias                                  |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.0.k_lin.weight                                |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.0.k_lin.bias                                  |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.0.v_lin.weight                                |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.0.v_lin.bias                                  |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.0.out_lin.weight                              |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.0.out_lin.bias                                |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.1.q_lin.weight                                |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.1.q_lin.bias                                  |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.1.k_lin.weight                                |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.1.k_lin.bias                                  |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.1.v_lin.weight                                |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.1.v_lin.bias                                  |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.1.out_lin.weight                              |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.1.out_lin.bias                                |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.2.q_lin.weight                                |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.2.q_lin.bias                                  |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.2.k_lin.weight                                |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.2.k_lin.bias                                  |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.2.v_lin.weight                                |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.2.v_lin.bias                                  |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.2.out_lin.weight                              |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.2.out_lin.bias                                |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.3.q_lin.weight                                |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.3.q_lin.bias                                  |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.3.k_lin.weight                                |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.3.k_lin.bias                                  |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.3.v_lin.weight                                |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.3.v_lin.bias                                  |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.3.out_lin.weight                              |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.3.out_lin.bias                                |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.4.q_lin.weight                                |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.4.q_lin.bias                                  |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.4.k_lin.weight                                |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.4.k_lin.bias                                  |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.4.v_lin.weight                                |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.4.v_lin.bias                                  |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.4.out_lin.weight                              |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.4.out_lin.bias                                |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.5.q_lin.weight                                |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.5.q_lin.bias                                  |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.5.k_lin.weight                                |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.5.k_lin.bias                                  |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.5.v_lin.weight                                |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.5.v_lin.bias                                  |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.5.out_lin.weight                              |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.5.out_lin.bias                                |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.6.q_lin.weight                                |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.6.q_lin.bias                                  |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.6.k_lin.weight                                |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.6.k_lin.bias                                  |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.6.v_lin.weight                                |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.6.v_lin.bias                                  |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.6.out_lin.weight                              |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.6.out_lin.bias                                |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.7.q_lin.weight                                |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.7.q_lin.bias                                  |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.7.k_lin.weight                                |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.7.k_lin.bias                                  |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.7.v_lin.weight                                |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.7.v_lin.bias                                  |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.7.out_lin.weight                              |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.7.out_lin.bias                                |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.8.q_lin.weight                                |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.8.q_lin.bias                                  |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.8.k_lin.weight                                |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.8.k_lin.bias                                  |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.8.v_lin.weight                                |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.8.v_lin.bias                                  |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.8.out_lin.weight                              |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.8.out_lin.bias                                |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.9.q_lin.weight                                |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.9.q_lin.bias                                  |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.9.k_lin.weight                                |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.9.k_lin.bias                                  |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.9.v_lin.weight                                |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.9.v_lin.bias                                  |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.9.out_lin.weight                              |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.9.out_lin.bias                                |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.10.q_lin.weight                               |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.10.q_lin.bias                                 |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.10.k_lin.weight                               |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.10.k_lin.bias                                 |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.10.v_lin.weight                               |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.10.v_lin.bias                                 |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.10.out_lin.weight                             |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.10.out_lin.bias                               |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.11.q_lin.weight                               |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.11.q_lin.bias                                 |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.11.k_lin.weight                               |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.11.k_lin.bias                                 |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.11.v_lin.weight                               |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.11.v_lin.bias                                 |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.11.out_lin.weight                             |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.encoder_attn.11.out_lin.bias                               |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.latent_transforms.0.x_to_mu.weight                         |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.latent_transforms.0.x_to_mu.bias                           |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.latent_transforms.0.x_to_logvar.weight                     |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.latent_transforms.0.x_to_logvar.bias                       |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.latent_transforms.0.out_dense.weight                       |torch.float32    |(768, 1536)      |1179648      |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.latent_transforms.0.out_dense.bias                         |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.latent_transforms.1.x_to_mu.weight                         |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.latent_transforms.1.x_to_mu.bias                           |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.latent_transforms.1.x_to_logvar.weight                     |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.latent_transforms.1.x_to_logvar.bias                       |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.latent_transforms.1.out_dense.weight                       |torch.float32    |(768, 1536)      |1179648      |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.latent_transforms.1.out_dense.bias                         |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.original_transforms.0.dense.weight                         |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.original_transforms.0.dense.bias                           |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.original_transforms.0.dense_mu.weight                      |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.original_transforms.0.dense_mu.bias                        |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.original_transforms.0.LayerNorm.weight                     |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.original_transforms.0.LayerNorm.bias                       |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.original_transforms.1.dense.weight                         |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.original_transforms.1.dense.bias                           |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.original_transforms.1.dense_mu.weight                      |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.original_transforms.1.dense_mu.bias                        |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.original_transforms.1.LayerNorm.weight                     |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.original_transforms.1.LayerNorm.bias                       |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.pooled_layer.dense.weight                                  |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.pooled_layer.dense.bias                                    |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.seq_relationship.weight                                    |torch.float32    |(1, 768)         |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.seq_relationship.bias                                      |torch.float32    |(1,)             |1            |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.pooled_layer2.dense.weight                                 |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.pooled_layer2.dense.bias                                   |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.seq_relationship2.weight                                   |torch.float32    |(1, 768)         |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.seq_relationship2.bias                                     |torch.float32    |(1,)             |1            |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.mrfr_dense.weight                                          |torch.float32    |(2048, 768)      |1572864      |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.mrfr_dense.bias                                            |torch.float32    |(2048,)          |2048         |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.transformer_obj.dense.weight                               |torch.float32    |(768, 768)       |589824       |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.transformer_obj.dense.bias                                 |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.transformer_obj.LayerNorm.weight                           |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |bert.encoder.transformer_obj.LayerNorm.bias                             |torch.float32    |(768,)           |768          |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |clfs_dict.TASK19.weight                                                 |torch.float32    |(3, 768)         |2304         |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   |clfs_dict.TASK19.bias                                                   |torch.float32    |(3,)             |3            |True    |
12/04/2021 23:38:33 - INFO - __main__ -   -------------------------------------------------------------------------------------------------------------------------------------
12/04/2021 23:38:33 - INFO - __main__ -   >> # TrainableParams:       	372.89	M
12/04/2021 23:38:33 - INFO - __main__ -   >> # NonTrainableParams:    	0.00	M
12/04/2021 23:38:33 - INFO - __main__ -   >> # TotalParams:           	372.89	M
Epoch:   0%|          | 0/10 [00:00<?, ?it/s]/home/projects/ku_00062/envs/iglue/lib/python3.6/site-packages/pytorch_transformers/optimization.py:166: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
12/04/2021 23:39:56 - INFO - volta.train_utils -   [XVNLI]: iter 160 Ep: 0.00 loss 0.012 score 0.040 lr 3.10596e-09 
12/04/2021 23:41:03 - INFO - volta.train_utils -   [XVNLI]: iter 320 Ep: 0.01 loss 0.011 score 0.040 lr 9.02207e-09 
12/04/2021 23:42:01 - INFO - volta.train_utils -   [XVNLI]: iter 480 Ep: 0.01 loss 0.011 score 0.039 lr 1.49382e-08 
12/04/2021 23:42:54 - INFO - volta.train_utils -   [XVNLI]: iter 640 Ep: 0.02 loss 0.011 score 0.037 lr 2.08543e-08 
12/04/2021 23:43:45 - INFO - volta.train_utils -   [XVNLI]: iter 800 Ep: 0.02 loss 0.011 score 0.038 lr 2.67704e-08 
12/04/2021 23:44:32 - INFO - volta.train_utils -   [XVNLI]: iter 960 Ep: 0.03 loss 0.011 score 0.041 lr 3.26865e-08 
12/04/2021 23:45:19 - INFO - volta.train_utils -   [XVNLI]: iter 1120 Ep: 0.03 loss 0.011 score 0.040 lr 3.86026e-08 
12/04/2021 23:46:01 - INFO - volta.train_utils -   [XVNLI]: iter 1280 Ep: 0.04 loss 0.011 score 0.041 lr 4.45187e-08 
12/04/2021 23:46:43 - INFO - volta.train_utils -   [XVNLI]: iter 1440 Ep: 0.04 loss 0.011 score 0.040 lr 5.04348e-08 
12/04/2021 23:47:22 - INFO - volta.train_utils -   [XVNLI]: iter 1600 Ep: 0.05 loss 0.010 score 0.041 lr 5.63509e-08 
12/04/2021 23:48:02 - INFO - volta.train_utils -   [XVNLI]: iter 1760 Ep: 0.05 loss 0.010 score 0.042 lr 6.22671e-08 
12/04/2021 23:48:38 - INFO - volta.train_utils -   [XVNLI]: iter 1920 Ep: 0.06 loss 0.010 score 0.043 lr 6.81832e-08 
12/04/2021 23:49:16 - INFO - volta.train_utils -   [XVNLI]: iter 2080 Ep: 0.06 loss 0.010 score 0.044 lr 7.40993e-08 
12/04/2021 23:49:51 - INFO - volta.train_utils -   [XVNLI]: iter 2240 Ep: 0.07 loss 0.010 score 0.042 lr 8.00154e-08 
12/04/2021 23:50:25 - INFO - volta.train_utils -   [XVNLI]: iter 2400 Ep: 0.07 loss 0.010 score 0.041 lr 8.59315e-08 
12/04/2021 23:50:59 - INFO - volta.train_utils -   [XVNLI]: iter 2560 Ep: 0.08 loss 0.010 score 0.043 lr 9.18476e-08 
12/04/2021 23:51:34 - INFO - volta.train_utils -   [XVNLI]: iter 2720 Ep: 0.08 loss 0.010 score 0.043 lr 9.77637e-08 
12/04/2021 23:52:11 - INFO - volta.train_utils -   [XVNLI]: iter 2880 Ep: 0.09 loss 0.010 score 0.044 lr 1.0368e-07 
12/04/2021 23:52:44 - INFO - volta.train_utils -   [XVNLI]: iter 3040 Ep: 0.09 loss 0.010 score 0.045 lr 1.09596e-07 
12/04/2021 23:53:18 - INFO - volta.train_utils -   [XVNLI]: iter 3200 Ep: 0.09 loss 0.010 score 0.046 lr 1.15512e-07 
12/04/2021 23:53:50 - INFO - volta.train_utils -   [XVNLI]: iter 3360 Ep: 0.10 loss 0.010 score 0.048 lr 1.21428e-07 
12/04/2021 23:54:23 - INFO - volta.train_utils -   [XVNLI]: iter 3520 Ep: 0.10 loss 0.010 score 0.049 lr 1.27344e-07 
12/04/2021 23:54:55 - INFO - volta.train_utils -   [XVNLI]: iter 3680 Ep: 0.11 loss 0.010 score 0.051 lr 1.3326e-07 
12/04/2021 23:55:26 - INFO - volta.train_utils -   [XVNLI]: iter 3840 Ep: 0.11 loss 0.010 score 0.053 lr 1.39176e-07 
12/04/2021 23:55:58 - INFO - volta.train_utils -   [XVNLI]: iter 4000 Ep: 0.12 loss 0.010 score 0.053 lr 1.45093e-07 
12/04/2021 23:56:29 - INFO - volta.train_utils -   [XVNLI]: iter 4160 Ep: 0.12 loss 0.010 score 0.057 lr 1.51009e-07 
12/04/2021 23:57:00 - INFO - volta.train_utils -   [XVNLI]: iter 4320 Ep: 0.13 loss 0.010 score 0.055 lr 1.56925e-07 
12/04/2021 23:57:31 - INFO - volta.train_utils -   [XVNLI]: iter 4480 Ep: 0.13 loss 0.010 score 0.057 lr 1.62841e-07 
12/04/2021 23:58:03 - INFO - volta.train_utils -   [XVNLI]: iter 4640 Ep: 0.14 loss 0.010 score 0.058 lr 1.68757e-07 
12/04/2021 23:58:34 - INFO - volta.train_utils -   [XVNLI]: iter 4800 Ep: 0.14 loss 0.009 score 0.060 lr 1.74673e-07 
12/04/2021 23:59:06 - INFO - volta.train_utils -   [XVNLI]: iter 4960 Ep: 0.15 loss 0.010 score 0.057 lr 1.80589e-07 
12/04/2021 23:59:37 - INFO - volta.train_utils -   [XVNLI]: iter 5120 Ep: 0.15 loss 0.009 score 0.060 lr 1.86505e-07 
12/05/2021 00:00:08 - INFO - volta.train_utils -   [XVNLI]: iter 5280 Ep: 0.16 loss 0.009 score 0.062 lr 1.92421e-07 
12/05/2021 00:00:39 - INFO - volta.train_utils -   [XVNLI]: iter 5440 Ep: 0.16 loss 0.009 score 0.061 lr 1.98338e-07 
12/05/2021 00:01:10 - INFO - volta.train_utils -   [XVNLI]: iter 5600 Ep: 0.17 loss 0.009 score 0.062 lr 2.04254e-07 
12/05/2021 00:01:41 - INFO - volta.train_utils -   [XVNLI]: iter 5760 Ep: 0.17 loss 0.010 score 0.059 lr 2.1017e-07 
12/05/2021 00:02:12 - INFO - volta.train_utils -   [XVNLI]: iter 5920 Ep: 0.18 loss 0.009 score 0.060 lr 2.16086e-07 
12/05/2021 00:02:43 - INFO - volta.train_utils -   [XVNLI]: iter 6080 Ep: 0.18 loss 0.009 score 0.064 lr 2.22002e-07 
12/05/2021 00:03:15 - INFO - volta.train_utils -   [XVNLI]: iter 6240 Ep: 0.18 loss 0.009 score 0.063 lr 2.27918e-07 
12/05/2021 00:03:46 - INFO - volta.train_utils -   [XVNLI]: iter 6400 Ep: 0.19 loss 0.009 score 0.064 lr 2.33834e-07 
12/05/2021 00:04:17 - INFO - volta.train_utils -   [XVNLI]: iter 6560 Ep: 0.19 loss 0.009 score 0.063 lr 2.3975e-07 
12/05/2021 00:04:48 - INFO - volta.train_utils -   [XVNLI]: iter 6720 Ep: 0.20 loss 0.009 score 0.062 lr 2.45666e-07 
12/05/2021 00:05:19 - INFO - volta.train_utils -   [XVNLI]: iter 6880 Ep: 0.20 loss 0.009 score 0.063 lr 2.51583e-07 
12/05/2021 00:05:50 - INFO - volta.train_utils -   [XVNLI]: iter 7040 Ep: 0.21 loss 0.009 score 0.065 lr 2.57499e-07 
12/05/2021 00:06:21 - INFO - volta.train_utils -   [XVNLI]: iter 7200 Ep: 0.21 loss 0.009 score 0.066 lr 2.63415e-07 
12/05/2021 00:06:52 - INFO - volta.train_utils -   [XVNLI]: iter 7360 Ep: 0.22 loss 0.009 score 0.066 lr 2.69331e-07 
12/05/2021 00:07:23 - INFO - volta.train_utils -   [XVNLI]: iter 7520 Ep: 0.22 loss 0.009 score 0.065 lr 2.75247e-07 
12/05/2021 00:07:54 - INFO - volta.train_utils -   [XVNLI]: iter 7680 Ep: 0.23 loss 0.009 score 0.068 lr 2.81163e-07 
12/05/2021 00:08:25 - INFO - volta.train_utils -   [XVNLI]: iter 7840 Ep: 0.23 loss 0.009 score 0.066 lr 2.87079e-07 
12/05/2021 00:08:57 - INFO - volta.train_utils -   [XVNLI]: iter 8000 Ep: 0.24 loss 0.009 score 0.070 lr 2.92995e-07 
12/05/2021 00:09:28 - INFO - volta.train_utils -   [XVNLI]: iter 8160 Ep: 0.24 loss 0.009 score 0.068 lr 2.98911e-07 
12/05/2021 00:09:59 - INFO - volta.train_utils -   [XVNLI]: iter 8320 Ep: 0.25 loss 0.009 score 0.066 lr 3.04828e-07 
12/05/2021 00:10:30 - INFO - volta.train_utils -   [XVNLI]: iter 8480 Ep: 0.25 loss 0.009 score 0.069 lr 3.10744e-07 
12/05/2021 00:11:02 - INFO - volta.train_utils -   [XVNLI]: iter 8640 Ep: 0.26 loss 0.009 score 0.069 lr 3.1666e-07 
12/05/2021 00:11:33 - INFO - volta.train_utils -   [XVNLI]: iter 8800 Ep: 0.26 loss 0.009 score 0.071 lr 3.22576e-07 
12/05/2021 00:12:04 - INFO - volta.train_utils -   [XVNLI]: iter 8960 Ep: 0.27 loss 0.009 score 0.071 lr 3.28492e-07 
12/05/2021 00:12:35 - INFO - volta.train_utils -   [XVNLI]: iter 9120 Ep: 0.27 loss 0.009 score 0.071 lr 3.34408e-07 
12/05/2021 00:13:06 - INFO - volta.train_utils -   [XVNLI]: iter 9280 Ep: 0.27 loss 0.009 score 0.073 lr 3.40324e-07 
12/05/2021 00:13:37 - INFO - volta.train_utils -   [XVNLI]: iter 9440 Ep: 0.28 loss 0.009 score 0.074 lr 3.4624e-07 
12/05/2021 00:14:08 - INFO - volta.train_utils -   [XVNLI]: iter 9600 Ep: 0.28 loss 0.009 score 0.074 lr 3.52156e-07 
12/05/2021 00:14:40 - INFO - volta.train_utils -   [XVNLI]: iter 9760 Ep: 0.29 loss 0.009 score 0.072 lr 3.58073e-07 
12/05/2021 00:15:11 - INFO - volta.train_utils -   [XVNLI]: iter 9920 Ep: 0.29 loss 0.008 score 0.075 lr 3.63989e-07 
12/05/2021 00:15:42 - INFO - volta.train_utils -   [XVNLI]: iter 10080 Ep: 0.30 loss 0.009 score 0.074 lr 3.69905e-07 
12/05/2021 00:16:13 - INFO - volta.train_utils -   [XVNLI]: iter 10240 Ep: 0.30 loss 0.009 score 0.073 lr 3.75821e-07 
12/05/2021 00:16:44 - INFO - volta.train_utils -   [XVNLI]: iter 10400 Ep: 0.31 loss 0.009 score 0.076 lr 3.81737e-07 
12/05/2021 00:17:15 - INFO - volta.train_utils -   [XVNLI]: iter 10560 Ep: 0.31 loss 0.008 score 0.077 lr 3.87653e-07 
12/05/2021 00:17:46 - INFO - volta.train_utils -   [XVNLI]: iter 10720 Ep: 0.32 loss 0.008 score 0.077 lr 3.93569e-07 
12/05/2021 00:18:18 - INFO - volta.train_utils -   [XVNLI]: iter 10880 Ep: 0.32 loss 0.008 score 0.076 lr 3.99485e-07 
12/05/2021 00:18:51 - INFO - volta.train_utils -   [XVNLI]: iter 11040 Ep: 0.33 loss 0.008 score 0.077 lr 4.05401e-07 
12/05/2021 00:19:24 - INFO - volta.train_utils -   [XVNLI]: iter 11200 Ep: 0.33 loss 0.008 score 0.079 lr 4.11318e-07 
12/05/2021 00:19:57 - INFO - volta.train_utils -   [XVNLI]: iter 11360 Ep: 0.34 loss 0.008 score 0.077 lr 4.17234e-07 
12/05/2021 00:20:29 - INFO - volta.train_utils -   [XVNLI]: iter 11520 Ep: 0.34 loss 0.008 score 0.080 lr 4.2315e-07 
12/05/2021 00:21:02 - INFO - volta.train_utils -   [XVNLI]: iter 11680 Ep: 0.35 loss 0.008 score 0.078 lr 4.29066e-07 
12/05/2021 00:21:34 - INFO - volta.train_utils -   [XVNLI]: iter 11840 Ep: 0.35 loss 0.008 score 0.079 lr 4.34982e-07 
12/05/2021 00:22:08 - INFO - volta.train_utils -   [XVNLI]: iter 12000 Ep: 0.35 loss 0.008 score 0.079 lr 4.40898e-07 
12/05/2021 00:22:40 - INFO - volta.train_utils -   [XVNLI]: iter 12160 Ep: 0.36 loss 0.008 score 0.080 lr 4.46814e-07 
12/05/2021 00:23:12 - INFO - volta.train_utils -   [XVNLI]: iter 12320 Ep: 0.36 loss 0.008 score 0.078 lr 4.5273e-07 
12/05/2021 00:23:45 - INFO - volta.train_utils -   [XVNLI]: iter 12480 Ep: 0.37 loss 0.008 score 0.078 lr 4.58646e-07 
12/05/2021 00:24:16 - INFO - volta.train_utils -   [XVNLI]: iter 12640 Ep: 0.37 loss 0.008 score 0.082 lr 4.64563e-07 
12/05/2021 00:24:47 - INFO - volta.train_utils -   [XVNLI]: iter 12800 Ep: 0.38 loss 0.008 score 0.080 lr 4.70479e-07 
12/05/2021 00:25:19 - INFO - volta.train_utils -   [XVNLI]: iter 12960 Ep: 0.38 loss 0.008 score 0.080 lr 4.76395e-07 
12/05/2021 00:25:50 - INFO - volta.train_utils -   [XVNLI]: iter 13120 Ep: 0.39 loss 0.007 score 0.083 lr 4.82311e-07 
12/05/2021 00:26:21 - INFO - volta.train_utils -   [XVNLI]: iter 13280 Ep: 0.39 loss 0.008 score 0.081 lr 4.88227e-07 
12/05/2021 00:26:52 - INFO - volta.train_utils -   [XVNLI]: iter 13440 Ep: 0.40 loss 0.008 score 0.079 lr 4.94143e-07 
12/05/2021 00:27:23 - INFO - volta.train_utils -   [XVNLI]: iter 13600 Ep: 0.40 loss 0.007 score 0.081 lr 5.00059e-07 
12/05/2021 00:27:54 - INFO - volta.train_utils -   [XVNLI]: iter 13760 Ep: 0.41 loss 0.007 score 0.082 lr 5.05975e-07 
12/05/2021 00:28:26 - INFO - volta.train_utils -   [XVNLI]: iter 13920 Ep: 0.41 loss 0.007 score 0.080 lr 5.11891e-07 
12/05/2021 00:28:58 - INFO - volta.train_utils -   [XVNLI]: iter 14080 Ep: 0.42 loss 0.008 score 0.082 lr 5.17807e-07 
12/05/2021 00:29:31 - INFO - volta.train_utils -   [XVNLI]: iter 14240 Ep: 0.42 loss 0.007 score 0.081 lr 5.23724e-07 
12/05/2021 00:30:02 - INFO - volta.train_utils -   [XVNLI]: iter 14400 Ep: 0.43 loss 0.007 score 0.084 lr 5.2964e-07 
12/05/2021 00:30:33 - INFO - volta.train_utils -   [XVNLI]: iter 14560 Ep: 0.43 loss 0.007 score 0.081 lr 5.35556e-07 
12/05/2021 00:31:05 - INFO - volta.train_utils -   [XVNLI]: iter 14720 Ep: 0.44 loss 0.007 score 0.083 lr 5.41472e-07 
12/05/2021 00:31:39 - INFO - volta.train_utils -   [XVNLI]: iter 14880 Ep: 0.44 loss 0.007 score 0.081 lr 5.47388e-07 
12/05/2021 00:32:12 - INFO - volta.train_utils -   [XVNLI]: iter 15040 Ep: 0.44 loss 0.008 score 0.083 lr 5.53304e-07 
12/05/2021 00:32:47 - INFO - volta.train_utils -   [XVNLI]: iter 15200 Ep: 0.45 loss 0.008 score 0.082 lr 5.5922e-07 
12/05/2021 00:33:20 - INFO - volta.train_utils -   [XVNLI]: iter 15360 Ep: 0.45 loss 0.008 score 0.083 lr 5.65136e-07 
12/05/2021 00:33:56 - INFO - volta.train_utils -   [XVNLI]: iter 15520 Ep: 0.46 loss 0.007 score 0.082 lr 5.71052e-07 
12/05/2021 00:34:29 - INFO - volta.train_utils -   [XVNLI]: iter 15680 Ep: 0.46 loss 0.008 score 0.081 lr 5.76969e-07 
12/05/2021 00:35:04 - INFO - volta.train_utils -   [XVNLI]: iter 15840 Ep: 0.47 loss 0.007 score 0.082 lr 5.82885e-07 
12/05/2021 00:35:38 - INFO - volta.train_utils -   [XVNLI]: iter 16000 Ep: 0.47 loss 0.007 score 0.084 lr 5.88801e-07 
12/05/2021 00:36:10 - INFO - volta.train_utils -   [XVNLI]: iter 16160 Ep: 0.48 loss 0.007 score 0.084 lr 5.94717e-07 
12/05/2021 00:36:44 - INFO - volta.train_utils -   [XVNLI]: iter 16320 Ep: 0.48 loss 0.007 score 0.082 lr 6.00633e-07 
12/05/2021 00:37:19 - INFO - volta.train_utils -   [XVNLI]: iter 16480 Ep: 0.49 loss 0.007 score 0.084 lr 6.06549e-07 
12/05/2021 00:37:52 - INFO - volta.train_utils -   [XVNLI]: iter 16640 Ep: 0.49 loss 0.008 score 0.083 lr 6.12465e-07 
12/05/2021 00:38:28 - INFO - volta.train_utils -   [XVNLI]: iter 16800 Ep: 0.50 loss 0.007 score 0.080 lr 6.18381e-07 
12/05/2021 00:39:01 - INFO - volta.train_utils -   [XVNLI]: iter 16960 Ep: 0.50 loss 0.007 score 0.084 lr 6.24297e-07 
12/05/2021 00:39:35 - INFO - volta.train_utils -   [XVNLI]: iter 17120 Ep: 0.51 loss 0.007 score 0.083 lr 6.30214e-07 
12/05/2021 00:40:10 - INFO - volta.train_utils -   [XVNLI]: iter 17280 Ep: 0.51 loss 0.008 score 0.083 lr 6.3613e-07 
12/05/2021 00:40:46 - INFO - volta.train_utils -   [XVNLI]: iter 17440 Ep: 0.52 loss 0.007 score 0.087 lr 6.42046e-07 
12/05/2021 00:41:22 - INFO - volta.train_utils -   [XVNLI]: iter 17600 Ep: 0.52 loss 0.007 score 0.085 lr 6.47962e-07 
12/05/2021 00:41:57 - INFO - volta.train_utils -   [XVNLI]: iter 17760 Ep: 0.53 loss 0.007 score 0.081 lr 6.53878e-07 
12/05/2021 00:42:32 - INFO - volta.train_utils -   [XVNLI]: iter 17920 Ep: 0.53 loss 0.007 score 0.084 lr 6.59794e-07 
12/05/2021 00:43:09 - INFO - volta.train_utils -   [XVNLI]: iter 18080 Ep: 0.53 loss 0.007 score 0.085 lr 6.6571e-07 
12/05/2021 00:43:46 - INFO - volta.train_utils -   [XVNLI]: iter 18240 Ep: 0.54 loss 0.007 score 0.084 lr 6.71626e-07 
12/05/2021 00:44:20 - INFO - volta.train_utils -   [XVNLI]: iter 18400 Ep: 0.54 loss 0.008 score 0.083 lr 6.77542e-07 
12/05/2021 00:44:58 - INFO - volta.train_utils -   [XVNLI]: iter 18560 Ep: 0.55 loss 0.007 score 0.083 lr 6.83459e-07 
12/05/2021 00:45:33 - INFO - volta.train_utils -   [XVNLI]: iter 18720 Ep: 0.55 loss 0.007 score 0.085 lr 6.89375e-07 
12/05/2021 00:46:09 - INFO - volta.train_utils -   [XVNLI]: iter 18880 Ep: 0.56 loss 0.007 score 0.085 lr 6.95291e-07 
12/05/2021 00:46:44 - INFO - volta.train_utils -   [XVNLI]: iter 19040 Ep: 0.56 loss 0.007 score 0.085 lr 7.01207e-07 
12/05/2021 00:47:20 - INFO - volta.train_utils -   [XVNLI]: iter 19200 Ep: 0.57 loss 0.007 score 0.084 lr 7.07123e-07 
12/05/2021 00:47:54 - INFO - volta.train_utils -   [XVNLI]: iter 19360 Ep: 0.57 loss 0.007 score 0.086 lr 7.13039e-07 
12/05/2021 00:48:29 - INFO - volta.train_utils -   [XVNLI]: iter 19520 Ep: 0.58 loss 0.007 score 0.087 lr 7.18955e-07 
12/05/2021 00:49:01 - INFO - volta.train_utils -   [XVNLI]: iter 19680 Ep: 0.58 loss 0.006 score 0.087 lr 7.24871e-07 
12/05/2021 00:49:37 - INFO - volta.train_utils -   [XVNLI]: iter 19840 Ep: 0.59 loss 0.006 score 0.086 lr 7.30787e-07 
12/05/2021 00:50:12 - INFO - volta.train_utils -   [XVNLI]: iter 20000 Ep: 0.59 loss 0.006 score 0.087 lr 7.36704e-07 
12/05/2021 00:50:49 - INFO - volta.train_utils -   [XVNLI]: iter 20160 Ep: 0.60 loss 0.006 score 0.085 lr 7.4262e-07 
12/05/2021 00:51:23 - INFO - volta.train_utils -   [XVNLI]: iter 20320 Ep: 0.60 loss 0.006 score 0.087 lr 7.48536e-07 
12/05/2021 00:51:59 - INFO - volta.train_utils -   [XVNLI]: iter 20480 Ep: 0.61 loss 0.007 score 0.084 lr 7.54452e-07 
12/05/2021 00:52:32 - INFO - volta.train_utils -   [XVNLI]: iter 20640 Ep: 0.61 loss 0.007 score 0.085 lr 7.60368e-07 
12/05/2021 00:53:06 - INFO - volta.train_utils -   [XVNLI]: iter 20800 Ep: 0.62 loss 0.007 score 0.085 lr 7.66284e-07 
12/05/2021 00:53:42 - INFO - volta.train_utils -   [XVNLI]: iter 20960 Ep: 0.62 loss 0.007 score 0.086 lr 7.722e-07 
12/05/2021 00:54:15 - INFO - volta.train_utils -   [XVNLI]: iter 21120 Ep: 0.62 loss 0.007 score 0.087 lr 7.78116e-07 
12/05/2021 00:54:49 - INFO - volta.train_utils -   [XVNLI]: iter 21280 Ep: 0.63 loss 0.007 score 0.087 lr 7.84032e-07 
12/05/2021 00:55:22 - INFO - volta.train_utils -   [XVNLI]: iter 21440 Ep: 0.63 loss 0.008 score 0.085 lr 7.89949e-07 
12/05/2021 00:55:57 - INFO - volta.train_utils -   [XVNLI]: iter 21600 Ep: 0.64 loss 0.006 score 0.088 lr 7.95865e-07 
12/05/2021 00:56:32 - INFO - volta.train_utils -   [XVNLI]: iter 21760 Ep: 0.64 loss 0.006 score 0.089 lr 8.01781e-07 
12/05/2021 00:57:10 - INFO - volta.train_utils -   [XVNLI]: iter 21920 Ep: 0.65 loss 0.007 score 0.086 lr 8.07697e-07 
12/05/2021 00:57:45 - INFO - volta.train_utils -   [XVNLI]: iter 22080 Ep: 0.65 loss 0.007 score 0.086 lr 8.13613e-07 
12/05/2021 00:58:23 - INFO - volta.train_utils -   [XVNLI]: iter 22240 Ep: 0.66 loss 0.007 score 0.085 lr 8.19529e-07 
12/05/2021 00:58:59 - INFO - volta.train_utils -   [XVNLI]: iter 22400 Ep: 0.66 loss 0.007 score 0.086 lr 8.25445e-07 
12/05/2021 00:59:35 - INFO - volta.train_utils -   [XVNLI]: iter 22560 Ep: 0.67 loss 0.007 score 0.086 lr 8.31361e-07 
12/05/2021 01:00:12 - INFO - volta.train_utils -   [XVNLI]: iter 22720 Ep: 0.67 loss 0.006 score 0.087 lr 8.37277e-07 
12/05/2021 01:00:46 - INFO - volta.train_utils -   [XVNLI]: iter 22880 Ep: 0.68 loss 0.007 score 0.086 lr 8.43194e-07 
12/05/2021 01:01:20 - INFO - volta.train_utils -   [XVNLI]: iter 23040 Ep: 0.68 loss 0.007 score 0.087 lr 8.4911e-07 
12/05/2021 01:01:54 - INFO - volta.train_utils -   [XVNLI]: iter 23200 Ep: 0.69 loss 0.007 score 0.086 lr 8.55026e-07 
12/05/2021 01:02:29 - INFO - volta.train_utils -   [XVNLI]: iter 23360 Ep: 0.69 loss 0.007 score 0.087 lr 8.60942e-07 
12/05/2021 01:03:03 - INFO - volta.train_utils -   [XVNLI]: iter 23520 Ep: 0.70 loss 0.007 score 0.086 lr 8.66858e-07 
12/05/2021 01:03:38 - INFO - volta.train_utils -   [XVNLI]: iter 23680 Ep: 0.70 loss 0.007 score 0.086 lr 8.72774e-07 
12/05/2021 01:04:13 - INFO - volta.train_utils -   [XVNLI]: iter 23840 Ep: 0.71 loss 0.006 score 0.087 lr 8.7869e-07 
12/05/2021 01:04:48 - INFO - volta.train_utils -   [XVNLI]: iter 24000 Ep: 0.71 loss 0.007 score 0.089 lr 8.84606e-07 
12/05/2021 01:05:22 - INFO - volta.train_utils -   [XVNLI]: iter 24160 Ep: 0.71 loss 0.007 score 0.086 lr 8.90522e-07 
12/05/2021 01:05:58 - INFO - volta.train_utils -   [XVNLI]: iter 24320 Ep: 0.72 loss 0.007 score 0.087 lr 8.96439e-07 
12/05/2021 01:06:34 - INFO - volta.train_utils -   [XVNLI]: iter 24480 Ep: 0.72 loss 0.007 score 0.088 lr 9.02355e-07 
12/05/2021 01:07:09 - INFO - volta.train_utils -   [XVNLI]: iter 24640 Ep: 0.73 loss 0.007 score 0.083 lr 9.08271e-07 
12/05/2021 01:07:46 - INFO - volta.train_utils -   [XVNLI]: iter 24800 Ep: 0.73 loss 0.007 score 0.087 lr 9.14187e-07 
12/05/2021 01:08:23 - INFO - volta.train_utils -   [XVNLI]: iter 24960 Ep: 0.74 loss 0.006 score 0.088 lr 9.20103e-07 
12/05/2021 01:08:59 - INFO - volta.train_utils -   [XVNLI]: iter 25120 Ep: 0.74 loss 0.007 score 0.087 lr 9.26019e-07 
12/05/2021 01:09:35 - INFO - volta.train_utils -   [XVNLI]: iter 25280 Ep: 0.75 loss 0.006 score 0.088 lr 9.31935e-07 
12/05/2021 01:10:10 - INFO - volta.train_utils -   [XVNLI]: iter 25440 Ep: 0.75 loss 0.006 score 0.087 lr 9.37851e-07 
12/05/2021 01:10:45 - INFO - volta.train_utils -   [XVNLI]: iter 25600 Ep: 0.76 loss 0.007 score 0.086 lr 9.43767e-07 
12/05/2021 01:11:18 - INFO - volta.train_utils -   [XVNLI]: iter 25760 Ep: 0.76 loss 0.007 score 0.087 lr 9.49683e-07 
12/05/2021 01:11:53 - INFO - volta.train_utils -   [XVNLI]: iter 25920 Ep: 0.77 loss 0.007 score 0.087 lr 9.556e-07 
12/05/2021 01:12:27 - INFO - volta.train_utils -   [XVNLI]: iter 26080 Ep: 0.77 loss 0.007 score 0.086 lr 9.61516e-07 
12/05/2021 01:13:00 - INFO - volta.train_utils -   [XVNLI]: iter 26240 Ep: 0.78 loss 0.007 score 0.087 lr 9.67432e-07 
12/05/2021 01:13:36 - INFO - volta.train_utils -   [XVNLI]: iter 26400 Ep: 0.78 loss 0.007 score 0.087 lr 9.73348e-07 
12/05/2021 01:14:11 - INFO - volta.train_utils -   [XVNLI]: iter 26560 Ep: 0.79 loss 0.007 score 0.087 lr 9.79264e-07 
12/05/2021 01:14:47 - INFO - volta.train_utils -   [XVNLI]: iter 26720 Ep: 0.79 loss 0.006 score 0.089 lr 9.8518e-07 
12/05/2021 01:15:21 - INFO - volta.train_utils -   [XVNLI]: iter 26880 Ep: 0.80 loss 0.006 score 0.086 lr 9.91096e-07 
12/05/2021 01:15:55 - INFO - volta.train_utils -   [XVNLI]: iter 27040 Ep: 0.80 loss 0.007 score 0.087 lr 9.97012e-07 
12/05/2021 01:16:31 - INFO - volta.train_utils -   [XVNLI]: iter 27200 Ep: 0.80 loss 0.006 score 0.086 lr 1.00293e-06 
12/05/2021 01:17:07 - INFO - volta.train_utils -   [XVNLI]: iter 27360 Ep: 0.81 loss 0.007 score 0.086 lr 1.00884e-06 
12/05/2021 01:17:42 - INFO - volta.train_utils -   [XVNLI]: iter 27520 Ep: 0.81 loss 0.006 score 0.089 lr 1.01476e-06 
12/05/2021 01:18:21 - INFO - volta.train_utils -   [XVNLI]: iter 27680 Ep: 0.82 loss 0.007 score 0.088 lr 1.02068e-06 
12/05/2021 01:18:59 - INFO - volta.train_utils -   [XVNLI]: iter 27840 Ep: 0.82 loss 0.007 score 0.089 lr 1.02659e-06 
12/05/2021 01:19:39 - INFO - volta.train_utils -   [XVNLI]: iter 28000 Ep: 0.83 loss 0.006 score 0.088 lr 1.03251e-06 
12/05/2021 01:20:19 - INFO - volta.train_utils -   [XVNLI]: iter 28160 Ep: 0.83 loss 0.006 score 0.087 lr 1.03843e-06 
12/05/2021 01:20:58 - INFO - volta.train_utils -   [XVNLI]: iter 28320 Ep: 0.84 loss 0.006 score 0.087 lr 1.04434e-06 
12/05/2021 01:21:37 - INFO - volta.train_utils -   [XVNLI]: iter 28480 Ep: 0.84 loss 0.007 score 0.088 lr 1.05026e-06 
12/05/2021 01:22:14 - INFO - volta.train_utils -   [XVNLI]: iter 28640 Ep: 0.85 loss 0.006 score 0.087 lr 1.05617e-06 
12/05/2021 01:22:48 - INFO - volta.train_utils -   [XVNLI]: iter 28800 Ep: 0.85 loss 0.007 score 0.088 lr 1.06209e-06 
12/05/2021 01:23:24 - INFO - volta.train_utils -   [XVNLI]: iter 28960 Ep: 0.86 loss 0.006 score 0.088 lr 1.06801e-06 
12/05/2021 01:23:59 - INFO - volta.train_utils -   [XVNLI]: iter 29120 Ep: 0.86 loss 0.006 score 0.089 lr 1.07392e-06 
12/05/2021 01:24:34 - INFO - volta.train_utils -   [XVNLI]: iter 29280 Ep: 0.87 loss 0.006 score 0.090 lr 1.07984e-06 
12/05/2021 01:25:12 - INFO - volta.train_utils -   [XVNLI]: iter 29440 Ep: 0.87 loss 0.007 score 0.086 lr 1.08575e-06 
12/05/2021 01:25:49 - INFO - volta.train_utils -   [XVNLI]: iter 29600 Ep: 0.88 loss 0.006 score 0.089 lr 1.09167e-06 
12/05/2021 01:26:25 - INFO - volta.train_utils -   [XVNLI]: iter 29760 Ep: 0.88 loss 0.007 score 0.089 lr 1.09759e-06 
12/05/2021 01:27:01 - INFO - volta.train_utils -   [XVNLI]: iter 29920 Ep: 0.89 loss 0.006 score 0.088 lr 1.1035e-06 
12/05/2021 01:27:35 - INFO - volta.train_utils -   [XVNLI]: iter 30080 Ep: 0.89 loss 0.006 score 0.089 lr 1.10942e-06 
12/05/2021 01:28:13 - INFO - volta.train_utils -   [XVNLI]: iter 30240 Ep: 0.89 loss 0.006 score 0.089 lr 1.11533e-06 
12/05/2021 01:28:49 - INFO - volta.train_utils -   [XVNLI]: iter 30400 Ep: 0.90 loss 0.006 score 0.087 lr 1.12125e-06 
12/05/2021 01:29:23 - INFO - volta.train_utils -   [XVNLI]: iter 30560 Ep: 0.90 loss 0.006 score 0.088 lr 1.12717e-06 
12/05/2021 01:29:59 - INFO - volta.train_utils -   [XVNLI]: iter 30720 Ep: 0.91 loss 0.007 score 0.088 lr 1.13308e-06 
12/05/2021 01:30:37 - INFO - volta.train_utils -   [XVNLI]: iter 30880 Ep: 0.91 loss 0.006 score 0.087 lr 1.139e-06 
12/05/2021 01:31:12 - INFO - volta.train_utils -   [XVNLI]: iter 31040 Ep: 0.92 loss 0.006 score 0.087 lr 1.14492e-06 
12/05/2021 01:31:48 - INFO - volta.train_utils -   [XVNLI]: iter 31200 Ep: 0.92 loss 0.007 score 0.087 lr 1.15083e-06 
12/05/2021 01:32:23 - INFO - volta.train_utils -   [XVNLI]: iter 31360 Ep: 0.93 loss 0.007 score 0.089 lr 1.15675e-06 
12/05/2021 01:33:00 - INFO - volta.train_utils -   [XVNLI]: iter 31520 Ep: 0.93 loss 0.007 score 0.085 lr 1.16266e-06 
12/05/2021 01:33:37 - INFO - volta.train_utils -   [XVNLI]: iter 31680 Ep: 0.94 loss 0.006 score 0.088 lr 1.16858e-06 
12/05/2021 01:34:14 - INFO - volta.train_utils -   [XVNLI]: iter 31840 Ep: 0.94 loss 0.007 score 0.087 lr 1.1745e-06 
12/05/2021 01:34:51 - INFO - volta.train_utils -   [XVNLI]: iter 32000 Ep: 0.95 loss 0.007 score 0.087 lr 1.18041e-06 
12/05/2021 01:35:28 - INFO - volta.train_utils -   [XVNLI]: iter 32160 Ep: 0.95 loss 0.007 score 0.087 lr 1.18633e-06 
12/05/2021 01:36:03 - INFO - volta.train_utils -   [XVNLI]: iter 32320 Ep: 0.96 loss 0.007 score 0.088 lr 1.19224e-06 
12/05/2021 01:36:39 - INFO - volta.train_utils -   [XVNLI]: iter 32480 Ep: 0.96 loss 0.006 score 0.087 lr 1.19816e-06 
12/05/2021 01:37:18 - INFO - volta.train_utils -   [XVNLI]: iter 32640 Ep: 0.97 loss 0.006 score 0.091 lr 1.20408e-06 
12/05/2021 01:37:57 - INFO - volta.train_utils -   [XVNLI]: iter 32800 Ep: 0.97 loss 0.006 score 0.089 lr 1.20999e-06 
12/05/2021 01:38:38 - INFO - volta.train_utils -   [XVNLI]: iter 32960 Ep: 0.97 loss 0.006 score 0.088 lr 1.21591e-06 
12/05/2021 01:39:17 - INFO - volta.train_utils -   [XVNLI]: iter 33120 Ep: 0.98 loss 0.006 score 0.089 lr 1.22182e-06 
12/05/2021 01:39:55 - INFO - volta.train_utils -   [XVNLI]: iter 33280 Ep: 0.98 loss 0.006 score 0.089 lr 1.22774e-06 
12/05/2021 01:40:34 - INFO - volta.train_utils -   [XVNLI]: iter 33440 Ep: 0.99 loss 0.007 score 0.090 lr 1.23366e-06 
12/05/2021 01:41:11 - INFO - volta.train_utils -   [XVNLI]: iter 33600 Ep: 0.99 loss 0.007 score 0.089 lr 1.23957e-06 
12/05/2021 01:41:49 - INFO - volta.train_utils -   [XVNLI]: iter 33760 Ep: 1.00 loss 0.006 score 0.088 lr 1.24549e-06 
12/05/2021 01:45:42 - INFO - volta.train_utils -   Eval task TASK19 on iteration 33800 
12/05/2021 01:45:42 - INFO - volta.train_utils -   Validation [XVNLI]: loss 0.405 score 71.715 
12/05/2021 01:45:42 - INFO - __main__ -   ** ** * Saving model * ** ** 
Epoch:  10%|█         | 1/10 [2:07:39<19:08:51, 7659.08s/it]12/05/2021 01:46:53 - INFO - volta.train_utils -   [XVNLI]: iter 33960 Ep: 1.00 loss 0.006 score 0.092 lr 1.25214e-06 
12/05/2021 01:47:25 - INFO - volta.train_utils -   [XVNLI]: iter 34120 Ep: 1.01 loss 0.006 score 0.091 lr 1.2588e-06 
12/05/2021 01:47:56 - INFO - volta.train_utils -   [XVNLI]: iter 34280 Ep: 1.01 loss 0.006 score 0.090 lr 1.26472e-06 
12/05/2021 01:48:28 - INFO - volta.train_utils -   [XVNLI]: iter 34440 Ep: 1.02 loss 0.007 score 0.090 lr 1.27063e-06 
12/05/2021 01:48:59 - INFO - volta.train_utils -   [XVNLI]: iter 34600 Ep: 1.02 loss 0.006 score 0.092 lr 1.27655e-06 
12/05/2021 01:49:39 - INFO - volta.train_utils -   [XVNLI]: iter 34760 Ep: 1.03 loss 0.006 score 0.091 lr 1.28246e-06 
12/05/2021 01:50:10 - INFO - volta.train_utils -   [XVNLI]: iter 34920 Ep: 1.03 loss 0.006 score 0.090 lr 1.28838e-06 
12/05/2021 01:50:41 - INFO - volta.train_utils -   [XVNLI]: iter 35080 Ep: 1.04 loss 0.006 score 0.090 lr 1.2943e-06 
12/05/2021 01:51:13 - INFO - volta.train_utils -   [XVNLI]: iter 35240 Ep: 1.04 loss 0.006 score 0.088 lr 1.30021e-06 
12/05/2021 01:51:44 - INFO - volta.train_utils -   [XVNLI]: iter 35400 Ep: 1.05 loss 0.007 score 0.089 lr 1.30613e-06 
12/05/2021 01:52:15 - INFO - volta.train_utils -   [XVNLI]: iter 35560 Ep: 1.05 loss 0.006 score 0.091 lr 1.31205e-06 
12/05/2021 01:52:46 - INFO - volta.train_utils -   [XVNLI]: iter 35720 Ep: 1.06 loss 0.006 score 0.091 lr 1.31796e-06 
12/05/2021 01:53:17 - INFO - volta.train_utils -   [XVNLI]: iter 35880 Ep: 1.06 loss 0.006 score 0.090 lr 1.32388e-06 
12/05/2021 01:53:48 - INFO - volta.train_utils -   [XVNLI]: iter 36040 Ep: 1.07 loss 0.007 score 0.088 lr 1.32979e-06 
12/05/2021 01:54:19 - INFO - volta.train_utils -   [XVNLI]: iter 36200 Ep: 1.07 loss 0.007 score 0.090 lr 1.33571e-06 
12/05/2021 01:54:51 - INFO - volta.train_utils -   [XVNLI]: iter 36360 Ep: 1.08 loss 0.007 score 0.090 lr 1.34163e-06 
12/05/2021 01:55:22 - INFO - volta.train_utils -   [XVNLI]: iter 36520 Ep: 1.08 loss 0.006 score 0.089 lr 1.34754e-06 
12/05/2021 01:55:53 - INFO - volta.train_utils -   [XVNLI]: iter 36680 Ep: 1.09 loss 0.006 score 0.089 lr 1.35346e-06 
12/05/2021 01:56:24 - INFO - volta.train_utils -   [XVNLI]: iter 36840 Ep: 1.09 loss 0.007 score 0.089 lr 1.35937e-06 
12/05/2021 01:56:55 - INFO - volta.train_utils -   [XVNLI]: iter 37000 Ep: 1.09 loss 0.006 score 0.088 lr 1.36529e-06 
12/05/2021 01:57:26 - INFO - volta.train_utils -   [XVNLI]: iter 37160 Ep: 1.10 loss 0.006 score 0.091 lr 1.37121e-06 
12/05/2021 01:57:57 - INFO - volta.train_utils -   [XVNLI]: iter 37320 Ep: 1.10 loss 0.006 score 0.089 lr 1.37712e-06 
12/05/2021 01:58:28 - INFO - volta.train_utils -   [XVNLI]: iter 37480 Ep: 1.11 loss 0.006 score 0.091 lr 1.38304e-06 
12/05/2021 01:58:59 - INFO - volta.train_utils -   [XVNLI]: iter 37640 Ep: 1.11 loss 0.007 score 0.092 lr 1.38895e-06 
12/05/2021 01:59:30 - INFO - volta.train_utils -   [XVNLI]: iter 37800 Ep: 1.12 loss 0.007 score 0.091 lr 1.39487e-06 
12/05/2021 02:00:01 - INFO - volta.train_utils -   [XVNLI]: iter 37960 Ep: 1.12 loss 0.006 score 0.090 lr 1.40079e-06 
12/05/2021 02:00:33 - INFO - volta.train_utils -   [XVNLI]: iter 38120 Ep: 1.13 loss 0.006 score 0.089 lr 1.4067e-06 
12/05/2021 02:01:04 - INFO - volta.train_utils -   [XVNLI]: iter 38280 Ep: 1.13 loss 0.007 score 0.089 lr 1.41262e-06 
12/05/2021 02:01:35 - INFO - volta.train_utils -   [XVNLI]: iter 38440 Ep: 1.14 loss 0.006 score 0.089 lr 1.41854e-06 
12/05/2021 02:02:06 - INFO - volta.train_utils -   [XVNLI]: iter 38600 Ep: 1.14 loss 0.006 score 0.090 lr 1.42445e-06 
12/05/2021 02:02:37 - INFO - volta.train_utils -   [XVNLI]: iter 38760 Ep: 1.15 loss 0.006 score 0.090 lr 1.43037e-06 
12/05/2021 02:03:08 - INFO - volta.train_utils -   [XVNLI]: iter 38920 Ep: 1.15 loss 0.006 score 0.088 lr 1.43628e-06 
12/05/2021 02:03:39 - INFO - volta.train_utils -   [XVNLI]: iter 39080 Ep: 1.16 loss 0.006 score 0.090 lr 1.4422e-06 
12/05/2021 02:04:11 - INFO - volta.train_utils -   [XVNLI]: iter 39240 Ep: 1.16 loss 0.006 score 0.091 lr 1.44812e-06 
12/05/2021 02:04:42 - INFO - volta.train_utils -   [XVNLI]: iter 39400 Ep: 1.17 loss 0.006 score 0.090 lr 1.45403e-06 
12/05/2021 02:05:13 - INFO - volta.train_utils -   [XVNLI]: iter 39560 Ep: 1.17 loss 0.006 score 0.091 lr 1.45995e-06 
12/05/2021 02:05:44 - INFO - volta.train_utils -   [XVNLI]: iter 39720 Ep: 1.17 loss 0.006 score 0.090 lr 1.46586e-06 
12/05/2021 02:06:16 - INFO - volta.train_utils -   [XVNLI]: iter 39880 Ep: 1.18 loss 0.006 score 0.091 lr 1.47178e-06 
12/05/2021 02:06:47 - INFO - volta.train_utils -   [XVNLI]: iter 40040 Ep: 1.18 loss 0.006 score 0.088 lr 1.4777e-06 
12/05/2021 02:07:18 - INFO - volta.train_utils -   [XVNLI]: iter 40200 Ep: 1.19 loss 0.006 score 0.089 lr 1.48361e-06 
12/05/2021 02:07:49 - INFO - volta.train_utils -   [XVNLI]: iter 40360 Ep: 1.19 loss 0.007 score 0.089 lr 1.48953e-06 
12/05/2021 02:08:20 - INFO - volta.train_utils -   [XVNLI]: iter 40520 Ep: 1.20 loss 0.006 score 0.091 lr 1.49544e-06 
12/05/2021 02:08:52 - INFO - volta.train_utils -   [XVNLI]: iter 40680 Ep: 1.20 loss 0.006 score 0.092 lr 1.50136e-06 
12/05/2021 02:09:23 - INFO - volta.train_utils -   [XVNLI]: iter 40840 Ep: 1.21 loss 0.006 score 0.089 lr 1.50728e-06 
12/05/2021 02:09:54 - INFO - volta.train_utils -   [XVNLI]: iter 41000 Ep: 1.21 loss 0.007 score 0.089 lr 1.51319e-06 
12/05/2021 02:10:25 - INFO - volta.train_utils -   [XVNLI]: iter 41160 Ep: 1.22 loss 0.006 score 0.090 lr 1.51911e-06 
12/05/2021 02:10:56 - INFO - volta.train_utils -   [XVNLI]: iter 41320 Ep: 1.22 loss 0.007 score 0.091 lr 1.52503e-06 
12/05/2021 02:11:27 - INFO - volta.train_utils -   [XVNLI]: iter 41480 Ep: 1.23 loss 0.007 score 0.088 lr 1.53094e-06 
12/05/2021 02:11:58 - INFO - volta.train_utils -   [XVNLI]: iter 41640 Ep: 1.23 loss 0.006 score 0.089 lr 1.53686e-06 
12/05/2021 02:12:30 - INFO - volta.train_utils -   [XVNLI]: iter 41800 Ep: 1.24 loss 0.006 score 0.090 lr 1.54277e-06 
12/05/2021 02:13:01 - INFO - volta.train_utils -   [XVNLI]: iter 41960 Ep: 1.24 loss 0.006 score 0.091 lr 1.54869e-06 
12/05/2021 02:13:33 - INFO - volta.train_utils -   [XVNLI]: iter 42120 Ep: 1.25 loss 0.007 score 0.090 lr 1.55461e-06 
12/05/2021 02:14:04 - INFO - volta.train_utils -   [XVNLI]: iter 42280 Ep: 1.25 loss 0.006 score 0.089 lr 1.56052e-06 
12/05/2021 02:14:35 - INFO - volta.train_utils -   [XVNLI]: iter 42440 Ep: 1.26 loss 0.006 score 0.091 lr 1.56644e-06 
12/05/2021 02:15:07 - INFO - volta.train_utils -   [XVNLI]: iter 42600 Ep: 1.26 loss 0.006 score 0.089 lr 1.57235e-06 
12/05/2021 02:15:38 - INFO - volta.train_utils -   [XVNLI]: iter 42760 Ep: 1.26 loss 0.006 score 0.089 lr 1.57827e-06 
12/05/2021 02:16:09 - INFO - volta.train_utils -   [XVNLI]: iter 42920 Ep: 1.27 loss 0.007 score 0.090 lr 1.58419e-06 
12/05/2021 02:16:40 - INFO - volta.train_utils -   [XVNLI]: iter 43080 Ep: 1.27 loss 0.006 score 0.091 lr 1.5901e-06 
12/05/2021 02:17:11 - INFO - volta.train_utils -   [XVNLI]: iter 43240 Ep: 1.28 loss 0.006 score 0.091 lr 1.59602e-06 
12/05/2021 02:17:42 - INFO - volta.train_utils -   [XVNLI]: iter 43400 Ep: 1.28 loss 0.007 score 0.090 lr 1.60193e-06 
12/05/2021 02:18:14 - INFO - volta.train_utils -   [XVNLI]: iter 43560 Ep: 1.29 loss 0.006 score 0.090 lr 1.60785e-06 
12/05/2021 02:18:45 - INFO - volta.train_utils -   [XVNLI]: iter 43720 Ep: 1.29 loss 0.006 score 0.089 lr 1.61377e-06 
12/05/2021 02:19:16 - INFO - volta.train_utils -   [XVNLI]: iter 43880 Ep: 1.30 loss 0.007 score 0.087 lr 1.61968e-06 
12/05/2021 02:19:47 - INFO - volta.train_utils -   [XVNLI]: iter 44040 Ep: 1.30 loss 0.006 score 0.091 lr 1.6256e-06 
12/05/2021 02:20:18 - INFO - volta.train_utils -   [XVNLI]: iter 44200 Ep: 1.31 loss 0.006 score 0.089 lr 1.63152e-06 
12/05/2021 02:20:49 - INFO - volta.train_utils -   [XVNLI]: iter 44360 Ep: 1.31 loss 0.006 score 0.089 lr 1.63743e-06 
12/05/2021 02:21:20 - INFO - volta.train_utils -   [XVNLI]: iter 44520 Ep: 1.32 loss 0.006 score 0.088 lr 1.64335e-06 
12/05/2021 02:21:51 - INFO - volta.train_utils -   [XVNLI]: iter 44680 Ep: 1.32 loss 0.006 score 0.090 lr 1.64926e-06 
12/05/2021 02:22:23 - INFO - volta.train_utils -   [XVNLI]: iter 44840 Ep: 1.33 loss 0.006 score 0.090 lr 1.65518e-06 
12/05/2021 02:22:54 - INFO - volta.train_utils -   [XVNLI]: iter 45000 Ep: 1.33 loss 0.007 score 0.092 lr 1.6611e-06 
12/05/2021 02:23:25 - INFO - volta.train_utils -   [XVNLI]: iter 45160 Ep: 1.34 loss 0.006 score 0.091 lr 1.66701e-06 
12/05/2021 02:23:56 - INFO - volta.train_utils -   [XVNLI]: iter 45320 Ep: 1.34 loss 0.007 score 0.091 lr 1.67293e-06 
12/05/2021 02:24:27 - INFO - volta.train_utils -   [XVNLI]: iter 45480 Ep: 1.35 loss 0.006 score 0.090 lr 1.67884e-06 
12/05/2021 02:24:59 - INFO - volta.train_utils -   [XVNLI]: iter 45640 Ep: 1.35 loss 0.006 score 0.090 lr 1.68476e-06 
12/05/2021 02:25:30 - INFO - volta.train_utils -   [XVNLI]: iter 45800 Ep: 1.35 loss 0.006 score 0.092 lr 1.69068e-06 
12/05/2021 02:26:01 - INFO - volta.train_utils -   [XVNLI]: iter 45960 Ep: 1.36 loss 0.007 score 0.088 lr 1.69659e-06 
12/05/2021 02:26:32 - INFO - volta.train_utils -   [XVNLI]: iter 46120 Ep: 1.36 loss 0.007 score 0.090 lr 1.70251e-06 
12/05/2021 02:27:03 - INFO - volta.train_utils -   [XVNLI]: iter 46280 Ep: 1.37 loss 0.006 score 0.091 lr 1.70842e-06 
12/05/2021 02:27:34 - INFO - volta.train_utils -   [XVNLI]: iter 46440 Ep: 1.37 loss 0.006 score 0.092 lr 1.71434e-06 
12/05/2021 02:28:05 - INFO - volta.train_utils -   [XVNLI]: iter 46600 Ep: 1.38 loss 0.006 score 0.092 lr 1.72026e-06 
12/05/2021 02:28:36 - INFO - volta.train_utils -   [XVNLI]: iter 46760 Ep: 1.38 loss 0.006 score 0.091 lr 1.72617e-06 
12/05/2021 02:29:07 - INFO - volta.train_utils -   [XVNLI]: iter 46920 Ep: 1.39 loss 0.006 score 0.090 lr 1.73209e-06 
12/05/2021 02:29:38 - INFO - volta.train_utils -   [XVNLI]: iter 47080 Ep: 1.39 loss 0.006 score 0.091 lr 1.73801e-06 
12/05/2021 02:30:10 - INFO - volta.train_utils -   [XVNLI]: iter 47240 Ep: 1.40 loss 0.006 score 0.092 lr 1.74392e-06 
12/05/2021 02:30:41 - INFO - volta.train_utils -   [XVNLI]: iter 47400 Ep: 1.40 loss 0.007 score 0.090 lr 1.74984e-06 
12/05/2021 02:31:12 - INFO - volta.train_utils -   [XVNLI]: iter 47560 Ep: 1.41 loss 0.006 score 0.089 lr 1.75575e-06 
12/05/2021 02:31:43 - INFO - volta.train_utils -   [XVNLI]: iter 47720 Ep: 1.41 loss 0.007 score 0.091 lr 1.76167e-06 
12/05/2021 02:32:14 - INFO - volta.train_utils -   [XVNLI]: iter 47880 Ep: 1.42 loss 0.006 score 0.092 lr 1.76759e-06 
12/05/2021 02:32:45 - INFO - volta.train_utils -   [XVNLI]: iter 48040 Ep: 1.42 loss 0.006 score 0.090 lr 1.7735e-06 
12/05/2021 02:33:17 - INFO - volta.train_utils -   [XVNLI]: iter 48200 Ep: 1.43 loss 0.006 score 0.091 lr 1.77942e-06 
12/05/2021 02:33:48 - INFO - volta.train_utils -   [XVNLI]: iter 48360 Ep: 1.43 loss 0.006 score 0.092 lr 1.78533e-06 
12/05/2021 02:34:19 - INFO - volta.train_utils -   [XVNLI]: iter 48520 Ep: 1.44 loss 0.006 score 0.090 lr 1.79125e-06 
12/05/2021 02:34:50 - INFO - volta.train_utils -   [XVNLI]: iter 48680 Ep: 1.44 loss 0.006 score 0.092 lr 1.79717e-06 
12/05/2021 02:35:21 - INFO - volta.train_utils -   [XVNLI]: iter 48840 Ep: 1.44 loss 0.006 score 0.093 lr 1.80308e-06 
12/05/2021 02:35:52 - INFO - volta.train_utils -   [XVNLI]: iter 49000 Ep: 1.45 loss 0.006 score 0.093 lr 1.809e-06 
12/05/2021 02:36:23 - INFO - volta.train_utils -   [XVNLI]: iter 49160 Ep: 1.45 loss 0.006 score 0.091 lr 1.81491e-06 
12/05/2021 02:36:54 - INFO - volta.train_utils -   [XVNLI]: iter 49320 Ep: 1.46 loss 0.006 score 0.090 lr 1.82083e-06 
12/05/2021 02:37:25 - INFO - volta.train_utils -   [XVNLI]: iter 49480 Ep: 1.46 loss 0.005 score 0.092 lr 1.82675e-06 
12/05/2021 02:37:57 - INFO - volta.train_utils -   [XVNLI]: iter 49640 Ep: 1.47 loss 0.006 score 0.091 lr 1.83266e-06 
12/05/2021 02:38:28 - INFO - volta.train_utils -   [XVNLI]: iter 49800 Ep: 1.47 loss 0.006 score 0.090 lr 1.83858e-06 
12/05/2021 02:39:00 - INFO - volta.train_utils -   [XVNLI]: iter 49960 Ep: 1.48 loss 0.006 score 0.093 lr 1.8445e-06 
12/05/2021 02:39:31 - INFO - volta.train_utils -   [XVNLI]: iter 50120 Ep: 1.48 loss 0.006 score 0.090 lr 1.85041e-06 
12/05/2021 02:40:03 - INFO - volta.train_utils -   [XVNLI]: iter 50280 Ep: 1.49 loss 0.005 score 0.092 lr 1.85633e-06 
12/05/2021 02:40:34 - INFO - volta.train_utils -   [XVNLI]: iter 50440 Ep: 1.49 loss 0.006 score 0.091 lr 1.86224e-06 
12/05/2021 02:41:05 - INFO - volta.train_utils -   [XVNLI]: iter 50600 Ep: 1.50 loss 0.005 score 0.092 lr 1.86816e-06 
12/05/2021 02:41:36 - INFO - volta.train_utils -   [XVNLI]: iter 50760 Ep: 1.50 loss 0.006 score 0.093 lr 1.87408e-06 
12/05/2021 02:42:07 - INFO - volta.train_utils -   [XVNLI]: iter 50920 Ep: 1.51 loss 0.006 score 0.091 lr 1.87999e-06 
12/05/2021 02:42:39 - INFO - volta.train_utils -   [XVNLI]: iter 51080 Ep: 1.51 loss 0.007 score 0.090 lr 1.88591e-06 
12/05/2021 02:43:10 - INFO - volta.train_utils -   [XVNLI]: iter 51240 Ep: 1.52 loss 0.006 score 0.091 lr 1.89182e-06 
12/05/2021 02:43:42 - INFO - volta.train_utils -   [XVNLI]: iter 51400 Ep: 1.52 loss 0.006 score 0.091 lr 1.89774e-06 
12/05/2021 02:44:13 - INFO - volta.train_utils -   [XVNLI]: iter 51560 Ep: 1.53 loss 0.007 score 0.091 lr 1.90366e-06 
12/05/2021 02:44:45 - INFO - volta.train_utils -   [XVNLI]: iter 51720 Ep: 1.53 loss 0.006 score 0.093 lr 1.90957e-06 
12/05/2021 02:45:17 - INFO - volta.train_utils -   [XVNLI]: iter 51880 Ep: 1.53 loss 0.006 score 0.089 lr 1.91549e-06 
12/05/2021 02:45:48 - INFO - volta.train_utils -   [XVNLI]: iter 52040 Ep: 1.54 loss 0.006 score 0.090 lr 1.9214e-06 
12/05/2021 02:46:19 - INFO - volta.train_utils -   [XVNLI]: iter 52200 Ep: 1.54 loss 0.005 score 0.091 lr 1.92732e-06 
12/05/2021 02:46:50 - INFO - volta.train_utils -   [XVNLI]: iter 52360 Ep: 1.55 loss 0.006 score 0.092 lr 1.93324e-06 
12/05/2021 02:47:21 - INFO - volta.train_utils -   [XVNLI]: iter 52520 Ep: 1.55 loss 0.006 score 0.091 lr 1.93915e-06 
12/05/2021 02:47:52 - INFO - volta.train_utils -   [XVNLI]: iter 52680 Ep: 1.56 loss 0.006 score 0.090 lr 1.94507e-06 
12/05/2021 02:48:24 - INFO - volta.train_utils -   [XVNLI]: iter 52840 Ep: 1.56 loss 0.006 score 0.093 lr 1.95099e-06 
12/05/2021 02:48:55 - INFO - volta.train_utils -   [XVNLI]: iter 53000 Ep: 1.57 loss 0.006 score 0.090 lr 1.9569e-06 
12/05/2021 02:49:26 - INFO - volta.train_utils -   [XVNLI]: iter 53160 Ep: 1.57 loss 0.007 score 0.090 lr 1.96282e-06 
12/05/2021 02:49:57 - INFO - volta.train_utils -   [XVNLI]: iter 53320 Ep: 1.58 loss 0.005 score 0.091 lr 1.96873e-06 
12/05/2021 02:50:28 - INFO - volta.train_utils -   [XVNLI]: iter 53480 Ep: 1.58 loss 0.006 score 0.092 lr 1.97465e-06 
12/05/2021 02:50:59 - INFO - volta.train_utils -   [XVNLI]: iter 53640 Ep: 1.59 loss 0.006 score 0.089 lr 1.98057e-06 
12/05/2021 02:51:30 - INFO - volta.train_utils -   [XVNLI]: iter 53800 Ep: 1.59 loss 0.006 score 0.093 lr 1.98648e-06 
12/05/2021 02:52:01 - INFO - volta.train_utils -   [XVNLI]: iter 53960 Ep: 1.60 loss 0.006 score 0.091 lr 1.9924e-06 
12/05/2021 02:52:32 - INFO - volta.train_utils -   [XVNLI]: iter 54120 Ep: 1.60 loss 0.006 score 0.090 lr 1.99831e-06 
12/05/2021 02:53:03 - INFO - volta.train_utils -   [XVNLI]: iter 54280 Ep: 1.61 loss 0.006 score 0.090 lr 2.00423e-06 
12/05/2021 02:53:35 - INFO - volta.train_utils -   [XVNLI]: iter 54440 Ep: 1.61 loss 0.006 score 0.090 lr 2.01015e-06 
12/05/2021 02:54:06 - INFO - volta.train_utils -   [XVNLI]: iter 54600 Ep: 1.62 loss 0.006 score 0.092 lr 2.01606e-06 
12/05/2021 02:54:37 - INFO - volta.train_utils -   [XVNLI]: iter 54760 Ep: 1.62 loss 0.006 score 0.093 lr 2.02198e-06 
12/05/2021 02:55:08 - INFO - volta.train_utils -   [XVNLI]: iter 54920 Ep: 1.62 loss 0.006 score 0.091 lr 2.02789e-06 
12/05/2021 02:55:39 - INFO - volta.train_utils -   [XVNLI]: iter 55080 Ep: 1.63 loss 0.006 score 0.093 lr 2.03381e-06 
12/05/2021 02:56:10 - INFO - volta.train_utils -   [XVNLI]: iter 55240 Ep: 1.63 loss 0.006 score 0.092 lr 2.03973e-06 
12/05/2021 02:56:42 - INFO - volta.train_utils -   [XVNLI]: iter 55400 Ep: 1.64 loss 0.006 score 0.090 lr 2.04564e-06 
12/05/2021 02:57:13 - INFO - volta.train_utils -   [XVNLI]: iter 55560 Ep: 1.64 loss 0.007 score 0.092 lr 2.05156e-06 
12/05/2021 02:57:44 - INFO - volta.train_utils -   [XVNLI]: iter 55720 Ep: 1.65 loss 0.006 score 0.091 lr 2.05748e-06 
12/05/2021 02:58:15 - INFO - volta.train_utils -   [XVNLI]: iter 55880 Ep: 1.65 loss 0.006 score 0.091 lr 2.06339e-06 
12/05/2021 02:58:46 - INFO - volta.train_utils -   [XVNLI]: iter 56040 Ep: 1.66 loss 0.006 score 0.093 lr 2.06931e-06 
12/05/2021 02:59:17 - INFO - volta.train_utils -   [XVNLI]: iter 56200 Ep: 1.66 loss 0.007 score 0.091 lr 2.07522e-06 
12/05/2021 02:59:49 - INFO - volta.train_utils -   [XVNLI]: iter 56360 Ep: 1.67 loss 0.006 score 0.092 lr 2.08114e-06 
12/05/2021 03:00:20 - INFO - volta.train_utils -   [XVNLI]: iter 56520 Ep: 1.67 loss 0.006 score 0.091 lr 2.08706e-06 
12/05/2021 03:00:51 - INFO - volta.train_utils -   [XVNLI]: iter 56680 Ep: 1.68 loss 0.006 score 0.092 lr 2.09297e-06 
12/05/2021 03:01:23 - INFO - volta.train_utils -   [XVNLI]: iter 56840 Ep: 1.68 loss 0.006 score 0.093 lr 2.09889e-06 
12/05/2021 03:01:54 - INFO - volta.train_utils -   [XVNLI]: iter 57000 Ep: 1.69 loss 0.007 score 0.092 lr 2.1048e-06 
12/05/2021 03:02:25 - INFO - volta.train_utils -   [XVNLI]: iter 57160 Ep: 1.69 loss 0.007 score 0.090 lr 2.11072e-06 
12/05/2021 03:02:56 - INFO - volta.train_utils -   [XVNLI]: iter 57320 Ep: 1.70 loss 0.006 score 0.092 lr 2.11664e-06 
12/05/2021 03:03:28 - INFO - volta.train_utils -   [XVNLI]: iter 57480 Ep: 1.70 loss 0.006 score 0.092 lr 2.12255e-06 
12/05/2021 03:03:59 - INFO - volta.train_utils -   [XVNLI]: iter 57640 Ep: 1.71 loss 0.005 score 0.093 lr 2.12847e-06 
12/05/2021 03:04:31 - INFO - volta.train_utils -   [XVNLI]: iter 57800 Ep: 1.71 loss 0.005 score 0.091 lr 2.13438e-06 
12/05/2021 03:05:02 - INFO - volta.train_utils -   [XVNLI]: iter 57960 Ep: 1.71 loss 0.006 score 0.093 lr 2.1403e-06 
12/05/2021 03:05:33 - INFO - volta.train_utils -   [XVNLI]: iter 58120 Ep: 1.72 loss 0.006 score 0.091 lr 2.14622e-06 
12/05/2021 03:06:04 - INFO - volta.train_utils -   [XVNLI]: iter 58280 Ep: 1.72 loss 0.006 score 0.092 lr 2.15213e-06 
12/05/2021 03:06:36 - INFO - volta.train_utils -   [XVNLI]: iter 58440 Ep: 1.73 loss 0.005 score 0.094 lr 2.15805e-06 
12/05/2021 03:07:07 - INFO - volta.train_utils -   [XVNLI]: iter 58600 Ep: 1.73 loss 0.006 score 0.092 lr 2.16396e-06 
12/05/2021 03:07:38 - INFO - volta.train_utils -   [XVNLI]: iter 58760 Ep: 1.74 loss 0.006 score 0.092 lr 2.16988e-06 
12/05/2021 03:08:10 - INFO - volta.train_utils -   [XVNLI]: iter 58920 Ep: 1.74 loss 0.006 score 0.090 lr 2.1758e-06 
12/05/2021 03:08:41 - INFO - volta.train_utils -   [XVNLI]: iter 59080 Ep: 1.75 loss 0.006 score 0.091 lr 2.18171e-06 
12/05/2021 03:09:12 - INFO - volta.train_utils -   [XVNLI]: iter 59240 Ep: 1.75 loss 0.006 score 0.091 lr 2.18763e-06 
12/05/2021 03:09:45 - INFO - volta.train_utils -   [XVNLI]: iter 59400 Ep: 1.76 loss 0.006 score 0.091 lr 2.19355e-06 
12/05/2021 03:10:18 - INFO - volta.train_utils -   [XVNLI]: iter 59560 Ep: 1.76 loss 0.006 score 0.091 lr 2.19946e-06 
12/05/2021 03:10:49 - INFO - volta.train_utils -   [XVNLI]: iter 59720 Ep: 1.77 loss 0.006 score 0.090 lr 2.20538e-06 
12/05/2021 03:11:22 - INFO - volta.train_utils -   [XVNLI]: iter 59880 Ep: 1.77 loss 0.006 score 0.091 lr 2.21129e-06 
12/05/2021 03:11:53 - INFO - volta.train_utils -   [XVNLI]: iter 60040 Ep: 1.78 loss 0.005 score 0.092 lr 2.21721e-06 
12/05/2021 03:12:25 - INFO - volta.train_utils -   [XVNLI]: iter 60200 Ep: 1.78 loss 0.006 score 0.091 lr 2.22313e-06 
12/05/2021 03:12:56 - INFO - volta.train_utils -   [XVNLI]: iter 60360 Ep: 1.79 loss 0.006 score 0.093 lr 2.22904e-06 
12/05/2021 03:13:29 - INFO - volta.train_utils -   [XVNLI]: iter 60520 Ep: 1.79 loss 0.006 score 0.091 lr 2.23496e-06 
12/05/2021 03:14:00 - INFO - volta.train_utils -   [XVNLI]: iter 60680 Ep: 1.79 loss 0.006 score 0.091 lr 2.24087e-06 
12/05/2021 03:14:32 - INFO - volta.train_utils -   [XVNLI]: iter 60840 Ep: 1.80 loss 0.006 score 0.090 lr 2.24679e-06 
12/05/2021 03:15:03 - INFO - volta.train_utils -   [XVNLI]: iter 61000 Ep: 1.80 loss 0.006 score 0.091 lr 2.25271e-06 
12/05/2021 03:15:34 - INFO - volta.train_utils -   [XVNLI]: iter 61160 Ep: 1.81 loss 0.006 score 0.090 lr 2.25862e-06 
12/05/2021 03:16:07 - INFO - volta.train_utils -   [XVNLI]: iter 61320 Ep: 1.81 loss 0.006 score 0.093 lr 2.26454e-06 
12/05/2021 03:16:39 - INFO - volta.train_utils -   [XVNLI]: iter 61480 Ep: 1.82 loss 0.006 score 0.092 lr 2.27045e-06 
12/05/2021 03:17:12 - INFO - volta.train_utils -   [XVNLI]: iter 61640 Ep: 1.82 loss 0.006 score 0.089 lr 2.27637e-06 
12/05/2021 03:17:44 - INFO - volta.train_utils -   [XVNLI]: iter 61800 Ep: 1.83 loss 0.006 score 0.091 lr 2.28229e-06 
12/05/2021 03:18:16 - INFO - volta.train_utils -   [XVNLI]: iter 61960 Ep: 1.83 loss 0.006 score 0.092 lr 2.2882e-06 
12/05/2021 03:18:50 - INFO - volta.train_utils -   [XVNLI]: iter 62120 Ep: 1.84 loss 0.006 score 0.092 lr 2.29412e-06 
12/05/2021 03:19:23 - INFO - volta.train_utils -   [XVNLI]: iter 62280 Ep: 1.84 loss 0.006 score 0.092 lr 2.30004e-06 
12/05/2021 03:19:56 - INFO - volta.train_utils -   [XVNLI]: iter 62440 Ep: 1.85 loss 0.006 score 0.092 lr 2.30595e-06 
12/05/2021 03:20:30 - INFO - volta.train_utils -   [XVNLI]: iter 62600 Ep: 1.85 loss 0.006 score 0.093 lr 2.31187e-06 
12/05/2021 03:21:04 - INFO - volta.train_utils -   [XVNLI]: iter 62760 Ep: 1.86 loss 0.006 score 0.093 lr 2.31778e-06 
12/05/2021 03:21:36 - INFO - volta.train_utils -   [XVNLI]: iter 62920 Ep: 1.86 loss 0.006 score 0.091 lr 2.3237e-06 
12/05/2021 03:22:11 - INFO - volta.train_utils -   [XVNLI]: iter 63080 Ep: 1.87 loss 0.006 score 0.091 lr 2.32962e-06 
12/05/2021 03:22:43 - INFO - volta.train_utils -   [XVNLI]: iter 63240 Ep: 1.87 loss 0.006 score 0.092 lr 2.33553e-06 
12/05/2021 03:23:15 - INFO - volta.train_utils -   [XVNLI]: iter 63400 Ep: 1.88 loss 0.006 score 0.094 lr 2.34145e-06 
12/05/2021 03:23:47 - INFO - volta.train_utils -   [XVNLI]: iter 63560 Ep: 1.88 loss 0.006 score 0.092 lr 2.34736e-06 
12/05/2021 03:24:21 - INFO - volta.train_utils -   [XVNLI]: iter 63720 Ep: 1.88 loss 0.006 score 0.094 lr 2.35328e-06 
12/05/2021 03:24:53 - INFO - volta.train_utils -   [XVNLI]: iter 63880 Ep: 1.89 loss 0.006 score 0.091 lr 2.3592e-06 
12/05/2021 03:25:26 - INFO - volta.train_utils -   [XVNLI]: iter 64040 Ep: 1.89 loss 0.006 score 0.092 lr 2.36511e-06 
12/05/2021 03:25:58 - INFO - volta.train_utils -   [XVNLI]: iter 64200 Ep: 1.90 loss 0.005 score 0.092 lr 2.37103e-06 
12/05/2021 03:26:32 - INFO - volta.train_utils -   [XVNLI]: iter 64360 Ep: 1.90 loss 0.006 score 0.094 lr 2.37694e-06 
12/05/2021 03:27:05 - INFO - volta.train_utils -   [XVNLI]: iter 64520 Ep: 1.91 loss 0.006 score 0.093 lr 2.38286e-06 
12/05/2021 03:27:38 - INFO - volta.train_utils -   [XVNLI]: iter 64680 Ep: 1.91 loss 0.006 score 0.092 lr 2.38878e-06 
12/05/2021 03:28:13 - INFO - volta.train_utils -   [XVNLI]: iter 64840 Ep: 1.92 loss 0.006 score 0.091 lr 2.39469e-06 
12/05/2021 03:28:44 - INFO - volta.train_utils -   [XVNLI]: iter 65000 Ep: 1.92 loss 0.006 score 0.094 lr 2.40061e-06 
12/05/2021 03:29:17 - INFO - volta.train_utils -   [XVNLI]: iter 65160 Ep: 1.93 loss 0.005 score 0.093 lr 2.40653e-06 
12/05/2021 03:29:50 - INFO - volta.train_utils -   [XVNLI]: iter 65320 Ep: 1.93 loss 0.006 score 0.091 lr 2.41244e-06 
12/05/2021 03:30:24 - INFO - volta.train_utils -   [XVNLI]: iter 65480 Ep: 1.94 loss 0.006 score 0.093 lr 2.41836e-06 
12/05/2021 03:30:58 - INFO - volta.train_utils -   [XVNLI]: iter 65640 Ep: 1.94 loss 0.006 score 0.092 lr 2.42427e-06 
12/05/2021 03:31:32 - INFO - volta.train_utils -   [XVNLI]: iter 65800 Ep: 1.95 loss 0.005 score 0.095 lr 2.43019e-06 
12/05/2021 03:32:05 - INFO - volta.train_utils -   [XVNLI]: iter 65960 Ep: 1.95 loss 0.006 score 0.091 lr 2.43611e-06 
12/05/2021 03:32:37 - INFO - volta.train_utils -   [XVNLI]: iter 66120 Ep: 1.96 loss 0.006 score 0.095 lr 2.44202e-06 
12/05/2021 03:33:12 - INFO - volta.train_utils -   [XVNLI]: iter 66280 Ep: 1.96 loss 0.006 score 0.091 lr 2.44794e-06 
12/05/2021 03:33:46 - INFO - volta.train_utils -   [XVNLI]: iter 66440 Ep: 1.97 loss 0.006 score 0.092 lr 2.45385e-06 
12/05/2021 03:34:19 - INFO - volta.train_utils -   [XVNLI]: iter 66600 Ep: 1.97 loss 0.006 score 0.092 lr 2.45977e-06 
12/05/2021 03:34:53 - INFO - volta.train_utils -   [XVNLI]: iter 66760 Ep: 1.97 loss 0.006 score 0.092 lr 2.46569e-06 
12/05/2021 03:35:26 - INFO - volta.train_utils -   [XVNLI]: iter 66920 Ep: 1.98 loss 0.005 score 0.094 lr 2.4716e-06 
12/05/2021 03:35:59 - INFO - volta.train_utils -   [XVNLI]: iter 67080 Ep: 1.98 loss 0.006 score 0.093 lr 2.47752e-06 
12/05/2021 03:36:32 - INFO - volta.train_utils -   [XVNLI]: iter 67240 Ep: 1.99 loss 0.007 score 0.093 lr 2.48343e-06 
12/05/2021 03:37:07 - INFO - volta.train_utils -   [XVNLI]: iter 67400 Ep: 1.99 loss 0.006 score 0.093 lr 2.48935e-06 
12/05/2021 03:37:39 - INFO - volta.train_utils -   [XVNLI]: iter 67560 Ep: 2.00 loss 0.006 score 0.094 lr 2.49527e-06 
12/05/2021 03:41:41 - INFO - volta.train_utils -   Eval task TASK19 on iteration 67600 
12/05/2021 03:41:41 - INFO - volta.train_utils -   Validation [XVNLI]: loss 0.387 score 73.494 
12/05/2021 03:41:41 - INFO - __main__ -   ** ** * Saving model * ** ** 
Epoch:  20%|██        | 2/10 [4:03:36<16:33:08, 7448.56s/it]12/05/2021 03:42:47 - INFO - volta.train_utils -   [XVNLI]: iter 67760 Ep: 2.00 loss 0.006 score 0.096 lr 2.49955e-06 
12/05/2021 03:43:18 - INFO - volta.train_utils -   [XVNLI]: iter 67920 Ep: 2.01 loss 0.005 score 0.094 lr 2.49905e-06 
12/05/2021 03:43:49 - INFO - volta.train_utils -   [XVNLI]: iter 68080 Ep: 2.01 loss 0.005 score 0.094 lr 2.49839e-06 
12/05/2021 03:44:20 - INFO - volta.train_utils -   [XVNLI]: iter 68240 Ep: 2.02 loss 0.006 score 0.095 lr 2.49773e-06 
12/05/2021 03:44:52 - INFO - volta.train_utils -   [XVNLI]: iter 68400 Ep: 2.02 loss 0.005 score 0.094 lr 2.49707e-06 
12/05/2021 03:45:30 - INFO - volta.train_utils -   [XVNLI]: iter 68560 Ep: 2.03 loss 0.006 score 0.094 lr 2.49642e-06 
12/05/2021 03:46:01 - INFO - volta.train_utils -   [XVNLI]: iter 68720 Ep: 2.03 loss 0.006 score 0.094 lr 2.49576e-06 
12/05/2021 03:46:32 - INFO - volta.train_utils -   [XVNLI]: iter 68880 Ep: 2.04 loss 0.005 score 0.095 lr 2.4951e-06 
12/05/2021 03:47:03 - INFO - volta.train_utils -   [XVNLI]: iter 69040 Ep: 2.04 loss 0.006 score 0.092 lr 2.49445e-06 
12/05/2021 03:47:34 - INFO - volta.train_utils -   [XVNLI]: iter 69200 Ep: 2.05 loss 0.006 score 0.094 lr 2.49379e-06 
12/05/2021 03:48:06 - INFO - volta.train_utils -   [XVNLI]: iter 69360 Ep: 2.05 loss 0.005 score 0.095 lr 2.49313e-06 
12/05/2021 03:48:37 - INFO - volta.train_utils -   [XVNLI]: iter 69520 Ep: 2.06 loss 0.006 score 0.094 lr 2.49247e-06 
12/05/2021 03:49:08 - INFO - volta.train_utils -   [XVNLI]: iter 69680 Ep: 2.06 loss 0.005 score 0.093 lr 2.49182e-06 
12/05/2021 03:49:39 - INFO - volta.train_utils -   [XVNLI]: iter 69840 Ep: 2.07 loss 0.006 score 0.094 lr 2.49116e-06 
12/05/2021 03:50:10 - INFO - volta.train_utils -   [XVNLI]: iter 70000 Ep: 2.07 loss 0.005 score 0.094 lr 2.4905e-06 
12/05/2021 03:50:41 - INFO - volta.train_utils -   [XVNLI]: iter 70160 Ep: 2.08 loss 0.006 score 0.094 lr 2.48984e-06 
12/05/2021 03:51:13 - INFO - volta.train_utils -   [XVNLI]: iter 70320 Ep: 2.08 loss 0.007 score 0.093 lr 2.48919e-06 
12/05/2021 03:51:44 - INFO - volta.train_utils -   [XVNLI]: iter 70480 Ep: 2.08 loss 0.006 score 0.094 lr 2.48853e-06 
12/05/2021 03:52:15 - INFO - volta.train_utils -   [XVNLI]: iter 70640 Ep: 2.09 loss 0.006 score 0.094 lr 2.48787e-06 
12/05/2021 03:52:47 - INFO - volta.train_utils -   [XVNLI]: iter 70800 Ep: 2.09 loss 0.005 score 0.093 lr 2.48721e-06 
12/05/2021 03:53:18 - INFO - volta.train_utils -   [XVNLI]: iter 70960 Ep: 2.10 loss 0.006 score 0.094 lr 2.48656e-06 
12/05/2021 03:53:49 - INFO - volta.train_utils -   [XVNLI]: iter 71120 Ep: 2.10 loss 0.006 score 0.094 lr 2.4859e-06 
12/05/2021 03:54:20 - INFO - volta.train_utils -   [XVNLI]: iter 71280 Ep: 2.11 loss 0.007 score 0.092 lr 2.48524e-06 
12/05/2021 03:54:51 - INFO - volta.train_utils -   [XVNLI]: iter 71440 Ep: 2.11 loss 0.006 score 0.094 lr 2.48459e-06 
12/05/2021 03:55:22 - INFO - volta.train_utils -   [XVNLI]: iter 71600 Ep: 2.12 loss 0.006 score 0.094 lr 2.48393e-06 
12/05/2021 03:55:53 - INFO - volta.train_utils -   [XVNLI]: iter 71760 Ep: 2.12 loss 0.006 score 0.095 lr 2.48327e-06 
12/05/2021 03:56:24 - INFO - volta.train_utils -   [XVNLI]: iter 71920 Ep: 2.13 loss 0.005 score 0.094 lr 2.48261e-06 
12/05/2021 03:56:55 - INFO - volta.train_utils -   [XVNLI]: iter 72080 Ep: 2.13 loss 0.005 score 0.093 lr 2.48196e-06 
12/05/2021 03:57:26 - INFO - volta.train_utils -   [XVNLI]: iter 72240 Ep: 2.14 loss 0.005 score 0.095 lr 2.4813e-06 
12/05/2021 03:57:58 - INFO - volta.train_utils -   [XVNLI]: iter 72400 Ep: 2.14 loss 0.006 score 0.094 lr 2.48064e-06 
12/05/2021 03:58:30 - INFO - volta.train_utils -   [XVNLI]: iter 72560 Ep: 2.15 loss 0.006 score 0.096 lr 2.47998e-06 
12/05/2021 03:59:01 - INFO - volta.train_utils -   [XVNLI]: iter 72720 Ep: 2.15 loss 0.006 score 0.096 lr 2.47933e-06 
12/05/2021 03:59:32 - INFO - volta.train_utils -   [XVNLI]: iter 72880 Ep: 2.16 loss 0.006 score 0.094 lr 2.47867e-06 
12/05/2021 04:00:03 - INFO - volta.train_utils -   [XVNLI]: iter 73040 Ep: 2.16 loss 0.005 score 0.094 lr 2.47801e-06 
12/05/2021 04:00:34 - INFO - volta.train_utils -   [XVNLI]: iter 73200 Ep: 2.17 loss 0.006 score 0.096 lr 2.47735e-06 
12/05/2021 04:01:05 - INFO - volta.train_utils -   [XVNLI]: iter 73360 Ep: 2.17 loss 0.006 score 0.093 lr 2.4767e-06 
12/05/2021 04:01:36 - INFO - volta.train_utils -   [XVNLI]: iter 73520 Ep: 2.17 loss 0.006 score 0.095 lr 2.47604e-06 
12/05/2021 04:02:07 - INFO - volta.train_utils -   [XVNLI]: iter 73680 Ep: 2.18 loss 0.005 score 0.095 lr 2.47538e-06 
12/05/2021 04:02:38 - INFO - volta.train_utils -   [XVNLI]: iter 73840 Ep: 2.18 loss 0.005 score 0.093 lr 2.47473e-06 
12/05/2021 04:03:09 - INFO - volta.train_utils -   [XVNLI]: iter 74000 Ep: 2.19 loss 0.005 score 0.095 lr 2.47407e-06 
12/05/2021 04:03:40 - INFO - volta.train_utils -   [XVNLI]: iter 74160 Ep: 2.19 loss 0.005 score 0.095 lr 2.47341e-06 
12/05/2021 04:04:11 - INFO - volta.train_utils -   [XVNLI]: iter 74320 Ep: 2.20 loss 0.006 score 0.094 lr 2.47275e-06 
12/05/2021 04:04:43 - INFO - volta.train_utils -   [XVNLI]: iter 74480 Ep: 2.20 loss 0.006 score 0.093 lr 2.4721e-06 
12/05/2021 04:05:13 - INFO - volta.train_utils -   [XVNLI]: iter 74640 Ep: 2.21 loss 0.005 score 0.094 lr 2.47144e-06 
12/05/2021 04:05:44 - INFO - volta.train_utils -   [XVNLI]: iter 74800 Ep: 2.21 loss 0.006 score 0.092 lr 2.47078e-06 
12/05/2021 04:06:16 - INFO - volta.train_utils -   [XVNLI]: iter 74960 Ep: 2.22 loss 0.006 score 0.095 lr 2.47012e-06 
12/05/2021 04:06:47 - INFO - volta.train_utils -   [XVNLI]: iter 75120 Ep: 2.22 loss 0.006 score 0.094 lr 2.46947e-06 
12/05/2021 04:07:18 - INFO - volta.train_utils -   [XVNLI]: iter 75280 Ep: 2.23 loss 0.007 score 0.092 lr 2.46881e-06 
12/05/2021 04:07:49 - INFO - volta.train_utils -   [XVNLI]: iter 75440 Ep: 2.23 loss 0.006 score 0.093 lr 2.46815e-06 
12/05/2021 04:08:20 - INFO - volta.train_utils -   [XVNLI]: iter 75600 Ep: 2.24 loss 0.006 score 0.095 lr 2.46749e-06 
12/05/2021 04:08:51 - INFO - volta.train_utils -   [XVNLI]: iter 75760 Ep: 2.24 loss 0.006 score 0.093 lr 2.46684e-06 
12/05/2021 04:09:23 - INFO - volta.train_utils -   [XVNLI]: iter 75920 Ep: 2.25 loss 0.006 score 0.093 lr 2.46618e-06 
12/05/2021 04:09:54 - INFO - volta.train_utils -   [XVNLI]: iter 76080 Ep: 2.25 loss 0.005 score 0.095 lr 2.46552e-06 
12/05/2021 04:10:25 - INFO - volta.train_utils -   [XVNLI]: iter 76240 Ep: 2.26 loss 0.006 score 0.094 lr 2.46486e-06 
12/05/2021 04:10:56 - INFO - volta.train_utils -   [XVNLI]: iter 76400 Ep: 2.26 loss 0.006 score 0.096 lr 2.46421e-06 
12/05/2021 04:11:27 - INFO - volta.train_utils -   [XVNLI]: iter 76560 Ep: 2.26 loss 0.005 score 0.095 lr 2.46355e-06 
12/05/2021 04:11:58 - INFO - volta.train_utils -   [XVNLI]: iter 76720 Ep: 2.27 loss 0.006 score 0.094 lr 2.46289e-06 
12/05/2021 04:12:29 - INFO - volta.train_utils -   [XVNLI]: iter 76880 Ep: 2.27 loss 0.006 score 0.094 lr 2.46224e-06 
12/05/2021 04:13:01 - INFO - volta.train_utils -   [XVNLI]: iter 77040 Ep: 2.28 loss 0.005 score 0.094 lr 2.46158e-06 
12/05/2021 04:13:32 - INFO - volta.train_utils -   [XVNLI]: iter 77200 Ep: 2.28 loss 0.006 score 0.093 lr 2.46092e-06 
12/05/2021 04:14:03 - INFO - volta.train_utils -   [XVNLI]: iter 77360 Ep: 2.29 loss 0.006 score 0.094 lr 2.46026e-06 
12/05/2021 04:14:34 - INFO - volta.train_utils -   [XVNLI]: iter 77520 Ep: 2.29 loss 0.006 score 0.096 lr 2.45961e-06 
12/05/2021 04:15:05 - INFO - volta.train_utils -   [XVNLI]: iter 77680 Ep: 2.30 loss 0.006 score 0.092 lr 2.45895e-06 
12/05/2021 04:15:36 - INFO - volta.train_utils -   [XVNLI]: iter 77840 Ep: 2.30 loss 0.005 score 0.095 lr 2.45829e-06 
12/05/2021 04:16:07 - INFO - volta.train_utils -   [XVNLI]: iter 78000 Ep: 2.31 loss 0.005 score 0.095 lr 2.45763e-06 
12/05/2021 04:16:38 - INFO - volta.train_utils -   [XVNLI]: iter 78160 Ep: 2.31 loss 0.006 score 0.095 lr 2.45698e-06 
12/05/2021 04:17:10 - INFO - volta.train_utils -   [XVNLI]: iter 78320 Ep: 2.32 loss 0.006 score 0.093 lr 2.45632e-06 
12/05/2021 04:17:41 - INFO - volta.train_utils -   [XVNLI]: iter 78480 Ep: 2.32 loss 0.006 score 0.095 lr 2.45566e-06 
12/05/2021 04:18:12 - INFO - volta.train_utils -   [XVNLI]: iter 78640 Ep: 2.33 loss 0.006 score 0.094 lr 2.455e-06 
12/05/2021 04:18:43 - INFO - volta.train_utils -   [XVNLI]: iter 78800 Ep: 2.33 loss 0.006 score 0.097 lr 2.45435e-06 
12/05/2021 04:19:15 - INFO - volta.train_utils -   [XVNLI]: iter 78960 Ep: 2.34 loss 0.006 score 0.093 lr 2.45369e-06 
12/05/2021 04:19:46 - INFO - volta.train_utils -   [XVNLI]: iter 79120 Ep: 2.34 loss 0.005 score 0.094 lr 2.45303e-06 
12/05/2021 04:20:17 - INFO - volta.train_utils -   [XVNLI]: iter 79280 Ep: 2.35 loss 0.005 score 0.095 lr 2.45238e-06 
12/05/2021 04:20:49 - INFO - volta.train_utils -   [XVNLI]: iter 79440 Ep: 2.35 loss 0.006 score 0.094 lr 2.45172e-06 
12/05/2021 04:21:20 - INFO - volta.train_utils -   [XVNLI]: iter 79600 Ep: 2.35 loss 0.005 score 0.094 lr 2.45106e-06 
12/05/2021 04:21:51 - INFO - volta.train_utils -   [XVNLI]: iter 79760 Ep: 2.36 loss 0.006 score 0.093 lr 2.4504e-06 
12/05/2021 04:22:22 - INFO - volta.train_utils -   [XVNLI]: iter 79920 Ep: 2.36 loss 0.007 score 0.091 lr 2.44975e-06 
12/05/2021 04:22:54 - INFO - volta.train_utils -   [XVNLI]: iter 80080 Ep: 2.37 loss 0.006 score 0.094 lr 2.44909e-06 
12/05/2021 04:23:25 - INFO - volta.train_utils -   [XVNLI]: iter 80240 Ep: 2.37 loss 0.005 score 0.094 lr 2.44843e-06 
12/05/2021 04:23:56 - INFO - volta.train_utils -   [XVNLI]: iter 80400 Ep: 2.38 loss 0.005 score 0.095 lr 2.44777e-06 
12/05/2021 04:24:28 - INFO - volta.train_utils -   [XVNLI]: iter 80560 Ep: 2.38 loss 0.006 score 0.093 lr 2.44712e-06 
12/05/2021 04:24:59 - INFO - volta.train_utils -   [XVNLI]: iter 80720 Ep: 2.39 loss 0.005 score 0.095 lr 2.44646e-06 
12/05/2021 04:25:30 - INFO - volta.train_utils -   [XVNLI]: iter 80880 Ep: 2.39 loss 0.005 score 0.095 lr 2.4458e-06 
12/05/2021 04:26:01 - INFO - volta.train_utils -   [XVNLI]: iter 81040 Ep: 2.40 loss 0.006 score 0.095 lr 2.44514e-06 
12/05/2021 04:26:32 - INFO - volta.train_utils -   [XVNLI]: iter 81200 Ep: 2.40 loss 0.005 score 0.097 lr 2.44449e-06 
12/05/2021 04:27:03 - INFO - volta.train_utils -   [XVNLI]: iter 81360 Ep: 2.41 loss 0.006 score 0.095 lr 2.44383e-06 
12/05/2021 04:27:34 - INFO - volta.train_utils -   [XVNLI]: iter 81520 Ep: 2.41 loss 0.006 score 0.093 lr 2.44317e-06 
12/05/2021 04:28:06 - INFO - volta.train_utils -   [XVNLI]: iter 81680 Ep: 2.42 loss 0.006 score 0.093 lr 2.44252e-06 
12/05/2021 04:28:37 - INFO - volta.train_utils -   [XVNLI]: iter 81840 Ep: 2.42 loss 0.005 score 0.095 lr 2.44186e-06 
12/05/2021 04:29:08 - INFO - volta.train_utils -   [XVNLI]: iter 82000 Ep: 2.43 loss 0.005 score 0.094 lr 2.4412e-06 
12/05/2021 04:29:39 - INFO - volta.train_utils -   [XVNLI]: iter 82160 Ep: 2.43 loss 0.006 score 0.094 lr 2.44054e-06 
12/05/2021 04:30:11 - INFO - volta.train_utils -   [XVNLI]: iter 82320 Ep: 2.44 loss 0.006 score 0.094 lr 2.43989e-06 
12/05/2021 04:30:42 - INFO - volta.train_utils -   [XVNLI]: iter 82480 Ep: 2.44 loss 0.007 score 0.093 lr 2.43923e-06 
12/05/2021 04:31:13 - INFO - volta.train_utils -   [XVNLI]: iter 82640 Ep: 2.44 loss 0.005 score 0.095 lr 2.43857e-06 
12/05/2021 04:31:44 - INFO - volta.train_utils -   [XVNLI]: iter 82800 Ep: 2.45 loss 0.005 score 0.095 lr 2.43791e-06 
12/05/2021 04:32:16 - INFO - volta.train_utils -   [XVNLI]: iter 82960 Ep: 2.45 loss 0.007 score 0.093 lr 2.43726e-06 
12/05/2021 04:32:47 - INFO - volta.train_utils -   [XVNLI]: iter 83120 Ep: 2.46 loss 0.005 score 0.095 lr 2.4366e-06 
12/05/2021 04:33:18 - INFO - volta.train_utils -   [XVNLI]: iter 83280 Ep: 2.46 loss 0.005 score 0.095 lr 2.43594e-06 
12/05/2021 04:33:49 - INFO - volta.train_utils -   [XVNLI]: iter 83440 Ep: 2.47 loss 0.006 score 0.095 lr 2.43528e-06 
12/05/2021 04:34:21 - INFO - volta.train_utils -   [XVNLI]: iter 83600 Ep: 2.47 loss 0.005 score 0.094 lr 2.43463e-06 
12/05/2021 04:34:52 - INFO - volta.train_utils -   [XVNLI]: iter 83760 Ep: 2.48 loss 0.006 score 0.094 lr 2.43397e-06 
12/05/2021 04:35:23 - INFO - volta.train_utils -   [XVNLI]: iter 83920 Ep: 2.48 loss 0.006 score 0.093 lr 2.43331e-06 
12/05/2021 04:35:54 - INFO - volta.train_utils -   [XVNLI]: iter 84080 Ep: 2.49 loss 0.006 score 0.095 lr 2.43265e-06 
12/05/2021 04:36:25 - INFO - volta.train_utils -   [XVNLI]: iter 84240 Ep: 2.49 loss 0.006 score 0.094 lr 2.432e-06 
12/05/2021 04:36:56 - INFO - volta.train_utils -   [XVNLI]: iter 84400 Ep: 2.50 loss 0.006 score 0.096 lr 2.43134e-06 
12/05/2021 04:37:27 - INFO - volta.train_utils -   [XVNLI]: iter 84560 Ep: 2.50 loss 0.006 score 0.095 lr 2.43068e-06 
12/05/2021 04:37:58 - INFO - volta.train_utils -   [XVNLI]: iter 84720 Ep: 2.51 loss 0.005 score 0.093 lr 2.43003e-06 
12/05/2021 04:38:30 - INFO - volta.train_utils -   [XVNLI]: iter 84880 Ep: 2.51 loss 0.006 score 0.096 lr 2.42937e-06 
12/05/2021 04:39:01 - INFO - volta.train_utils -   [XVNLI]: iter 85040 Ep: 2.52 loss 0.005 score 0.094 lr 2.42871e-06 
12/05/2021 04:39:32 - INFO - volta.train_utils -   [XVNLI]: iter 85200 Ep: 2.52 loss 0.006 score 0.094 lr 2.42805e-06 
12/05/2021 04:40:03 - INFO - volta.train_utils -   [XVNLI]: iter 85360 Ep: 2.52 loss 0.005 score 0.095 lr 2.4274e-06 
12/05/2021 04:40:34 - INFO - volta.train_utils -   [XVNLI]: iter 85520 Ep: 2.53 loss 0.006 score 0.096 lr 2.42674e-06 
12/05/2021 04:41:05 - INFO - volta.train_utils -   [XVNLI]: iter 85680 Ep: 2.53 loss 0.006 score 0.095 lr 2.42608e-06 
12/05/2021 04:41:36 - INFO - volta.train_utils -   [XVNLI]: iter 85840 Ep: 2.54 loss 0.006 score 0.093 lr 2.42542e-06 
12/05/2021 04:42:08 - INFO - volta.train_utils -   [XVNLI]: iter 86000 Ep: 2.54 loss 0.006 score 0.095 lr 2.42477e-06 
12/05/2021 04:42:39 - INFO - volta.train_utils -   [XVNLI]: iter 86160 Ep: 2.55 loss 0.006 score 0.096 lr 2.42411e-06 
12/05/2021 04:43:10 - INFO - volta.train_utils -   [XVNLI]: iter 86320 Ep: 2.55 loss 0.005 score 0.095 lr 2.42345e-06 
12/05/2021 04:43:41 - INFO - volta.train_utils -   [XVNLI]: iter 86480 Ep: 2.56 loss 0.006 score 0.093 lr 2.42279e-06 
12/05/2021 04:44:12 - INFO - volta.train_utils -   [XVNLI]: iter 86640 Ep: 2.56 loss 0.006 score 0.093 lr 2.42214e-06 
12/05/2021 04:44:43 - INFO - volta.train_utils -   [XVNLI]: iter 86800 Ep: 2.57 loss 0.006 score 0.095 lr 2.42148e-06 
12/05/2021 04:45:15 - INFO - volta.train_utils -   [XVNLI]: iter 86960 Ep: 2.57 loss 0.005 score 0.095 lr 2.42082e-06 
12/05/2021 04:45:46 - INFO - volta.train_utils -   [XVNLI]: iter 87120 Ep: 2.58 loss 0.006 score 0.096 lr 2.42017e-06 
12/05/2021 04:46:17 - INFO - volta.train_utils -   [XVNLI]: iter 87280 Ep: 2.58 loss 0.005 score 0.096 lr 2.41951e-06 
12/05/2021 04:46:48 - INFO - volta.train_utils -   [XVNLI]: iter 87440 Ep: 2.59 loss 0.005 score 0.092 lr 2.41885e-06 
12/05/2021 04:47:20 - INFO - volta.train_utils -   [XVNLI]: iter 87600 Ep: 2.59 loss 0.006 score 0.095 lr 2.41819e-06 
12/05/2021 04:47:51 - INFO - volta.train_utils -   [XVNLI]: iter 87760 Ep: 2.60 loss 0.006 score 0.094 lr 2.41754e-06 
12/05/2021 04:48:22 - INFO - volta.train_utils -   [XVNLI]: iter 87920 Ep: 2.60 loss 0.005 score 0.095 lr 2.41688e-06 
12/05/2021 04:48:53 - INFO - volta.train_utils -   [XVNLI]: iter 88080 Ep: 2.61 loss 0.006 score 0.095 lr 2.41622e-06 
12/05/2021 04:49:24 - INFO - volta.train_utils -   [XVNLI]: iter 88240 Ep: 2.61 loss 0.006 score 0.093 lr 2.41556e-06 
12/05/2021 04:49:55 - INFO - volta.train_utils -   [XVNLI]: iter 88400 Ep: 2.61 loss 0.006 score 0.095 lr 2.41491e-06 
12/05/2021 04:50:26 - INFO - volta.train_utils -   [XVNLI]: iter 88560 Ep: 2.62 loss 0.006 score 0.093 lr 2.41425e-06 
12/05/2021 04:50:57 - INFO - volta.train_utils -   [XVNLI]: iter 88720 Ep: 2.62 loss 0.005 score 0.095 lr 2.41359e-06 
12/05/2021 04:51:29 - INFO - volta.train_utils -   [XVNLI]: iter 88880 Ep: 2.63 loss 0.005 score 0.094 lr 2.41293e-06 
12/05/2021 04:52:00 - INFO - volta.train_utils -   [XVNLI]: iter 89040 Ep: 2.63 loss 0.005 score 0.094 lr 2.41228e-06 
12/05/2021 04:52:31 - INFO - volta.train_utils -   [XVNLI]: iter 89200 Ep: 2.64 loss 0.006 score 0.093 lr 2.41162e-06 
12/05/2021 04:53:03 - INFO - volta.train_utils -   [XVNLI]: iter 89360 Ep: 2.64 loss 0.006 score 0.093 lr 2.41096e-06 
12/05/2021 04:53:34 - INFO - volta.train_utils -   [XVNLI]: iter 89520 Ep: 2.65 loss 0.006 score 0.092 lr 2.41031e-06 
12/05/2021 04:54:05 - INFO - volta.train_utils -   [XVNLI]: iter 89680 Ep: 2.65 loss 0.007 score 0.094 lr 2.40965e-06 
12/05/2021 04:54:36 - INFO - volta.train_utils -   [XVNLI]: iter 89840 Ep: 2.66 loss 0.006 score 0.095 lr 2.40899e-06 
12/05/2021 04:55:08 - INFO - volta.train_utils -   [XVNLI]: iter 90000 Ep: 2.66 loss 0.005 score 0.094 lr 2.40833e-06 
12/05/2021 04:55:39 - INFO - volta.train_utils -   [XVNLI]: iter 90160 Ep: 2.67 loss 0.005 score 0.095 lr 2.40768e-06 
12/05/2021 04:56:10 - INFO - volta.train_utils -   [XVNLI]: iter 90320 Ep: 2.67 loss 0.005 score 0.095 lr 2.40702e-06 
12/05/2021 04:56:41 - INFO - volta.train_utils -   [XVNLI]: iter 90480 Ep: 2.68 loss 0.006 score 0.094 lr 2.40636e-06 
12/05/2021 04:57:12 - INFO - volta.train_utils -   [XVNLI]: iter 90640 Ep: 2.68 loss 0.006 score 0.093 lr 2.4057e-06 
12/05/2021 04:57:44 - INFO - volta.train_utils -   [XVNLI]: iter 90800 Ep: 2.69 loss 0.006 score 0.095 lr 2.40505e-06 
12/05/2021 04:58:15 - INFO - volta.train_utils -   [XVNLI]: iter 90960 Ep: 2.69 loss 0.005 score 0.094 lr 2.40439e-06 
12/05/2021 04:58:46 - INFO - volta.train_utils -   [XVNLI]: iter 91120 Ep: 2.70 loss 0.006 score 0.097 lr 2.40373e-06 
12/05/2021 04:59:17 - INFO - volta.train_utils -   [XVNLI]: iter 91280 Ep: 2.70 loss 0.006 score 0.093 lr 2.40307e-06 
12/05/2021 04:59:48 - INFO - volta.train_utils -   [XVNLI]: iter 91440 Ep: 2.70 loss 0.005 score 0.094 lr 2.40242e-06 
12/05/2021 05:00:19 - INFO - volta.train_utils -   [XVNLI]: iter 91600 Ep: 2.71 loss 0.006 score 0.096 lr 2.40176e-06 
12/05/2021 05:00:51 - INFO - volta.train_utils -   [XVNLI]: iter 91760 Ep: 2.71 loss 0.005 score 0.096 lr 2.4011e-06 
12/05/2021 05:01:23 - INFO - volta.train_utils -   [XVNLI]: iter 91920 Ep: 2.72 loss 0.006 score 0.094 lr 2.40045e-06 
12/05/2021 05:01:54 - INFO - volta.train_utils -   [XVNLI]: iter 92080 Ep: 2.72 loss 0.005 score 0.095 lr 2.39979e-06 
12/05/2021 05:02:25 - INFO - volta.train_utils -   [XVNLI]: iter 92240 Ep: 2.73 loss 0.005 score 0.094 lr 2.39913e-06 
12/05/2021 05:02:56 - INFO - volta.train_utils -   [XVNLI]: iter 92400 Ep: 2.73 loss 0.005 score 0.094 lr 2.39847e-06 
12/05/2021 05:03:27 - INFO - volta.train_utils -   [XVNLI]: iter 92560 Ep: 2.74 loss 0.006 score 0.094 lr 2.39782e-06 
12/05/2021 05:03:58 - INFO - volta.train_utils -   [XVNLI]: iter 92720 Ep: 2.74 loss 0.006 score 0.095 lr 2.39716e-06 
12/05/2021 05:04:31 - INFO - volta.train_utils -   [XVNLI]: iter 92880 Ep: 2.75 loss 0.006 score 0.094 lr 2.3965e-06 
12/05/2021 05:05:02 - INFO - volta.train_utils -   [XVNLI]: iter 93040 Ep: 2.75 loss 0.006 score 0.094 lr 2.39584e-06 
12/05/2021 05:05:33 - INFO - volta.train_utils -   [XVNLI]: iter 93200 Ep: 2.76 loss 0.006 score 0.095 lr 2.39519e-06 
12/05/2021 05:06:04 - INFO - volta.train_utils -   [XVNLI]: iter 93360 Ep: 2.76 loss 0.006 score 0.094 lr 2.39453e-06 
12/05/2021 05:06:35 - INFO - volta.train_utils -   [XVNLI]: iter 93520 Ep: 2.77 loss 0.005 score 0.094 lr 2.39387e-06 
12/05/2021 05:07:07 - INFO - volta.train_utils -   [XVNLI]: iter 93680 Ep: 2.77 loss 0.005 score 0.095 lr 2.39321e-06 
12/05/2021 05:07:38 - INFO - volta.train_utils -   [XVNLI]: iter 93840 Ep: 2.78 loss 0.007 score 0.093 lr 2.39256e-06 
12/05/2021 05:08:10 - INFO - volta.train_utils -   [XVNLI]: iter 94000 Ep: 2.78 loss 0.006 score 0.095 lr 2.3919e-06 
12/05/2021 05:08:41 - INFO - volta.train_utils -   [XVNLI]: iter 94160 Ep: 2.79 loss 0.005 score 0.094 lr 2.39124e-06 
12/05/2021 05:09:12 - INFO - volta.train_utils -   [XVNLI]: iter 94320 Ep: 2.79 loss 0.006 score 0.093 lr 2.39058e-06 
12/05/2021 05:09:43 - INFO - volta.train_utils -   [XVNLI]: iter 94480 Ep: 2.79 loss 0.005 score 0.095 lr 2.38993e-06 
12/05/2021 05:10:16 - INFO - volta.train_utils -   [XVNLI]: iter 94640 Ep: 2.80 loss 0.006 score 0.095 lr 2.38927e-06 
12/05/2021 05:10:47 - INFO - volta.train_utils -   [XVNLI]: iter 94800 Ep: 2.80 loss 0.006 score 0.094 lr 2.38861e-06 
12/05/2021 05:11:18 - INFO - volta.train_utils -   [XVNLI]: iter 94960 Ep: 2.81 loss 0.006 score 0.094 lr 2.38796e-06 
12/05/2021 05:11:50 - INFO - volta.train_utils -   [XVNLI]: iter 95120 Ep: 2.81 loss 0.006 score 0.095 lr 2.3873e-06 
12/05/2021 05:12:21 - INFO - volta.train_utils -   [XVNLI]: iter 95280 Ep: 2.82 loss 0.005 score 0.096 lr 2.38664e-06 
12/05/2021 05:12:53 - INFO - volta.train_utils -   [XVNLI]: iter 95440 Ep: 2.82 loss 0.005 score 0.095 lr 2.38598e-06 
12/05/2021 05:13:24 - INFO - volta.train_utils -   [XVNLI]: iter 95600 Ep: 2.83 loss 0.006 score 0.095 lr 2.38533e-06 
12/05/2021 05:13:55 - INFO - volta.train_utils -   [XVNLI]: iter 95760 Ep: 2.83 loss 0.005 score 0.094 lr 2.38467e-06 
12/05/2021 05:14:26 - INFO - volta.train_utils -   [XVNLI]: iter 95920 Ep: 2.84 loss 0.005 score 0.094 lr 2.38401e-06 
12/05/2021 05:14:58 - INFO - volta.train_utils -   [XVNLI]: iter 96080 Ep: 2.84 loss 0.005 score 0.095 lr 2.38335e-06 
12/05/2021 05:15:29 - INFO - volta.train_utils -   [XVNLI]: iter 96240 Ep: 2.85 loss 0.006 score 0.094 lr 2.3827e-06 
12/05/2021 05:16:00 - INFO - volta.train_utils -   [XVNLI]: iter 96400 Ep: 2.85 loss 0.005 score 0.095 lr 2.38204e-06 
12/05/2021 05:16:31 - INFO - volta.train_utils -   [XVNLI]: iter 96560 Ep: 2.86 loss 0.006 score 0.094 lr 2.38138e-06 
12/05/2021 05:17:02 - INFO - volta.train_utils -   [XVNLI]: iter 96720 Ep: 2.86 loss 0.006 score 0.095 lr 2.38072e-06 
12/05/2021 05:17:33 - INFO - volta.train_utils -   [XVNLI]: iter 96880 Ep: 2.87 loss 0.005 score 0.095 lr 2.38007e-06 
12/05/2021 05:18:05 - INFO - volta.train_utils -   [XVNLI]: iter 97040 Ep: 2.87 loss 0.006 score 0.096 lr 2.37941e-06 
12/05/2021 05:18:36 - INFO - volta.train_utils -   [XVNLI]: iter 97200 Ep: 2.88 loss 0.006 score 0.095 lr 2.37875e-06 
12/05/2021 05:19:07 - INFO - volta.train_utils -   [XVNLI]: iter 97360 Ep: 2.88 loss 0.006 score 0.093 lr 2.3781e-06 
12/05/2021 05:19:38 - INFO - volta.train_utils -   [XVNLI]: iter 97520 Ep: 2.88 loss 0.006 score 0.095 lr 2.37744e-06 
12/05/2021 05:20:09 - INFO - volta.train_utils -   [XVNLI]: iter 97680 Ep: 2.89 loss 0.006 score 0.097 lr 2.37678e-06 
12/05/2021 05:20:41 - INFO - volta.train_utils -   [XVNLI]: iter 97840 Ep: 2.89 loss 0.005 score 0.095 lr 2.37612e-06 
12/05/2021 05:21:12 - INFO - volta.train_utils -   [XVNLI]: iter 98000 Ep: 2.90 loss 0.006 score 0.095 lr 2.37547e-06 
12/05/2021 05:21:43 - INFO - volta.train_utils -   [XVNLI]: iter 98160 Ep: 2.90 loss 0.005 score 0.094 lr 2.37481e-06 
12/05/2021 05:22:14 - INFO - volta.train_utils -   [XVNLI]: iter 98320 Ep: 2.91 loss 0.006 score 0.096 lr 2.37415e-06 
12/05/2021 05:22:45 - INFO - volta.train_utils -   [XVNLI]: iter 98480 Ep: 2.91 loss 0.005 score 0.094 lr 2.37349e-06 
12/05/2021 05:23:16 - INFO - volta.train_utils -   [XVNLI]: iter 98640 Ep: 2.92 loss 0.006 score 0.096 lr 2.37284e-06 
12/05/2021 05:23:47 - INFO - volta.train_utils -   [XVNLI]: iter 98800 Ep: 2.92 loss 0.005 score 0.095 lr 2.37218e-06 
12/05/2021 05:24:19 - INFO - volta.train_utils -   [XVNLI]: iter 98960 Ep: 2.93 loss 0.006 score 0.096 lr 2.37152e-06 
12/05/2021 05:24:50 - INFO - volta.train_utils -   [XVNLI]: iter 99120 Ep: 2.93 loss 0.006 score 0.095 lr 2.37086e-06 
12/05/2021 05:25:24 - INFO - volta.train_utils -   [XVNLI]: iter 99280 Ep: 2.94 loss 0.006 score 0.093 lr 2.37021e-06 
12/05/2021 05:25:58 - INFO - volta.train_utils -   [XVNLI]: iter 99440 Ep: 2.94 loss 0.005 score 0.095 lr 2.36955e-06 
12/05/2021 05:26:32 - INFO - volta.train_utils -   [XVNLI]: iter 99600 Ep: 2.95 loss 0.006 score 0.095 lr 2.36889e-06 
12/05/2021 05:27:05 - INFO - volta.train_utils -   [XVNLI]: iter 99760 Ep: 2.95 loss 0.006 score 0.094 lr 2.36824e-06 
12/05/2021 05:27:37 - INFO - volta.train_utils -   [XVNLI]: iter 99920 Ep: 2.96 loss 0.006 score 0.094 lr 2.36758e-06 
12/05/2021 05:28:09 - INFO - volta.train_utils -   [XVNLI]: iter 100080 Ep: 2.96 loss 0.005 score 0.095 lr 2.36692e-06 
12/05/2021 05:28:41 - INFO - volta.train_utils -   [XVNLI]: iter 100240 Ep: 2.97 loss 0.006 score 0.096 lr 2.36626e-06 
12/05/2021 05:29:12 - INFO - volta.train_utils -   [XVNLI]: iter 100400 Ep: 2.97 loss 0.005 score 0.094 lr 2.36561e-06 
12/05/2021 05:29:44 - INFO - volta.train_utils -   [XVNLI]: iter 100560 Ep: 2.97 loss 0.006 score 0.096 lr 2.36495e-06 
12/05/2021 05:30:15 - INFO - volta.train_utils -   [XVNLI]: iter 100720 Ep: 2.98 loss 0.005 score 0.094 lr 2.36429e-06 
12/05/2021 05:30:46 - INFO - volta.train_utils -   [XVNLI]: iter 100880 Ep: 2.98 loss 0.005 score 0.096 lr 2.36363e-06 
12/05/2021 05:31:17 - INFO - volta.train_utils -   [XVNLI]: iter 101040 Ep: 2.99 loss 0.006 score 0.094 lr 2.36298e-06 
12/05/2021 05:31:48 - INFO - volta.train_utils -   [XVNLI]: iter 101200 Ep: 2.99 loss 0.006 score 0.096 lr 2.36232e-06 
12/05/2021 05:32:19 - INFO - volta.train_utils -   [XVNLI]: iter 101360 Ep: 3.00 loss 0.006 score 0.094 lr 2.36166e-06 
12/05/2021 05:36:14 - INFO - volta.train_utils -   Eval task TASK19 on iteration 101400 
12/05/2021 05:36:14 - INFO - volta.train_utils -   Validation [XVNLI]: loss 0.376 score 74.458 
12/05/2021 05:36:14 - INFO - __main__ -   ** ** * Saving model * ** ** 
Epoch:  30%|███       | 3/10 [5:58:10<14:08:54, 7276.36s/it]12/05/2021 05:37:21 - INFO - volta.train_utils -   [XVNLI]: iter 101560 Ep: 3.00 loss 0.006 score 0.100 lr 2.36092e-06 
12/05/2021 05:37:53 - INFO - volta.train_utils -   [XVNLI]: iter 101720 Ep: 3.01 loss 0.005 score 0.097 lr 2.36018e-06 
12/05/2021 05:38:24 - INFO - volta.train_utils -   [XVNLI]: iter 101880 Ep: 3.01 loss 0.006 score 0.097 lr 2.35953e-06 
12/05/2021 05:38:55 - INFO - volta.train_utils -   [XVNLI]: iter 102040 Ep: 3.02 loss 0.006 score 0.097 lr 2.35887e-06 
12/05/2021 05:39:26 - INFO - volta.train_utils -   [XVNLI]: iter 102200 Ep: 3.02 loss 0.005 score 0.098 lr 2.35821e-06 
12/05/2021 05:39:57 - INFO - volta.train_utils -   [XVNLI]: iter 102360 Ep: 3.03 loss 0.005 score 0.098 lr 2.35755e-06 
12/05/2021 05:40:35 - INFO - volta.train_utils -   [XVNLI]: iter 102520 Ep: 3.03 loss 0.004 score 0.096 lr 2.3569e-06 
12/05/2021 05:41:06 - INFO - volta.train_utils -   [XVNLI]: iter 102680 Ep: 3.04 loss 0.005 score 0.098 lr 2.35624e-06 
12/05/2021 05:41:37 - INFO - volta.train_utils -   [XVNLI]: iter 102840 Ep: 3.04 loss 0.006 score 0.097 lr 2.35558e-06 
12/05/2021 05:42:08 - INFO - volta.train_utils -   [XVNLI]: iter 103000 Ep: 3.05 loss 0.005 score 0.097 lr 2.35492e-06 
12/05/2021 05:42:39 - INFO - volta.train_utils -   [XVNLI]: iter 103160 Ep: 3.05 loss 0.005 score 0.099 lr 2.35427e-06 
12/05/2021 05:43:10 - INFO - volta.train_utils -   [XVNLI]: iter 103320 Ep: 3.06 loss 0.005 score 0.097 lr 2.35361e-06 
12/05/2021 05:43:41 - INFO - volta.train_utils -   [XVNLI]: iter 103480 Ep: 3.06 loss 0.005 score 0.097 lr 2.35295e-06 
12/05/2021 05:44:12 - INFO - volta.train_utils -   [XVNLI]: iter 103640 Ep: 3.07 loss 0.005 score 0.097 lr 2.35229e-06 
12/05/2021 05:44:43 - INFO - volta.train_utils -   [XVNLI]: iter 103800 Ep: 3.07 loss 0.005 score 0.097 lr 2.35164e-06 
12/05/2021 05:45:14 - INFO - volta.train_utils -   [XVNLI]: iter 103960 Ep: 3.08 loss 0.005 score 0.096 lr 2.35098e-06 
12/05/2021 05:45:45 - INFO - volta.train_utils -   [XVNLI]: iter 104120 Ep: 3.08 loss 0.005 score 0.094 lr 2.35032e-06 
12/05/2021 05:46:16 - INFO - volta.train_utils -   [XVNLI]: iter 104280 Ep: 3.08 loss 0.005 score 0.097 lr 2.34967e-06 
12/05/2021 05:46:47 - INFO - volta.train_utils -   [XVNLI]: iter 104440 Ep: 3.09 loss 0.005 score 0.097 lr 2.34901e-06 
12/05/2021 05:47:18 - INFO - volta.train_utils -   [XVNLI]: iter 104600 Ep: 3.09 loss 0.005 score 0.097 lr 2.34835e-06 
12/05/2021 05:47:49 - INFO - volta.train_utils -   [XVNLI]: iter 104760 Ep: 3.10 loss 0.005 score 0.096 lr 2.34769e-06 
12/05/2021 05:48:20 - INFO - volta.train_utils -   [XVNLI]: iter 104920 Ep: 3.10 loss 0.005 score 0.096 lr 2.34704e-06 
12/05/2021 05:48:51 - INFO - volta.train_utils -   [XVNLI]: iter 105080 Ep: 3.11 loss 0.006 score 0.098 lr 2.34638e-06 
12/05/2021 05:49:23 - INFO - volta.train_utils -   [XVNLI]: iter 105240 Ep: 3.11 loss 0.005 score 0.097 lr 2.34572e-06 
12/05/2021 05:49:54 - INFO - volta.train_utils -   [XVNLI]: iter 105400 Ep: 3.12 loss 0.006 score 0.097 lr 2.34506e-06 
12/05/2021 05:50:25 - INFO - volta.train_utils -   [XVNLI]: iter 105560 Ep: 3.12 loss 0.005 score 0.096 lr 2.34441e-06 
12/05/2021 05:50:56 - INFO - volta.train_utils -   [XVNLI]: iter 105720 Ep: 3.13 loss 0.005 score 0.096 lr 2.34375e-06 
12/05/2021 05:51:27 - INFO - volta.train_utils -   [XVNLI]: iter 105880 Ep: 3.13 loss 0.005 score 0.095 lr 2.34309e-06 
12/05/2021 05:51:58 - INFO - volta.train_utils -   [XVNLI]: iter 106040 Ep: 3.14 loss 0.005 score 0.096 lr 2.34243e-06 
12/05/2021 05:52:29 - INFO - volta.train_utils -   [XVNLI]: iter 106200 Ep: 3.14 loss 0.006 score 0.097 lr 2.34178e-06 
12/05/2021 05:53:00 - INFO - volta.train_utils -   [XVNLI]: iter 106360 Ep: 3.15 loss 0.005 score 0.098 lr 2.34112e-06 
12/05/2021 05:53:31 - INFO - volta.train_utils -   [XVNLI]: iter 106520 Ep: 3.15 loss 0.005 score 0.097 lr 2.34046e-06 
12/05/2021 05:54:03 - INFO - volta.train_utils -   [XVNLI]: iter 106680 Ep: 3.16 loss 0.005 score 0.097 lr 2.3398e-06 
12/05/2021 05:54:34 - INFO - volta.train_utils -   [XVNLI]: iter 106840 Ep: 3.16 loss 0.005 score 0.097 lr 2.33915e-06 
12/05/2021 05:55:05 - INFO - volta.train_utils -   [XVNLI]: iter 107000 Ep: 3.17 loss 0.005 score 0.096 lr 2.33849e-06 
12/05/2021 05:55:36 - INFO - volta.train_utils -   [XVNLI]: iter 107160 Ep: 3.17 loss 0.005 score 0.098 lr 2.33783e-06 
12/05/2021 05:56:07 - INFO - volta.train_utils -   [XVNLI]: iter 107320 Ep: 3.17 loss 0.006 score 0.097 lr 2.33718e-06 
12/05/2021 05:56:38 - INFO - volta.train_utils -   [XVNLI]: iter 107480 Ep: 3.18 loss 0.005 score 0.095 lr 2.33652e-06 
12/05/2021 05:57:09 - INFO - volta.train_utils -   [XVNLI]: iter 107640 Ep: 3.18 loss 0.006 score 0.098 lr 2.33586e-06 
12/05/2021 05:57:40 - INFO - volta.train_utils -   [XVNLI]: iter 107800 Ep: 3.19 loss 0.005 score 0.096 lr 2.3352e-06 
12/05/2021 05:58:11 - INFO - volta.train_utils -   [XVNLI]: iter 107960 Ep: 3.19 loss 0.005 score 0.096 lr 2.33455e-06 
12/05/2021 05:58:42 - INFO - volta.train_utils -   [XVNLI]: iter 108120 Ep: 3.20 loss 0.005 score 0.098 lr 2.33389e-06 
12/05/2021 05:59:13 - INFO - volta.train_utils -   [XVNLI]: iter 108280 Ep: 3.20 loss 0.005 score 0.096 lr 2.33323e-06 
12/05/2021 05:59:44 - INFO - volta.train_utils -   [XVNLI]: iter 108440 Ep: 3.21 loss 0.004 score 0.098 lr 2.33257e-06 
12/05/2021 06:00:16 - INFO - volta.train_utils -   [XVNLI]: iter 108600 Ep: 3.21 loss 0.005 score 0.097 lr 2.33192e-06 
12/05/2021 06:00:47 - INFO - volta.train_utils -   [XVNLI]: iter 108760 Ep: 3.22 loss 0.005 score 0.096 lr 2.33126e-06 
12/05/2021 06:01:18 - INFO - volta.train_utils -   [XVNLI]: iter 108920 Ep: 3.22 loss 0.005 score 0.098 lr 2.3306e-06 
12/05/2021 06:01:49 - INFO - volta.train_utils -   [XVNLI]: iter 109080 Ep: 3.23 loss 0.005 score 0.099 lr 2.32994e-06 
12/05/2021 06:02:20 - INFO - volta.train_utils -   [XVNLI]: iter 109240 Ep: 3.23 loss 0.006 score 0.098 lr 2.32929e-06 
12/05/2021 06:02:51 - INFO - volta.train_utils -   [XVNLI]: iter 109400 Ep: 3.24 loss 0.005 score 0.098 lr 2.32863e-06 
12/05/2021 06:03:22 - INFO - volta.train_utils -   [XVNLI]: iter 109560 Ep: 3.24 loss 0.006 score 0.096 lr 2.32797e-06 
12/05/2021 06:03:53 - INFO - volta.train_utils -   [XVNLI]: iter 109720 Ep: 3.25 loss 0.006 score 0.095 lr 2.32732e-06 
12/05/2021 06:04:24 - INFO - volta.train_utils -   [XVNLI]: iter 109880 Ep: 3.25 loss 0.005 score 0.096 lr 2.32666e-06 
12/05/2021 06:04:55 - INFO - volta.train_utils -   [XVNLI]: iter 110040 Ep: 3.26 loss 0.005 score 0.099 lr 2.326e-06 
12/05/2021 06:05:26 - INFO - volta.train_utils -   [XVNLI]: iter 110200 Ep: 3.26 loss 0.005 score 0.097 lr 2.32534e-06 
12/05/2021 06:05:57 - INFO - volta.train_utils -   [XVNLI]: iter 110360 Ep: 3.26 loss 0.006 score 0.097 lr 2.32469e-06 
12/05/2021 06:06:28 - INFO - volta.train_utils -   [XVNLI]: iter 110520 Ep: 3.27 loss 0.004 score 0.096 lr 2.32403e-06 
12/05/2021 06:06:59 - INFO - volta.train_utils -   [XVNLI]: iter 110680 Ep: 3.27 loss 0.005 score 0.098 lr 2.32337e-06 
12/05/2021 06:07:30 - INFO - volta.train_utils -   [XVNLI]: iter 110840 Ep: 3.28 loss 0.006 score 0.097 lr 2.32271e-06 
12/05/2021 06:08:01 - INFO - volta.train_utils -   [XVNLI]: iter 111000 Ep: 3.28 loss 0.005 score 0.096 lr 2.32206e-06 
12/05/2021 06:08:32 - INFO - volta.train_utils -   [XVNLI]: iter 111160 Ep: 3.29 loss 0.005 score 0.098 lr 2.3214e-06 
12/05/2021 06:09:04 - INFO - volta.train_utils -   [XVNLI]: iter 111320 Ep: 3.29 loss 0.005 score 0.097 lr 2.32074e-06 
12/05/2021 06:09:35 - INFO - volta.train_utils -   [XVNLI]: iter 111480 Ep: 3.30 loss 0.005 score 0.096 lr 2.32008e-06 
12/05/2021 06:10:06 - INFO - volta.train_utils -   [XVNLI]: iter 111640 Ep: 3.30 loss 0.005 score 0.096 lr 2.31943e-06 
12/05/2021 06:10:37 - INFO - volta.train_utils -   [XVNLI]: iter 111800 Ep: 3.31 loss 0.005 score 0.097 lr 2.31877e-06 
12/05/2021 06:11:08 - INFO - volta.train_utils -   [XVNLI]: iter 111960 Ep: 3.31 loss 0.006 score 0.099 lr 2.31811e-06 
12/05/2021 06:11:39 - INFO - volta.train_utils -   [XVNLI]: iter 112120 Ep: 3.32 loss 0.005 score 0.097 lr 2.31746e-06 
12/05/2021 06:12:10 - INFO - volta.train_utils -   [XVNLI]: iter 112280 Ep: 3.32 loss 0.005 score 0.098 lr 2.3168e-06 
12/05/2021 06:12:41 - INFO - volta.train_utils -   [XVNLI]: iter 112440 Ep: 3.33 loss 0.005 score 0.098 lr 2.31614e-06 
12/05/2021 06:13:12 - INFO - volta.train_utils -   [XVNLI]: iter 112600 Ep: 3.33 loss 0.005 score 0.096 lr 2.31548e-06 
12/05/2021 06:13:43 - INFO - volta.train_utils -   [XVNLI]: iter 112760 Ep: 3.34 loss 0.005 score 0.098 lr 2.31483e-06 
12/05/2021 06:14:14 - INFO - volta.train_utils -   [XVNLI]: iter 112920 Ep: 3.34 loss 0.005 score 0.098 lr 2.31417e-06 
12/05/2021 06:14:45 - INFO - volta.train_utils -   [XVNLI]: iter 113080 Ep: 3.34 loss 0.005 score 0.096 lr 2.31351e-06 
12/05/2021 06:15:16 - INFO - volta.train_utils -   [XVNLI]: iter 113240 Ep: 3.35 loss 0.005 score 0.096 lr 2.31285e-06 
12/05/2021 06:15:47 - INFO - volta.train_utils -   [XVNLI]: iter 113400 Ep: 3.35 loss 0.005 score 0.097 lr 2.3122e-06 
12/05/2021 06:16:18 - INFO - volta.train_utils -   [XVNLI]: iter 113560 Ep: 3.36 loss 0.005 score 0.097 lr 2.31154e-06 
12/05/2021 06:16:49 - INFO - volta.train_utils -   [XVNLI]: iter 113720 Ep: 3.36 loss 0.005 score 0.098 lr 2.31088e-06 
12/05/2021 06:17:20 - INFO - volta.train_utils -   [XVNLI]: iter 113880 Ep: 3.37 loss 0.005 score 0.098 lr 2.31022e-06 
12/05/2021 06:17:52 - INFO - volta.train_utils -   [XVNLI]: iter 114040 Ep: 3.37 loss 0.005 score 0.096 lr 2.30957e-06 
12/05/2021 06:18:23 - INFO - volta.train_utils -   [XVNLI]: iter 114200 Ep: 3.38 loss 0.005 score 0.097 lr 2.30891e-06 
12/05/2021 06:18:54 - INFO - volta.train_utils -   [XVNLI]: iter 114360 Ep: 3.38 loss 0.005 score 0.098 lr 2.30825e-06 
12/05/2021 06:19:25 - INFO - volta.train_utils -   [XVNLI]: iter 114520 Ep: 3.39 loss 0.005 score 0.098 lr 2.30759e-06 
12/05/2021 06:19:56 - INFO - volta.train_utils -   [XVNLI]: iter 114680 Ep: 3.39 loss 0.005 score 0.096 lr 2.30694e-06 
12/05/2021 06:20:27 - INFO - volta.train_utils -   [XVNLI]: iter 114840 Ep: 3.40 loss 0.005 score 0.098 lr 2.30628e-06 
12/05/2021 06:20:58 - INFO - volta.train_utils -   [XVNLI]: iter 115000 Ep: 3.40 loss 0.005 score 0.098 lr 2.30562e-06 
12/05/2021 06:21:29 - INFO - volta.train_utils -   [XVNLI]: iter 115160 Ep: 3.41 loss 0.006 score 0.097 lr 2.30497e-06 
12/05/2021 06:22:00 - INFO - volta.train_utils -   [XVNLI]: iter 115320 Ep: 3.41 loss 0.006 score 0.099 lr 2.30431e-06 
12/05/2021 06:22:32 - INFO - volta.train_utils -   [XVNLI]: iter 115480 Ep: 3.42 loss 0.005 score 0.098 lr 2.30365e-06 
12/05/2021 06:23:03 - INFO - volta.train_utils -   [XVNLI]: iter 115640 Ep: 3.42 loss 0.005 score 0.097 lr 2.30299e-06 
12/05/2021 06:23:34 - INFO - volta.train_utils -   [XVNLI]: iter 115800 Ep: 3.43 loss 0.006 score 0.095 lr 2.30234e-06 
12/05/2021 06:24:05 - INFO - volta.train_utils -   [XVNLI]: iter 115960 Ep: 3.43 loss 0.005 score 0.097 lr 2.30168e-06 
12/05/2021 06:24:36 - INFO - volta.train_utils -   [XVNLI]: iter 116120 Ep: 3.43 loss 0.006 score 0.098 lr 2.30102e-06 
12/05/2021 06:25:07 - INFO - volta.train_utils -   [XVNLI]: iter 116280 Ep: 3.44 loss 0.006 score 0.096 lr 2.30036e-06 
12/05/2021 06:25:38 - INFO - volta.train_utils -   [XVNLI]: iter 116440 Ep: 3.44 loss 0.005 score 0.099 lr 2.29971e-06 
12/05/2021 06:26:09 - INFO - volta.train_utils -   [XVNLI]: iter 116600 Ep: 3.45 loss 0.005 score 0.097 lr 2.29905e-06 
12/05/2021 06:26:41 - INFO - volta.train_utils -   [XVNLI]: iter 116760 Ep: 3.45 loss 0.005 score 0.098 lr 2.29839e-06 
12/05/2021 06:27:12 - INFO - volta.train_utils -   [XVNLI]: iter 116920 Ep: 3.46 loss 0.006 score 0.095 lr 2.29773e-06 
12/05/2021 06:27:43 - INFO - volta.train_utils -   [XVNLI]: iter 117080 Ep: 3.46 loss 0.005 score 0.097 lr 2.29708e-06 
12/05/2021 06:28:14 - INFO - volta.train_utils -   [XVNLI]: iter 117240 Ep: 3.47 loss 0.005 score 0.099 lr 2.29642e-06 
12/05/2021 06:28:45 - INFO - volta.train_utils -   [XVNLI]: iter 117400 Ep: 3.47 loss 0.005 score 0.096 lr 2.29576e-06 
12/05/2021 06:29:16 - INFO - volta.train_utils -   [XVNLI]: iter 117560 Ep: 3.48 loss 0.004 score 0.098 lr 2.29511e-06 
12/05/2021 06:29:48 - INFO - volta.train_utils -   [XVNLI]: iter 117720 Ep: 3.48 loss 0.005 score 0.098 lr 2.29445e-06 
12/05/2021 06:30:19 - INFO - volta.train_utils -   [XVNLI]: iter 117880 Ep: 3.49 loss 0.005 score 0.095 lr 2.29379e-06 
12/05/2021 06:30:50 - INFO - volta.train_utils -   [XVNLI]: iter 118040 Ep: 3.49 loss 0.005 score 0.096 lr 2.29313e-06 
12/05/2021 06:31:21 - INFO - volta.train_utils -   [XVNLI]: iter 118200 Ep: 3.50 loss 0.005 score 0.096 lr 2.29248e-06 
12/05/2021 06:31:52 - INFO - volta.train_utils -   [XVNLI]: iter 118360 Ep: 3.50 loss 0.005 score 0.099 lr 2.29182e-06 
12/05/2021 06:32:23 - INFO - volta.train_utils -   [XVNLI]: iter 118520 Ep: 3.51 loss 0.005 score 0.097 lr 2.29116e-06 
12/05/2021 06:32:54 - INFO - volta.train_utils -   [XVNLI]: iter 118680 Ep: 3.51 loss 0.004 score 0.098 lr 2.2905e-06 
12/05/2021 06:33:26 - INFO - volta.train_utils -   [XVNLI]: iter 118840 Ep: 3.52 loss 0.004 score 0.098 lr 2.28985e-06 
12/05/2021 06:33:57 - INFO - volta.train_utils -   [XVNLI]: iter 119000 Ep: 3.52 loss 0.005 score 0.096 lr 2.28919e-06 
12/05/2021 06:34:28 - INFO - volta.train_utils -   [XVNLI]: iter 119160 Ep: 3.52 loss 0.005 score 0.097 lr 2.28853e-06 
12/05/2021 06:34:59 - INFO - volta.train_utils -   [XVNLI]: iter 119320 Ep: 3.53 loss 0.005 score 0.100 lr 2.28787e-06 
12/05/2021 06:35:30 - INFO - volta.train_utils -   [XVNLI]: iter 119480 Ep: 3.53 loss 0.005 score 0.097 lr 2.28722e-06 
12/05/2021 06:36:01 - INFO - volta.train_utils -   [XVNLI]: iter 119640 Ep: 3.54 loss 0.005 score 0.097 lr 2.28656e-06 
12/05/2021 06:36:32 - INFO - volta.train_utils -   [XVNLI]: iter 119800 Ep: 3.54 loss 0.006 score 0.096 lr 2.2859e-06 
12/05/2021 06:37:03 - INFO - volta.train_utils -   [XVNLI]: iter 119960 Ep: 3.55 loss 0.005 score 0.097 lr 2.28525e-06 
12/05/2021 06:37:34 - INFO - volta.train_utils -   [XVNLI]: iter 120120 Ep: 3.55 loss 0.005 score 0.094 lr 2.28459e-06 
12/05/2021 06:38:05 - INFO - volta.train_utils -   [XVNLI]: iter 120280 Ep: 3.56 loss 0.005 score 0.099 lr 2.28393e-06 
12/05/2021 06:38:36 - INFO - volta.train_utils -   [XVNLI]: iter 120440 Ep: 3.56 loss 0.006 score 0.098 lr 2.28327e-06 
12/05/2021 06:39:07 - INFO - volta.train_utils -   [XVNLI]: iter 120600 Ep: 3.57 loss 0.005 score 0.098 lr 2.28262e-06 
12/05/2021 06:39:39 - INFO - volta.train_utils -   [XVNLI]: iter 120760 Ep: 3.57 loss 0.005 score 0.097 lr 2.28196e-06 
12/05/2021 06:40:10 - INFO - volta.train_utils -   [XVNLI]: iter 120920 Ep: 3.58 loss 0.006 score 0.096 lr 2.2813e-06 
12/05/2021 06:40:41 - INFO - volta.train_utils -   [XVNLI]: iter 121080 Ep: 3.58 loss 0.005 score 0.097 lr 2.28064e-06 
12/05/2021 06:41:12 - INFO - volta.train_utils -   [XVNLI]: iter 121240 Ep: 3.59 loss 0.005 score 0.097 lr 2.27999e-06 
12/05/2021 06:41:43 - INFO - volta.train_utils -   [XVNLI]: iter 121400 Ep: 3.59 loss 0.005 score 0.097 lr 2.27933e-06 
12/05/2021 06:42:15 - INFO - volta.train_utils -   [XVNLI]: iter 121560 Ep: 3.60 loss 0.005 score 0.096 lr 2.27867e-06 
12/05/2021 06:42:46 - INFO - volta.train_utils -   [XVNLI]: iter 121720 Ep: 3.60 loss 0.005 score 0.098 lr 2.27801e-06 
12/05/2021 06:43:17 - INFO - volta.train_utils -   [XVNLI]: iter 121880 Ep: 3.61 loss 0.006 score 0.098 lr 2.27736e-06 
12/05/2021 06:43:48 - INFO - volta.train_utils -   [XVNLI]: iter 122040 Ep: 3.61 loss 0.005 score 0.098 lr 2.2767e-06 
12/05/2021 06:44:19 - INFO - volta.train_utils -   [XVNLI]: iter 122200 Ep: 3.61 loss 0.005 score 0.098 lr 2.27604e-06 
12/05/2021 06:44:50 - INFO - volta.train_utils -   [XVNLI]: iter 122360 Ep: 3.62 loss 0.006 score 0.096 lr 2.27539e-06 
12/05/2021 06:45:21 - INFO - volta.train_utils -   [XVNLI]: iter 122520 Ep: 3.62 loss 0.006 score 0.098 lr 2.27473e-06 
12/05/2021 06:45:52 - INFO - volta.train_utils -   [XVNLI]: iter 122680 Ep: 3.63 loss 0.005 score 0.097 lr 2.27407e-06 
12/05/2021 06:46:23 - INFO - volta.train_utils -   [XVNLI]: iter 122840 Ep: 3.63 loss 0.005 score 0.099 lr 2.27341e-06 
12/05/2021 06:46:54 - INFO - volta.train_utils -   [XVNLI]: iter 123000 Ep: 3.64 loss 0.005 score 0.095 lr 2.27276e-06 
12/05/2021 06:47:25 - INFO - volta.train_utils -   [XVNLI]: iter 123160 Ep: 3.64 loss 0.006 score 0.099 lr 2.2721e-06 
12/05/2021 06:47:57 - INFO - volta.train_utils -   [XVNLI]: iter 123320 Ep: 3.65 loss 0.005 score 0.097 lr 2.27144e-06 
12/05/2021 06:48:28 - INFO - volta.train_utils -   [XVNLI]: iter 123480 Ep: 3.65 loss 0.005 score 0.098 lr 2.27078e-06 
12/05/2021 06:48:59 - INFO - volta.train_utils -   [XVNLI]: iter 123640 Ep: 3.66 loss 0.005 score 0.097 lr 2.27013e-06 
12/05/2021 06:49:30 - INFO - volta.train_utils -   [XVNLI]: iter 123800 Ep: 3.66 loss 0.005 score 0.097 lr 2.26947e-06 
12/05/2021 06:50:02 - INFO - volta.train_utils -   [XVNLI]: iter 123960 Ep: 3.67 loss 0.005 score 0.096 lr 2.26881e-06 
12/05/2021 06:50:33 - INFO - volta.train_utils -   [XVNLI]: iter 124120 Ep: 3.67 loss 0.005 score 0.097 lr 2.26815e-06 
12/05/2021 06:51:04 - INFO - volta.train_utils -   [XVNLI]: iter 124280 Ep: 3.68 loss 0.005 score 0.098 lr 2.2675e-06 
12/05/2021 06:51:35 - INFO - volta.train_utils -   [XVNLI]: iter 124440 Ep: 3.68 loss 0.005 score 0.095 lr 2.26684e-06 
12/05/2021 06:52:07 - INFO - volta.train_utils -   [XVNLI]: iter 124600 Ep: 3.69 loss 0.005 score 0.096 lr 2.26618e-06 
12/05/2021 06:52:38 - INFO - volta.train_utils -   [XVNLI]: iter 124760 Ep: 3.69 loss 0.005 score 0.097 lr 2.26552e-06 
12/05/2021 06:53:09 - INFO - volta.train_utils -   [XVNLI]: iter 124920 Ep: 3.70 loss 0.005 score 0.097 lr 2.26487e-06 
12/05/2021 06:53:40 - INFO - volta.train_utils -   [XVNLI]: iter 125080 Ep: 3.70 loss 0.005 score 0.098 lr 2.26421e-06 
12/05/2021 06:54:11 - INFO - volta.train_utils -   [XVNLI]: iter 125240 Ep: 3.70 loss 0.005 score 0.098 lr 2.26355e-06 
12/05/2021 06:54:42 - INFO - volta.train_utils -   [XVNLI]: iter 125400 Ep: 3.71 loss 0.005 score 0.098 lr 2.2629e-06 
12/05/2021 06:55:14 - INFO - volta.train_utils -   [XVNLI]: iter 125560 Ep: 3.71 loss 0.006 score 0.096 lr 2.26224e-06 
12/05/2021 06:55:45 - INFO - volta.train_utils -   [XVNLI]: iter 125720 Ep: 3.72 loss 0.005 score 0.097 lr 2.26158e-06 
12/05/2021 06:56:16 - INFO - volta.train_utils -   [XVNLI]: iter 125880 Ep: 3.72 loss 0.005 score 0.097 lr 2.26092e-06 
12/05/2021 06:56:47 - INFO - volta.train_utils -   [XVNLI]: iter 126040 Ep: 3.73 loss 0.005 score 0.097 lr 2.26027e-06 
12/05/2021 06:57:18 - INFO - volta.train_utils -   [XVNLI]: iter 126200 Ep: 3.73 loss 0.005 score 0.098 lr 2.25961e-06 
12/05/2021 06:57:50 - INFO - volta.train_utils -   [XVNLI]: iter 126360 Ep: 3.74 loss 0.004 score 0.098 lr 2.25895e-06 
12/05/2021 06:58:21 - INFO - volta.train_utils -   [XVNLI]: iter 126520 Ep: 3.74 loss 0.006 score 0.099 lr 2.25829e-06 
12/05/2021 06:58:52 - INFO - volta.train_utils -   [XVNLI]: iter 126680 Ep: 3.75 loss 0.004 score 0.098 lr 2.25764e-06 
12/05/2021 06:59:23 - INFO - volta.train_utils -   [XVNLI]: iter 126840 Ep: 3.75 loss 0.006 score 0.097 lr 2.25698e-06 
12/05/2021 06:59:54 - INFO - volta.train_utils -   [XVNLI]: iter 127000 Ep: 3.76 loss 0.005 score 0.098 lr 2.25632e-06 
12/05/2021 07:00:25 - INFO - volta.train_utils -   [XVNLI]: iter 127160 Ep: 3.76 loss 0.005 score 0.097 lr 2.25566e-06 
12/05/2021 07:00:57 - INFO - volta.train_utils -   [XVNLI]: iter 127320 Ep: 3.77 loss 0.005 score 0.098 lr 2.25501e-06 
12/05/2021 07:01:28 - INFO - volta.train_utils -   [XVNLI]: iter 127480 Ep: 3.77 loss 0.005 score 0.097 lr 2.25435e-06 
12/05/2021 07:01:59 - INFO - volta.train_utils -   [XVNLI]: iter 127640 Ep: 3.78 loss 0.005 score 0.096 lr 2.25369e-06 
12/05/2021 07:02:30 - INFO - volta.train_utils -   [XVNLI]: iter 127800 Ep: 3.78 loss 0.005 score 0.095 lr 2.25304e-06 
12/05/2021 07:03:01 - INFO - volta.train_utils -   [XVNLI]: iter 127960 Ep: 3.79 loss 0.006 score 0.095 lr 2.25238e-06 
12/05/2021 07:03:32 - INFO - volta.train_utils -   [XVNLI]: iter 128120 Ep: 3.79 loss 0.005 score 0.097 lr 2.25172e-06 
12/05/2021 07:04:03 - INFO - volta.train_utils -   [XVNLI]: iter 128280 Ep: 3.79 loss 0.005 score 0.098 lr 2.25106e-06 
12/05/2021 07:04:34 - INFO - volta.train_utils -   [XVNLI]: iter 128440 Ep: 3.80 loss 0.005 score 0.097 lr 2.25041e-06 
12/05/2021 07:05:05 - INFO - volta.train_utils -   [XVNLI]: iter 128600 Ep: 3.80 loss 0.006 score 0.096 lr 2.24975e-06 
12/05/2021 07:05:36 - INFO - volta.train_utils -   [XVNLI]: iter 128760 Ep: 3.81 loss 0.005 score 0.098 lr 2.24909e-06 
12/05/2021 07:06:08 - INFO - volta.train_utils -   [XVNLI]: iter 128920 Ep: 3.81 loss 0.005 score 0.098 lr 2.24843e-06 
12/05/2021 07:06:41 - INFO - volta.train_utils -   [XVNLI]: iter 129080 Ep: 3.82 loss 0.005 score 0.096 lr 2.24778e-06 
12/05/2021 07:07:13 - INFO - volta.train_utils -   [XVNLI]: iter 129240 Ep: 3.82 loss 0.006 score 0.095 lr 2.24712e-06 
12/05/2021 07:07:44 - INFO - volta.train_utils -   [XVNLI]: iter 129400 Ep: 3.83 loss 0.005 score 0.097 lr 2.24646e-06 
12/05/2021 07:08:16 - INFO - volta.train_utils -   [XVNLI]: iter 129560 Ep: 3.83 loss 0.005 score 0.097 lr 2.2458e-06 
12/05/2021 07:08:47 - INFO - volta.train_utils -   [XVNLI]: iter 129720 Ep: 3.84 loss 0.005 score 0.097 lr 2.24515e-06 
12/05/2021 07:09:18 - INFO - volta.train_utils -   [XVNLI]: iter 129880 Ep: 3.84 loss 0.005 score 0.098 lr 2.24449e-06 
12/05/2021 07:09:50 - INFO - volta.train_utils -   [XVNLI]: iter 130040 Ep: 3.85 loss 0.005 score 0.096 lr 2.24383e-06 
12/05/2021 07:10:21 - INFO - volta.train_utils -   [XVNLI]: iter 130200 Ep: 3.85 loss 0.005 score 0.097 lr 2.24318e-06 
12/05/2021 07:10:52 - INFO - volta.train_utils -   [XVNLI]: iter 130360 Ep: 3.86 loss 0.005 score 0.098 lr 2.24252e-06 
12/05/2021 07:11:23 - INFO - volta.train_utils -   [XVNLI]: iter 130520 Ep: 3.86 loss 0.005 score 0.096 lr 2.24186e-06 
12/05/2021 07:11:54 - INFO - volta.train_utils -   [XVNLI]: iter 130680 Ep: 3.87 loss 0.005 score 0.097 lr 2.2412e-06 
12/05/2021 07:12:25 - INFO - volta.train_utils -   [XVNLI]: iter 130840 Ep: 3.87 loss 0.005 score 0.098 lr 2.24055e-06 
12/05/2021 07:12:56 - INFO - volta.train_utils -   [XVNLI]: iter 131000 Ep: 3.88 loss 0.005 score 0.097 lr 2.23989e-06 
12/05/2021 07:13:27 - INFO - volta.train_utils -   [XVNLI]: iter 131160 Ep: 3.88 loss 0.005 score 0.098 lr 2.23923e-06 
12/05/2021 07:13:58 - INFO - volta.train_utils -   [XVNLI]: iter 131320 Ep: 3.88 loss 0.005 score 0.098 lr 2.23857e-06 
12/05/2021 07:14:29 - INFO - volta.train_utils -   [XVNLI]: iter 131480 Ep: 3.89 loss 0.005 score 0.099 lr 2.23792e-06 
12/05/2021 07:15:03 - INFO - volta.train_utils -   [XVNLI]: iter 131640 Ep: 3.89 loss 0.005 score 0.098 lr 2.23726e-06 
12/05/2021 07:15:36 - INFO - volta.train_utils -   [XVNLI]: iter 131800 Ep: 3.90 loss 0.006 score 0.096 lr 2.2366e-06 
12/05/2021 07:16:09 - INFO - volta.train_utils -   [XVNLI]: iter 131960 Ep: 3.90 loss 0.005 score 0.097 lr 2.23594e-06 
12/05/2021 07:16:42 - INFO - volta.train_utils -   [XVNLI]: iter 132120 Ep: 3.91 loss 0.006 score 0.096 lr 2.23529e-06 
12/05/2021 07:17:16 - INFO - volta.train_utils -   [XVNLI]: iter 132280 Ep: 3.91 loss 0.006 score 0.095 lr 2.23463e-06 
12/05/2021 07:17:48 - INFO - volta.train_utils -   [XVNLI]: iter 132440 Ep: 3.92 loss 0.005 score 0.097 lr 2.23397e-06 
12/05/2021 07:18:19 - INFO - volta.train_utils -   [XVNLI]: iter 132600 Ep: 3.92 loss 0.004 score 0.097 lr 2.23331e-06 
12/05/2021 07:18:52 - INFO - volta.train_utils -   [XVNLI]: iter 132760 Ep: 3.93 loss 0.005 score 0.098 lr 2.23266e-06 
12/05/2021 07:19:23 - INFO - volta.train_utils -   [XVNLI]: iter 132920 Ep: 3.93 loss 0.005 score 0.098 lr 2.232e-06 
12/05/2021 07:19:55 - INFO - volta.train_utils -   [XVNLI]: iter 133080 Ep: 3.94 loss 0.005 score 0.099 lr 2.23134e-06 
12/05/2021 07:20:27 - INFO - volta.train_utils -   [XVNLI]: iter 133240 Ep: 3.94 loss 0.005 score 0.097 lr 2.23069e-06 
12/05/2021 07:20:58 - INFO - volta.train_utils -   [XVNLI]: iter 133400 Ep: 3.95 loss 0.005 score 0.097 lr 2.23003e-06 
12/05/2021 07:21:29 - INFO - volta.train_utils -   [XVNLI]: iter 133560 Ep: 3.95 loss 0.005 score 0.096 lr 2.22937e-06 
12/05/2021 07:22:01 - INFO - volta.train_utils -   [XVNLI]: iter 133720 Ep: 3.96 loss 0.006 score 0.097 lr 2.22871e-06 
12/05/2021 07:22:32 - INFO - volta.train_utils -   [XVNLI]: iter 133880 Ep: 3.96 loss 0.005 score 0.099 lr 2.22806e-06 
12/05/2021 07:23:04 - INFO - volta.train_utils -   [XVNLI]: iter 134040 Ep: 3.96 loss 0.005 score 0.098 lr 2.2274e-06 
12/05/2021 07:23:35 - INFO - volta.train_utils -   [XVNLI]: iter 134200 Ep: 3.97 loss 0.006 score 0.098 lr 2.22674e-06 
12/05/2021 07:24:07 - INFO - volta.train_utils -   [XVNLI]: iter 134360 Ep: 3.97 loss 0.005 score 0.098 lr 2.22608e-06 
12/05/2021 07:24:40 - INFO - volta.train_utils -   [XVNLI]: iter 134520 Ep: 3.98 loss 0.005 score 0.098 lr 2.22543e-06 
12/05/2021 07:25:15 - INFO - volta.train_utils -   [XVNLI]: iter 134680 Ep: 3.98 loss 0.006 score 0.097 lr 2.22477e-06 
12/05/2021 07:25:48 - INFO - volta.train_utils -   [XVNLI]: iter 134840 Ep: 3.99 loss 0.005 score 0.096 lr 2.22411e-06 
12/05/2021 07:26:21 - INFO - volta.train_utils -   [XVNLI]: iter 135000 Ep: 3.99 loss 0.005 score 0.097 lr 2.22345e-06 
12/05/2021 07:26:56 - INFO - volta.train_utils -   [XVNLI]: iter 135160 Ep: 4.00 loss 0.005 score 0.097 lr 2.2228e-06 
12/05/2021 07:30:46 - INFO - volta.train_utils -   Eval task TASK19 on iteration 135200 
12/05/2021 07:30:46 - INFO - volta.train_utils -   Validation [XVNLI]: loss 0.369 score 75.367 
12/05/2021 07:30:46 - INFO - __main__ -   ** ** * Saving model * ** ** 
Epoch:  40%|████      | 4/10 [7:52:42<11:55:29, 7154.98s/it]12/05/2021 07:31:53 - INFO - volta.train_utils -   [XVNLI]: iter 135360 Ep: 4.00 loss 0.005 score 0.102 lr 2.22206e-06 
12/05/2021 07:32:24 - INFO - volta.train_utils -   [XVNLI]: iter 135520 Ep: 4.01 loss 0.005 score 0.100 lr 2.22132e-06 
12/05/2021 07:32:55 - INFO - volta.train_utils -   [XVNLI]: iter 135680 Ep: 4.01 loss 0.004 score 0.101 lr 2.22066e-06 
12/05/2021 07:33:26 - INFO - volta.train_utils -   [XVNLI]: iter 135840 Ep: 4.02 loss 0.004 score 0.100 lr 2.22e-06 
12/05/2021 07:33:57 - INFO - volta.train_utils -   [XVNLI]: iter 136000 Ep: 4.02 loss 0.004 score 0.101 lr 2.21935e-06 
12/05/2021 07:34:28 - INFO - volta.train_utils -   [XVNLI]: iter 136160 Ep: 4.03 loss 0.005 score 0.100 lr 2.21869e-06 
12/05/2021 07:35:05 - INFO - volta.train_utils -   [XVNLI]: iter 136320 Ep: 4.03 loss 0.005 score 0.100 lr 2.21803e-06 
12/05/2021 07:35:36 - INFO - volta.train_utils -   [XVNLI]: iter 136480 Ep: 4.04 loss 0.005 score 0.101 lr 2.21737e-06 
12/05/2021 07:36:07 - INFO - volta.train_utils -   [XVNLI]: iter 136640 Ep: 4.04 loss 0.005 score 0.100 lr 2.21672e-06 
12/05/2021 07:36:38 - INFO - volta.train_utils -   [XVNLI]: iter 136800 Ep: 4.05 loss 0.005 score 0.100 lr 2.21606e-06 
12/05/2021 07:37:09 - INFO - volta.train_utils -   [XVNLI]: iter 136960 Ep: 4.05 loss 0.005 score 0.100 lr 2.2154e-06 
12/05/2021 07:37:40 - INFO - volta.train_utils -   [XVNLI]: iter 137120 Ep: 4.06 loss 0.004 score 0.101 lr 2.21474e-06 
12/05/2021 07:38:12 - INFO - volta.train_utils -   [XVNLI]: iter 137280 Ep: 4.06 loss 0.004 score 0.100 lr 2.21409e-06 
12/05/2021 07:38:43 - INFO - volta.train_utils -   [XVNLI]: iter 137440 Ep: 4.07 loss 0.005 score 0.100 lr 2.21343e-06 
12/05/2021 07:39:14 - INFO - volta.train_utils -   [XVNLI]: iter 137600 Ep: 4.07 loss 0.005 score 0.100 lr 2.21277e-06 
12/05/2021 07:39:45 - INFO - volta.train_utils -   [XVNLI]: iter 137760 Ep: 4.08 loss 0.005 score 0.100 lr 2.21212e-06 
12/05/2021 07:40:16 - INFO - volta.train_utils -   [XVNLI]: iter 137920 Ep: 4.08 loss 0.005 score 0.098 lr 2.21146e-06 
12/05/2021 07:40:47 - INFO - volta.train_utils -   [XVNLI]: iter 138080 Ep: 4.08 loss 0.005 score 0.100 lr 2.2108e-06 
12/05/2021 07:41:18 - INFO - volta.train_utils -   [XVNLI]: iter 138240 Ep: 4.09 loss 0.005 score 0.100 lr 2.21014e-06 
12/05/2021 07:41:49 - INFO - volta.train_utils -   [XVNLI]: iter 138400 Ep: 4.09 loss 0.005 score 0.100 lr 2.20949e-06 
12/05/2021 07:42:20 - INFO - volta.train_utils -   [XVNLI]: iter 138560 Ep: 4.10 loss 0.005 score 0.098 lr 2.20883e-06 
12/05/2021 07:42:52 - INFO - volta.train_utils -   [XVNLI]: iter 138720 Ep: 4.10 loss 0.004 score 0.101 lr 2.20817e-06 
12/05/2021 07:43:23 - INFO - volta.train_utils -   [XVNLI]: iter 138880 Ep: 4.11 loss 0.004 score 0.101 lr 2.20751e-06 
12/05/2021 07:43:54 - INFO - volta.train_utils -   [XVNLI]: iter 139040 Ep: 4.11 loss 0.005 score 0.100 lr 2.20686e-06 
12/05/2021 07:44:25 - INFO - volta.train_utils -   [XVNLI]: iter 139200 Ep: 4.12 loss 0.005 score 0.099 lr 2.2062e-06 
12/05/2021 07:44:57 - INFO - volta.train_utils -   [XVNLI]: iter 139360 Ep: 4.12 loss 0.005 score 0.100 lr 2.20554e-06 
12/05/2021 07:45:28 - INFO - volta.train_utils -   [XVNLI]: iter 139520 Ep: 4.13 loss 0.004 score 0.100 lr 2.20488e-06 
12/05/2021 07:45:59 - INFO - volta.train_utils -   [XVNLI]: iter 139680 Ep: 4.13 loss 0.005 score 0.100 lr 2.20423e-06 
12/05/2021 07:46:30 - INFO - volta.train_utils -   [XVNLI]: iter 139840 Ep: 4.14 loss 0.005 score 0.099 lr 2.20357e-06 
12/05/2021 07:47:01 - INFO - volta.train_utils -   [XVNLI]: iter 140000 Ep: 4.14 loss 0.005 score 0.099 lr 2.20291e-06 
12/05/2021 07:47:32 - INFO - volta.train_utils -   [XVNLI]: iter 140160 Ep: 4.15 loss 0.004 score 0.099 lr 2.20226e-06 
12/05/2021 07:48:04 - INFO - volta.train_utils -   [XVNLI]: iter 140320 Ep: 4.15 loss 0.004 score 0.098 lr 2.2016e-06 
12/05/2021 07:48:35 - INFO - volta.train_utils -   [XVNLI]: iter 140480 Ep: 4.16 loss 0.005 score 0.100 lr 2.20094e-06 
12/05/2021 07:49:06 - INFO - volta.train_utils -   [XVNLI]: iter 140640 Ep: 4.16 loss 0.005 score 0.100 lr 2.20028e-06 
12/05/2021 07:49:37 - INFO - volta.train_utils -   [XVNLI]: iter 140800 Ep: 4.16 loss 0.006 score 0.099 lr 2.19963e-06 
12/05/2021 07:50:08 - INFO - volta.train_utils -   [XVNLI]: iter 140960 Ep: 4.17 loss 0.005 score 0.099 lr 2.19897e-06 
12/05/2021 07:50:39 - INFO - volta.train_utils -   [XVNLI]: iter 141120 Ep: 4.17 loss 0.005 score 0.099 lr 2.19831e-06 
12/05/2021 07:51:10 - INFO - volta.train_utils -   [XVNLI]: iter 141280 Ep: 4.18 loss 0.004 score 0.100 lr 2.19765e-06 
12/05/2021 07:51:41 - INFO - volta.train_utils -   [XVNLI]: iter 141440 Ep: 4.18 loss 0.005 score 0.101 lr 2.197e-06 
12/05/2021 07:52:12 - INFO - volta.train_utils -   [XVNLI]: iter 141600 Ep: 4.19 loss 0.005 score 0.099 lr 2.19634e-06 
12/05/2021 07:52:43 - INFO - volta.train_utils -   [XVNLI]: iter 141760 Ep: 4.19 loss 0.005 score 0.099 lr 2.19568e-06 
12/05/2021 07:53:15 - INFO - volta.train_utils -   [XVNLI]: iter 141920 Ep: 4.20 loss 0.005 score 0.100 lr 2.19502e-06 
12/05/2021 07:53:46 - INFO - volta.train_utils -   [XVNLI]: iter 142080 Ep: 4.20 loss 0.004 score 0.101 lr 2.19437e-06 
12/05/2021 07:54:17 - INFO - volta.train_utils -   [XVNLI]: iter 142240 Ep: 4.21 loss 0.005 score 0.100 lr 2.19371e-06 
12/05/2021 07:54:48 - INFO - volta.train_utils -   [XVNLI]: iter 142400 Ep: 4.21 loss 0.004 score 0.100 lr 2.19305e-06 
12/05/2021 07:55:19 - INFO - volta.train_utils -   [XVNLI]: iter 142560 Ep: 4.22 loss 0.005 score 0.098 lr 2.1924e-06 
12/05/2021 07:55:50 - INFO - volta.train_utils -   [XVNLI]: iter 142720 Ep: 4.22 loss 0.005 score 0.099 lr 2.19174e-06 
12/05/2021 07:56:21 - INFO - volta.train_utils -   [XVNLI]: iter 142880 Ep: 4.23 loss 0.005 score 0.099 lr 2.19108e-06 
12/05/2021 07:56:52 - INFO - volta.train_utils -   [XVNLI]: iter 143040 Ep: 4.23 loss 0.005 score 0.099 lr 2.19042e-06 
12/05/2021 07:57:23 - INFO - volta.train_utils -   [XVNLI]: iter 143200 Ep: 4.24 loss 0.005 score 0.098 lr 2.18977e-06 
12/05/2021 07:57:54 - INFO - volta.train_utils -   [XVNLI]: iter 143360 Ep: 4.24 loss 0.004 score 0.099 lr 2.18911e-06 
12/05/2021 07:58:25 - INFO - volta.train_utils -   [XVNLI]: iter 143520 Ep: 4.25 loss 0.004 score 0.102 lr 2.18845e-06 
12/05/2021 07:58:56 - INFO - volta.train_utils -   [XVNLI]: iter 143680 Ep: 4.25 loss 0.004 score 0.099 lr 2.18779e-06 
12/05/2021 07:59:27 - INFO - volta.train_utils -   [XVNLI]: iter 143840 Ep: 4.25 loss 0.005 score 0.099 lr 2.18714e-06 
12/05/2021 07:59:58 - INFO - volta.train_utils -   [XVNLI]: iter 144000 Ep: 4.26 loss 0.005 score 0.100 lr 2.18648e-06 
12/05/2021 08:00:30 - INFO - volta.train_utils -   [XVNLI]: iter 144160 Ep: 4.26 loss 0.005 score 0.100 lr 2.18582e-06 
12/05/2021 08:01:01 - INFO - volta.train_utils -   [XVNLI]: iter 144320 Ep: 4.27 loss 0.005 score 0.101 lr 2.18516e-06 
12/05/2021 08:01:32 - INFO - volta.train_utils -   [XVNLI]: iter 144480 Ep: 4.27 loss 0.006 score 0.098 lr 2.18451e-06 
12/05/2021 08:02:03 - INFO - volta.train_utils -   [XVNLI]: iter 144640 Ep: 4.28 loss 0.004 score 0.102 lr 2.18385e-06 
12/05/2021 08:02:34 - INFO - volta.train_utils -   [XVNLI]: iter 144800 Ep: 4.28 loss 0.004 score 0.100 lr 2.18319e-06 
12/05/2021 08:03:05 - INFO - volta.train_utils -   [XVNLI]: iter 144960 Ep: 4.29 loss 0.005 score 0.100 lr 2.18253e-06 
12/05/2021 08:03:36 - INFO - volta.train_utils -   [XVNLI]: iter 145120 Ep: 4.29 loss 0.005 score 0.099 lr 2.18188e-06 
12/05/2021 08:04:07 - INFO - volta.train_utils -   [XVNLI]: iter 145280 Ep: 4.30 loss 0.005 score 0.101 lr 2.18122e-06 
12/05/2021 08:04:38 - INFO - volta.train_utils -   [XVNLI]: iter 145440 Ep: 4.30 loss 0.005 score 0.100 lr 2.18056e-06 
12/05/2021 08:05:09 - INFO - volta.train_utils -   [XVNLI]: iter 145600 Ep: 4.31 loss 0.005 score 0.099 lr 2.17991e-06 
12/05/2021 08:05:40 - INFO - volta.train_utils -   [XVNLI]: iter 145760 Ep: 4.31 loss 0.005 score 0.100 lr 2.17925e-06 
12/05/2021 08:06:11 - INFO - volta.train_utils -   [XVNLI]: iter 145920 Ep: 4.32 loss 0.005 score 0.100 lr 2.17859e-06 
12/05/2021 08:06:42 - INFO - volta.train_utils -   [XVNLI]: iter 146080 Ep: 4.32 loss 0.005 score 0.100 lr 2.17793e-06 
12/05/2021 08:07:13 - INFO - volta.train_utils -   [XVNLI]: iter 146240 Ep: 4.33 loss 0.005 score 0.100 lr 2.17728e-06 
12/05/2021 08:07:45 - INFO - volta.train_utils -   [XVNLI]: iter 146400 Ep: 4.33 loss 0.005 score 0.099 lr 2.17662e-06 
12/05/2021 08:08:17 - INFO - volta.train_utils -   [XVNLI]: iter 146560 Ep: 4.34 loss 0.005 score 0.101 lr 2.17596e-06 
12/05/2021 08:08:48 - INFO - volta.train_utils -   [XVNLI]: iter 146720 Ep: 4.34 loss 0.005 score 0.099 lr 2.1753e-06 
12/05/2021 08:09:19 - INFO - volta.train_utils -   [XVNLI]: iter 146880 Ep: 4.34 loss 0.005 score 0.100 lr 2.17465e-06 
12/05/2021 08:09:50 - INFO - volta.train_utils -   [XVNLI]: iter 147040 Ep: 4.35 loss 0.004 score 0.101 lr 2.17399e-06 
12/05/2021 08:10:21 - INFO - volta.train_utils -   [XVNLI]: iter 147200 Ep: 4.35 loss 0.004 score 0.101 lr 2.17333e-06 
12/05/2021 08:10:52 - INFO - volta.train_utils -   [XVNLI]: iter 147360 Ep: 4.36 loss 0.005 score 0.099 lr 2.17267e-06 
12/05/2021 08:11:23 - INFO - volta.train_utils -   [XVNLI]: iter 147520 Ep: 4.36 loss 0.005 score 0.099 lr 2.17202e-06 
12/05/2021 08:11:54 - INFO - volta.train_utils -   [XVNLI]: iter 147680 Ep: 4.37 loss 0.005 score 0.101 lr 2.17136e-06 
12/05/2021 08:12:25 - INFO - volta.train_utils -   [XVNLI]: iter 147840 Ep: 4.37 loss 0.005 score 0.099 lr 2.1707e-06 
12/05/2021 08:12:56 - INFO - volta.train_utils -   [XVNLI]: iter 148000 Ep: 4.38 loss 0.005 score 0.100 lr 2.17005e-06 
12/05/2021 08:13:27 - INFO - volta.train_utils -   [XVNLI]: iter 148160 Ep: 4.38 loss 0.005 score 0.097 lr 2.16939e-06 
12/05/2021 08:13:59 - INFO - volta.train_utils -   [XVNLI]: iter 148320 Ep: 4.39 loss 0.005 score 0.100 lr 2.16873e-06 
12/05/2021 08:14:29 - INFO - volta.train_utils -   [XVNLI]: iter 148480 Ep: 4.39 loss 0.005 score 0.100 lr 2.16807e-06 
12/05/2021 08:15:01 - INFO - volta.train_utils -   [XVNLI]: iter 148640 Ep: 4.40 loss 0.005 score 0.099 lr 2.16742e-06 
12/05/2021 08:15:32 - INFO - volta.train_utils -   [XVNLI]: iter 148800 Ep: 4.40 loss 0.005 score 0.099 lr 2.16676e-06 
12/05/2021 08:16:03 - INFO - volta.train_utils -   [XVNLI]: iter 148960 Ep: 4.41 loss 0.005 score 0.099 lr 2.1661e-06 
12/05/2021 08:16:34 - INFO - volta.train_utils -   [XVNLI]: iter 149120 Ep: 4.41 loss 0.004 score 0.101 lr 2.16544e-06 
12/05/2021 08:17:05 - INFO - volta.train_utils -   [XVNLI]: iter 149280 Ep: 4.42 loss 0.005 score 0.100 lr 2.16479e-06 
12/05/2021 08:17:36 - INFO - volta.train_utils -   [XVNLI]: iter 149440 Ep: 4.42 loss 0.005 score 0.099 lr 2.16413e-06 
12/05/2021 08:18:07 - INFO - volta.train_utils -   [XVNLI]: iter 149600 Ep: 4.43 loss 0.005 score 0.098 lr 2.16347e-06 
12/05/2021 08:18:38 - INFO - volta.train_utils -   [XVNLI]: iter 149760 Ep: 4.43 loss 0.005 score 0.099 lr 2.16281e-06 
12/05/2021 08:19:09 - INFO - volta.train_utils -   [XVNLI]: iter 149920 Ep: 4.43 loss 0.005 score 0.100 lr 2.16216e-06 
12/05/2021 08:19:40 - INFO - volta.train_utils -   [XVNLI]: iter 150080 Ep: 4.44 loss 0.005 score 0.100 lr 2.1615e-06 
12/05/2021 08:20:12 - INFO - volta.train_utils -   [XVNLI]: iter 150240 Ep: 4.44 loss 0.005 score 0.099 lr 2.16084e-06 
12/05/2021 08:20:43 - INFO - volta.train_utils -   [XVNLI]: iter 150400 Ep: 4.45 loss 0.005 score 0.098 lr 2.16019e-06 
12/05/2021 08:21:14 - INFO - volta.train_utils -   [XVNLI]: iter 150560 Ep: 4.45 loss 0.005 score 0.099 lr 2.15953e-06 
12/05/2021 08:21:45 - INFO - volta.train_utils -   [XVNLI]: iter 150720 Ep: 4.46 loss 0.005 score 0.100 lr 2.15887e-06 
12/05/2021 08:22:16 - INFO - volta.train_utils -   [XVNLI]: iter 150880 Ep: 4.46 loss 0.006 score 0.100 lr 2.15821e-06 
12/05/2021 08:22:47 - INFO - volta.train_utils -   [XVNLI]: iter 151040 Ep: 4.47 loss 0.005 score 0.099 lr 2.15756e-06 
12/05/2021 08:23:19 - INFO - volta.train_utils -   [XVNLI]: iter 151200 Ep: 4.47 loss 0.005 score 0.099 lr 2.1569e-06 
12/05/2021 08:23:50 - INFO - volta.train_utils -   [XVNLI]: iter 151360 Ep: 4.48 loss 0.005 score 0.099 lr 2.15624e-06 
12/05/2021 08:24:21 - INFO - volta.train_utils -   [XVNLI]: iter 151520 Ep: 4.48 loss 0.005 score 0.099 lr 2.15558e-06 
12/05/2021 08:24:52 - INFO - volta.train_utils -   [XVNLI]: iter 151680 Ep: 4.49 loss 0.005 score 0.100 lr 2.15493e-06 
12/05/2021 08:25:23 - INFO - volta.train_utils -   [XVNLI]: iter 151840 Ep: 4.49 loss 0.005 score 0.098 lr 2.15427e-06 
12/05/2021 08:25:54 - INFO - volta.train_utils -   [XVNLI]: iter 152000 Ep: 4.50 loss 0.004 score 0.101 lr 2.15361e-06 
12/05/2021 08:26:26 - INFO - volta.train_utils -   [XVNLI]: iter 152160 Ep: 4.50 loss 0.005 score 0.099 lr 2.15295e-06 
12/05/2021 08:26:57 - INFO - volta.train_utils -   [XVNLI]: iter 152320 Ep: 4.51 loss 0.005 score 0.099 lr 2.1523e-06 
12/05/2021 08:27:28 - INFO - volta.train_utils -   [XVNLI]: iter 152480 Ep: 4.51 loss 0.004 score 0.100 lr 2.15164e-06 
12/05/2021 08:27:59 - INFO - volta.train_utils -   [XVNLI]: iter 152640 Ep: 4.52 loss 0.005 score 0.099 lr 2.15098e-06 
12/05/2021 08:28:30 - INFO - volta.train_utils -   [XVNLI]: iter 152800 Ep: 4.52 loss 0.005 score 0.101 lr 2.15033e-06 
12/05/2021 08:29:01 - INFO - volta.train_utils -   [XVNLI]: iter 152960 Ep: 4.52 loss 0.004 score 0.099 lr 2.14967e-06 
12/05/2021 08:29:32 - INFO - volta.train_utils -   [XVNLI]: iter 153120 Ep: 4.53 loss 0.005 score 0.100 lr 2.14901e-06 
12/05/2021 08:30:03 - INFO - volta.train_utils -   [XVNLI]: iter 153280 Ep: 4.53 loss 0.005 score 0.100 lr 2.14835e-06 
12/05/2021 08:30:34 - INFO - volta.train_utils -   [XVNLI]: iter 153440 Ep: 4.54 loss 0.005 score 0.098 lr 2.1477e-06 
12/05/2021 08:31:05 - INFO - volta.train_utils -   [XVNLI]: iter 153600 Ep: 4.54 loss 0.005 score 0.100 lr 2.14704e-06 
12/05/2021 08:31:36 - INFO - volta.train_utils -   [XVNLI]: iter 153760 Ep: 4.55 loss 0.004 score 0.101 lr 2.14638e-06 
12/05/2021 08:32:07 - INFO - volta.train_utils -   [XVNLI]: iter 153920 Ep: 4.55 loss 0.004 score 0.100 lr 2.14572e-06 
12/05/2021 08:32:39 - INFO - volta.train_utils -   [XVNLI]: iter 154080 Ep: 4.56 loss 0.005 score 0.100 lr 2.14507e-06 
12/05/2021 08:33:10 - INFO - volta.train_utils -   [XVNLI]: iter 154240 Ep: 4.56 loss 0.005 score 0.101 lr 2.14441e-06 
12/05/2021 08:33:41 - INFO - volta.train_utils -   [XVNLI]: iter 154400 Ep: 4.57 loss 0.006 score 0.099 lr 2.14375e-06 
12/05/2021 08:34:13 - INFO - volta.train_utils -   [XVNLI]: iter 154560 Ep: 4.57 loss 0.004 score 0.100 lr 2.14309e-06 
12/05/2021 08:34:44 - INFO - volta.train_utils -   [XVNLI]: iter 154720 Ep: 4.58 loss 0.005 score 0.102 lr 2.14244e-06 
12/05/2021 08:35:15 - INFO - volta.train_utils -   [XVNLI]: iter 154880 Ep: 4.58 loss 0.004 score 0.099 lr 2.14178e-06 
12/05/2021 08:35:46 - INFO - volta.train_utils -   [XVNLI]: iter 155040 Ep: 4.59 loss 0.005 score 0.099 lr 2.14112e-06 
12/05/2021 08:36:17 - INFO - volta.train_utils -   [XVNLI]: iter 155200 Ep: 4.59 loss 0.004 score 0.100 lr 2.14046e-06 
12/05/2021 08:36:48 - INFO - volta.train_utils -   [XVNLI]: iter 155360 Ep: 4.60 loss 0.005 score 0.100 lr 2.13981e-06 
12/05/2021 08:37:19 - INFO - volta.train_utils -   [XVNLI]: iter 155520 Ep: 4.60 loss 0.005 score 0.100 lr 2.13915e-06 
12/05/2021 08:37:50 - INFO - volta.train_utils -   [XVNLI]: iter 155680 Ep: 4.61 loss 0.005 score 0.101 lr 2.13849e-06 
12/05/2021 08:38:21 - INFO - volta.train_utils -   [XVNLI]: iter 155840 Ep: 4.61 loss 0.004 score 0.099 lr 2.13784e-06 
12/05/2021 08:38:52 - INFO - volta.train_utils -   [XVNLI]: iter 156000 Ep: 4.61 loss 0.005 score 0.099 lr 2.13718e-06 
12/05/2021 08:39:24 - INFO - volta.train_utils -   [XVNLI]: iter 156160 Ep: 4.62 loss 0.005 score 0.100 lr 2.13652e-06 
12/05/2021 08:39:55 - INFO - volta.train_utils -   [XVNLI]: iter 156320 Ep: 4.62 loss 0.005 score 0.099 lr 2.13586e-06 
12/05/2021 08:40:26 - INFO - volta.train_utils -   [XVNLI]: iter 156480 Ep: 4.63 loss 0.004 score 0.101 lr 2.13521e-06 
12/05/2021 08:40:57 - INFO - volta.train_utils -   [XVNLI]: iter 156640 Ep: 4.63 loss 0.005 score 0.099 lr 2.13455e-06 
12/05/2021 08:41:28 - INFO - volta.train_utils -   [XVNLI]: iter 156800 Ep: 4.64 loss 0.005 score 0.099 lr 2.13389e-06 
12/05/2021 08:41:59 - INFO - volta.train_utils -   [XVNLI]: iter 156960 Ep: 4.64 loss 0.004 score 0.101 lr 2.13323e-06 
12/05/2021 08:42:30 - INFO - volta.train_utils -   [XVNLI]: iter 157120 Ep: 4.65 loss 0.005 score 0.098 lr 2.13258e-06 
12/05/2021 08:43:02 - INFO - volta.train_utils -   [XVNLI]: iter 157280 Ep: 4.65 loss 0.005 score 0.098 lr 2.13192e-06 
12/05/2021 08:43:33 - INFO - volta.train_utils -   [XVNLI]: iter 157440 Ep: 4.66 loss 0.005 score 0.098 lr 2.13126e-06 
12/05/2021 08:44:04 - INFO - volta.train_utils -   [XVNLI]: iter 157600 Ep: 4.66 loss 0.005 score 0.100 lr 2.1306e-06 
12/05/2021 08:44:36 - INFO - volta.train_utils -   [XVNLI]: iter 157760 Ep: 4.67 loss 0.005 score 0.099 lr 2.12995e-06 
12/05/2021 08:45:07 - INFO - volta.train_utils -   [XVNLI]: iter 157920 Ep: 4.67 loss 0.005 score 0.101 lr 2.12929e-06 
12/05/2021 08:45:38 - INFO - volta.train_utils -   [XVNLI]: iter 158080 Ep: 4.68 loss 0.005 score 0.099 lr 2.12863e-06 
12/05/2021 08:46:10 - INFO - volta.train_utils -   [XVNLI]: iter 158240 Ep: 4.68 loss 0.005 score 0.100 lr 2.12798e-06 
12/05/2021 08:46:41 - INFO - volta.train_utils -   [XVNLI]: iter 158400 Ep: 4.69 loss 0.005 score 0.099 lr 2.12732e-06 
12/05/2021 08:47:12 - INFO - volta.train_utils -   [XVNLI]: iter 158560 Ep: 4.69 loss 0.005 score 0.101 lr 2.12666e-06 
12/05/2021 08:47:43 - INFO - volta.train_utils -   [XVNLI]: iter 158720 Ep: 4.70 loss 0.005 score 0.101 lr 2.126e-06 
12/05/2021 08:48:14 - INFO - volta.train_utils -   [XVNLI]: iter 158880 Ep: 4.70 loss 0.005 score 0.100 lr 2.12535e-06 
12/05/2021 08:48:45 - INFO - volta.train_utils -   [XVNLI]: iter 159040 Ep: 4.70 loss 0.005 score 0.099 lr 2.12469e-06 
12/05/2021 08:49:16 - INFO - volta.train_utils -   [XVNLI]: iter 159200 Ep: 4.71 loss 0.005 score 0.100 lr 2.12403e-06 
12/05/2021 08:49:47 - INFO - volta.train_utils -   [XVNLI]: iter 159360 Ep: 4.71 loss 0.005 score 0.099 lr 2.12337e-06 
12/05/2021 08:50:19 - INFO - volta.train_utils -   [XVNLI]: iter 159520 Ep: 4.72 loss 0.005 score 0.099 lr 2.12272e-06 
12/05/2021 08:50:50 - INFO - volta.train_utils -   [XVNLI]: iter 159680 Ep: 4.72 loss 0.005 score 0.100 lr 2.12206e-06 
12/05/2021 08:51:22 - INFO - volta.train_utils -   [XVNLI]: iter 159840 Ep: 4.73 loss 0.004 score 0.100 lr 2.1214e-06 
12/05/2021 08:51:53 - INFO - volta.train_utils -   [XVNLI]: iter 160000 Ep: 4.73 loss 0.005 score 0.099 lr 2.12074e-06 
12/05/2021 08:52:24 - INFO - volta.train_utils -   [XVNLI]: iter 160160 Ep: 4.74 loss 0.005 score 0.098 lr 2.12009e-06 
12/05/2021 08:52:56 - INFO - volta.train_utils -   [XVNLI]: iter 160320 Ep: 4.74 loss 0.005 score 0.100 lr 2.11943e-06 
12/05/2021 08:53:27 - INFO - volta.train_utils -   [XVNLI]: iter 160480 Ep: 4.75 loss 0.005 score 0.099 lr 2.11877e-06 
12/05/2021 08:53:58 - INFO - volta.train_utils -   [XVNLI]: iter 160640 Ep: 4.75 loss 0.005 score 0.101 lr 2.11812e-06 
12/05/2021 08:54:29 - INFO - volta.train_utils -   [XVNLI]: iter 160800 Ep: 4.76 loss 0.004 score 0.099 lr 2.11746e-06 
12/05/2021 08:55:00 - INFO - volta.train_utils -   [XVNLI]: iter 160960 Ep: 4.76 loss 0.005 score 0.099 lr 2.1168e-06 
12/05/2021 08:55:31 - INFO - volta.train_utils -   [XVNLI]: iter 161120 Ep: 4.77 loss 0.004 score 0.100 lr 2.11614e-06 
12/05/2021 08:56:02 - INFO - volta.train_utils -   [XVNLI]: iter 161280 Ep: 4.77 loss 0.005 score 0.099 lr 2.11549e-06 
12/05/2021 08:56:34 - INFO - volta.train_utils -   [XVNLI]: iter 161440 Ep: 4.78 loss 0.005 score 0.099 lr 2.11483e-06 
12/05/2021 08:57:05 - INFO - volta.train_utils -   [XVNLI]: iter 161600 Ep: 4.78 loss 0.005 score 0.099 lr 2.11417e-06 
12/05/2021 08:57:36 - INFO - volta.train_utils -   [XVNLI]: iter 161760 Ep: 4.78 loss 0.004 score 0.100 lr 2.11351e-06 
12/05/2021 08:58:07 - INFO - volta.train_utils -   [XVNLI]: iter 161920 Ep: 4.79 loss 0.005 score 0.098 lr 2.11286e-06 
12/05/2021 08:58:38 - INFO - volta.train_utils -   [XVNLI]: iter 162080 Ep: 4.79 loss 0.005 score 0.099 lr 2.1122e-06 
12/05/2021 08:59:09 - INFO - volta.train_utils -   [XVNLI]: iter 162240 Ep: 4.80 loss 0.005 score 0.100 lr 2.11154e-06 
12/05/2021 08:59:40 - INFO - volta.train_utils -   [XVNLI]: iter 162400 Ep: 4.80 loss 0.005 score 0.098 lr 2.11088e-06 
12/05/2021 09:00:12 - INFO - volta.train_utils -   [XVNLI]: iter 162560 Ep: 4.81 loss 0.006 score 0.098 lr 2.11023e-06 
12/05/2021 09:00:44 - INFO - volta.train_utils -   [XVNLI]: iter 162720 Ep: 4.81 loss 0.005 score 0.099 lr 2.10957e-06 
12/05/2021 09:01:15 - INFO - volta.train_utils -   [XVNLI]: iter 162880 Ep: 4.82 loss 0.005 score 0.100 lr 2.10891e-06 
12/05/2021 09:01:47 - INFO - volta.train_utils -   [XVNLI]: iter 163040 Ep: 4.82 loss 0.006 score 0.098 lr 2.10825e-06 
12/05/2021 09:02:18 - INFO - volta.train_utils -   [XVNLI]: iter 163200 Ep: 4.83 loss 0.005 score 0.100 lr 2.1076e-06 
12/05/2021 09:02:49 - INFO - volta.train_utils -   [XVNLI]: iter 163360 Ep: 4.83 loss 0.005 score 0.100 lr 2.10694e-06 
12/05/2021 09:03:20 - INFO - volta.train_utils -   [XVNLI]: iter 163520 Ep: 4.84 loss 0.004 score 0.101 lr 2.10628e-06 
12/05/2021 09:03:51 - INFO - volta.train_utils -   [XVNLI]: iter 163680 Ep: 4.84 loss 0.005 score 0.102 lr 2.10563e-06 
12/05/2021 09:04:22 - INFO - volta.train_utils -   [XVNLI]: iter 163840 Ep: 4.85 loss 0.005 score 0.100 lr 2.10497e-06 
12/05/2021 09:04:54 - INFO - volta.train_utils -   [XVNLI]: iter 164000 Ep: 4.85 loss 0.005 score 0.098 lr 2.10431e-06 
12/05/2021 09:05:25 - INFO - volta.train_utils -   [XVNLI]: iter 164160 Ep: 4.86 loss 0.004 score 0.101 lr 2.10365e-06 
12/05/2021 09:05:56 - INFO - volta.train_utils -   [XVNLI]: iter 164320 Ep: 4.86 loss 0.005 score 0.100 lr 2.103e-06 
12/05/2021 09:06:27 - INFO - volta.train_utils -   [XVNLI]: iter 164480 Ep: 4.87 loss 0.005 score 0.099 lr 2.10234e-06 
12/05/2021 09:06:58 - INFO - volta.train_utils -   [XVNLI]: iter 164640 Ep: 4.87 loss 0.005 score 0.100 lr 2.10168e-06 
12/05/2021 09:07:29 - INFO - volta.train_utils -   [XVNLI]: iter 164800 Ep: 4.87 loss 0.004 score 0.100 lr 2.10102e-06 
12/05/2021 09:08:01 - INFO - volta.train_utils -   [XVNLI]: iter 164960 Ep: 4.88 loss 0.005 score 0.097 lr 2.10037e-06 
12/05/2021 09:08:32 - INFO - volta.train_utils -   [XVNLI]: iter 165120 Ep: 4.88 loss 0.006 score 0.099 lr 2.09971e-06 
12/05/2021 09:09:03 - INFO - volta.train_utils -   [XVNLI]: iter 165280 Ep: 4.89 loss 0.005 score 0.100 lr 2.09905e-06 
12/05/2021 09:09:35 - INFO - volta.train_utils -   [XVNLI]: iter 165440 Ep: 4.89 loss 0.005 score 0.100 lr 2.09839e-06 
12/05/2021 09:10:06 - INFO - volta.train_utils -   [XVNLI]: iter 165600 Ep: 4.90 loss 0.005 score 0.097 lr 2.09774e-06 
12/05/2021 09:10:37 - INFO - volta.train_utils -   [XVNLI]: iter 165760 Ep: 4.90 loss 0.005 score 0.101 lr 2.09708e-06 
12/05/2021 09:11:09 - INFO - volta.train_utils -   [XVNLI]: iter 165920 Ep: 4.91 loss 0.005 score 0.099 lr 2.09642e-06 
12/05/2021 09:11:40 - INFO - volta.train_utils -   [XVNLI]: iter 166080 Ep: 4.91 loss 0.006 score 0.097 lr 2.09577e-06 
12/05/2021 09:12:11 - INFO - volta.train_utils -   [XVNLI]: iter 166240 Ep: 4.92 loss 0.004 score 0.101 lr 2.09511e-06 
12/05/2021 09:12:43 - INFO - volta.train_utils -   [XVNLI]: iter 166400 Ep: 4.92 loss 0.005 score 0.101 lr 2.09445e-06 
12/05/2021 09:13:15 - INFO - volta.train_utils -   [XVNLI]: iter 166560 Ep: 4.93 loss 0.005 score 0.100 lr 2.09379e-06 
12/05/2021 09:13:46 - INFO - volta.train_utils -   [XVNLI]: iter 166720 Ep: 4.93 loss 0.004 score 0.101 lr 2.09314e-06 
12/05/2021 09:14:18 - INFO - volta.train_utils -   [XVNLI]: iter 166880 Ep: 4.94 loss 0.004 score 0.100 lr 2.09248e-06 
12/05/2021 09:14:49 - INFO - volta.train_utils -   [XVNLI]: iter 167040 Ep: 4.94 loss 0.005 score 0.099 lr 2.09182e-06 
12/05/2021 09:15:21 - INFO - volta.train_utils -   [XVNLI]: iter 167200 Ep: 4.95 loss 0.004 score 0.099 lr 2.09116e-06 
12/05/2021 09:15:52 - INFO - volta.train_utils -   [XVNLI]: iter 167360 Ep: 4.95 loss 0.004 score 0.099 lr 2.09051e-06 
12/05/2021 09:16:23 - INFO - volta.train_utils -   [XVNLI]: iter 167520 Ep: 4.96 loss 0.005 score 0.099 lr 2.08985e-06 
12/05/2021 09:16:54 - INFO - volta.train_utils -   [XVNLI]: iter 167680 Ep: 4.96 loss 0.005 score 0.099 lr 2.08919e-06 
12/05/2021 09:17:25 - INFO - volta.train_utils -   [XVNLI]: iter 167840 Ep: 4.96 loss 0.005 score 0.098 lr 2.08853e-06 
12/05/2021 09:17:57 - INFO - volta.train_utils -   [XVNLI]: iter 168000 Ep: 4.97 loss 0.005 score 0.099 lr 2.08788e-06 
12/05/2021 09:18:29 - INFO - volta.train_utils -   [XVNLI]: iter 168160 Ep: 4.97 loss 0.005 score 0.098 lr 2.08722e-06 
12/05/2021 09:19:00 - INFO - volta.train_utils -   [XVNLI]: iter 168320 Ep: 4.98 loss 0.004 score 0.098 lr 2.08656e-06 
12/05/2021 09:19:31 - INFO - volta.train_utils -   [XVNLI]: iter 168480 Ep: 4.98 loss 0.005 score 0.099 lr 2.08591e-06 
12/05/2021 09:20:02 - INFO - volta.train_utils -   [XVNLI]: iter 168640 Ep: 4.99 loss 0.005 score 0.099 lr 2.08525e-06 
12/05/2021 09:20:36 - INFO - volta.train_utils -   [XVNLI]: iter 168800 Ep: 4.99 loss 0.005 score 0.098 lr 2.08459e-06 
12/05/2021 09:21:09 - INFO - volta.train_utils -   [XVNLI]: iter 168960 Ep: 5.00 loss 0.005 score 0.099 lr 2.08393e-06 
12/05/2021 09:24:57 - INFO - volta.train_utils -   Eval task TASK19 on iteration 169000 
12/05/2021 09:24:57 - INFO - volta.train_utils -   Validation [XVNLI]: loss 0.385 score 75.334 
Epoch:  50%|█████     | 5/10 [9:46:23<9:47:53, 7054.78s/it] 12/05/2021 09:25:33 - INFO - volta.train_utils -   [XVNLI]: iter 169160 Ep: 5.00 loss 0.005 score 0.104 lr 2.08319e-06 
12/05/2021 09:26:04 - INFO - volta.train_utils -   [XVNLI]: iter 169320 Ep: 5.01 loss 0.005 score 0.102 lr 2.08245e-06 
12/05/2021 09:26:35 - INFO - volta.train_utils -   [XVNLI]: iter 169480 Ep: 5.01 loss 0.005 score 0.103 lr 2.0818e-06 
12/05/2021 09:27:06 - INFO - volta.train_utils -   [XVNLI]: iter 169640 Ep: 5.02 loss 0.004 score 0.101 lr 2.08114e-06 
12/05/2021 09:27:37 - INFO - volta.train_utils -   [XVNLI]: iter 169800 Ep: 5.02 loss 0.004 score 0.103 lr 2.08048e-06 
12/05/2021 09:28:08 - INFO - volta.train_utils -   [XVNLI]: iter 169960 Ep: 5.03 loss 0.004 score 0.101 lr 2.07982e-06 
12/05/2021 09:28:42 - INFO - volta.train_utils -   [XVNLI]: iter 170120 Ep: 5.03 loss 0.005 score 0.103 lr 2.07917e-06 
12/05/2021 09:29:13 - INFO - volta.train_utils -   [XVNLI]: iter 170280 Ep: 5.04 loss 0.005 score 0.102 lr 2.07851e-06 
12/05/2021 09:29:44 - INFO - volta.train_utils -   [XVNLI]: iter 170440 Ep: 5.04 loss 0.004 score 0.104 lr 2.07785e-06 
12/05/2021 09:30:16 - INFO - volta.train_utils -   [XVNLI]: iter 170600 Ep: 5.05 loss 0.005 score 0.103 lr 2.0772e-06 
12/05/2021 09:30:47 - INFO - volta.train_utils -   [XVNLI]: iter 170760 Ep: 5.05 loss 0.005 score 0.102 lr 2.07654e-06 
12/05/2021 09:31:18 - INFO - volta.train_utils -   [XVNLI]: iter 170920 Ep: 5.06 loss 0.004 score 0.103 lr 2.07588e-06 
12/05/2021 09:31:49 - INFO - volta.train_utils -   [XVNLI]: iter 171080 Ep: 5.06 loss 0.004 score 0.101 lr 2.07522e-06 
12/05/2021 09:32:20 - INFO - volta.train_utils -   [XVNLI]: iter 171240 Ep: 5.07 loss 0.004 score 0.103 lr 2.07457e-06 
12/05/2021 09:32:51 - INFO - volta.train_utils -   [XVNLI]: iter 171400 Ep: 5.07 loss 0.004 score 0.102 lr 2.07391e-06 
12/05/2021 09:33:22 - INFO - volta.train_utils -   [XVNLI]: iter 171560 Ep: 5.07 loss 0.004 score 0.101 lr 2.07325e-06 
12/05/2021 09:33:53 - INFO - volta.train_utils -   [XVNLI]: iter 171720 Ep: 5.08 loss 0.005 score 0.101 lr 2.07259e-06 
12/05/2021 09:34:25 - INFO - volta.train_utils -   [XVNLI]: iter 171880 Ep: 5.08 loss 0.005 score 0.102 lr 2.07194e-06 
12/05/2021 09:34:56 - INFO - volta.train_utils -   [XVNLI]: iter 172040 Ep: 5.09 loss 0.005 score 0.102 lr 2.07128e-06 
12/05/2021 09:35:27 - INFO - volta.train_utils -   [XVNLI]: iter 172200 Ep: 5.09 loss 0.005 score 0.102 lr 2.07062e-06 
12/05/2021 09:35:58 - INFO - volta.train_utils -   [XVNLI]: iter 172360 Ep: 5.10 loss 0.004 score 0.101 lr 2.06996e-06 
12/05/2021 09:36:29 - INFO - volta.train_utils -   [XVNLI]: iter 172520 Ep: 5.10 loss 0.005 score 0.101 lr 2.06931e-06 
12/05/2021 09:37:00 - INFO - volta.train_utils -   [XVNLI]: iter 172680 Ep: 5.11 loss 0.005 score 0.101 lr 2.06865e-06 
12/05/2021 09:37:31 - INFO - volta.train_utils -   [XVNLI]: iter 172840 Ep: 5.11 loss 0.004 score 0.102 lr 2.06799e-06 
12/05/2021 09:38:02 - INFO - volta.train_utils -   [XVNLI]: iter 173000 Ep: 5.12 loss 0.004 score 0.101 lr 2.06734e-06 
12/05/2021 09:38:33 - INFO - volta.train_utils -   [XVNLI]: iter 173160 Ep: 5.12 loss 0.005 score 0.102 lr 2.06668e-06 
12/05/2021 09:39:05 - INFO - volta.train_utils -   [XVNLI]: iter 173320 Ep: 5.13 loss 0.005 score 0.101 lr 2.06602e-06 
12/05/2021 09:39:36 - INFO - volta.train_utils -   [XVNLI]: iter 173480 Ep: 5.13 loss 0.005 score 0.103 lr 2.06536e-06 
12/05/2021 09:40:07 - INFO - volta.train_utils -   [XVNLI]: iter 173640 Ep: 5.14 loss 0.005 score 0.103 lr 2.06471e-06 
12/05/2021 09:40:38 - INFO - volta.train_utils -   [XVNLI]: iter 173800 Ep: 5.14 loss 0.004 score 0.103 lr 2.06405e-06 
12/05/2021 09:41:09 - INFO - volta.train_utils -   [XVNLI]: iter 173960 Ep: 5.15 loss 0.004 score 0.102 lr 2.06339e-06 
12/05/2021 09:41:40 - INFO - volta.train_utils -   [XVNLI]: iter 174120 Ep: 5.15 loss 0.004 score 0.102 lr 2.06273e-06 
12/05/2021 09:42:11 - INFO - volta.train_utils -   [XVNLI]: iter 174280 Ep: 5.16 loss 0.004 score 0.102 lr 2.06208e-06 
12/05/2021 09:42:42 - INFO - volta.train_utils -   [XVNLI]: iter 174440 Ep: 5.16 loss 0.005 score 0.100 lr 2.06142e-06 
12/05/2021 09:43:13 - INFO - volta.train_utils -   [XVNLI]: iter 174600 Ep: 5.16 loss 0.005 score 0.101 lr 2.06076e-06 
12/05/2021 09:43:44 - INFO - volta.train_utils -   [XVNLI]: iter 174760 Ep: 5.17 loss 0.004 score 0.101 lr 2.0601e-06 
12/05/2021 09:44:15 - INFO - volta.train_utils -   [XVNLI]: iter 174920 Ep: 5.17 loss 0.005 score 0.101 lr 2.05945e-06 
12/05/2021 09:44:46 - INFO - volta.train_utils -   [XVNLI]: iter 175080 Ep: 5.18 loss 0.004 score 0.100 lr 2.05879e-06 
12/05/2021 09:45:18 - INFO - volta.train_utils -   [XVNLI]: iter 175240 Ep: 5.18 loss 0.004 score 0.102 lr 2.05813e-06 
12/05/2021 09:45:49 - INFO - volta.train_utils -   [XVNLI]: iter 175400 Ep: 5.19 loss 0.004 score 0.102 lr 2.05748e-06 
12/05/2021 09:46:20 - INFO - volta.train_utils -   [XVNLI]: iter 175560 Ep: 5.19 loss 0.004 score 0.102 lr 2.05682e-06 
12/05/2021 09:46:51 - INFO - volta.train_utils -   [XVNLI]: iter 175720 Ep: 5.20 loss 0.005 score 0.102 lr 2.05616e-06 
12/05/2021 09:47:22 - INFO - volta.train_utils -   [XVNLI]: iter 175880 Ep: 5.20 loss 0.005 score 0.103 lr 2.0555e-06 
12/05/2021 09:47:53 - INFO - volta.train_utils -   [XVNLI]: iter 176040 Ep: 5.21 loss 0.005 score 0.102 lr 2.05485e-06 
12/05/2021 09:48:24 - INFO - volta.train_utils -   [XVNLI]: iter 176200 Ep: 5.21 loss 0.005 score 0.102 lr 2.05419e-06 
12/05/2021 09:48:55 - INFO - volta.train_utils -   [XVNLI]: iter 176360 Ep: 5.22 loss 0.004 score 0.101 lr 2.05353e-06 
12/05/2021 09:49:27 - INFO - volta.train_utils -   [XVNLI]: iter 176520 Ep: 5.22 loss 0.005 score 0.101 lr 2.05287e-06 
12/05/2021 09:49:58 - INFO - volta.train_utils -   [XVNLI]: iter 176680 Ep: 5.23 loss 0.004 score 0.103 lr 2.05222e-06 
12/05/2021 09:50:29 - INFO - volta.train_utils -   [XVNLI]: iter 176840 Ep: 5.23 loss 0.005 score 0.102 lr 2.05156e-06 
12/05/2021 09:51:00 - INFO - volta.train_utils -   [XVNLI]: iter 177000 Ep: 5.24 loss 0.005 score 0.103 lr 2.0509e-06 
12/05/2021 09:51:32 - INFO - volta.train_utils -   [XVNLI]: iter 177160 Ep: 5.24 loss 0.005 score 0.101 lr 2.05024e-06 
12/05/2021 09:52:03 - INFO - volta.train_utils -   [XVNLI]: iter 177320 Ep: 5.25 loss 0.004 score 0.102 lr 2.04959e-06 
12/05/2021 09:52:34 - INFO - volta.train_utils -   [XVNLI]: iter 177480 Ep: 5.25 loss 0.006 score 0.100 lr 2.04893e-06 
12/05/2021 09:53:05 - INFO - volta.train_utils -   [XVNLI]: iter 177640 Ep: 5.25 loss 0.005 score 0.101 lr 2.04827e-06 
12/05/2021 09:53:36 - INFO - volta.train_utils -   [XVNLI]: iter 177800 Ep: 5.26 loss 0.005 score 0.102 lr 2.04761e-06 
12/05/2021 09:54:07 - INFO - volta.train_utils -   [XVNLI]: iter 177960 Ep: 5.26 loss 0.004 score 0.103 lr 2.04696e-06 
12/05/2021 09:54:38 - INFO - volta.train_utils -   [XVNLI]: iter 178120 Ep: 5.27 loss 0.004 score 0.102 lr 2.0463e-06 
12/05/2021 09:55:09 - INFO - volta.train_utils -   [XVNLI]: iter 178280 Ep: 5.27 loss 0.005 score 0.100 lr 2.04564e-06 
12/05/2021 09:55:40 - INFO - volta.train_utils -   [XVNLI]: iter 178440 Ep: 5.28 loss 0.005 score 0.102 lr 2.04499e-06 
12/05/2021 09:56:11 - INFO - volta.train_utils -   [XVNLI]: iter 178600 Ep: 5.28 loss 0.004 score 0.104 lr 2.04433e-06 
12/05/2021 09:56:42 - INFO - volta.train_utils -   [XVNLI]: iter 178760 Ep: 5.29 loss 0.005 score 0.103 lr 2.04367e-06 
12/05/2021 09:57:13 - INFO - volta.train_utils -   [XVNLI]: iter 178920 Ep: 5.29 loss 0.005 score 0.101 lr 2.04301e-06 
12/05/2021 09:57:44 - INFO - volta.train_utils -   [XVNLI]: iter 179080 Ep: 5.30 loss 0.004 score 0.102 lr 2.04236e-06 
12/05/2021 09:58:16 - INFO - volta.train_utils -   [XVNLI]: iter 179240 Ep: 5.30 loss 0.004 score 0.102 lr 2.0417e-06 
12/05/2021 09:58:47 - INFO - volta.train_utils -   [XVNLI]: iter 179400 Ep: 5.31 loss 0.005 score 0.103 lr 2.04104e-06 
12/05/2021 09:59:18 - INFO - volta.train_utils -   [XVNLI]: iter 179560 Ep: 5.31 loss 0.004 score 0.104 lr 2.04038e-06 
12/05/2021 09:59:49 - INFO - volta.train_utils -   [XVNLI]: iter 179720 Ep: 5.32 loss 0.004 score 0.102 lr 2.03973e-06 
12/05/2021 10:00:20 - INFO - volta.train_utils -   [XVNLI]: iter 179880 Ep: 5.32 loss 0.004 score 0.101 lr 2.03907e-06 
12/05/2021 10:00:51 - INFO - volta.train_utils -   [XVNLI]: iter 180040 Ep: 5.33 loss 0.005 score 0.101 lr 2.03841e-06 
12/05/2021 10:01:22 - INFO - volta.train_utils -   [XVNLI]: iter 180200 Ep: 5.33 loss 0.004 score 0.102 lr 2.03775e-06 
12/05/2021 10:01:54 - INFO - volta.train_utils -   [XVNLI]: iter 180360 Ep: 5.34 loss 0.005 score 0.101 lr 2.0371e-06 
12/05/2021 10:02:25 - INFO - volta.train_utils -   [XVNLI]: iter 180520 Ep: 5.34 loss 0.005 score 0.102 lr 2.03644e-06 
12/05/2021 10:02:56 - INFO - volta.train_utils -   [XVNLI]: iter 180680 Ep: 5.34 loss 0.005 score 0.101 lr 2.03578e-06 
12/05/2021 10:03:27 - INFO - volta.train_utils -   [XVNLI]: iter 180840 Ep: 5.35 loss 0.004 score 0.102 lr 2.03513e-06 
12/05/2021 10:03:58 - INFO - volta.train_utils -   [XVNLI]: iter 181000 Ep: 5.35 loss 0.004 score 0.101 lr 2.03447e-06 
12/05/2021 10:04:29 - INFO - volta.train_utils -   [XVNLI]: iter 181160 Ep: 5.36 loss 0.004 score 0.103 lr 2.03381e-06 
12/05/2021 10:05:00 - INFO - volta.train_utils -   [XVNLI]: iter 181320 Ep: 5.36 loss 0.004 score 0.102 lr 2.03315e-06 
12/05/2021 10:05:31 - INFO - volta.train_utils -   [XVNLI]: iter 181480 Ep: 5.37 loss 0.005 score 0.103 lr 2.0325e-06 
12/05/2021 10:06:02 - INFO - volta.train_utils -   [XVNLI]: iter 181640 Ep: 5.37 loss 0.004 score 0.102 lr 2.03184e-06 
12/05/2021 10:06:34 - INFO - volta.train_utils -   [XVNLI]: iter 181800 Ep: 5.38 loss 0.004 score 0.101 lr 2.03118e-06 
12/05/2021 10:07:05 - INFO - volta.train_utils -   [XVNLI]: iter 181960 Ep: 5.38 loss 0.004 score 0.102 lr 2.03052e-06 
12/05/2021 10:07:36 - INFO - volta.train_utils -   [XVNLI]: iter 182120 Ep: 5.39 loss 0.004 score 0.101 lr 2.02987e-06 
12/05/2021 10:08:07 - INFO - volta.train_utils -   [XVNLI]: iter 182280 Ep: 5.39 loss 0.005 score 0.100 lr 2.02921e-06 
12/05/2021 10:08:38 - INFO - volta.train_utils -   [XVNLI]: iter 182440 Ep: 5.40 loss 0.005 score 0.101 lr 2.02855e-06 
12/05/2021 10:09:09 - INFO - volta.train_utils -   [XVNLI]: iter 182600 Ep: 5.40 loss 0.004 score 0.103 lr 2.02789e-06 
12/05/2021 10:09:40 - INFO - volta.train_utils -   [XVNLI]: iter 182760 Ep: 5.41 loss 0.005 score 0.104 lr 2.02724e-06 
12/05/2021 10:10:11 - INFO - volta.train_utils -   [XVNLI]: iter 182920 Ep: 5.41 loss 0.004 score 0.101 lr 2.02658e-06 
12/05/2021 10:10:43 - INFO - volta.train_utils -   [XVNLI]: iter 183080 Ep: 5.42 loss 0.005 score 0.103 lr 2.02592e-06 
12/05/2021 10:11:14 - INFO - volta.train_utils -   [XVNLI]: iter 183240 Ep: 5.42 loss 0.005 score 0.100 lr 2.02527e-06 
12/05/2021 10:11:45 - INFO - volta.train_utils -   [XVNLI]: iter 183400 Ep: 5.43 loss 0.004 score 0.101 lr 2.02461e-06 
12/05/2021 10:12:16 - INFO - volta.train_utils -   [XVNLI]: iter 183560 Ep: 5.43 loss 0.004 score 0.101 lr 2.02395e-06 
12/05/2021 10:12:47 - INFO - volta.train_utils -   [XVNLI]: iter 183720 Ep: 5.43 loss 0.005 score 0.103 lr 2.02329e-06 
12/05/2021 10:13:18 - INFO - volta.train_utils -   [XVNLI]: iter 183880 Ep: 5.44 loss 0.005 score 0.101 lr 2.02264e-06 
12/05/2021 10:13:49 - INFO - volta.train_utils -   [XVNLI]: iter 184040 Ep: 5.44 loss 0.005 score 0.101 lr 2.02198e-06 
12/05/2021 10:14:20 - INFO - volta.train_utils -   [XVNLI]: iter 184200 Ep: 5.45 loss 0.004 score 0.101 lr 2.02132e-06 
12/05/2021 10:14:51 - INFO - volta.train_utils -   [XVNLI]: iter 184360 Ep: 5.45 loss 0.005 score 0.101 lr 2.02066e-06 
12/05/2021 10:15:22 - INFO - volta.train_utils -   [XVNLI]: iter 184520 Ep: 5.46 loss 0.005 score 0.102 lr 2.02001e-06 
12/05/2021 10:15:53 - INFO - volta.train_utils -   [XVNLI]: iter 184680 Ep: 5.46 loss 0.005 score 0.102 lr 2.01935e-06 
12/05/2021 10:16:25 - INFO - volta.train_utils -   [XVNLI]: iter 184840 Ep: 5.47 loss 0.005 score 0.101 lr 2.01869e-06 
12/05/2021 10:16:56 - INFO - volta.train_utils -   [XVNLI]: iter 185000 Ep: 5.47 loss 0.005 score 0.102 lr 2.01803e-06 
12/05/2021 10:17:27 - INFO - volta.train_utils -   [XVNLI]: iter 185160 Ep: 5.48 loss 0.005 score 0.102 lr 2.01738e-06 
12/05/2021 10:17:59 - INFO - volta.train_utils -   [XVNLI]: iter 185320 Ep: 5.48 loss 0.005 score 0.102 lr 2.01672e-06 
12/05/2021 10:18:31 - INFO - volta.train_utils -   [XVNLI]: iter 185480 Ep: 5.49 loss 0.004 score 0.102 lr 2.01606e-06 
12/05/2021 10:19:02 - INFO - volta.train_utils -   [XVNLI]: iter 185640 Ep: 5.49 loss 0.005 score 0.101 lr 2.0154e-06 
12/05/2021 10:19:33 - INFO - volta.train_utils -   [XVNLI]: iter 185800 Ep: 5.50 loss 0.005 score 0.103 lr 2.01475e-06 
12/05/2021 10:20:04 - INFO - volta.train_utils -   [XVNLI]: iter 185960 Ep: 5.50 loss 0.004 score 0.102 lr 2.01409e-06 
12/05/2021 10:20:36 - INFO - volta.train_utils -   [XVNLI]: iter 186120 Ep: 5.51 loss 0.005 score 0.101 lr 2.01343e-06 
12/05/2021 10:21:07 - INFO - volta.train_utils -   [XVNLI]: iter 186280 Ep: 5.51 loss 0.004 score 0.101 lr 2.01278e-06 
12/05/2021 10:21:38 - INFO - volta.train_utils -   [XVNLI]: iter 186440 Ep: 5.51 loss 0.004 score 0.102 lr 2.01212e-06 
12/05/2021 10:22:09 - INFO - volta.train_utils -   [XVNLI]: iter 186600 Ep: 5.52 loss 0.004 score 0.102 lr 2.01146e-06 
12/05/2021 10:22:40 - INFO - volta.train_utils -   [XVNLI]: iter 186760 Ep: 5.52 loss 0.004 score 0.103 lr 2.0108e-06 
12/05/2021 10:23:11 - INFO - volta.train_utils -   [XVNLI]: iter 186920 Ep: 5.53 loss 0.004 score 0.101 lr 2.01015e-06 
12/05/2021 10:23:42 - INFO - volta.train_utils -   [XVNLI]: iter 187080 Ep: 5.53 loss 0.004 score 0.103 lr 2.00949e-06 
12/05/2021 10:24:13 - INFO - volta.train_utils -   [XVNLI]: iter 187240 Ep: 5.54 loss 0.005 score 0.101 lr 2.00883e-06 
12/05/2021 10:24:44 - INFO - volta.train_utils -   [XVNLI]: iter 187400 Ep: 5.54 loss 0.005 score 0.101 lr 2.00817e-06 
12/05/2021 10:25:15 - INFO - volta.train_utils -   [XVNLI]: iter 187560 Ep: 5.55 loss 0.004 score 0.101 lr 2.00752e-06 
12/05/2021 10:25:46 - INFO - volta.train_utils -   [XVNLI]: iter 187720 Ep: 5.55 loss 0.005 score 0.101 lr 2.00686e-06 
12/05/2021 10:26:18 - INFO - volta.train_utils -   [XVNLI]: iter 187880 Ep: 5.56 loss 0.005 score 0.102 lr 2.0062e-06 
12/05/2021 10:26:49 - INFO - volta.train_utils -   [XVNLI]: iter 188040 Ep: 5.56 loss 0.004 score 0.102 lr 2.00554e-06 
12/05/2021 10:27:20 - INFO - volta.train_utils -   [XVNLI]: iter 188200 Ep: 5.57 loss 0.005 score 0.104 lr 2.00489e-06 
12/05/2021 10:27:51 - INFO - volta.train_utils -   [XVNLI]: iter 188360 Ep: 5.57 loss 0.004 score 0.102 lr 2.00423e-06 
12/05/2021 10:28:22 - INFO - volta.train_utils -   [XVNLI]: iter 188520 Ep: 5.58 loss 0.005 score 0.104 lr 2.00357e-06 
12/05/2021 10:28:53 - INFO - volta.train_utils -   [XVNLI]: iter 188680 Ep: 5.58 loss 0.005 score 0.100 lr 2.00292e-06 
12/05/2021 10:29:24 - INFO - volta.train_utils -   [XVNLI]: iter 188840 Ep: 5.59 loss 0.004 score 0.101 lr 2.00226e-06 
12/05/2021 10:29:55 - INFO - volta.train_utils -   [XVNLI]: iter 189000 Ep: 5.59 loss 0.005 score 0.101 lr 2.0016e-06 
12/05/2021 10:30:27 - INFO - volta.train_utils -   [XVNLI]: iter 189160 Ep: 5.60 loss 0.005 score 0.102 lr 2.00094e-06 
12/05/2021 10:30:58 - INFO - volta.train_utils -   [XVNLI]: iter 189320 Ep: 5.60 loss 0.005 score 0.100 lr 2.00029e-06 
12/05/2021 10:31:29 - INFO - volta.train_utils -   [XVNLI]: iter 189480 Ep: 5.60 loss 0.005 score 0.103 lr 1.99963e-06 
12/05/2021 10:32:00 - INFO - volta.train_utils -   [XVNLI]: iter 189640 Ep: 5.61 loss 0.004 score 0.101 lr 1.99897e-06 
12/05/2021 10:32:31 - INFO - volta.train_utils -   [XVNLI]: iter 189800 Ep: 5.61 loss 0.005 score 0.100 lr 1.99831e-06 
12/05/2021 10:33:02 - INFO - volta.train_utils -   [XVNLI]: iter 189960 Ep: 5.62 loss 0.005 score 0.101 lr 1.99766e-06 
12/05/2021 10:33:34 - INFO - volta.train_utils -   [XVNLI]: iter 190120 Ep: 5.62 loss 0.004 score 0.101 lr 1.997e-06 
12/05/2021 10:34:05 - INFO - volta.train_utils -   [XVNLI]: iter 190280 Ep: 5.63 loss 0.004 score 0.100 lr 1.99634e-06 
12/05/2021 10:34:36 - INFO - volta.train_utils -   [XVNLI]: iter 190440 Ep: 5.63 loss 0.004 score 0.101 lr 1.99568e-06 
12/05/2021 10:35:07 - INFO - volta.train_utils -   [XVNLI]: iter 190600 Ep: 5.64 loss 0.004 score 0.101 lr 1.99503e-06 
12/05/2021 10:35:38 - INFO - volta.train_utils -   [XVNLI]: iter 190760 Ep: 5.64 loss 0.004 score 0.103 lr 1.99437e-06 
12/05/2021 10:36:10 - INFO - volta.train_utils -   [XVNLI]: iter 190920 Ep: 5.65 loss 0.005 score 0.102 lr 1.99371e-06 
12/05/2021 10:36:41 - INFO - volta.train_utils -   [XVNLI]: iter 191080 Ep: 5.65 loss 0.004 score 0.102 lr 1.99306e-06 
12/05/2021 10:37:12 - INFO - volta.train_utils -   [XVNLI]: iter 191240 Ep: 5.66 loss 0.005 score 0.100 lr 1.9924e-06 
12/05/2021 10:37:43 - INFO - volta.train_utils -   [XVNLI]: iter 191400 Ep: 5.66 loss 0.004 score 0.100 lr 1.99174e-06 
12/05/2021 10:38:14 - INFO - volta.train_utils -   [XVNLI]: iter 191560 Ep: 5.67 loss 0.004 score 0.101 lr 1.99108e-06 
12/05/2021 10:38:45 - INFO - volta.train_utils -   [XVNLI]: iter 191720 Ep: 5.67 loss 0.005 score 0.101 lr 1.99043e-06 
12/05/2021 10:39:16 - INFO - volta.train_utils -   [XVNLI]: iter 191880 Ep: 5.68 loss 0.004 score 0.102 lr 1.98977e-06 
12/05/2021 10:39:47 - INFO - volta.train_utils -   [XVNLI]: iter 192040 Ep: 5.68 loss 0.004 score 0.101 lr 1.98911e-06 
12/05/2021 10:40:18 - INFO - volta.train_utils -   [XVNLI]: iter 192200 Ep: 5.69 loss 0.004 score 0.103 lr 1.98845e-06 
12/05/2021 10:40:49 - INFO - volta.train_utils -   [XVNLI]: iter 192360 Ep: 5.69 loss 0.004 score 0.102 lr 1.9878e-06 
12/05/2021 10:41:20 - INFO - volta.train_utils -   [XVNLI]: iter 192520 Ep: 5.69 loss 0.004 score 0.102 lr 1.98714e-06 
12/05/2021 10:41:52 - INFO - volta.train_utils -   [XVNLI]: iter 192680 Ep: 5.70 loss 0.004 score 0.103 lr 1.98648e-06 
12/05/2021 10:42:23 - INFO - volta.train_utils -   [XVNLI]: iter 192840 Ep: 5.70 loss 0.004 score 0.101 lr 1.98582e-06 
12/05/2021 10:42:54 - INFO - volta.train_utils -   [XVNLI]: iter 193000 Ep: 5.71 loss 0.005 score 0.100 lr 1.98517e-06 
12/05/2021 10:43:25 - INFO - volta.train_utils -   [XVNLI]: iter 193160 Ep: 5.71 loss 0.004 score 0.103 lr 1.98451e-06 
12/05/2021 10:43:56 - INFO - volta.train_utils -   [XVNLI]: iter 193320 Ep: 5.72 loss 0.004 score 0.102 lr 1.98385e-06 
12/05/2021 10:44:27 - INFO - volta.train_utils -   [XVNLI]: iter 193480 Ep: 5.72 loss 0.005 score 0.101 lr 1.98319e-06 
12/05/2021 10:44:58 - INFO - volta.train_utils -   [XVNLI]: iter 193640 Ep: 5.73 loss 0.004 score 0.102 lr 1.98254e-06 
12/05/2021 10:45:29 - INFO - volta.train_utils -   [XVNLI]: iter 193800 Ep: 5.73 loss 0.004 score 0.101 lr 1.98188e-06 
12/05/2021 10:46:01 - INFO - volta.train_utils -   [XVNLI]: iter 193960 Ep: 5.74 loss 0.006 score 0.103 lr 1.98122e-06 
12/05/2021 10:46:32 - INFO - volta.train_utils -   [XVNLI]: iter 194120 Ep: 5.74 loss 0.005 score 0.101 lr 1.98057e-06 
12/05/2021 10:47:03 - INFO - volta.train_utils -   [XVNLI]: iter 194280 Ep: 5.75 loss 0.004 score 0.103 lr 1.97991e-06 
12/05/2021 10:47:34 - INFO - volta.train_utils -   [XVNLI]: iter 194440 Ep: 5.75 loss 0.004 score 0.102 lr 1.97925e-06 
12/05/2021 10:48:05 - INFO - volta.train_utils -   [XVNLI]: iter 194600 Ep: 5.76 loss 0.005 score 0.102 lr 1.97859e-06 
12/05/2021 10:48:36 - INFO - volta.train_utils -   [XVNLI]: iter 194760 Ep: 5.76 loss 0.004 score 0.102 lr 1.97794e-06 
12/05/2021 10:49:07 - INFO - volta.train_utils -   [XVNLI]: iter 194920 Ep: 5.77 loss 0.005 score 0.101 lr 1.97728e-06 
12/05/2021 10:49:39 - INFO - volta.train_utils -   [XVNLI]: iter 195080 Ep: 5.77 loss 0.005 score 0.102 lr 1.97662e-06 
12/05/2021 10:50:10 - INFO - volta.train_utils -   [XVNLI]: iter 195240 Ep: 5.78 loss 0.005 score 0.101 lr 1.97596e-06 
12/05/2021 10:50:41 - INFO - volta.train_utils -   [XVNLI]: iter 195400 Ep: 5.78 loss 0.005 score 0.101 lr 1.97531e-06 
12/05/2021 10:51:12 - INFO - volta.train_utils -   [XVNLI]: iter 195560 Ep: 5.78 loss 0.005 score 0.103 lr 1.97465e-06 
12/05/2021 10:51:43 - INFO - volta.train_utils -   [XVNLI]: iter 195720 Ep: 5.79 loss 0.005 score 0.102 lr 1.97399e-06 
12/05/2021 10:52:14 - INFO - volta.train_utils -   [XVNLI]: iter 195880 Ep: 5.79 loss 0.005 score 0.101 lr 1.97333e-06 
12/05/2021 10:52:45 - INFO - volta.train_utils -   [XVNLI]: iter 196040 Ep: 5.80 loss 0.005 score 0.101 lr 1.97268e-06 
12/05/2021 10:53:16 - INFO - volta.train_utils -   [XVNLI]: iter 196200 Ep: 5.80 loss 0.004 score 0.103 lr 1.97202e-06 
12/05/2021 10:53:47 - INFO - volta.train_utils -   [XVNLI]: iter 196360 Ep: 5.81 loss 0.004 score 0.102 lr 1.97136e-06 
12/05/2021 10:54:19 - INFO - volta.train_utils -   [XVNLI]: iter 196520 Ep: 5.81 loss 0.005 score 0.100 lr 1.97071e-06 
12/05/2021 10:54:51 - INFO - volta.train_utils -   [XVNLI]: iter 196680 Ep: 5.82 loss 0.004 score 0.100 lr 1.97005e-06 
12/05/2021 10:55:23 - INFO - volta.train_utils -   [XVNLI]: iter 196840 Ep: 5.82 loss 0.004 score 0.101 lr 1.96939e-06 
12/05/2021 10:55:54 - INFO - volta.train_utils -   [XVNLI]: iter 197000 Ep: 5.83 loss 0.005 score 0.101 lr 1.96873e-06 
12/05/2021 10:56:25 - INFO - volta.train_utils -   [XVNLI]: iter 197160 Ep: 5.83 loss 0.004 score 0.100 lr 1.96808e-06 
12/05/2021 10:56:56 - INFO - volta.train_utils -   [XVNLI]: iter 197320 Ep: 5.84 loss 0.004 score 0.102 lr 1.96742e-06 
12/05/2021 10:57:27 - INFO - volta.train_utils -   [XVNLI]: iter 197480 Ep: 5.84 loss 0.004 score 0.103 lr 1.96676e-06 
12/05/2021 10:57:59 - INFO - volta.train_utils -   [XVNLI]: iter 197640 Ep: 5.85 loss 0.005 score 0.102 lr 1.9661e-06 
12/05/2021 10:58:30 - INFO - volta.train_utils -   [XVNLI]: iter 197800 Ep: 5.85 loss 0.004 score 0.102 lr 1.96545e-06 
12/05/2021 10:59:01 - INFO - volta.train_utils -   [XVNLI]: iter 197960 Ep: 5.86 loss 0.005 score 0.102 lr 1.96479e-06 
12/05/2021 10:59:33 - INFO - volta.train_utils -   [XVNLI]: iter 198120 Ep: 5.86 loss 0.005 score 0.102 lr 1.96413e-06 
12/05/2021 11:00:04 - INFO - volta.train_utils -   [XVNLI]: iter 198280 Ep: 5.87 loss 0.005 score 0.100 lr 1.96347e-06 
12/05/2021 11:00:36 - INFO - volta.train_utils -   [XVNLI]: iter 198440 Ep: 5.87 loss 0.006 score 0.102 lr 1.96282e-06 
12/05/2021 11:01:07 - INFO - volta.train_utils -   [XVNLI]: iter 198600 Ep: 5.87 loss 0.005 score 0.100 lr 1.96216e-06 
12/05/2021 11:01:38 - INFO - volta.train_utils -   [XVNLI]: iter 198760 Ep: 5.88 loss 0.004 score 0.102 lr 1.9615e-06 
12/05/2021 11:02:09 - INFO - volta.train_utils -   [XVNLI]: iter 198920 Ep: 5.88 loss 0.005 score 0.101 lr 1.96085e-06 
12/05/2021 11:02:41 - INFO - volta.train_utils -   [XVNLI]: iter 199080 Ep: 5.89 loss 0.004 score 0.101 lr 1.96019e-06 
12/05/2021 11:03:12 - INFO - volta.train_utils -   [XVNLI]: iter 199240 Ep: 5.89 loss 0.004 score 0.102 lr 1.95953e-06 
12/05/2021 11:03:43 - INFO - volta.train_utils -   [XVNLI]: iter 199400 Ep: 5.90 loss 0.004 score 0.101 lr 1.95887e-06 
12/05/2021 11:04:14 - INFO - volta.train_utils -   [XVNLI]: iter 199560 Ep: 5.90 loss 0.004 score 0.101 lr 1.95822e-06 
12/05/2021 11:04:46 - INFO - volta.train_utils -   [XVNLI]: iter 199720 Ep: 5.91 loss 0.004 score 0.100 lr 1.95756e-06 
12/05/2021 11:05:17 - INFO - volta.train_utils -   [XVNLI]: iter 199880 Ep: 5.91 loss 0.005 score 0.101 lr 1.9569e-06 
12/05/2021 11:05:48 - INFO - volta.train_utils -   [XVNLI]: iter 200040 Ep: 5.92 loss 0.004 score 0.102 lr 1.95624e-06 
12/05/2021 11:06:20 - INFO - volta.train_utils -   [XVNLI]: iter 200200 Ep: 5.92 loss 0.005 score 0.103 lr 1.95559e-06 
12/05/2021 11:06:51 - INFO - volta.train_utils -   [XVNLI]: iter 200360 Ep: 5.93 loss 0.005 score 0.102 lr 1.95493e-06 
12/05/2021 11:07:22 - INFO - volta.train_utils -   [XVNLI]: iter 200520 Ep: 5.93 loss 0.005 score 0.100 lr 1.95427e-06 
12/05/2021 11:07:53 - INFO - volta.train_utils -   [XVNLI]: iter 200680 Ep: 5.94 loss 0.005 score 0.101 lr 1.95361e-06 
12/05/2021 11:08:24 - INFO - volta.train_utils -   [XVNLI]: iter 200840 Ep: 5.94 loss 0.004 score 0.101 lr 1.95296e-06 
12/05/2021 11:08:55 - INFO - volta.train_utils -   [XVNLI]: iter 201000 Ep: 5.95 loss 0.005 score 0.101 lr 1.9523e-06 
12/05/2021 11:09:26 - INFO - volta.train_utils -   [XVNLI]: iter 201160 Ep: 5.95 loss 0.005 score 0.102 lr 1.95164e-06 
12/05/2021 11:09:57 - INFO - volta.train_utils -   [XVNLI]: iter 201320 Ep: 5.96 loss 0.004 score 0.102 lr 1.95099e-06 
12/05/2021 11:10:29 - INFO - volta.train_utils -   [XVNLI]: iter 201480 Ep: 5.96 loss 0.004 score 0.103 lr 1.95033e-06 
12/05/2021 11:11:00 - INFO - volta.train_utils -   [XVNLI]: iter 201640 Ep: 5.96 loss 0.005 score 0.101 lr 1.94967e-06 
12/05/2021 11:11:31 - INFO - volta.train_utils -   [XVNLI]: iter 201800 Ep: 5.97 loss 0.004 score 0.103 lr 1.94901e-06 
12/05/2021 11:12:02 - INFO - volta.train_utils -   [XVNLI]: iter 201960 Ep: 5.97 loss 0.004 score 0.102 lr 1.94836e-06 
12/05/2021 11:12:34 - INFO - volta.train_utils -   [XVNLI]: iter 202120 Ep: 5.98 loss 0.005 score 0.101 lr 1.9477e-06 
12/05/2021 11:13:05 - INFO - volta.train_utils -   [XVNLI]: iter 202280 Ep: 5.98 loss 0.005 score 0.102 lr 1.94704e-06 
12/05/2021 11:13:36 - INFO - volta.train_utils -   [XVNLI]: iter 202440 Ep: 5.99 loss 0.005 score 0.101 lr 1.94638e-06 
12/05/2021 11:14:07 - INFO - volta.train_utils -   [XVNLI]: iter 202600 Ep: 5.99 loss 0.005 score 0.102 lr 1.94573e-06 
12/05/2021 11:14:38 - INFO - volta.train_utils -   [XVNLI]: iter 202760 Ep: 6.00 loss 0.005 score 0.101 lr 1.94507e-06 
12/05/2021 11:18:27 - INFO - volta.train_utils -   Eval task TASK19 on iteration 202800 
12/05/2021 11:18:27 - INFO - volta.train_utils -   Validation [XVNLI]: loss 0.389 score 75.567 
12/05/2021 11:18:27 - INFO - __main__ -   ** ** * Saving model * ** ** 
Epoch:  60%|██████    | 6/10 [11:40:26<7:46:04, 6991.18s/it]12/05/2021 11:19:36 - INFO - volta.train_utils -   [XVNLI]: iter 202960 Ep: 6.00 loss 0.004 score 0.107 lr 1.94433e-06 
12/05/2021 11:20:07 - INFO - volta.train_utils -   [XVNLI]: iter 203120 Ep: 6.01 loss 0.004 score 0.104 lr 1.94359e-06 
12/05/2021 11:20:38 - INFO - volta.train_utils -   [XVNLI]: iter 203280 Ep: 6.01 loss 0.003 score 0.105 lr 1.94293e-06 
12/05/2021 11:21:09 - INFO - volta.train_utils -   [XVNLI]: iter 203440 Ep: 6.02 loss 0.004 score 0.106 lr 1.94228e-06 
12/05/2021 11:21:40 - INFO - volta.train_utils -   [XVNLI]: iter 203600 Ep: 6.02 loss 0.005 score 0.103 lr 1.94162e-06 
12/05/2021 11:22:11 - INFO - volta.train_utils -   [XVNLI]: iter 203760 Ep: 6.03 loss 0.005 score 0.105 lr 1.94096e-06 
12/05/2021 11:22:50 - INFO - volta.train_utils -   [XVNLI]: iter 203920 Ep: 6.03 loss 0.005 score 0.103 lr 1.9403e-06 
12/05/2021 11:23:21 - INFO - volta.train_utils -   [XVNLI]: iter 204080 Ep: 6.04 loss 0.004 score 0.103 lr 1.93965e-06 
12/05/2021 11:23:52 - INFO - volta.train_utils -   [XVNLI]: iter 204240 Ep: 6.04 loss 0.004 score 0.104 lr 1.93899e-06 
12/05/2021 11:24:23 - INFO - volta.train_utils -   [XVNLI]: iter 204400 Ep: 6.05 loss 0.004 score 0.104 lr 1.93833e-06 
12/05/2021 11:24:54 - INFO - volta.train_utils -   [XVNLI]: iter 204560 Ep: 6.05 loss 0.004 score 0.104 lr 1.93767e-06 
12/05/2021 11:25:26 - INFO - volta.train_utils -   [XVNLI]: iter 204720 Ep: 6.06 loss 0.003 score 0.107 lr 1.93702e-06 
12/05/2021 11:25:57 - INFO - volta.train_utils -   [XVNLI]: iter 204880 Ep: 6.06 loss 0.004 score 0.104 lr 1.93636e-06 
12/05/2021 11:26:28 - INFO - volta.train_utils -   [XVNLI]: iter 205040 Ep: 6.07 loss 0.004 score 0.105 lr 1.9357e-06 
12/05/2021 11:26:59 - INFO - volta.train_utils -   [XVNLI]: iter 205200 Ep: 6.07 loss 0.004 score 0.103 lr 1.93504e-06 
12/05/2021 11:27:30 - INFO - volta.train_utils -   [XVNLI]: iter 205360 Ep: 6.07 loss 0.004 score 0.103 lr 1.93439e-06 
12/05/2021 11:28:01 - INFO - volta.train_utils -   [XVNLI]: iter 205520 Ep: 6.08 loss 0.005 score 0.103 lr 1.93373e-06 
12/05/2021 11:28:32 - INFO - volta.train_utils -   [XVNLI]: iter 205680 Ep: 6.08 loss 0.004 score 0.105 lr 1.93307e-06 
12/05/2021 11:29:03 - INFO - volta.train_utils -   [XVNLI]: iter 205840 Ep: 6.09 loss 0.004 score 0.102 lr 1.93242e-06 
12/05/2021 11:29:36 - INFO - volta.train_utils -   [XVNLI]: iter 206000 Ep: 6.09 loss 0.004 score 0.105 lr 1.93176e-06 
12/05/2021 11:30:07 - INFO - volta.train_utils -   [XVNLI]: iter 206160 Ep: 6.10 loss 0.004 score 0.105 lr 1.9311e-06 
12/05/2021 11:30:38 - INFO - volta.train_utils -   [XVNLI]: iter 206320 Ep: 6.10 loss 0.005 score 0.105 lr 1.93044e-06 
12/05/2021 11:31:09 - INFO - volta.train_utils -   [XVNLI]: iter 206480 Ep: 6.11 loss 0.004 score 0.104 lr 1.92979e-06 
12/05/2021 11:31:40 - INFO - volta.train_utils -   [XVNLI]: iter 206640 Ep: 6.11 loss 0.004 score 0.104 lr 1.92913e-06 
12/05/2021 11:32:11 - INFO - volta.train_utils -   [XVNLI]: iter 206800 Ep: 6.12 loss 0.004 score 0.103 lr 1.92847e-06 
12/05/2021 11:32:42 - INFO - volta.train_utils -   [XVNLI]: iter 206960 Ep: 6.12 loss 0.004 score 0.102 lr 1.92781e-06 
12/05/2021 11:33:13 - INFO - volta.train_utils -   [XVNLI]: iter 207120 Ep: 6.13 loss 0.004 score 0.104 lr 1.92716e-06 
12/05/2021 11:33:44 - INFO - volta.train_utils -   [XVNLI]: iter 207280 Ep: 6.13 loss 0.004 score 0.105 lr 1.9265e-06 
12/05/2021 11:34:15 - INFO - volta.train_utils -   [XVNLI]: iter 207440 Ep: 6.14 loss 0.005 score 0.104 lr 1.92584e-06 
12/05/2021 11:34:47 - INFO - volta.train_utils -   [XVNLI]: iter 207600 Ep: 6.14 loss 0.004 score 0.106 lr 1.92518e-06 
12/05/2021 11:35:18 - INFO - volta.train_utils -   [XVNLI]: iter 207760 Ep: 6.15 loss 0.004 score 0.104 lr 1.92453e-06 
12/05/2021 11:35:49 - INFO - volta.train_utils -   [XVNLI]: iter 207920 Ep: 6.15 loss 0.004 score 0.103 lr 1.92387e-06 
12/05/2021 11:36:20 - INFO - volta.train_utils -   [XVNLI]: iter 208080 Ep: 6.16 loss 0.004 score 0.105 lr 1.92321e-06 
12/05/2021 11:36:51 - INFO - volta.train_utils -   [XVNLI]: iter 208240 Ep: 6.16 loss 0.004 score 0.104 lr 1.92255e-06 
12/05/2021 11:37:22 - INFO - volta.train_utils -   [XVNLI]: iter 208400 Ep: 6.16 loss 0.004 score 0.103 lr 1.9219e-06 
12/05/2021 11:37:53 - INFO - volta.train_utils -   [XVNLI]: iter 208560 Ep: 6.17 loss 0.004 score 0.104 lr 1.92124e-06 
12/05/2021 11:38:24 - INFO - volta.train_utils -   [XVNLI]: iter 208720 Ep: 6.17 loss 0.004 score 0.105 lr 1.92058e-06 
12/05/2021 11:38:55 - INFO - volta.train_utils -   [XVNLI]: iter 208880 Ep: 6.18 loss 0.004 score 0.104 lr 1.91993e-06 
12/05/2021 11:39:27 - INFO - volta.train_utils -   [XVNLI]: iter 209040 Ep: 6.18 loss 0.004 score 0.104 lr 1.91927e-06 
12/05/2021 11:39:58 - INFO - volta.train_utils -   [XVNLI]: iter 209200 Ep: 6.19 loss 0.004 score 0.104 lr 1.91861e-06 
12/05/2021 11:40:29 - INFO - volta.train_utils -   [XVNLI]: iter 209360 Ep: 6.19 loss 0.004 score 0.104 lr 1.91795e-06 
12/05/2021 11:41:00 - INFO - volta.train_utils -   [XVNLI]: iter 209520 Ep: 6.20 loss 0.004 score 0.103 lr 1.9173e-06 
12/05/2021 11:41:31 - INFO - volta.train_utils -   [XVNLI]: iter 209680 Ep: 6.20 loss 0.005 score 0.101 lr 1.91664e-06 
12/05/2021 11:42:02 - INFO - volta.train_utils -   [XVNLI]: iter 209840 Ep: 6.21 loss 0.005 score 0.104 lr 1.91598e-06 
12/05/2021 11:42:33 - INFO - volta.train_utils -   [XVNLI]: iter 210000 Ep: 6.21 loss 0.004 score 0.104 lr 1.91532e-06 
12/05/2021 11:43:04 - INFO - volta.train_utils -   [XVNLI]: iter 210160 Ep: 6.22 loss 0.004 score 0.105 lr 1.91467e-06 
12/05/2021 11:43:35 - INFO - volta.train_utils -   [XVNLI]: iter 210320 Ep: 6.22 loss 0.004 score 0.105 lr 1.91401e-06 
12/05/2021 11:44:06 - INFO - volta.train_utils -   [XVNLI]: iter 210480 Ep: 6.23 loss 0.004 score 0.104 lr 1.91335e-06 
12/05/2021 11:44:38 - INFO - volta.train_utils -   [XVNLI]: iter 210640 Ep: 6.23 loss 0.004 score 0.103 lr 1.91269e-06 
12/05/2021 11:45:09 - INFO - volta.train_utils -   [XVNLI]: iter 210800 Ep: 6.24 loss 0.004 score 0.104 lr 1.91204e-06 
12/05/2021 11:45:40 - INFO - volta.train_utils -   [XVNLI]: iter 210960 Ep: 6.24 loss 0.004 score 0.104 lr 1.91138e-06 
12/05/2021 11:46:11 - INFO - volta.train_utils -   [XVNLI]: iter 211120 Ep: 6.25 loss 0.004 score 0.104 lr 1.91072e-06 
12/05/2021 11:46:43 - INFO - volta.train_utils -   [XVNLI]: iter 211280 Ep: 6.25 loss 0.004 score 0.106 lr 1.91007e-06 
12/05/2021 11:47:14 - INFO - volta.train_utils -   [XVNLI]: iter 211440 Ep: 6.25 loss 0.004 score 0.103 lr 1.90941e-06 
12/05/2021 11:47:45 - INFO - volta.train_utils -   [XVNLI]: iter 211600 Ep: 6.26 loss 0.004 score 0.105 lr 1.90875e-06 
12/05/2021 11:48:16 - INFO - volta.train_utils -   [XVNLI]: iter 211760 Ep: 6.26 loss 0.004 score 0.102 lr 1.90809e-06 
12/05/2021 11:48:47 - INFO - volta.train_utils -   [XVNLI]: iter 211920 Ep: 6.27 loss 0.004 score 0.104 lr 1.90744e-06 
12/05/2021 11:49:18 - INFO - volta.train_utils -   [XVNLI]: iter 212080 Ep: 6.27 loss 0.004 score 0.104 lr 1.90678e-06 
12/05/2021 11:49:49 - INFO - volta.train_utils -   [XVNLI]: iter 212240 Ep: 6.28 loss 0.004 score 0.105 lr 1.90612e-06 
12/05/2021 11:50:20 - INFO - volta.train_utils -   [XVNLI]: iter 212400 Ep: 6.28 loss 0.003 score 0.105 lr 1.90546e-06 
12/05/2021 11:50:51 - INFO - volta.train_utils -   [XVNLI]: iter 212560 Ep: 6.29 loss 0.004 score 0.104 lr 1.90481e-06 
12/05/2021 11:51:22 - INFO - volta.train_utils -   [XVNLI]: iter 212720 Ep: 6.29 loss 0.004 score 0.103 lr 1.90415e-06 
12/05/2021 11:51:53 - INFO - volta.train_utils -   [XVNLI]: iter 212880 Ep: 6.30 loss 0.005 score 0.103 lr 1.90349e-06 
12/05/2021 11:52:25 - INFO - volta.train_utils -   [XVNLI]: iter 213040 Ep: 6.30 loss 0.004 score 0.103 lr 1.90283e-06 
12/05/2021 11:52:56 - INFO - volta.train_utils -   [XVNLI]: iter 213200 Ep: 6.31 loss 0.004 score 0.104 lr 1.90218e-06 
12/05/2021 11:53:27 - INFO - volta.train_utils -   [XVNLI]: iter 213360 Ep: 6.31 loss 0.004 score 0.103 lr 1.90152e-06 
12/05/2021 11:53:58 - INFO - volta.train_utils -   [XVNLI]: iter 213520 Ep: 6.32 loss 0.005 score 0.104 lr 1.90086e-06 
12/05/2021 11:54:29 - INFO - volta.train_utils -   [XVNLI]: iter 213680 Ep: 6.32 loss 0.004 score 0.105 lr 1.90021e-06 
12/05/2021 11:55:00 - INFO - volta.train_utils -   [XVNLI]: iter 213840 Ep: 6.33 loss 0.004 score 0.105 lr 1.89955e-06 
12/05/2021 11:55:31 - INFO - volta.train_utils -   [XVNLI]: iter 214000 Ep: 6.33 loss 0.004 score 0.104 lr 1.89889e-06 
12/05/2021 11:56:02 - INFO - volta.train_utils -   [XVNLI]: iter 214160 Ep: 6.33 loss 0.005 score 0.104 lr 1.89823e-06 
12/05/2021 11:56:33 - INFO - volta.train_utils -   [XVNLI]: iter 214320 Ep: 6.34 loss 0.004 score 0.103 lr 1.89758e-06 
12/05/2021 11:57:04 - INFO - volta.train_utils -   [XVNLI]: iter 214480 Ep: 6.34 loss 0.004 score 0.105 lr 1.89692e-06 
12/05/2021 11:57:36 - INFO - volta.train_utils -   [XVNLI]: iter 214640 Ep: 6.35 loss 0.005 score 0.104 lr 1.89626e-06 
12/05/2021 11:58:07 - INFO - volta.train_utils -   [XVNLI]: iter 214800 Ep: 6.35 loss 0.004 score 0.104 lr 1.8956e-06 
12/05/2021 11:58:38 - INFO - volta.train_utils -   [XVNLI]: iter 214960 Ep: 6.36 loss 0.004 score 0.103 lr 1.89495e-06 
12/05/2021 11:59:09 - INFO - volta.train_utils -   [XVNLI]: iter 215120 Ep: 6.36 loss 0.005 score 0.103 lr 1.89429e-06 
12/05/2021 11:59:40 - INFO - volta.train_utils -   [XVNLI]: iter 215280 Ep: 6.37 loss 0.004 score 0.104 lr 1.89363e-06 
12/05/2021 12:00:11 - INFO - volta.train_utils -   [XVNLI]: iter 215440 Ep: 6.37 loss 0.004 score 0.103 lr 1.89297e-06 
12/05/2021 12:00:42 - INFO - volta.train_utils -   [XVNLI]: iter 215600 Ep: 6.38 loss 0.005 score 0.104 lr 1.89232e-06 
12/05/2021 12:01:13 - INFO - volta.train_utils -   [XVNLI]: iter 215760 Ep: 6.38 loss 0.005 score 0.102 lr 1.89166e-06 
12/05/2021 12:01:44 - INFO - volta.train_utils -   [XVNLI]: iter 215920 Ep: 6.39 loss 0.004 score 0.103 lr 1.891e-06 
12/05/2021 12:02:16 - INFO - volta.train_utils -   [XVNLI]: iter 216080 Ep: 6.39 loss 0.004 score 0.103 lr 1.89034e-06 
12/05/2021 12:02:47 - INFO - volta.train_utils -   [XVNLI]: iter 216240 Ep: 6.40 loss 0.005 score 0.103 lr 1.88969e-06 
12/05/2021 12:03:18 - INFO - volta.train_utils -   [XVNLI]: iter 216400 Ep: 6.40 loss 0.004 score 0.104 lr 1.88903e-06 
12/05/2021 12:03:50 - INFO - volta.train_utils -   [XVNLI]: iter 216560 Ep: 6.41 loss 0.005 score 0.102 lr 1.88837e-06 
12/05/2021 12:04:21 - INFO - volta.train_utils -   [XVNLI]: iter 216720 Ep: 6.41 loss 0.004 score 0.104 lr 1.88772e-06 
12/05/2021 12:04:53 - INFO - volta.train_utils -   [XVNLI]: iter 216880 Ep: 6.42 loss 0.004 score 0.104 lr 1.88706e-06 
12/05/2021 12:05:24 - INFO - volta.train_utils -   [XVNLI]: iter 217040 Ep: 6.42 loss 0.004 score 0.102 lr 1.8864e-06 
12/05/2021 12:05:55 - INFO - volta.train_utils -   [XVNLI]: iter 217200 Ep: 6.42 loss 0.003 score 0.104 lr 1.88574e-06 
12/05/2021 12:06:26 - INFO - volta.train_utils -   [XVNLI]: iter 217360 Ep: 6.43 loss 0.004 score 0.104 lr 1.88509e-06 
12/05/2021 12:06:57 - INFO - volta.train_utils -   [XVNLI]: iter 217520 Ep: 6.43 loss 0.005 score 0.103 lr 1.88443e-06 
12/05/2021 12:07:28 - INFO - volta.train_utils -   [XVNLI]: iter 217680 Ep: 6.44 loss 0.005 score 0.102 lr 1.88377e-06 
12/05/2021 12:07:59 - INFO - volta.train_utils -   [XVNLI]: iter 217840 Ep: 6.44 loss 0.004 score 0.103 lr 1.88311e-06 
12/05/2021 12:08:30 - INFO - volta.train_utils -   [XVNLI]: iter 218000 Ep: 6.45 loss 0.005 score 0.103 lr 1.88246e-06 
12/05/2021 12:09:01 - INFO - volta.train_utils -   [XVNLI]: iter 218160 Ep: 6.45 loss 0.004 score 0.105 lr 1.8818e-06 
12/05/2021 12:09:33 - INFO - volta.train_utils -   [XVNLI]: iter 218320 Ep: 6.46 loss 0.004 score 0.105 lr 1.88114e-06 
12/05/2021 12:10:04 - INFO - volta.train_utils -   [XVNLI]: iter 218480 Ep: 6.46 loss 0.004 score 0.104 lr 1.88048e-06 
12/05/2021 12:10:35 - INFO - volta.train_utils -   [XVNLI]: iter 218640 Ep: 6.47 loss 0.005 score 0.103 lr 1.87983e-06 
12/05/2021 12:11:07 - INFO - volta.train_utils -   [XVNLI]: iter 218800 Ep: 6.47 loss 0.004 score 0.103 lr 1.87917e-06 
12/05/2021 12:11:38 - INFO - volta.train_utils -   [XVNLI]: iter 218960 Ep: 6.48 loss 0.004 score 0.103 lr 1.87851e-06 
12/05/2021 12:12:09 - INFO - volta.train_utils -   [XVNLI]: iter 219120 Ep: 6.48 loss 0.004 score 0.103 lr 1.87786e-06 
12/05/2021 12:12:40 - INFO - volta.train_utils -   [XVNLI]: iter 219280 Ep: 6.49 loss 0.004 score 0.105 lr 1.8772e-06 
12/05/2021 12:13:12 - INFO - volta.train_utils -   [XVNLI]: iter 219440 Ep: 6.49 loss 0.004 score 0.103 lr 1.87654e-06 
12/05/2021 12:13:43 - INFO - volta.train_utils -   [XVNLI]: iter 219600 Ep: 6.50 loss 0.004 score 0.103 lr 1.87588e-06 
12/05/2021 12:14:14 - INFO - volta.train_utils -   [XVNLI]: iter 219760 Ep: 6.50 loss 0.004 score 0.104 lr 1.87523e-06 
12/05/2021 12:14:46 - INFO - volta.train_utils -   [XVNLI]: iter 219920 Ep: 6.51 loss 0.004 score 0.103 lr 1.87457e-06 
12/05/2021 12:15:16 - INFO - volta.train_utils -   [XVNLI]: iter 220080 Ep: 6.51 loss 0.004 score 0.102 lr 1.87391e-06 
12/05/2021 12:15:48 - INFO - volta.train_utils -   [XVNLI]: iter 220240 Ep: 6.51 loss 0.004 score 0.105 lr 1.87325e-06 
12/05/2021 12:16:19 - INFO - volta.train_utils -   [XVNLI]: iter 220400 Ep: 6.52 loss 0.004 score 0.105 lr 1.8726e-06 
12/05/2021 12:16:50 - INFO - volta.train_utils -   [XVNLI]: iter 220560 Ep: 6.52 loss 0.005 score 0.102 lr 1.87194e-06 
12/05/2021 12:17:21 - INFO - volta.train_utils -   [XVNLI]: iter 220720 Ep: 6.53 loss 0.004 score 0.103 lr 1.87128e-06 
12/05/2021 12:17:52 - INFO - volta.train_utils -   [XVNLI]: iter 220880 Ep: 6.53 loss 0.004 score 0.104 lr 1.87062e-06 
12/05/2021 12:18:23 - INFO - volta.train_utils -   [XVNLI]: iter 221040 Ep: 6.54 loss 0.004 score 0.104 lr 1.86997e-06 
12/05/2021 12:18:54 - INFO - volta.train_utils -   [XVNLI]: iter 221200 Ep: 6.54 loss 0.004 score 0.104 lr 1.86931e-06 
12/05/2021 12:19:25 - INFO - volta.train_utils -   [XVNLI]: iter 221360 Ep: 6.55 loss 0.004 score 0.105 lr 1.86865e-06 
12/05/2021 12:19:57 - INFO - volta.train_utils -   [XVNLI]: iter 221520 Ep: 6.55 loss 0.004 score 0.104 lr 1.868e-06 
12/05/2021 12:20:28 - INFO - volta.train_utils -   [XVNLI]: iter 221680 Ep: 6.56 loss 0.004 score 0.104 lr 1.86734e-06 
12/05/2021 12:21:00 - INFO - volta.train_utils -   [XVNLI]: iter 221840 Ep: 6.56 loss 0.005 score 0.104 lr 1.86668e-06 
12/05/2021 12:21:31 - INFO - volta.train_utils -   [XVNLI]: iter 222000 Ep: 6.57 loss 0.004 score 0.103 lr 1.86602e-06 
12/05/2021 12:22:02 - INFO - volta.train_utils -   [XVNLI]: iter 222160 Ep: 6.57 loss 0.005 score 0.103 lr 1.86537e-06 
12/05/2021 12:22:33 - INFO - volta.train_utils -   [XVNLI]: iter 222320 Ep: 6.58 loss 0.005 score 0.103 lr 1.86471e-06 
12/05/2021 12:23:04 - INFO - volta.train_utils -   [XVNLI]: iter 222480 Ep: 6.58 loss 0.004 score 0.103 lr 1.86405e-06 
12/05/2021 12:23:35 - INFO - volta.train_utils -   [XVNLI]: iter 222640 Ep: 6.59 loss 0.004 score 0.104 lr 1.86339e-06 
12/05/2021 12:24:07 - INFO - volta.train_utils -   [XVNLI]: iter 222800 Ep: 6.59 loss 0.005 score 0.103 lr 1.86274e-06 
12/05/2021 12:24:38 - INFO - volta.train_utils -   [XVNLI]: iter 222960 Ep: 6.60 loss 0.004 score 0.103 lr 1.86208e-06 
12/05/2021 12:25:09 - INFO - volta.train_utils -   [XVNLI]: iter 223120 Ep: 6.60 loss 0.004 score 0.104 lr 1.86142e-06 
12/05/2021 12:25:40 - INFO - volta.train_utils -   [XVNLI]: iter 223280 Ep: 6.60 loss 0.004 score 0.103 lr 1.86076e-06 
12/05/2021 12:26:11 - INFO - volta.train_utils -   [XVNLI]: iter 223440 Ep: 6.61 loss 0.004 score 0.104 lr 1.86011e-06 
12/05/2021 12:26:42 - INFO - volta.train_utils -   [XVNLI]: iter 223600 Ep: 6.61 loss 0.004 score 0.102 lr 1.85945e-06 
12/05/2021 12:27:14 - INFO - volta.train_utils -   [XVNLI]: iter 223760 Ep: 6.62 loss 0.004 score 0.104 lr 1.85879e-06 
12/05/2021 12:27:45 - INFO - volta.train_utils -   [XVNLI]: iter 223920 Ep: 6.62 loss 0.004 score 0.103 lr 1.85813e-06 
12/05/2021 12:28:17 - INFO - volta.train_utils -   [XVNLI]: iter 224080 Ep: 6.63 loss 0.004 score 0.101 lr 1.85748e-06 
12/05/2021 12:28:48 - INFO - volta.train_utils -   [XVNLI]: iter 224240 Ep: 6.63 loss 0.004 score 0.103 lr 1.85682e-06 
12/05/2021 12:29:19 - INFO - volta.train_utils -   [XVNLI]: iter 224400 Ep: 6.64 loss 0.004 score 0.104 lr 1.85616e-06 
12/05/2021 12:29:50 - INFO - volta.train_utils -   [XVNLI]: iter 224560 Ep: 6.64 loss 0.004 score 0.103 lr 1.85551e-06 
12/05/2021 12:30:21 - INFO - volta.train_utils -   [XVNLI]: iter 224720 Ep: 6.65 loss 0.004 score 0.104 lr 1.85485e-06 
12/05/2021 12:30:52 - INFO - volta.train_utils -   [XVNLI]: iter 224880 Ep: 6.65 loss 0.004 score 0.104 lr 1.85419e-06 
12/05/2021 12:31:23 - INFO - volta.train_utils -   [XVNLI]: iter 225040 Ep: 6.66 loss 0.005 score 0.104 lr 1.85353e-06 
12/05/2021 12:31:55 - INFO - volta.train_utils -   [XVNLI]: iter 225200 Ep: 6.66 loss 0.005 score 0.103 lr 1.85288e-06 
12/05/2021 12:32:26 - INFO - volta.train_utils -   [XVNLI]: iter 225360 Ep: 6.67 loss 0.006 score 0.102 lr 1.85222e-06 
12/05/2021 12:32:57 - INFO - volta.train_utils -   [XVNLI]: iter 225520 Ep: 6.67 loss 0.004 score 0.104 lr 1.85156e-06 
12/05/2021 12:33:28 - INFO - volta.train_utils -   [XVNLI]: iter 225680 Ep: 6.68 loss 0.004 score 0.105 lr 1.8509e-06 
12/05/2021 12:33:59 - INFO - volta.train_utils -   [XVNLI]: iter 225840 Ep: 6.68 loss 0.004 score 0.103 lr 1.85025e-06 
12/05/2021 12:34:30 - INFO - volta.train_utils -   [XVNLI]: iter 226000 Ep: 6.69 loss 0.004 score 0.103 lr 1.84959e-06 
12/05/2021 12:35:02 - INFO - volta.train_utils -   [XVNLI]: iter 226160 Ep: 6.69 loss 0.004 score 0.103 lr 1.84893e-06 
12/05/2021 12:35:33 - INFO - volta.train_utils -   [XVNLI]: iter 226320 Ep: 6.69 loss 0.004 score 0.104 lr 1.84827e-06 
12/05/2021 12:36:04 - INFO - volta.train_utils -   [XVNLI]: iter 226480 Ep: 6.70 loss 0.004 score 0.103 lr 1.84762e-06 
12/05/2021 12:36:35 - INFO - volta.train_utils -   [XVNLI]: iter 226640 Ep: 6.70 loss 0.004 score 0.102 lr 1.84696e-06 
12/05/2021 12:37:06 - INFO - volta.train_utils -   [XVNLI]: iter 226800 Ep: 6.71 loss 0.005 score 0.103 lr 1.8463e-06 
12/05/2021 12:37:38 - INFO - volta.train_utils -   [XVNLI]: iter 226960 Ep: 6.71 loss 0.004 score 0.105 lr 1.84565e-06 
12/05/2021 12:38:09 - INFO - volta.train_utils -   [XVNLI]: iter 227120 Ep: 6.72 loss 0.004 score 0.105 lr 1.84499e-06 
12/05/2021 12:38:40 - INFO - volta.train_utils -   [XVNLI]: iter 227280 Ep: 6.72 loss 0.004 score 0.103 lr 1.84433e-06 
12/05/2021 12:39:12 - INFO - volta.train_utils -   [XVNLI]: iter 227440 Ep: 6.73 loss 0.005 score 0.104 lr 1.84367e-06 
12/05/2021 12:39:44 - INFO - volta.train_utils -   [XVNLI]: iter 227600 Ep: 6.73 loss 0.004 score 0.104 lr 1.84302e-06 
12/05/2021 12:40:15 - INFO - volta.train_utils -   [XVNLI]: iter 227760 Ep: 6.74 loss 0.004 score 0.103 lr 1.84236e-06 
12/05/2021 12:40:46 - INFO - volta.train_utils -   [XVNLI]: iter 227920 Ep: 6.74 loss 0.004 score 0.103 lr 1.8417e-06 
12/05/2021 12:41:17 - INFO - volta.train_utils -   [XVNLI]: iter 228080 Ep: 6.75 loss 0.004 score 0.103 lr 1.84104e-06 
12/05/2021 12:41:48 - INFO - volta.train_utils -   [XVNLI]: iter 228240 Ep: 6.75 loss 0.004 score 0.103 lr 1.84039e-06 
12/05/2021 12:42:20 - INFO - volta.train_utils -   [XVNLI]: iter 228400 Ep: 6.76 loss 0.004 score 0.103 lr 1.83973e-06 
12/05/2021 12:42:51 - INFO - volta.train_utils -   [XVNLI]: iter 228560 Ep: 6.76 loss 0.005 score 0.102 lr 1.83907e-06 
12/05/2021 12:43:22 - INFO - volta.train_utils -   [XVNLI]: iter 228720 Ep: 6.77 loss 0.004 score 0.104 lr 1.83841e-06 
12/05/2021 12:43:53 - INFO - volta.train_utils -   [XVNLI]: iter 228880 Ep: 6.77 loss 0.004 score 0.104 lr 1.83776e-06 
12/05/2021 12:44:25 - INFO - volta.train_utils -   [XVNLI]: iter 229040 Ep: 6.78 loss 0.004 score 0.104 lr 1.8371e-06 
12/05/2021 12:44:56 - INFO - volta.train_utils -   [XVNLI]: iter 229200 Ep: 6.78 loss 0.005 score 0.102 lr 1.83644e-06 
12/05/2021 12:45:27 - INFO - volta.train_utils -   [XVNLI]: iter 229360 Ep: 6.78 loss 0.004 score 0.103 lr 1.83579e-06 
12/05/2021 12:45:58 - INFO - volta.train_utils -   [XVNLI]: iter 229520 Ep: 6.79 loss 0.004 score 0.103 lr 1.83513e-06 
12/05/2021 12:46:30 - INFO - volta.train_utils -   [XVNLI]: iter 229680 Ep: 6.79 loss 0.005 score 0.103 lr 1.83447e-06 
12/05/2021 12:47:01 - INFO - volta.train_utils -   [XVNLI]: iter 229840 Ep: 6.80 loss 0.004 score 0.105 lr 1.83381e-06 
12/05/2021 12:47:32 - INFO - volta.train_utils -   [XVNLI]: iter 230000 Ep: 6.80 loss 0.004 score 0.102 lr 1.83316e-06 
12/05/2021 12:48:03 - INFO - volta.train_utils -   [XVNLI]: iter 230160 Ep: 6.81 loss 0.004 score 0.103 lr 1.8325e-06 
12/05/2021 12:48:34 - INFO - volta.train_utils -   [XVNLI]: iter 230320 Ep: 6.81 loss 0.004 score 0.104 lr 1.83184e-06 
12/05/2021 12:49:05 - INFO - volta.train_utils -   [XVNLI]: iter 230480 Ep: 6.82 loss 0.004 score 0.104 lr 1.83118e-06 
12/05/2021 12:49:36 - INFO - volta.train_utils -   [XVNLI]: iter 230640 Ep: 6.82 loss 0.004 score 0.102 lr 1.83053e-06 
12/05/2021 12:50:07 - INFO - volta.train_utils -   [XVNLI]: iter 230800 Ep: 6.83 loss 0.004 score 0.105 lr 1.82987e-06 
12/05/2021 12:50:39 - INFO - volta.train_utils -   [XVNLI]: iter 230960 Ep: 6.83 loss 0.005 score 0.104 lr 1.82921e-06 
12/05/2021 12:51:10 - INFO - volta.train_utils -   [XVNLI]: iter 231120 Ep: 6.84 loss 0.003 score 0.105 lr 1.82855e-06 
12/05/2021 12:51:41 - INFO - volta.train_utils -   [XVNLI]: iter 231280 Ep: 6.84 loss 0.004 score 0.104 lr 1.8279e-06 
12/05/2021 12:52:12 - INFO - volta.train_utils -   [XVNLI]: iter 231440 Ep: 6.85 loss 0.004 score 0.103 lr 1.82724e-06 
12/05/2021 12:52:43 - INFO - volta.train_utils -   [XVNLI]: iter 231600 Ep: 6.85 loss 0.004 score 0.104 lr 1.82658e-06 
12/05/2021 12:53:14 - INFO - volta.train_utils -   [XVNLI]: iter 231760 Ep: 6.86 loss 0.005 score 0.104 lr 1.82593e-06 
12/05/2021 12:53:46 - INFO - volta.train_utils -   [XVNLI]: iter 231920 Ep: 6.86 loss 0.004 score 0.102 lr 1.82527e-06 
12/05/2021 12:54:17 - INFO - volta.train_utils -   [XVNLI]: iter 232080 Ep: 6.87 loss 0.005 score 0.101 lr 1.82461e-06 
12/05/2021 12:54:48 - INFO - volta.train_utils -   [XVNLI]: iter 232240 Ep: 6.87 loss 0.004 score 0.102 lr 1.82395e-06 
12/05/2021 12:55:19 - INFO - volta.train_utils -   [XVNLI]: iter 232400 Ep: 6.87 loss 0.004 score 0.104 lr 1.8233e-06 
12/05/2021 12:55:51 - INFO - volta.train_utils -   [XVNLI]: iter 232560 Ep: 6.88 loss 0.004 score 0.102 lr 1.82264e-06 
12/05/2021 12:56:22 - INFO - volta.train_utils -   [XVNLI]: iter 232720 Ep: 6.88 loss 0.004 score 0.102 lr 1.82198e-06 
12/05/2021 12:56:54 - INFO - volta.train_utils -   [XVNLI]: iter 232880 Ep: 6.89 loss 0.004 score 0.103 lr 1.82132e-06 
12/05/2021 12:57:25 - INFO - volta.train_utils -   [XVNLI]: iter 233040 Ep: 6.89 loss 0.004 score 0.104 lr 1.82067e-06 
12/05/2021 12:57:57 - INFO - volta.train_utils -   [XVNLI]: iter 233200 Ep: 6.90 loss 0.005 score 0.103 lr 1.82001e-06 
12/05/2021 12:58:28 - INFO - volta.train_utils -   [XVNLI]: iter 233360 Ep: 6.90 loss 0.004 score 0.104 lr 1.81935e-06 
12/05/2021 12:58:59 - INFO - volta.train_utils -   [XVNLI]: iter 233520 Ep: 6.91 loss 0.004 score 0.103 lr 1.81869e-06 
12/05/2021 12:59:30 - INFO - volta.train_utils -   [XVNLI]: iter 233680 Ep: 6.91 loss 0.005 score 0.104 lr 1.81804e-06 
12/05/2021 13:00:01 - INFO - volta.train_utils -   [XVNLI]: iter 233840 Ep: 6.92 loss 0.004 score 0.103 lr 1.81738e-06 
12/05/2021 13:00:32 - INFO - volta.train_utils -   [XVNLI]: iter 234000 Ep: 6.92 loss 0.004 score 0.103 lr 1.81672e-06 
12/05/2021 13:01:03 - INFO - volta.train_utils -   [XVNLI]: iter 234160 Ep: 6.93 loss 0.004 score 0.103 lr 1.81606e-06 
12/05/2021 13:01:34 - INFO - volta.train_utils -   [XVNLI]: iter 234320 Ep: 6.93 loss 0.004 score 0.102 lr 1.81541e-06 
12/05/2021 13:02:06 - INFO - volta.train_utils -   [XVNLI]: iter 234480 Ep: 6.94 loss 0.004 score 0.105 lr 1.81475e-06 
12/05/2021 13:02:37 - INFO - volta.train_utils -   [XVNLI]: iter 234640 Ep: 6.94 loss 0.004 score 0.105 lr 1.81409e-06 
12/05/2021 13:03:08 - INFO - volta.train_utils -   [XVNLI]: iter 234800 Ep: 6.95 loss 0.004 score 0.102 lr 1.81344e-06 
12/05/2021 13:03:39 - INFO - volta.train_utils -   [XVNLI]: iter 234960 Ep: 6.95 loss 0.004 score 0.104 lr 1.81278e-06 
12/05/2021 13:04:10 - INFO - volta.train_utils -   [XVNLI]: iter 235120 Ep: 6.95 loss 0.005 score 0.103 lr 1.81212e-06 
12/05/2021 13:04:42 - INFO - volta.train_utils -   [XVNLI]: iter 235280 Ep: 6.96 loss 0.004 score 0.103 lr 1.81146e-06 
12/05/2021 13:05:13 - INFO - volta.train_utils -   [XVNLI]: iter 235440 Ep: 6.96 loss 0.004 score 0.103 lr 1.81081e-06 
12/05/2021 13:05:44 - INFO - volta.train_utils -   [XVNLI]: iter 235600 Ep: 6.97 loss 0.004 score 0.102 lr 1.81015e-06 
12/05/2021 13:06:15 - INFO - volta.train_utils -   [XVNLI]: iter 235760 Ep: 6.97 loss 0.004 score 0.103 lr 1.80949e-06 
12/05/2021 13:06:46 - INFO - volta.train_utils -   [XVNLI]: iter 235920 Ep: 6.98 loss 0.005 score 0.104 lr 1.80883e-06 
12/05/2021 13:07:18 - INFO - volta.train_utils -   [XVNLI]: iter 236080 Ep: 6.98 loss 0.004 score 0.103 lr 1.80818e-06 
12/05/2021 13:07:49 - INFO - volta.train_utils -   [XVNLI]: iter 236240 Ep: 6.99 loss 0.004 score 0.103 lr 1.80752e-06 
12/05/2021 13:08:20 - INFO - volta.train_utils -   [XVNLI]: iter 236400 Ep: 6.99 loss 0.004 score 0.103 lr 1.80686e-06 
12/05/2021 13:08:51 - INFO - volta.train_utils -   [XVNLI]: iter 236560 Ep: 7.00 loss 0.003 score 0.103 lr 1.8062e-06 
12/05/2021 13:11:22 - INFO - volta.train_utils -   Eval task TASK19 on iteration 236600 
12/05/2021 13:11:22 - INFO - volta.train_utils -   Validation [XVNLI]: loss 0.395 score 75.855 
12/05/2021 13:11:22 - INFO - __main__ -   ** ** * Saving model * ** ** 
Epoch:  70%|███████   | 7/10 [13:33:17<5:46:15, 6925.24s/it]12/05/2021 13:12:27 - INFO - volta.train_utils -   [XVNLI]: iter 236760 Ep: 7.00 loss 0.004 score 0.108 lr 1.80547e-06 
12/05/2021 13:12:58 - INFO - volta.train_utils -   [XVNLI]: iter 236920 Ep: 7.01 loss 0.004 score 0.106 lr 1.80473e-06 
12/05/2021 13:13:29 - INFO - volta.train_utils -   [XVNLI]: iter 237080 Ep: 7.01 loss 0.004 score 0.106 lr 1.80407e-06 
12/05/2021 13:14:01 - INFO - volta.train_utils -   [XVNLI]: iter 237240 Ep: 7.02 loss 0.003 score 0.106 lr 1.80341e-06 
12/05/2021 13:14:32 - INFO - volta.train_utils -   [XVNLI]: iter 237400 Ep: 7.02 loss 0.004 score 0.107 lr 1.80275e-06 
12/05/2021 13:15:03 - INFO - volta.train_utils -   [XVNLI]: iter 237560 Ep: 7.03 loss 0.004 score 0.105 lr 1.8021e-06 
12/05/2021 13:15:40 - INFO - volta.train_utils -   [XVNLI]: iter 237720 Ep: 7.03 loss 0.003 score 0.107 lr 1.80144e-06 
12/05/2021 13:16:11 - INFO - volta.train_utils -   [XVNLI]: iter 237880 Ep: 7.04 loss 0.004 score 0.106 lr 1.80078e-06 
12/05/2021 13:16:42 - INFO - volta.train_utils -   [XVNLI]: iter 238040 Ep: 7.04 loss 0.004 score 0.106 lr 1.80012e-06 
12/05/2021 13:17:13 - INFO - volta.train_utils -   [XVNLI]: iter 238200 Ep: 7.05 loss 0.004 score 0.105 lr 1.79947e-06 
12/05/2021 13:17:44 - INFO - volta.train_utils -   [XVNLI]: iter 238360 Ep: 7.05 loss 0.004 score 0.105 lr 1.79881e-06 
12/05/2021 13:18:15 - INFO - volta.train_utils -   [XVNLI]: iter 238520 Ep: 7.06 loss 0.004 score 0.106 lr 1.79815e-06 
12/05/2021 13:18:46 - INFO - volta.train_utils -   [XVNLI]: iter 238680 Ep: 7.06 loss 0.003 score 0.106 lr 1.79749e-06 
12/05/2021 13:19:17 - INFO - volta.train_utils -   [XVNLI]: iter 238840 Ep: 7.07 loss 0.004 score 0.107 lr 1.79684e-06 
12/05/2021 13:19:48 - INFO - volta.train_utils -   [XVNLI]: iter 239000 Ep: 7.07 loss 0.004 score 0.104 lr 1.79618e-06 
12/05/2021 13:20:19 - INFO - volta.train_utils -   [XVNLI]: iter 239160 Ep: 7.07 loss 0.004 score 0.105 lr 1.79552e-06 
12/05/2021 13:20:50 - INFO - volta.train_utils -   [XVNLI]: iter 239320 Ep: 7.08 loss 0.005 score 0.105 lr 1.79487e-06 
12/05/2021 13:21:21 - INFO - volta.train_utils -   [XVNLI]: iter 239480 Ep: 7.08 loss 0.004 score 0.106 lr 1.79421e-06 
12/05/2021 13:21:52 - INFO - volta.train_utils -   [XVNLI]: iter 239640 Ep: 7.09 loss 0.004 score 0.106 lr 1.79355e-06 
12/05/2021 13:22:23 - INFO - volta.train_utils -   [XVNLI]: iter 239800 Ep: 7.09 loss 0.004 score 0.106 lr 1.79289e-06 
12/05/2021 13:22:54 - INFO - volta.train_utils -   [XVNLI]: iter 239960 Ep: 7.10 loss 0.003 score 0.104 lr 1.79224e-06 
12/05/2021 13:23:26 - INFO - volta.train_utils -   [XVNLI]: iter 240120 Ep: 7.10 loss 0.003 score 0.107 lr 1.79158e-06 
12/05/2021 13:23:57 - INFO - volta.train_utils -   [XVNLI]: iter 240280 Ep: 7.11 loss 0.004 score 0.105 lr 1.79092e-06 
12/05/2021 13:24:28 - INFO - volta.train_utils -   [XVNLI]: iter 240440 Ep: 7.11 loss 0.004 score 0.106 lr 1.79026e-06 
12/05/2021 13:24:59 - INFO - volta.train_utils -   [XVNLI]: iter 240600 Ep: 7.12 loss 0.004 score 0.108 lr 1.78961e-06 
12/05/2021 13:25:30 - INFO - volta.train_utils -   [XVNLI]: iter 240760 Ep: 7.12 loss 0.004 score 0.107 lr 1.78895e-06 
12/05/2021 13:26:01 - INFO - volta.train_utils -   [XVNLI]: iter 240920 Ep: 7.13 loss 0.004 score 0.107 lr 1.78829e-06 
12/05/2021 13:26:32 - INFO - volta.train_utils -   [XVNLI]: iter 241080 Ep: 7.13 loss 0.004 score 0.105 lr 1.78763e-06 
12/05/2021 13:27:03 - INFO - volta.train_utils -   [XVNLI]: iter 241240 Ep: 7.14 loss 0.004 score 0.105 lr 1.78698e-06 
12/05/2021 13:27:34 - INFO - volta.train_utils -   [XVNLI]: iter 241400 Ep: 7.14 loss 0.004 score 0.107 lr 1.78632e-06 
12/05/2021 13:28:05 - INFO - volta.train_utils -   [XVNLI]: iter 241560 Ep: 7.15 loss 0.004 score 0.107 lr 1.78566e-06 
12/05/2021 13:28:36 - INFO - volta.train_utils -   [XVNLI]: iter 241720 Ep: 7.15 loss 0.004 score 0.106 lr 1.78501e-06 
12/05/2021 13:29:07 - INFO - volta.train_utils -   [XVNLI]: iter 241880 Ep: 7.15 loss 0.004 score 0.107 lr 1.78435e-06 
12/05/2021 13:29:38 - INFO - volta.train_utils -   [XVNLI]: iter 242040 Ep: 7.16 loss 0.004 score 0.105 lr 1.78369e-06 
12/05/2021 13:30:09 - INFO - volta.train_utils -   [XVNLI]: iter 242200 Ep: 7.16 loss 0.004 score 0.104 lr 1.78303e-06 
12/05/2021 13:30:40 - INFO - volta.train_utils -   [XVNLI]: iter 242360 Ep: 7.17 loss 0.004 score 0.104 lr 1.78238e-06 
12/05/2021 13:31:11 - INFO - volta.train_utils -   [XVNLI]: iter 242520 Ep: 7.17 loss 0.004 score 0.107 lr 1.78172e-06 
12/05/2021 13:31:42 - INFO - volta.train_utils -   [XVNLI]: iter 242680 Ep: 7.18 loss 0.003 score 0.105 lr 1.78106e-06 
12/05/2021 13:32:13 - INFO - volta.train_utils -   [XVNLI]: iter 242840 Ep: 7.18 loss 0.003 score 0.108 lr 1.7804e-06 
12/05/2021 13:32:44 - INFO - volta.train_utils -   [XVNLI]: iter 243000 Ep: 7.19 loss 0.004 score 0.106 lr 1.77975e-06 
12/05/2021 13:33:15 - INFO - volta.train_utils -   [XVNLI]: iter 243160 Ep: 7.19 loss 0.004 score 0.106 lr 1.77909e-06 
12/05/2021 13:33:46 - INFO - volta.train_utils -   [XVNLI]: iter 243320 Ep: 7.20 loss 0.004 score 0.105 lr 1.77843e-06 
12/05/2021 13:34:18 - INFO - volta.train_utils -   [XVNLI]: iter 243480 Ep: 7.20 loss 0.004 score 0.105 lr 1.77777e-06 
12/05/2021 13:34:49 - INFO - volta.train_utils -   [XVNLI]: iter 243640 Ep: 7.21 loss 0.004 score 0.106 lr 1.77712e-06 
12/05/2021 13:35:20 - INFO - volta.train_utils -   [XVNLI]: iter 243800 Ep: 7.21 loss 0.004 score 0.106 lr 1.77646e-06 
12/05/2021 13:35:51 - INFO - volta.train_utils -   [XVNLI]: iter 243960 Ep: 7.22 loss 0.003 score 0.106 lr 1.7758e-06 
12/05/2021 13:36:22 - INFO - volta.train_utils -   [XVNLI]: iter 244120 Ep: 7.22 loss 0.004 score 0.106 lr 1.77515e-06 
12/05/2021 13:36:54 - INFO - volta.train_utils -   [XVNLI]: iter 244280 Ep: 7.23 loss 0.004 score 0.105 lr 1.77449e-06 
12/05/2021 13:37:25 - INFO - volta.train_utils -   [XVNLI]: iter 244440 Ep: 7.23 loss 0.004 score 0.106 lr 1.77383e-06 
12/05/2021 13:37:56 - INFO - volta.train_utils -   [XVNLI]: iter 244600 Ep: 7.24 loss 0.003 score 0.107 lr 1.77317e-06 
12/05/2021 13:38:27 - INFO - volta.train_utils -   [XVNLI]: iter 244760 Ep: 7.24 loss 0.004 score 0.104 lr 1.77252e-06 
12/05/2021 13:38:58 - INFO - volta.train_utils -   [XVNLI]: iter 244920 Ep: 7.24 loss 0.004 score 0.106 lr 1.77186e-06 
12/05/2021 13:39:29 - INFO - volta.train_utils -   [XVNLI]: iter 245080 Ep: 7.25 loss 0.004 score 0.105 lr 1.7712e-06 
12/05/2021 13:40:00 - INFO - volta.train_utils -   [XVNLI]: iter 245240 Ep: 7.25 loss 0.004 score 0.106 lr 1.77054e-06 
12/05/2021 13:40:31 - INFO - volta.train_utils -   [XVNLI]: iter 245400 Ep: 7.26 loss 0.004 score 0.105 lr 1.76989e-06 
12/05/2021 13:41:02 - INFO - volta.train_utils -   [XVNLI]: iter 245560 Ep: 7.26 loss 0.004 score 0.104 lr 1.76923e-06 
12/05/2021 13:41:33 - INFO - volta.train_utils -   [XVNLI]: iter 245720 Ep: 7.27 loss 0.003 score 0.107 lr 1.76857e-06 
12/05/2021 13:42:04 - INFO - volta.train_utils -   [XVNLI]: iter 245880 Ep: 7.27 loss 0.004 score 0.106 lr 1.76791e-06 
12/05/2021 13:42:35 - INFO - volta.train_utils -   [XVNLI]: iter 246040 Ep: 7.28 loss 0.003 score 0.107 lr 1.76726e-06 
12/05/2021 13:43:06 - INFO - volta.train_utils -   [XVNLI]: iter 246200 Ep: 7.28 loss 0.004 score 0.106 lr 1.7666e-06 
12/05/2021 13:43:37 - INFO - volta.train_utils -   [XVNLI]: iter 246360 Ep: 7.29 loss 0.004 score 0.105 lr 1.76594e-06 
12/05/2021 13:44:09 - INFO - volta.train_utils -   [XVNLI]: iter 246520 Ep: 7.29 loss 0.004 score 0.107 lr 1.76528e-06 
12/05/2021 13:44:40 - INFO - volta.train_utils -   [XVNLI]: iter 246680 Ep: 7.30 loss 0.003 score 0.103 lr 1.76463e-06 
12/05/2021 13:45:11 - INFO - volta.train_utils -   [XVNLI]: iter 246840 Ep: 7.30 loss 0.004 score 0.105 lr 1.76397e-06 
12/05/2021 13:45:42 - INFO - volta.train_utils -   [XVNLI]: iter 247000 Ep: 7.31 loss 0.004 score 0.106 lr 1.76331e-06 
12/05/2021 13:46:13 - INFO - volta.train_utils -   [XVNLI]: iter 247160 Ep: 7.31 loss 0.003 score 0.106 lr 1.76266e-06 
12/05/2021 13:46:44 - INFO - volta.train_utils -   [XVNLI]: iter 247320 Ep: 7.32 loss 0.004 score 0.106 lr 1.762e-06 
12/05/2021 13:47:16 - INFO - volta.train_utils -   [XVNLI]: iter 247480 Ep: 7.32 loss 0.004 score 0.105 lr 1.76134e-06 
12/05/2021 13:47:46 - INFO - volta.train_utils -   [XVNLI]: iter 247640 Ep: 7.33 loss 0.004 score 0.104 lr 1.76068e-06 
12/05/2021 13:48:18 - INFO - volta.train_utils -   [XVNLI]: iter 247800 Ep: 7.33 loss 0.003 score 0.105 lr 1.76003e-06 
12/05/2021 13:48:49 - INFO - volta.train_utils -   [XVNLI]: iter 247960 Ep: 7.33 loss 0.004 score 0.105 lr 1.75937e-06 
12/05/2021 13:49:21 - INFO - volta.train_utils -   [XVNLI]: iter 248120 Ep: 7.34 loss 0.003 score 0.104 lr 1.75871e-06 
12/05/2021 13:49:53 - INFO - volta.train_utils -   [XVNLI]: iter 248280 Ep: 7.34 loss 0.003 score 0.106 lr 1.75805e-06 
12/05/2021 13:50:24 - INFO - volta.train_utils -   [XVNLI]: iter 248440 Ep: 7.35 loss 0.004 score 0.106 lr 1.7574e-06 
12/05/2021 13:50:55 - INFO - volta.train_utils -   [XVNLI]: iter 248600 Ep: 7.35 loss 0.003 score 0.105 lr 1.75674e-06 
12/05/2021 13:51:27 - INFO - volta.train_utils -   [XVNLI]: iter 248760 Ep: 7.36 loss 0.003 score 0.106 lr 1.75608e-06 
12/05/2021 13:51:58 - INFO - volta.train_utils -   [XVNLI]: iter 248920 Ep: 7.36 loss 0.003 score 0.105 lr 1.75542e-06 
12/05/2021 13:52:29 - INFO - volta.train_utils -   [XVNLI]: iter 249080 Ep: 7.37 loss 0.004 score 0.106 lr 1.75477e-06 
12/05/2021 13:53:00 - INFO - volta.train_utils -   [XVNLI]: iter 249240 Ep: 7.37 loss 0.004 score 0.105 lr 1.75411e-06 
12/05/2021 13:53:31 - INFO - volta.train_utils -   [XVNLI]: iter 249400 Ep: 7.38 loss 0.004 score 0.106 lr 1.75345e-06 
12/05/2021 13:54:02 - INFO - volta.train_utils -   [XVNLI]: iter 249560 Ep: 7.38 loss 0.003 score 0.107 lr 1.7528e-06 
12/05/2021 13:54:33 - INFO - volta.train_utils -   [XVNLI]: iter 249720 Ep: 7.39 loss 0.004 score 0.105 lr 1.75214e-06 
12/05/2021 13:55:04 - INFO - volta.train_utils -   [XVNLI]: iter 249880 Ep: 7.39 loss 0.003 score 0.106 lr 1.75148e-06 
12/05/2021 13:55:35 - INFO - volta.train_utils -   [XVNLI]: iter 250040 Ep: 7.40 loss 0.004 score 0.105 lr 1.75082e-06 
12/05/2021 13:56:07 - INFO - volta.train_utils -   [XVNLI]: iter 250200 Ep: 7.40 loss 0.004 score 0.105 lr 1.75017e-06 
12/05/2021 13:56:38 - INFO - volta.train_utils -   [XVNLI]: iter 250360 Ep: 7.41 loss 0.004 score 0.106 lr 1.74951e-06 
12/05/2021 13:57:09 - INFO - volta.train_utils -   [XVNLI]: iter 250520 Ep: 7.41 loss 0.004 score 0.103 lr 1.74885e-06 
12/05/2021 13:57:40 - INFO - volta.train_utils -   [XVNLI]: iter 250680 Ep: 7.42 loss 0.003 score 0.105 lr 1.74819e-06 
12/05/2021 13:58:11 - INFO - volta.train_utils -   [XVNLI]: iter 250840 Ep: 7.42 loss 0.004 score 0.105 lr 1.74754e-06 
12/05/2021 13:58:42 - INFO - volta.train_utils -   [XVNLI]: iter 251000 Ep: 7.42 loss 0.003 score 0.105 lr 1.74688e-06 
12/05/2021 13:59:13 - INFO - volta.train_utils -   [XVNLI]: iter 251160 Ep: 7.43 loss 0.004 score 0.105 lr 1.74622e-06 
12/05/2021 13:59:45 - INFO - volta.train_utils -   [XVNLI]: iter 251320 Ep: 7.43 loss 0.004 score 0.106 lr 1.74556e-06 
12/05/2021 14:00:16 - INFO - volta.train_utils -   [XVNLI]: iter 251480 Ep: 7.44 loss 0.003 score 0.106 lr 1.74491e-06 
12/05/2021 14:00:47 - INFO - volta.train_utils -   [XVNLI]: iter 251640 Ep: 7.44 loss 0.004 score 0.104 lr 1.74425e-06 
12/05/2021 14:01:18 - INFO - volta.train_utils -   [XVNLI]: iter 251800 Ep: 7.45 loss 0.004 score 0.105 lr 1.74359e-06 
12/05/2021 14:01:50 - INFO - volta.train_utils -   [XVNLI]: iter 251960 Ep: 7.45 loss 0.004 score 0.106 lr 1.74294e-06 
12/05/2021 14:02:21 - INFO - volta.train_utils -   [XVNLI]: iter 252120 Ep: 7.46 loss 0.004 score 0.107 lr 1.74228e-06 
12/05/2021 14:02:52 - INFO - volta.train_utils -   [XVNLI]: iter 252280 Ep: 7.46 loss 0.004 score 0.105 lr 1.74162e-06 
12/05/2021 14:03:23 - INFO - volta.train_utils -   [XVNLI]: iter 252440 Ep: 7.47 loss 0.004 score 0.105 lr 1.74096e-06 
12/05/2021 14:03:54 - INFO - volta.train_utils -   [XVNLI]: iter 252600 Ep: 7.47 loss 0.004 score 0.105 lr 1.74031e-06 
12/05/2021 14:04:25 - INFO - volta.train_utils -   [XVNLI]: iter 252760 Ep: 7.48 loss 0.004 score 0.105 lr 1.73965e-06 
12/05/2021 14:04:57 - INFO - volta.train_utils -   [XVNLI]: iter 252920 Ep: 7.48 loss 0.004 score 0.107 lr 1.73899e-06 
12/05/2021 14:05:28 - INFO - volta.train_utils -   [XVNLI]: iter 253080 Ep: 7.49 loss 0.004 score 0.106 lr 1.73833e-06 
12/05/2021 14:05:59 - INFO - volta.train_utils -   [XVNLI]: iter 253240 Ep: 7.49 loss 0.004 score 0.105 lr 1.73768e-06 
12/05/2021 14:06:30 - INFO - volta.train_utils -   [XVNLI]: iter 253400 Ep: 7.50 loss 0.003 score 0.105 lr 1.73702e-06 
12/05/2021 14:07:01 - INFO - volta.train_utils -   [XVNLI]: iter 253560 Ep: 7.50 loss 0.004 score 0.105 lr 1.73636e-06 
12/05/2021 14:07:32 - INFO - volta.train_utils -   [XVNLI]: iter 253720 Ep: 7.51 loss 0.004 score 0.106 lr 1.7357e-06 
12/05/2021 14:08:03 - INFO - volta.train_utils -   [XVNLI]: iter 253880 Ep: 7.51 loss 0.004 score 0.106 lr 1.73505e-06 
12/05/2021 14:08:35 - INFO - volta.train_utils -   [XVNLI]: iter 254040 Ep: 7.51 loss 0.004 score 0.106 lr 1.73439e-06 
12/05/2021 14:09:06 - INFO - volta.train_utils -   [XVNLI]: iter 254200 Ep: 7.52 loss 0.004 score 0.106 lr 1.73373e-06 
12/05/2021 14:09:37 - INFO - volta.train_utils -   [XVNLI]: iter 254360 Ep: 7.52 loss 0.004 score 0.106 lr 1.73307e-06 
12/05/2021 14:10:08 - INFO - volta.train_utils -   [XVNLI]: iter 254520 Ep: 7.53 loss 0.004 score 0.105 lr 1.73242e-06 
12/05/2021 14:10:39 - INFO - volta.train_utils -   [XVNLI]: iter 254680 Ep: 7.53 loss 0.004 score 0.105 lr 1.73176e-06 
12/05/2021 14:11:11 - INFO - volta.train_utils -   [XVNLI]: iter 254840 Ep: 7.54 loss 0.004 score 0.105 lr 1.7311e-06 
12/05/2021 14:11:42 - INFO - volta.train_utils -   [XVNLI]: iter 255000 Ep: 7.54 loss 0.004 score 0.106 lr 1.73045e-06 
12/05/2021 14:12:13 - INFO - volta.train_utils -   [XVNLI]: iter 255160 Ep: 7.55 loss 0.004 score 0.106 lr 1.72979e-06 
12/05/2021 14:12:44 - INFO - volta.train_utils -   [XVNLI]: iter 255320 Ep: 7.55 loss 0.003 score 0.105 lr 1.72913e-06 
12/05/2021 14:13:15 - INFO - volta.train_utils -   [XVNLI]: iter 255480 Ep: 7.56 loss 0.004 score 0.105 lr 1.72847e-06 
12/05/2021 14:13:46 - INFO - volta.train_utils -   [XVNLI]: iter 255640 Ep: 7.56 loss 0.004 score 0.103 lr 1.72782e-06 
12/05/2021 14:14:17 - INFO - volta.train_utils -   [XVNLI]: iter 255800 Ep: 7.57 loss 0.004 score 0.105 lr 1.72716e-06 
12/05/2021 14:14:49 - INFO - volta.train_utils -   [XVNLI]: iter 255960 Ep: 7.57 loss 0.005 score 0.104 lr 1.7265e-06 
12/05/2021 14:15:20 - INFO - volta.train_utils -   [XVNLI]: iter 256120 Ep: 7.58 loss 0.004 score 0.105 lr 1.72584e-06 
12/05/2021 14:15:51 - INFO - volta.train_utils -   [XVNLI]: iter 256280 Ep: 7.58 loss 0.003 score 0.106 lr 1.72519e-06 
12/05/2021 14:16:22 - INFO - volta.train_utils -   [XVNLI]: iter 256440 Ep: 7.59 loss 0.004 score 0.104 lr 1.72453e-06 
12/05/2021 14:16:53 - INFO - volta.train_utils -   [XVNLI]: iter 256600 Ep: 7.59 loss 0.004 score 0.105 lr 1.72387e-06 
12/05/2021 14:17:24 - INFO - volta.train_utils -   [XVNLI]: iter 256760 Ep: 7.60 loss 0.004 score 0.105 lr 1.72321e-06 
12/05/2021 14:17:55 - INFO - volta.train_utils -   [XVNLI]: iter 256920 Ep: 7.60 loss 0.004 score 0.104 lr 1.72256e-06 
12/05/2021 14:18:26 - INFO - volta.train_utils -   [XVNLI]: iter 257080 Ep: 7.60 loss 0.003 score 0.106 lr 1.7219e-06 
12/05/2021 14:18:57 - INFO - volta.train_utils -   [XVNLI]: iter 257240 Ep: 7.61 loss 0.004 score 0.106 lr 1.72124e-06 
12/05/2021 14:19:29 - INFO - volta.train_utils -   [XVNLI]: iter 257400 Ep: 7.61 loss 0.003 score 0.106 lr 1.72059e-06 
12/05/2021 14:20:00 - INFO - volta.train_utils -   [XVNLI]: iter 257560 Ep: 7.62 loss 0.004 score 0.105 lr 1.71993e-06 
12/05/2021 14:20:31 - INFO - volta.train_utils -   [XVNLI]: iter 257720 Ep: 7.62 loss 0.004 score 0.106 lr 1.71927e-06 
12/05/2021 14:21:02 - INFO - volta.train_utils -   [XVNLI]: iter 257880 Ep: 7.63 loss 0.004 score 0.106 lr 1.71861e-06 
12/05/2021 14:21:33 - INFO - volta.train_utils -   [XVNLI]: iter 258040 Ep: 7.63 loss 0.004 score 0.105 lr 1.71796e-06 
12/05/2021 14:22:04 - INFO - volta.train_utils -   [XVNLI]: iter 258200 Ep: 7.64 loss 0.004 score 0.105 lr 1.7173e-06 
12/05/2021 14:22:36 - INFO - volta.train_utils -   [XVNLI]: iter 258360 Ep: 7.64 loss 0.004 score 0.105 lr 1.71664e-06 
12/05/2021 14:23:07 - INFO - volta.train_utils -   [XVNLI]: iter 258520 Ep: 7.65 loss 0.004 score 0.106 lr 1.71598e-06 
12/05/2021 14:23:38 - INFO - volta.train_utils -   [XVNLI]: iter 258680 Ep: 7.65 loss 0.003 score 0.105 lr 1.71533e-06 
12/05/2021 14:24:09 - INFO - volta.train_utils -   [XVNLI]: iter 258840 Ep: 7.66 loss 0.004 score 0.105 lr 1.71467e-06 
12/05/2021 14:24:40 - INFO - volta.train_utils -   [XVNLI]: iter 259000 Ep: 7.66 loss 0.003 score 0.105 lr 1.71401e-06 
12/05/2021 14:25:11 - INFO - volta.train_utils -   [XVNLI]: iter 259160 Ep: 7.67 loss 0.004 score 0.104 lr 1.71335e-06 
12/05/2021 14:25:42 - INFO - volta.train_utils -   [XVNLI]: iter 259320 Ep: 7.67 loss 0.004 score 0.105 lr 1.7127e-06 
12/05/2021 14:26:14 - INFO - volta.train_utils -   [XVNLI]: iter 259480 Ep: 7.68 loss 0.004 score 0.105 lr 1.71204e-06 
12/05/2021 14:26:45 - INFO - volta.train_utils -   [XVNLI]: iter 259640 Ep: 7.68 loss 0.004 score 0.103 lr 1.71138e-06 
12/05/2021 14:27:16 - INFO - volta.train_utils -   [XVNLI]: iter 259800 Ep: 7.69 loss 0.004 score 0.104 lr 1.71073e-06 
12/05/2021 14:27:47 - INFO - volta.train_utils -   [XVNLI]: iter 259960 Ep: 7.69 loss 0.003 score 0.104 lr 1.71007e-06 
12/05/2021 14:28:18 - INFO - volta.train_utils -   [XVNLI]: iter 260120 Ep: 7.69 loss 0.004 score 0.104 lr 1.70941e-06 
12/05/2021 14:28:49 - INFO - volta.train_utils -   [XVNLI]: iter 260280 Ep: 7.70 loss 0.004 score 0.104 lr 1.70875e-06 
12/05/2021 14:29:21 - INFO - volta.train_utils -   [XVNLI]: iter 260440 Ep: 7.70 loss 0.003 score 0.105 lr 1.7081e-06 
12/05/2021 14:29:52 - INFO - volta.train_utils -   [XVNLI]: iter 260600 Ep: 7.71 loss 0.004 score 0.104 lr 1.70744e-06 
12/05/2021 14:30:23 - INFO - volta.train_utils -   [XVNLI]: iter 260760 Ep: 7.71 loss 0.004 score 0.106 lr 1.70678e-06 
12/05/2021 14:30:54 - INFO - volta.train_utils -   [XVNLI]: iter 260920 Ep: 7.72 loss 0.004 score 0.106 lr 1.70612e-06 
12/05/2021 14:31:25 - INFO - volta.train_utils -   [XVNLI]: iter 261080 Ep: 7.72 loss 0.004 score 0.103 lr 1.70547e-06 
12/05/2021 14:31:56 - INFO - volta.train_utils -   [XVNLI]: iter 261240 Ep: 7.73 loss 0.004 score 0.106 lr 1.70481e-06 
12/05/2021 14:32:27 - INFO - volta.train_utils -   [XVNLI]: iter 261400 Ep: 7.73 loss 0.004 score 0.104 lr 1.70415e-06 
12/05/2021 14:32:59 - INFO - volta.train_utils -   [XVNLI]: iter 261560 Ep: 7.74 loss 0.004 score 0.104 lr 1.70349e-06 
12/05/2021 14:33:30 - INFO - volta.train_utils -   [XVNLI]: iter 261720 Ep: 7.74 loss 0.004 score 0.106 lr 1.70284e-06 
12/05/2021 14:34:01 - INFO - volta.train_utils -   [XVNLI]: iter 261880 Ep: 7.75 loss 0.004 score 0.104 lr 1.70218e-06 
12/05/2021 14:34:32 - INFO - volta.train_utils -   [XVNLI]: iter 262040 Ep: 7.75 loss 0.003 score 0.105 lr 1.70152e-06 
12/05/2021 14:35:04 - INFO - volta.train_utils -   [XVNLI]: iter 262200 Ep: 7.76 loss 0.004 score 0.104 lr 1.70087e-06 
12/05/2021 14:35:35 - INFO - volta.train_utils -   [XVNLI]: iter 262360 Ep: 7.76 loss 0.004 score 0.104 lr 1.70021e-06 
12/05/2021 14:36:06 - INFO - volta.train_utils -   [XVNLI]: iter 262520 Ep: 7.77 loss 0.003 score 0.106 lr 1.69955e-06 
12/05/2021 14:36:37 - INFO - volta.train_utils -   [XVNLI]: iter 262680 Ep: 7.77 loss 0.005 score 0.104 lr 1.69889e-06 
12/05/2021 14:37:08 - INFO - volta.train_utils -   [XVNLI]: iter 262840 Ep: 7.77 loss 0.004 score 0.106 lr 1.69824e-06 
12/05/2021 14:37:39 - INFO - volta.train_utils -   [XVNLI]: iter 263000 Ep: 7.78 loss 0.004 score 0.105 lr 1.69758e-06 
12/05/2021 14:38:11 - INFO - volta.train_utils -   [XVNLI]: iter 263160 Ep: 7.78 loss 0.004 score 0.105 lr 1.69692e-06 
12/05/2021 14:38:42 - INFO - volta.train_utils -   [XVNLI]: iter 263320 Ep: 7.79 loss 0.004 score 0.106 lr 1.69626e-06 
12/05/2021 14:39:13 - INFO - volta.train_utils -   [XVNLI]: iter 263480 Ep: 7.79 loss 0.004 score 0.106 lr 1.69561e-06 
12/05/2021 14:39:45 - INFO - volta.train_utils -   [XVNLI]: iter 263640 Ep: 7.80 loss 0.003 score 0.105 lr 1.69495e-06 
12/05/2021 14:40:16 - INFO - volta.train_utils -   [XVNLI]: iter 263800 Ep: 7.80 loss 0.003 score 0.107 lr 1.69429e-06 
12/05/2021 14:40:47 - INFO - volta.train_utils -   [XVNLI]: iter 263960 Ep: 7.81 loss 0.004 score 0.104 lr 1.69363e-06 
12/05/2021 14:41:19 - INFO - volta.train_utils -   [XVNLI]: iter 264120 Ep: 7.81 loss 0.004 score 0.105 lr 1.69298e-06 
12/05/2021 14:41:50 - INFO - volta.train_utils -   [XVNLI]: iter 264280 Ep: 7.82 loss 0.004 score 0.104 lr 1.69232e-06 
12/05/2021 14:42:21 - INFO - volta.train_utils -   [XVNLI]: iter 264440 Ep: 7.82 loss 0.004 score 0.105 lr 1.69166e-06 
12/05/2021 14:42:52 - INFO - volta.train_utils -   [XVNLI]: iter 264600 Ep: 7.83 loss 0.004 score 0.104 lr 1.691e-06 
12/05/2021 14:43:23 - INFO - volta.train_utils -   [XVNLI]: iter 264760 Ep: 7.83 loss 0.004 score 0.105 lr 1.69035e-06 
12/05/2021 14:43:54 - INFO - volta.train_utils -   [XVNLI]: iter 264920 Ep: 7.84 loss 0.004 score 0.107 lr 1.68969e-06 
12/05/2021 14:44:25 - INFO - volta.train_utils -   [XVNLI]: iter 265080 Ep: 7.84 loss 0.004 score 0.106 lr 1.68903e-06 
12/05/2021 14:44:56 - INFO - volta.train_utils -   [XVNLI]: iter 265240 Ep: 7.85 loss 0.004 score 0.107 lr 1.68838e-06 
12/05/2021 14:45:27 - INFO - volta.train_utils -   [XVNLI]: iter 265400 Ep: 7.85 loss 0.004 score 0.105 lr 1.68772e-06 
12/05/2021 14:45:59 - INFO - volta.train_utils -   [XVNLI]: iter 265560 Ep: 7.86 loss 0.004 score 0.107 lr 1.68706e-06 
12/05/2021 14:46:30 - INFO - volta.train_utils -   [XVNLI]: iter 265720 Ep: 7.86 loss 0.003 score 0.104 lr 1.6864e-06 
12/05/2021 14:47:01 - INFO - volta.train_utils -   [XVNLI]: iter 265880 Ep: 7.86 loss 0.003 score 0.106 lr 1.68575e-06 
12/05/2021 14:47:32 - INFO - volta.train_utils -   [XVNLI]: iter 266040 Ep: 7.87 loss 0.003 score 0.105 lr 1.68509e-06 
12/05/2021 14:48:03 - INFO - volta.train_utils -   [XVNLI]: iter 266200 Ep: 7.87 loss 0.003 score 0.105 lr 1.68443e-06 
12/05/2021 14:48:34 - INFO - volta.train_utils -   [XVNLI]: iter 266360 Ep: 7.88 loss 0.005 score 0.105 lr 1.68377e-06 
12/05/2021 14:49:06 - INFO - volta.train_utils -   [XVNLI]: iter 266520 Ep: 7.88 loss 0.004 score 0.105 lr 1.68312e-06 
12/05/2021 14:49:37 - INFO - volta.train_utils -   [XVNLI]: iter 266680 Ep: 7.89 loss 0.004 score 0.105 lr 1.68246e-06 
12/05/2021 14:50:09 - INFO - volta.train_utils -   [XVNLI]: iter 266840 Ep: 7.89 loss 0.004 score 0.105 lr 1.6818e-06 
12/05/2021 14:50:40 - INFO - volta.train_utils -   [XVNLI]: iter 267000 Ep: 7.90 loss 0.004 score 0.104 lr 1.68114e-06 
12/05/2021 14:51:11 - INFO - volta.train_utils -   [XVNLI]: iter 267160 Ep: 7.90 loss 0.004 score 0.105 lr 1.68049e-06 
12/05/2021 14:51:42 - INFO - volta.train_utils -   [XVNLI]: iter 267320 Ep: 7.91 loss 0.004 score 0.104 lr 1.67983e-06 
12/05/2021 14:52:13 - INFO - volta.train_utils -   [XVNLI]: iter 267480 Ep: 7.91 loss 0.004 score 0.106 lr 1.67917e-06 
12/05/2021 14:52:44 - INFO - volta.train_utils -   [XVNLI]: iter 267640 Ep: 7.92 loss 0.004 score 0.107 lr 1.67852e-06 
12/05/2021 14:53:16 - INFO - volta.train_utils -   [XVNLI]: iter 267800 Ep: 7.92 loss 0.004 score 0.104 lr 1.67786e-06 
12/05/2021 14:53:47 - INFO - volta.train_utils -   [XVNLI]: iter 267960 Ep: 7.93 loss 0.005 score 0.105 lr 1.6772e-06 
12/05/2021 14:54:18 - INFO - volta.train_utils -   [XVNLI]: iter 268120 Ep: 7.93 loss 0.003 score 0.106 lr 1.67654e-06 
12/05/2021 14:54:51 - INFO - volta.train_utils -   [XVNLI]: iter 268280 Ep: 7.94 loss 0.004 score 0.104 lr 1.67589e-06 
12/05/2021 14:55:22 - INFO - volta.train_utils -   [XVNLI]: iter 268440 Ep: 7.94 loss 0.004 score 0.105 lr 1.67523e-06 
12/05/2021 14:55:53 - INFO - volta.train_utils -   [XVNLI]: iter 268600 Ep: 7.95 loss 0.004 score 0.105 lr 1.67457e-06 
12/05/2021 14:56:24 - INFO - volta.train_utils -   [XVNLI]: iter 268760 Ep: 7.95 loss 0.004 score 0.103 lr 1.67391e-06 
12/05/2021 14:56:55 - INFO - volta.train_utils -   [XVNLI]: iter 268920 Ep: 7.95 loss 0.004 score 0.105 lr 1.67326e-06 
12/05/2021 14:57:27 - INFO - volta.train_utils -   [XVNLI]: iter 269080 Ep: 7.96 loss 0.005 score 0.105 lr 1.6726e-06 
12/05/2021 14:57:58 - INFO - volta.train_utils -   [XVNLI]: iter 269240 Ep: 7.96 loss 0.004 score 0.106 lr 1.67194e-06 
12/05/2021 14:58:30 - INFO - volta.train_utils -   [XVNLI]: iter 269400 Ep: 7.97 loss 0.004 score 0.105 lr 1.67128e-06 
12/05/2021 14:59:01 - INFO - volta.train_utils -   [XVNLI]: iter 269560 Ep: 7.97 loss 0.004 score 0.104 lr 1.67063e-06 
12/05/2021 14:59:32 - INFO - volta.train_utils -   [XVNLI]: iter 269720 Ep: 7.98 loss 0.004 score 0.104 lr 1.66997e-06 
12/05/2021 15:00:03 - INFO - volta.train_utils -   [XVNLI]: iter 269880 Ep: 7.98 loss 0.004 score 0.104 lr 1.66931e-06 
12/05/2021 15:00:34 - INFO - volta.train_utils -   [XVNLI]: iter 270040 Ep: 7.99 loss 0.003 score 0.105 lr 1.66866e-06 
12/05/2021 15:01:06 - INFO - volta.train_utils -   [XVNLI]: iter 270200 Ep: 7.99 loss 0.004 score 0.104 lr 1.668e-06 
12/05/2021 15:01:37 - INFO - volta.train_utils -   [XVNLI]: iter 270360 Ep: 8.00 loss 0.005 score 0.103 lr 1.66734e-06 
12/05/2021 15:04:10 - INFO - volta.train_utils -   Eval task TASK19 on iteration 270400 
12/05/2021 15:04:10 - INFO - volta.train_utils -   Validation [XVNLI]: loss 0.417 score 75.583 
Epoch:  80%|████████  | 8/10 [15:25:37<3:48:58, 6869.41s/it]12/05/2021 15:04:47 - INFO - volta.train_utils -   [XVNLI]: iter 270560 Ep: 8.00 loss 0.004 score 0.109 lr 1.6666e-06 
12/05/2021 15:05:18 - INFO - volta.train_utils -   [XVNLI]: iter 270720 Ep: 8.01 loss 0.004 score 0.107 lr 1.66586e-06 
12/05/2021 15:05:49 - INFO - volta.train_utils -   [XVNLI]: iter 270880 Ep: 8.01 loss 0.003 score 0.107 lr 1.6652e-06 
12/05/2021 15:06:20 - INFO - volta.train_utils -   [XVNLI]: iter 271040 Ep: 8.02 loss 0.004 score 0.107 lr 1.66455e-06 
12/05/2021 15:06:51 - INFO - volta.train_utils -   [XVNLI]: iter 271200 Ep: 8.02 loss 0.003 score 0.106 lr 1.66389e-06 
12/05/2021 15:07:22 - INFO - volta.train_utils -   [XVNLI]: iter 271360 Ep: 8.03 loss 0.004 score 0.107 lr 1.66323e-06 
12/05/2021 15:07:57 - INFO - volta.train_utils -   [XVNLI]: iter 271520 Ep: 8.03 loss 0.003 score 0.109 lr 1.66257e-06 
12/05/2021 15:08:28 - INFO - volta.train_utils -   [XVNLI]: iter 271680 Ep: 8.04 loss 0.003 score 0.108 lr 1.66192e-06 
12/05/2021 15:08:59 - INFO - volta.train_utils -   [XVNLI]: iter 271840 Ep: 8.04 loss 0.003 score 0.107 lr 1.66126e-06 
12/05/2021 15:09:30 - INFO - volta.train_utils -   [XVNLI]: iter 272000 Ep: 8.05 loss 0.003 score 0.107 lr 1.6606e-06 
12/05/2021 15:10:01 - INFO - volta.train_utils -   [XVNLI]: iter 272160 Ep: 8.05 loss 0.004 score 0.107 lr 1.65995e-06 
12/05/2021 15:10:32 - INFO - volta.train_utils -   [XVNLI]: iter 272320 Ep: 8.06 loss 0.004 score 0.107 lr 1.65929e-06 
12/05/2021 15:11:03 - INFO - volta.train_utils -   [XVNLI]: iter 272480 Ep: 8.06 loss 0.004 score 0.108 lr 1.65863e-06 
12/05/2021 15:11:34 - INFO - volta.train_utils -   [XVNLI]: iter 272640 Ep: 8.06 loss 0.003 score 0.108 lr 1.65797e-06 
12/05/2021 15:12:05 - INFO - volta.train_utils -   [XVNLI]: iter 272800 Ep: 8.07 loss 0.003 score 0.107 lr 1.65732e-06 
12/05/2021 15:12:36 - INFO - volta.train_utils -   [XVNLI]: iter 272960 Ep: 8.07 loss 0.003 score 0.108 lr 1.65666e-06 
12/05/2021 15:13:07 - INFO - volta.train_utils -   [XVNLI]: iter 273120 Ep: 8.08 loss 0.003 score 0.108 lr 1.656e-06 
12/05/2021 15:13:38 - INFO - volta.train_utils -   [XVNLI]: iter 273280 Ep: 8.08 loss 0.004 score 0.108 lr 1.65534e-06 
12/05/2021 15:14:10 - INFO - volta.train_utils -   [XVNLI]: iter 273440 Ep: 8.09 loss 0.004 score 0.107 lr 1.65469e-06 
12/05/2021 15:14:41 - INFO - volta.train_utils -   [XVNLI]: iter 273600 Ep: 8.09 loss 0.004 score 0.107 lr 1.65403e-06 
12/05/2021 15:15:12 - INFO - volta.train_utils -   [XVNLI]: iter 273760 Ep: 8.10 loss 0.004 score 0.107 lr 1.65337e-06 
12/05/2021 15:15:43 - INFO - volta.train_utils -   [XVNLI]: iter 273920 Ep: 8.10 loss 0.003 score 0.107 lr 1.65271e-06 
12/05/2021 15:16:14 - INFO - volta.train_utils -   [XVNLI]: iter 274080 Ep: 8.11 loss 0.004 score 0.108 lr 1.65206e-06 
12/05/2021 15:16:45 - INFO - volta.train_utils -   [XVNLI]: iter 274240 Ep: 8.11 loss 0.003 score 0.108 lr 1.6514e-06 
12/05/2021 15:17:16 - INFO - volta.train_utils -   [XVNLI]: iter 274400 Ep: 8.12 loss 0.004 score 0.107 lr 1.65074e-06 
12/05/2021 15:17:47 - INFO - volta.train_utils -   [XVNLI]: iter 274560 Ep: 8.12 loss 0.003 score 0.107 lr 1.65009e-06 
12/05/2021 15:18:18 - INFO - volta.train_utils -   [XVNLI]: iter 274720 Ep: 8.13 loss 0.004 score 0.107 lr 1.64943e-06 
12/05/2021 15:18:49 - INFO - volta.train_utils -   [XVNLI]: iter 274880 Ep: 8.13 loss 0.003 score 0.108 lr 1.64877e-06 
12/05/2021 15:19:21 - INFO - volta.train_utils -   [XVNLI]: iter 275040 Ep: 8.14 loss 0.004 score 0.107 lr 1.64811e-06 
12/05/2021 15:19:52 - INFO - volta.train_utils -   [XVNLI]: iter 275200 Ep: 8.14 loss 0.003 score 0.107 lr 1.64746e-06 
12/05/2021 15:20:23 - INFO - volta.train_utils -   [XVNLI]: iter 275360 Ep: 8.15 loss 0.003 score 0.107 lr 1.6468e-06 
12/05/2021 15:20:54 - INFO - volta.train_utils -   [XVNLI]: iter 275520 Ep: 8.15 loss 0.003 score 0.106 lr 1.64614e-06 
12/05/2021 15:21:25 - INFO - volta.train_utils -   [XVNLI]: iter 275680 Ep: 8.15 loss 0.003 score 0.107 lr 1.64548e-06 
12/05/2021 15:21:56 - INFO - volta.train_utils -   [XVNLI]: iter 275840 Ep: 8.16 loss 0.003 score 0.108 lr 1.64483e-06 
12/05/2021 15:22:27 - INFO - volta.train_utils -   [XVNLI]: iter 276000 Ep: 8.16 loss 0.003 score 0.106 lr 1.64417e-06 
12/05/2021 15:22:58 - INFO - volta.train_utils -   [XVNLI]: iter 276160 Ep: 8.17 loss 0.003 score 0.109 lr 1.64351e-06 
12/05/2021 15:23:29 - INFO - volta.train_utils -   [XVNLI]: iter 276320 Ep: 8.17 loss 0.003 score 0.107 lr 1.64285e-06 
12/05/2021 15:24:01 - INFO - volta.train_utils -   [XVNLI]: iter 276480 Ep: 8.18 loss 0.003 score 0.108 lr 1.6422e-06 
12/05/2021 15:24:32 - INFO - volta.train_utils -   [XVNLI]: iter 276640 Ep: 8.18 loss 0.003 score 0.107 lr 1.64154e-06 
12/05/2021 15:25:03 - INFO - volta.train_utils -   [XVNLI]: iter 276800 Ep: 8.19 loss 0.003 score 0.108 lr 1.64088e-06 
12/05/2021 15:25:34 - INFO - volta.train_utils -   [XVNLI]: iter 276960 Ep: 8.19 loss 0.003 score 0.108 lr 1.64022e-06 
12/05/2021 15:26:05 - INFO - volta.train_utils -   [XVNLI]: iter 277120 Ep: 8.20 loss 0.003 score 0.109 lr 1.63957e-06 
12/05/2021 15:26:36 - INFO - volta.train_utils -   [XVNLI]: iter 277280 Ep: 8.20 loss 0.004 score 0.107 lr 1.63891e-06 
12/05/2021 15:27:07 - INFO - volta.train_utils -   [XVNLI]: iter 277440 Ep: 8.21 loss 0.004 score 0.107 lr 1.63825e-06 
12/05/2021 15:27:38 - INFO - volta.train_utils -   [XVNLI]: iter 277600 Ep: 8.21 loss 0.004 score 0.108 lr 1.6376e-06 
12/05/2021 15:28:09 - INFO - volta.train_utils -   [XVNLI]: iter 277760 Ep: 8.22 loss 0.004 score 0.107 lr 1.63694e-06 
12/05/2021 15:28:41 - INFO - volta.train_utils -   [XVNLI]: iter 277920 Ep: 8.22 loss 0.005 score 0.107 lr 1.63628e-06 
12/05/2021 15:29:12 - INFO - volta.train_utils -   [XVNLI]: iter 278080 Ep: 8.23 loss 0.003 score 0.108 lr 1.63562e-06 
12/05/2021 15:29:43 - INFO - volta.train_utils -   [XVNLI]: iter 278240 Ep: 8.23 loss 0.004 score 0.107 lr 1.63497e-06 
12/05/2021 15:30:15 - INFO - volta.train_utils -   [XVNLI]: iter 278400 Ep: 8.24 loss 0.004 score 0.108 lr 1.63431e-06 
12/05/2021 15:30:46 - INFO - volta.train_utils -   [XVNLI]: iter 278560 Ep: 8.24 loss 0.003 score 0.106 lr 1.63365e-06 
12/05/2021 15:31:17 - INFO - volta.train_utils -   [XVNLI]: iter 278720 Ep: 8.24 loss 0.003 score 0.106 lr 1.63299e-06 
12/05/2021 15:31:48 - INFO - volta.train_utils -   [XVNLI]: iter 278880 Ep: 8.25 loss 0.004 score 0.106 lr 1.63234e-06 
12/05/2021 15:32:19 - INFO - volta.train_utils -   [XVNLI]: iter 279040 Ep: 8.25 loss 0.003 score 0.107 lr 1.63168e-06 
12/05/2021 15:32:50 - INFO - volta.train_utils -   [XVNLI]: iter 279200 Ep: 8.26 loss 0.003 score 0.107 lr 1.63102e-06 
12/05/2021 15:33:21 - INFO - volta.train_utils -   [XVNLI]: iter 279360 Ep: 8.26 loss 0.003 score 0.107 lr 1.63036e-06 
12/05/2021 15:33:53 - INFO - volta.train_utils -   [XVNLI]: iter 279520 Ep: 8.27 loss 0.004 score 0.107 lr 1.62971e-06 
12/05/2021 15:34:24 - INFO - volta.train_utils -   [XVNLI]: iter 279680 Ep: 8.27 loss 0.004 score 0.107 lr 1.62905e-06 
12/05/2021 15:34:55 - INFO - volta.train_utils -   [XVNLI]: iter 279840 Ep: 8.28 loss 0.004 score 0.107 lr 1.62839e-06 
12/05/2021 15:35:26 - INFO - volta.train_utils -   [XVNLI]: iter 280000 Ep: 8.28 loss 0.004 score 0.107 lr 1.62774e-06 
12/05/2021 15:35:57 - INFO - volta.train_utils -   [XVNLI]: iter 280160 Ep: 8.29 loss 0.003 score 0.107 lr 1.62708e-06 
12/05/2021 15:36:28 - INFO - volta.train_utils -   [XVNLI]: iter 280320 Ep: 8.29 loss 0.003 score 0.108 lr 1.62642e-06 
12/05/2021 15:36:59 - INFO - volta.train_utils -   [XVNLI]: iter 280480 Ep: 8.30 loss 0.004 score 0.106 lr 1.62576e-06 
12/05/2021 15:37:30 - INFO - volta.train_utils -   [XVNLI]: iter 280640 Ep: 8.30 loss 0.004 score 0.107 lr 1.62511e-06 
12/05/2021 15:38:01 - INFO - volta.train_utils -   [XVNLI]: iter 280800 Ep: 8.31 loss 0.004 score 0.108 lr 1.62445e-06 
12/05/2021 15:38:32 - INFO - volta.train_utils -   [XVNLI]: iter 280960 Ep: 8.31 loss 0.004 score 0.106 lr 1.62379e-06 
12/05/2021 15:39:03 - INFO - volta.train_utils -   [XVNLI]: iter 281120 Ep: 8.32 loss 0.003 score 0.106 lr 1.62313e-06 
12/05/2021 15:39:34 - INFO - volta.train_utils -   [XVNLI]: iter 281280 Ep: 8.32 loss 0.003 score 0.109 lr 1.62248e-06 
12/05/2021 15:40:05 - INFO - volta.train_utils -   [XVNLI]: iter 281440 Ep: 8.33 loss 0.004 score 0.108 lr 1.62182e-06 
12/05/2021 15:40:37 - INFO - volta.train_utils -   [XVNLI]: iter 281600 Ep: 8.33 loss 0.004 score 0.108 lr 1.62116e-06 
12/05/2021 15:41:08 - INFO - volta.train_utils -   [XVNLI]: iter 281760 Ep: 8.33 loss 0.004 score 0.109 lr 1.6205e-06 
12/05/2021 15:41:39 - INFO - volta.train_utils -   [XVNLI]: iter 281920 Ep: 8.34 loss 0.004 score 0.105 lr 1.61985e-06 
12/05/2021 15:42:10 - INFO - volta.train_utils -   [XVNLI]: iter 282080 Ep: 8.34 loss 0.004 score 0.107 lr 1.61919e-06 
12/05/2021 15:42:41 - INFO - volta.train_utils -   [XVNLI]: iter 282240 Ep: 8.35 loss 0.003 score 0.107 lr 1.61853e-06 
12/05/2021 15:43:12 - INFO - volta.train_utils -   [XVNLI]: iter 282400 Ep: 8.35 loss 0.003 score 0.106 lr 1.61788e-06 
12/05/2021 15:43:43 - INFO - volta.train_utils -   [XVNLI]: iter 282560 Ep: 8.36 loss 0.003 score 0.106 lr 1.61722e-06 
12/05/2021 15:44:14 - INFO - volta.train_utils -   [XVNLI]: iter 282720 Ep: 8.36 loss 0.004 score 0.106 lr 1.61656e-06 
12/05/2021 15:44:46 - INFO - volta.train_utils -   [XVNLI]: iter 282880 Ep: 8.37 loss 0.004 score 0.106 lr 1.6159e-06 
12/05/2021 15:45:17 - INFO - volta.train_utils -   [XVNLI]: iter 283040 Ep: 8.37 loss 0.003 score 0.107 lr 1.61525e-06 
12/05/2021 15:45:48 - INFO - volta.train_utils -   [XVNLI]: iter 283200 Ep: 8.38 loss 0.003 score 0.108 lr 1.61459e-06 
12/05/2021 15:46:19 - INFO - volta.train_utils -   [XVNLI]: iter 283360 Ep: 8.38 loss 0.003 score 0.109 lr 1.61393e-06 
12/05/2021 15:46:50 - INFO - volta.train_utils -   [XVNLI]: iter 283520 Ep: 8.39 loss 0.003 score 0.108 lr 1.61327e-06 
12/05/2021 15:47:21 - INFO - volta.train_utils -   [XVNLI]: iter 283680 Ep: 8.39 loss 0.004 score 0.107 lr 1.61262e-06 
12/05/2021 15:47:52 - INFO - volta.train_utils -   [XVNLI]: iter 283840 Ep: 8.40 loss 0.003 score 0.106 lr 1.61196e-06 
12/05/2021 15:48:23 - INFO - volta.train_utils -   [XVNLI]: iter 284000 Ep: 8.40 loss 0.003 score 0.106 lr 1.6113e-06 
12/05/2021 15:48:54 - INFO - volta.train_utils -   [XVNLI]: iter 284160 Ep: 8.41 loss 0.004 score 0.108 lr 1.61064e-06 
12/05/2021 15:49:26 - INFO - volta.train_utils -   [XVNLI]: iter 284320 Ep: 8.41 loss 0.004 score 0.106 lr 1.60999e-06 
12/05/2021 15:49:57 - INFO - volta.train_utils -   [XVNLI]: iter 284480 Ep: 8.42 loss 0.004 score 0.107 lr 1.60933e-06 
12/05/2021 15:50:28 - INFO - volta.train_utils -   [XVNLI]: iter 284640 Ep: 8.42 loss 0.004 score 0.106 lr 1.60867e-06 
12/05/2021 15:50:59 - INFO - volta.train_utils -   [XVNLI]: iter 284800 Ep: 8.42 loss 0.003 score 0.106 lr 1.60802e-06 
12/05/2021 15:51:31 - INFO - volta.train_utils -   [XVNLI]: iter 284960 Ep: 8.43 loss 0.004 score 0.107 lr 1.60736e-06 
12/05/2021 15:52:02 - INFO - volta.train_utils -   [XVNLI]: iter 285120 Ep: 8.43 loss 0.003 score 0.107 lr 1.6067e-06 
12/05/2021 15:52:33 - INFO - volta.train_utils -   [XVNLI]: iter 285280 Ep: 8.44 loss 0.004 score 0.106 lr 1.60604e-06 
12/05/2021 15:53:05 - INFO - volta.train_utils -   [XVNLI]: iter 285440 Ep: 8.44 loss 0.003 score 0.107 lr 1.60539e-06 
12/05/2021 15:53:36 - INFO - volta.train_utils -   [XVNLI]: iter 285600 Ep: 8.45 loss 0.004 score 0.106 lr 1.60473e-06 
12/05/2021 15:54:07 - INFO - volta.train_utils -   [XVNLI]: iter 285760 Ep: 8.45 loss 0.004 score 0.107 lr 1.60407e-06 
12/05/2021 15:54:38 - INFO - volta.train_utils -   [XVNLI]: iter 285920 Ep: 8.46 loss 0.004 score 0.108 lr 1.60341e-06 
12/05/2021 15:55:09 - INFO - volta.train_utils -   [XVNLI]: iter 286080 Ep: 8.46 loss 0.004 score 0.106 lr 1.60276e-06 
12/05/2021 15:55:40 - INFO - volta.train_utils -   [XVNLI]: iter 286240 Ep: 8.47 loss 0.003 score 0.109 lr 1.6021e-06 
12/05/2021 15:56:11 - INFO - volta.train_utils -   [XVNLI]: iter 286400 Ep: 8.47 loss 0.004 score 0.105 lr 1.60144e-06 
12/05/2021 15:56:43 - INFO - volta.train_utils -   [XVNLI]: iter 286560 Ep: 8.48 loss 0.004 score 0.108 lr 1.60078e-06 
12/05/2021 15:57:14 - INFO - volta.train_utils -   [XVNLI]: iter 286720 Ep: 8.48 loss 0.003 score 0.107 lr 1.60013e-06 
12/05/2021 15:57:45 - INFO - volta.train_utils -   [XVNLI]: iter 286880 Ep: 8.49 loss 0.003 score 0.106 lr 1.59947e-06 
12/05/2021 15:58:16 - INFO - volta.train_utils -   [XVNLI]: iter 287040 Ep: 8.49 loss 0.003 score 0.107 lr 1.59881e-06 
12/05/2021 15:58:47 - INFO - volta.train_utils -   [XVNLI]: iter 287200 Ep: 8.50 loss 0.003 score 0.107 lr 1.59815e-06 
12/05/2021 15:59:18 - INFO - volta.train_utils -   [XVNLI]: iter 287360 Ep: 8.50 loss 0.003 score 0.107 lr 1.5975e-06 
12/05/2021 15:59:49 - INFO - volta.train_utils -   [XVNLI]: iter 287520 Ep: 8.50 loss 0.003 score 0.107 lr 1.59684e-06 
12/05/2021 16:00:20 - INFO - volta.train_utils -   [XVNLI]: iter 287680 Ep: 8.51 loss 0.004 score 0.108 lr 1.59618e-06 
12/05/2021 16:00:51 - INFO - volta.train_utils -   [XVNLI]: iter 287840 Ep: 8.51 loss 0.004 score 0.106 lr 1.59553e-06 
12/05/2021 16:01:22 - INFO - volta.train_utils -   [XVNLI]: iter 288000 Ep: 8.52 loss 0.004 score 0.107 lr 1.59487e-06 
12/05/2021 16:01:54 - INFO - volta.train_utils -   [XVNLI]: iter 288160 Ep: 8.52 loss 0.004 score 0.107 lr 1.59421e-06 
12/05/2021 16:02:25 - INFO - volta.train_utils -   [XVNLI]: iter 288320 Ep: 8.53 loss 0.003 score 0.108 lr 1.59355e-06 
12/05/2021 16:02:56 - INFO - volta.train_utils -   [XVNLI]: iter 288480 Ep: 8.53 loss 0.004 score 0.106 lr 1.5929e-06 
12/05/2021 16:03:28 - INFO - volta.train_utils -   [XVNLI]: iter 288640 Ep: 8.54 loss 0.004 score 0.106 lr 1.59224e-06 
12/05/2021 16:03:59 - INFO - volta.train_utils -   [XVNLI]: iter 288800 Ep: 8.54 loss 0.004 score 0.108 lr 1.59158e-06 
12/05/2021 16:04:30 - INFO - volta.train_utils -   [XVNLI]: iter 288960 Ep: 8.55 loss 0.004 score 0.107 lr 1.59092e-06 
12/05/2021 16:05:01 - INFO - volta.train_utils -   [XVNLI]: iter 289120 Ep: 8.55 loss 0.003 score 0.105 lr 1.59027e-06 
12/05/2021 16:05:32 - INFO - volta.train_utils -   [XVNLI]: iter 289280 Ep: 8.56 loss 0.004 score 0.107 lr 1.58961e-06 
12/05/2021 16:06:03 - INFO - volta.train_utils -   [XVNLI]: iter 289440 Ep: 8.56 loss 0.004 score 0.106 lr 1.58895e-06 
12/05/2021 16:06:34 - INFO - volta.train_utils -   [XVNLI]: iter 289600 Ep: 8.57 loss 0.004 score 0.107 lr 1.58829e-06 
12/05/2021 16:07:06 - INFO - volta.train_utils -   [XVNLI]: iter 289760 Ep: 8.57 loss 0.004 score 0.107 lr 1.58764e-06 
12/05/2021 16:07:37 - INFO - volta.train_utils -   [XVNLI]: iter 289920 Ep: 8.58 loss 0.003 score 0.108 lr 1.58698e-06 
12/05/2021 16:08:08 - INFO - volta.train_utils -   [XVNLI]: iter 290080 Ep: 8.58 loss 0.004 score 0.105 lr 1.58632e-06 
12/05/2021 16:08:39 - INFO - volta.train_utils -   [XVNLI]: iter 290240 Ep: 8.59 loss 0.003 score 0.107 lr 1.58567e-06 
12/05/2021 16:09:10 - INFO - volta.train_utils -   [XVNLI]: iter 290400 Ep: 8.59 loss 0.003 score 0.107 lr 1.58501e-06 
12/05/2021 16:09:42 - INFO - volta.train_utils -   [XVNLI]: iter 290560 Ep: 8.59 loss 0.004 score 0.108 lr 1.58435e-06 
12/05/2021 16:10:14 - INFO - volta.train_utils -   [XVNLI]: iter 290720 Ep: 8.60 loss 0.004 score 0.105 lr 1.58369e-06 
12/05/2021 16:10:45 - INFO - volta.train_utils -   [XVNLI]: iter 290880 Ep: 8.60 loss 0.004 score 0.107 lr 1.58304e-06 
12/05/2021 16:11:16 - INFO - volta.train_utils -   [XVNLI]: iter 291040 Ep: 8.61 loss 0.004 score 0.106 lr 1.58238e-06 
12/05/2021 16:11:47 - INFO - volta.train_utils -   [XVNLI]: iter 291200 Ep: 8.61 loss 0.003 score 0.107 lr 1.58172e-06 
12/05/2021 16:12:18 - INFO - volta.train_utils -   [XVNLI]: iter 291360 Ep: 8.62 loss 0.004 score 0.105 lr 1.58106e-06 
12/05/2021 16:12:49 - INFO - volta.train_utils -   [XVNLI]: iter 291520 Ep: 8.62 loss 0.004 score 0.106 lr 1.58041e-06 
12/05/2021 16:13:21 - INFO - volta.train_utils -   [XVNLI]: iter 291680 Ep: 8.63 loss 0.004 score 0.107 lr 1.57975e-06 
12/05/2021 16:13:52 - INFO - volta.train_utils -   [XVNLI]: iter 291840 Ep: 8.63 loss 0.004 score 0.108 lr 1.57909e-06 
12/05/2021 16:14:23 - INFO - volta.train_utils -   [XVNLI]: iter 292000 Ep: 8.64 loss 0.004 score 0.107 lr 1.57843e-06 
12/05/2021 16:14:55 - INFO - volta.train_utils -   [XVNLI]: iter 292160 Ep: 8.64 loss 0.004 score 0.107 lr 1.57778e-06 
12/05/2021 16:15:26 - INFO - volta.train_utils -   [XVNLI]: iter 292320 Ep: 8.65 loss 0.004 score 0.108 lr 1.57712e-06 
12/05/2021 16:15:57 - INFO - volta.train_utils -   [XVNLI]: iter 292480 Ep: 8.65 loss 0.004 score 0.106 lr 1.57646e-06 
12/05/2021 16:16:29 - INFO - volta.train_utils -   [XVNLI]: iter 292640 Ep: 8.66 loss 0.003 score 0.107 lr 1.57581e-06 
12/05/2021 16:17:00 - INFO - volta.train_utils -   [XVNLI]: iter 292800 Ep: 8.66 loss 0.004 score 0.108 lr 1.57515e-06 
12/05/2021 16:17:31 - INFO - volta.train_utils -   [XVNLI]: iter 292960 Ep: 8.67 loss 0.004 score 0.106 lr 1.57449e-06 
12/05/2021 16:18:02 - INFO - volta.train_utils -   [XVNLI]: iter 293120 Ep: 8.67 loss 0.004 score 0.108 lr 1.57383e-06 
12/05/2021 16:18:33 - INFO - volta.train_utils -   [XVNLI]: iter 293280 Ep: 8.68 loss 0.004 score 0.106 lr 1.57318e-06 
12/05/2021 16:19:04 - INFO - volta.train_utils -   [XVNLI]: iter 293440 Ep: 8.68 loss 0.003 score 0.107 lr 1.57252e-06 
12/05/2021 16:19:36 - INFO - volta.train_utils -   [XVNLI]: iter 293600 Ep: 8.68 loss 0.003 score 0.106 lr 1.57186e-06 
12/05/2021 16:20:07 - INFO - volta.train_utils -   [XVNLI]: iter 293760 Ep: 8.69 loss 0.004 score 0.106 lr 1.5712e-06 
12/05/2021 16:20:38 - INFO - volta.train_utils -   [XVNLI]: iter 293920 Ep: 8.69 loss 0.004 score 0.109 lr 1.57055e-06 
12/05/2021 16:21:09 - INFO - volta.train_utils -   [XVNLI]: iter 294080 Ep: 8.70 loss 0.003 score 0.107 lr 1.56989e-06 
12/05/2021 16:21:40 - INFO - volta.train_utils -   [XVNLI]: iter 294240 Ep: 8.70 loss 0.004 score 0.106 lr 1.56923e-06 
12/05/2021 16:22:11 - INFO - volta.train_utils -   [XVNLI]: iter 294400 Ep: 8.71 loss 0.003 score 0.107 lr 1.56857e-06 
12/05/2021 16:22:43 - INFO - volta.train_utils -   [XVNLI]: iter 294560 Ep: 8.71 loss 0.003 score 0.107 lr 1.56792e-06 
12/05/2021 16:23:14 - INFO - volta.train_utils -   [XVNLI]: iter 294720 Ep: 8.72 loss 0.003 score 0.106 lr 1.56726e-06 
12/05/2021 16:23:45 - INFO - volta.train_utils -   [XVNLI]: iter 294880 Ep: 8.72 loss 0.004 score 0.107 lr 1.5666e-06 
12/05/2021 16:24:16 - INFO - volta.train_utils -   [XVNLI]: iter 295040 Ep: 8.73 loss 0.004 score 0.106 lr 1.56594e-06 
12/05/2021 16:24:47 - INFO - volta.train_utils -   [XVNLI]: iter 295200 Ep: 8.73 loss 0.004 score 0.105 lr 1.56529e-06 
12/05/2021 16:25:18 - INFO - volta.train_utils -   [XVNLI]: iter 295360 Ep: 8.74 loss 0.003 score 0.107 lr 1.56463e-06 
12/05/2021 16:25:49 - INFO - volta.train_utils -   [XVNLI]: iter 295520 Ep: 8.74 loss 0.003 score 0.107 lr 1.56397e-06 
12/05/2021 16:26:21 - INFO - volta.train_utils -   [XVNLI]: iter 295680 Ep: 8.75 loss 0.004 score 0.106 lr 1.56332e-06 
12/05/2021 16:26:52 - INFO - volta.train_utils -   [XVNLI]: iter 295840 Ep: 8.75 loss 0.003 score 0.108 lr 1.56266e-06 
12/05/2021 16:27:23 - INFO - volta.train_utils -   [XVNLI]: iter 296000 Ep: 8.76 loss 0.003 score 0.106 lr 1.562e-06 
12/05/2021 16:27:54 - INFO - volta.train_utils -   [XVNLI]: iter 296160 Ep: 8.76 loss 0.004 score 0.106 lr 1.56134e-06 
12/05/2021 16:28:25 - INFO - volta.train_utils -   [XVNLI]: iter 296320 Ep: 8.77 loss 0.003 score 0.106 lr 1.56069e-06 
12/05/2021 16:28:56 - INFO - volta.train_utils -   [XVNLI]: iter 296480 Ep: 8.77 loss 0.004 score 0.107 lr 1.56003e-06 
12/05/2021 16:29:27 - INFO - volta.train_utils -   [XVNLI]: iter 296640 Ep: 8.77 loss 0.003 score 0.106 lr 1.55937e-06 
12/05/2021 16:29:58 - INFO - volta.train_utils -   [XVNLI]: iter 296800 Ep: 8.78 loss 0.004 score 0.106 lr 1.55871e-06 
12/05/2021 16:30:29 - INFO - volta.train_utils -   [XVNLI]: iter 296960 Ep: 8.78 loss 0.004 score 0.106 lr 1.55806e-06 
12/05/2021 16:31:00 - INFO - volta.train_utils -   [XVNLI]: iter 297120 Ep: 8.79 loss 0.004 score 0.105 lr 1.5574e-06 
12/05/2021 16:31:32 - INFO - volta.train_utils -   [XVNLI]: iter 297280 Ep: 8.79 loss 0.003 score 0.106 lr 1.55674e-06 
12/05/2021 16:32:03 - INFO - volta.train_utils -   [XVNLI]: iter 297440 Ep: 8.80 loss 0.004 score 0.106 lr 1.55608e-06 
12/05/2021 16:32:34 - INFO - volta.train_utils -   [XVNLI]: iter 297600 Ep: 8.80 loss 0.003 score 0.108 lr 1.55543e-06 
12/05/2021 16:33:05 - INFO - volta.train_utils -   [XVNLI]: iter 297760 Ep: 8.81 loss 0.004 score 0.106 lr 1.55477e-06 
12/05/2021 16:33:36 - INFO - volta.train_utils -   [XVNLI]: iter 297920 Ep: 8.81 loss 0.004 score 0.107 lr 1.55411e-06 
12/05/2021 16:34:07 - INFO - volta.train_utils -   [XVNLI]: iter 298080 Ep: 8.82 loss 0.003 score 0.108 lr 1.55346e-06 
12/05/2021 16:34:39 - INFO - volta.train_utils -   [XVNLI]: iter 298240 Ep: 8.82 loss 0.004 score 0.106 lr 1.5528e-06 
12/05/2021 16:35:09 - INFO - volta.train_utils -   [XVNLI]: iter 298400 Ep: 8.83 loss 0.004 score 0.106 lr 1.55214e-06 
12/05/2021 16:35:40 - INFO - volta.train_utils -   [XVNLI]: iter 298560 Ep: 8.83 loss 0.004 score 0.106 lr 1.55148e-06 
12/05/2021 16:36:11 - INFO - volta.train_utils -   [XVNLI]: iter 298720 Ep: 8.84 loss 0.004 score 0.106 lr 1.55083e-06 
12/05/2021 16:36:43 - INFO - volta.train_utils -   [XVNLI]: iter 298880 Ep: 8.84 loss 0.003 score 0.107 lr 1.55017e-06 
12/05/2021 16:37:14 - INFO - volta.train_utils -   [XVNLI]: iter 299040 Ep: 8.85 loss 0.004 score 0.106 lr 1.54951e-06 
12/05/2021 16:37:45 - INFO - volta.train_utils -   [XVNLI]: iter 299200 Ep: 8.85 loss 0.004 score 0.106 lr 1.54885e-06 
12/05/2021 16:38:16 - INFO - volta.train_utils -   [XVNLI]: iter 299360 Ep: 8.86 loss 0.004 score 0.106 lr 1.5482e-06 
12/05/2021 16:38:47 - INFO - volta.train_utils -   [XVNLI]: iter 299520 Ep: 8.86 loss 0.005 score 0.106 lr 1.54754e-06 
12/05/2021 16:39:18 - INFO - volta.train_utils -   [XVNLI]: iter 299680 Ep: 8.86 loss 0.003 score 0.106 lr 1.54688e-06 
12/05/2021 16:39:50 - INFO - volta.train_utils -   [XVNLI]: iter 299840 Ep: 8.87 loss 0.004 score 0.108 lr 1.54622e-06 
12/05/2021 16:40:21 - INFO - volta.train_utils -   [XVNLI]: iter 300000 Ep: 8.87 loss 0.003 score 0.107 lr 1.54557e-06 
12/05/2021 16:40:52 - INFO - volta.train_utils -   [XVNLI]: iter 300160 Ep: 8.88 loss 0.004 score 0.107 lr 1.54491e-06 
12/05/2021 16:41:23 - INFO - volta.train_utils -   [XVNLI]: iter 300320 Ep: 8.88 loss 0.003 score 0.106 lr 1.54425e-06 
12/05/2021 16:41:54 - INFO - volta.train_utils -   [XVNLI]: iter 300480 Ep: 8.89 loss 0.004 score 0.104 lr 1.5436e-06 
12/05/2021 16:42:26 - INFO - volta.train_utils -   [XVNLI]: iter 300640 Ep: 8.89 loss 0.004 score 0.105 lr 1.54294e-06 
12/05/2021 16:42:57 - INFO - volta.train_utils -   [XVNLI]: iter 300800 Ep: 8.90 loss 0.004 score 0.106 lr 1.54228e-06 
12/05/2021 16:43:28 - INFO - volta.train_utils -   [XVNLI]: iter 300960 Ep: 8.90 loss 0.003 score 0.107 lr 1.54162e-06 
12/05/2021 16:43:59 - INFO - volta.train_utils -   [XVNLI]: iter 301120 Ep: 8.91 loss 0.003 score 0.108 lr 1.54097e-06 
12/05/2021 16:44:30 - INFO - volta.train_utils -   [XVNLI]: iter 301280 Ep: 8.91 loss 0.004 score 0.107 lr 1.54031e-06 
12/05/2021 16:45:02 - INFO - volta.train_utils -   [XVNLI]: iter 301440 Ep: 8.92 loss 0.004 score 0.106 lr 1.53965e-06 
12/05/2021 16:45:33 - INFO - volta.train_utils -   [XVNLI]: iter 301600 Ep: 8.92 loss 0.003 score 0.106 lr 1.53899e-06 
12/05/2021 16:46:04 - INFO - volta.train_utils -   [XVNLI]: iter 301760 Ep: 8.93 loss 0.004 score 0.106 lr 1.53834e-06 
12/05/2021 16:46:35 - INFO - volta.train_utils -   [XVNLI]: iter 301920 Ep: 8.93 loss 0.004 score 0.106 lr 1.53768e-06 
12/05/2021 16:47:06 - INFO - volta.train_utils -   [XVNLI]: iter 302080 Ep: 8.94 loss 0.004 score 0.106 lr 1.53702e-06 
12/05/2021 16:47:38 - INFO - volta.train_utils -   [XVNLI]: iter 302240 Ep: 8.94 loss 0.004 score 0.107 lr 1.53636e-06 
12/05/2021 16:48:09 - INFO - volta.train_utils -   [XVNLI]: iter 302400 Ep: 8.95 loss 0.004 score 0.106 lr 1.53571e-06 
12/05/2021 16:48:40 - INFO - volta.train_utils -   [XVNLI]: iter 302560 Ep: 8.95 loss 0.003 score 0.106 lr 1.53505e-06 
12/05/2021 16:49:11 - INFO - volta.train_utils -   [XVNLI]: iter 302720 Ep: 8.95 loss 0.004 score 0.107 lr 1.53439e-06 
12/05/2021 16:49:42 - INFO - volta.train_utils -   [XVNLI]: iter 302880 Ep: 8.96 loss 0.003 score 0.108 lr 1.53373e-06 
12/05/2021 16:50:14 - INFO - volta.train_utils -   [XVNLI]: iter 303040 Ep: 8.96 loss 0.004 score 0.106 lr 1.53308e-06 
12/05/2021 16:50:45 - INFO - volta.train_utils -   [XVNLI]: iter 303200 Ep: 8.97 loss 0.003 score 0.108 lr 1.53242e-06 
12/05/2021 16:51:16 - INFO - volta.train_utils -   [XVNLI]: iter 303360 Ep: 8.97 loss 0.003 score 0.108 lr 1.53176e-06 
12/05/2021 16:51:47 - INFO - volta.train_utils -   [XVNLI]: iter 303520 Ep: 8.98 loss 0.003 score 0.106 lr 1.53111e-06 
12/05/2021 16:52:18 - INFO - volta.train_utils -   [XVNLI]: iter 303680 Ep: 8.98 loss 0.004 score 0.106 lr 1.53045e-06 
12/05/2021 16:52:49 - INFO - volta.train_utils -   [XVNLI]: iter 303840 Ep: 8.99 loss 0.003 score 0.106 lr 1.52979e-06 
12/05/2021 16:53:20 - INFO - volta.train_utils -   [XVNLI]: iter 304000 Ep: 8.99 loss 0.004 score 0.106 lr 1.52913e-06 
12/05/2021 16:53:51 - INFO - volta.train_utils -   [XVNLI]: iter 304160 Ep: 9.00 loss 0.003 score 0.106 lr 1.52848e-06 
12/05/2021 16:57:45 - INFO - volta.train_utils -   Eval task TASK19 on iteration 304200 
12/05/2021 16:57:45 - INFO - volta.train_utils -   Validation [XVNLI]: loss 0.432 score 75.162 
Epoch:  90%|█████████ | 9/10 [17:19:11<1:54:12, 6852.93s/it]12/05/2021 16:58:21 - INFO - volta.train_utils -   [XVNLI]: iter 304360 Ep: 9.00 loss 0.003 score 0.113 lr 1.52774e-06 
12/05/2021 16:58:52 - INFO - volta.train_utils -   [XVNLI]: iter 304520 Ep: 9.01 loss 0.003 score 0.109 lr 1.527e-06 
12/05/2021 16:59:23 - INFO - volta.train_utils -   [XVNLI]: iter 304680 Ep: 9.01 loss 0.003 score 0.110 lr 1.52634e-06 
12/05/2021 16:59:54 - INFO - volta.train_utils -   [XVNLI]: iter 304840 Ep: 9.02 loss 0.003 score 0.109 lr 1.52568e-06 
12/05/2021 17:00:25 - INFO - volta.train_utils -   [XVNLI]: iter 305000 Ep: 9.02 loss 0.003 score 0.109 lr 1.52503e-06 
12/05/2021 17:00:56 - INFO - volta.train_utils -   [XVNLI]: iter 305160 Ep: 9.03 loss 0.003 score 0.111 lr 1.52437e-06 
12/05/2021 17:01:28 - INFO - volta.train_utils -   [XVNLI]: iter 305320 Ep: 9.03 loss 0.003 score 0.109 lr 1.52371e-06 
12/05/2021 17:02:02 - INFO - volta.train_utils -   [XVNLI]: iter 305480 Ep: 9.04 loss 0.003 score 0.110 lr 1.52305e-06 
12/05/2021 17:02:32 - INFO - volta.train_utils -   [XVNLI]: iter 305640 Ep: 9.04 loss 0.003 score 0.110 lr 1.5224e-06 
12/05/2021 17:03:04 - INFO - volta.train_utils -   [XVNLI]: iter 305800 Ep: 9.05 loss 0.003 score 0.107 lr 1.52174e-06 
12/05/2021 17:03:35 - INFO - volta.train_utils -   [XVNLI]: iter 305960 Ep: 9.05 loss 0.003 score 0.108 lr 1.52108e-06 
12/05/2021 17:04:06 - INFO - volta.train_utils -   [XVNLI]: iter 306120 Ep: 9.06 loss 0.003 score 0.108 lr 1.52042e-06 
12/05/2021 17:04:37 - INFO - volta.train_utils -   [XVNLI]: iter 306280 Ep: 9.06 loss 0.003 score 0.109 lr 1.51977e-06 
12/05/2021 17:05:08 - INFO - volta.train_utils -   [XVNLI]: iter 306440 Ep: 9.06 loss 0.004 score 0.109 lr 1.51911e-06 
12/05/2021 17:05:39 - INFO - volta.train_utils -   [XVNLI]: iter 306600 Ep: 9.07 loss 0.003 score 0.109 lr 1.51845e-06 
12/05/2021 17:06:10 - INFO - volta.train_utils -   [XVNLI]: iter 306760 Ep: 9.07 loss 0.003 score 0.109 lr 1.51779e-06 
12/05/2021 17:06:41 - INFO - volta.train_utils -   [XVNLI]: iter 306920 Ep: 9.08 loss 0.003 score 0.110 lr 1.51714e-06 
12/05/2021 17:07:12 - INFO - volta.train_utils -   [XVNLI]: iter 307080 Ep: 9.08 loss 0.003 score 0.110 lr 1.51648e-06 
12/05/2021 17:07:43 - INFO - volta.train_utils -   [XVNLI]: iter 307240 Ep: 9.09 loss 0.004 score 0.108 lr 1.51582e-06 
12/05/2021 17:08:14 - INFO - volta.train_utils -   [XVNLI]: iter 307400 Ep: 9.09 loss 0.003 score 0.107 lr 1.51516e-06 
12/05/2021 17:08:45 - INFO - volta.train_utils -   [XVNLI]: iter 307560 Ep: 9.10 loss 0.003 score 0.109 lr 1.51451e-06 
12/05/2021 17:09:16 - INFO - volta.train_utils -   [XVNLI]: iter 307720 Ep: 9.10 loss 0.003 score 0.108 lr 1.51385e-06 
12/05/2021 17:09:48 - INFO - volta.train_utils -   [XVNLI]: iter 307880 Ep: 9.11 loss 0.004 score 0.110 lr 1.51319e-06 
12/05/2021 17:10:19 - INFO - volta.train_utils -   [XVNLI]: iter 308040 Ep: 9.11 loss 0.003 score 0.109 lr 1.51254e-06 
12/05/2021 17:10:50 - INFO - volta.train_utils -   [XVNLI]: iter 308200 Ep: 9.12 loss 0.003 score 0.107 lr 1.51188e-06 
12/05/2021 17:11:21 - INFO - volta.train_utils -   [XVNLI]: iter 308360 Ep: 9.12 loss 0.003 score 0.109 lr 1.51122e-06 
12/05/2021 17:11:52 - INFO - volta.train_utils -   [XVNLI]: iter 308520 Ep: 9.13 loss 0.004 score 0.108 lr 1.51056e-06 
12/05/2021 17:12:23 - INFO - volta.train_utils -   [XVNLI]: iter 308680 Ep: 9.13 loss 0.003 score 0.110 lr 1.50991e-06 
12/05/2021 17:12:54 - INFO - volta.train_utils -   [XVNLI]: iter 308840 Ep: 9.14 loss 0.003 score 0.109 lr 1.50925e-06 
12/05/2021 17:13:25 - INFO - volta.train_utils -   [XVNLI]: iter 309000 Ep: 9.14 loss 0.003 score 0.109 lr 1.50859e-06 
12/05/2021 17:13:56 - INFO - volta.train_utils -   [XVNLI]: iter 309160 Ep: 9.15 loss 0.003 score 0.109 lr 1.50793e-06 
12/05/2021 17:14:27 - INFO - volta.train_utils -   [XVNLI]: iter 309320 Ep: 9.15 loss 0.003 score 0.109 lr 1.50728e-06 
12/05/2021 17:14:58 - INFO - volta.train_utils -   [XVNLI]: iter 309480 Ep: 9.15 loss 0.003 score 0.109 lr 1.50662e-06 
12/05/2021 17:15:30 - INFO - volta.train_utils -   [XVNLI]: iter 309640 Ep: 9.16 loss 0.003 score 0.108 lr 1.50596e-06 
12/05/2021 17:16:01 - INFO - volta.train_utils -   [XVNLI]: iter 309800 Ep: 9.16 loss 0.004 score 0.109 lr 1.5053e-06 
12/05/2021 17:16:32 - INFO - volta.train_utils -   [XVNLI]: iter 309960 Ep: 9.17 loss 0.003 score 0.108 lr 1.50465e-06 
12/05/2021 17:17:03 - INFO - volta.train_utils -   [XVNLI]: iter 310120 Ep: 9.17 loss 0.003 score 0.109 lr 1.50399e-06 
12/05/2021 17:17:34 - INFO - volta.train_utils -   [XVNLI]: iter 310280 Ep: 9.18 loss 0.003 score 0.108 lr 1.50333e-06 
12/05/2021 17:18:06 - INFO - volta.train_utils -   [XVNLI]: iter 310440 Ep: 9.18 loss 0.003 score 0.110 lr 1.50268e-06 
12/05/2021 17:18:37 - INFO - volta.train_utils -   [XVNLI]: iter 310600 Ep: 9.19 loss 0.003 score 0.110 lr 1.50202e-06 
12/05/2021 17:19:08 - INFO - volta.train_utils -   [XVNLI]: iter 310760 Ep: 9.19 loss 0.003 score 0.108 lr 1.50136e-06 
12/05/2021 17:19:39 - INFO - volta.train_utils -   [XVNLI]: iter 310920 Ep: 9.20 loss 0.003 score 0.111 lr 1.5007e-06 
12/05/2021 17:20:11 - INFO - volta.train_utils -   [XVNLI]: iter 311080 Ep: 9.20 loss 0.004 score 0.108 lr 1.50005e-06 
12/05/2021 17:20:42 - INFO - volta.train_utils -   [XVNLI]: iter 311240 Ep: 9.21 loss 0.003 score 0.109 lr 1.49939e-06 
12/05/2021 17:21:13 - INFO - volta.train_utils -   [XVNLI]: iter 311400 Ep: 9.21 loss 0.004 score 0.108 lr 1.49873e-06 
12/05/2021 17:21:44 - INFO - volta.train_utils -   [XVNLI]: iter 311560 Ep: 9.22 loss 0.003 score 0.110 lr 1.49807e-06 
12/05/2021 17:22:15 - INFO - volta.train_utils -   [XVNLI]: iter 311720 Ep: 9.22 loss 0.003 score 0.109 lr 1.49742e-06 
12/05/2021 17:22:46 - INFO - volta.train_utils -   [XVNLI]: iter 311880 Ep: 9.23 loss 0.003 score 0.108 lr 1.49676e-06 
12/05/2021 17:23:17 - INFO - volta.train_utils -   [XVNLI]: iter 312040 Ep: 9.23 loss 0.004 score 0.110 lr 1.4961e-06 
12/05/2021 17:23:48 - INFO - volta.train_utils -   [XVNLI]: iter 312200 Ep: 9.24 loss 0.002 score 0.111 lr 1.49544e-06 
12/05/2021 17:24:19 - INFO - volta.train_utils -   [XVNLI]: iter 312360 Ep: 9.24 loss 0.003 score 0.110 lr 1.49479e-06 
12/05/2021 17:24:50 - INFO - volta.train_utils -   [XVNLI]: iter 312520 Ep: 9.24 loss 0.003 score 0.108 lr 1.49413e-06 
12/05/2021 17:25:21 - INFO - volta.train_utils -   [XVNLI]: iter 312680 Ep: 9.25 loss 0.004 score 0.107 lr 1.49347e-06 
12/05/2021 17:25:52 - INFO - volta.train_utils -   [XVNLI]: iter 312840 Ep: 9.25 loss 0.003 score 0.110 lr 1.49282e-06 
12/05/2021 17:26:23 - INFO - volta.train_utils -   [XVNLI]: iter 313000 Ep: 9.26 loss 0.004 score 0.107 lr 1.49216e-06 
12/05/2021 17:26:54 - INFO - volta.train_utils -   [XVNLI]: iter 313160 Ep: 9.26 loss 0.003 score 0.110 lr 1.4915e-06 
12/05/2021 17:27:26 - INFO - volta.train_utils -   [XVNLI]: iter 313320 Ep: 9.27 loss 0.004 score 0.106 lr 1.49084e-06 
12/05/2021 17:27:57 - INFO - volta.train_utils -   [XVNLI]: iter 313480 Ep: 9.27 loss 0.003 score 0.108 lr 1.49019e-06 
12/05/2021 17:28:28 - INFO - volta.train_utils -   [XVNLI]: iter 313640 Ep: 9.28 loss 0.003 score 0.109 lr 1.48953e-06 
12/05/2021 17:28:59 - INFO - volta.train_utils -   [XVNLI]: iter 313800 Ep: 9.28 loss 0.004 score 0.107 lr 1.48887e-06 
12/05/2021 17:29:30 - INFO - volta.train_utils -   [XVNLI]: iter 313960 Ep: 9.29 loss 0.004 score 0.109 lr 1.48821e-06 
12/05/2021 17:30:01 - INFO - volta.train_utils -   [XVNLI]: iter 314120 Ep: 9.29 loss 0.004 score 0.108 lr 1.48756e-06 
12/05/2021 17:30:32 - INFO - volta.train_utils -   [XVNLI]: iter 314280 Ep: 9.30 loss 0.003 score 0.108 lr 1.4869e-06 
12/05/2021 17:31:03 - INFO - volta.train_utils -   [XVNLI]: iter 314440 Ep: 9.30 loss 0.003 score 0.108 lr 1.48624e-06 
12/05/2021 17:31:34 - INFO - volta.train_utils -   [XVNLI]: iter 314600 Ep: 9.31 loss 0.003 score 0.108 lr 1.48558e-06 
12/05/2021 17:32:06 - INFO - volta.train_utils -   [XVNLI]: iter 314760 Ep: 9.31 loss 0.003 score 0.108 lr 1.48493e-06 
12/05/2021 17:32:37 - INFO - volta.train_utils -   [XVNLI]: iter 314920 Ep: 9.32 loss 0.003 score 0.108 lr 1.48427e-06 
12/05/2021 17:33:08 - INFO - volta.train_utils -   [XVNLI]: iter 315080 Ep: 9.32 loss 0.004 score 0.108 lr 1.48361e-06 
12/05/2021 17:33:39 - INFO - volta.train_utils -   [XVNLI]: iter 315240 Ep: 9.32 loss 0.003 score 0.110 lr 1.48296e-06 
12/05/2021 17:34:10 - INFO - volta.train_utils -   [XVNLI]: iter 315400 Ep: 9.33 loss 0.004 score 0.108 lr 1.4823e-06 
12/05/2021 17:34:41 - INFO - volta.train_utils -   [XVNLI]: iter 315560 Ep: 9.33 loss 0.003 score 0.108 lr 1.48164e-06 
12/05/2021 17:35:13 - INFO - volta.train_utils -   [XVNLI]: iter 315720 Ep: 9.34 loss 0.004 score 0.109 lr 1.48098e-06 
12/05/2021 17:35:44 - INFO - volta.train_utils -   [XVNLI]: iter 315880 Ep: 9.34 loss 0.003 score 0.110 lr 1.48033e-06 
12/05/2021 17:36:15 - INFO - volta.train_utils -   [XVNLI]: iter 316040 Ep: 9.35 loss 0.003 score 0.109 lr 1.47967e-06 
12/05/2021 17:36:46 - INFO - volta.train_utils -   [XVNLI]: iter 316200 Ep: 9.35 loss 0.004 score 0.108 lr 1.47901e-06 
12/05/2021 17:37:17 - INFO - volta.train_utils -   [XVNLI]: iter 316360 Ep: 9.36 loss 0.003 score 0.108 lr 1.47835e-06 
12/05/2021 17:37:48 - INFO - volta.train_utils -   [XVNLI]: iter 316520 Ep: 9.36 loss 0.003 score 0.109 lr 1.4777e-06 
12/05/2021 17:38:19 - INFO - volta.train_utils -   [XVNLI]: iter 316680 Ep: 9.37 loss 0.004 score 0.108 lr 1.47704e-06 
12/05/2021 17:38:50 - INFO - volta.train_utils -   [XVNLI]: iter 316840 Ep: 9.37 loss 0.003 score 0.108 lr 1.47638e-06 
12/05/2021 17:39:21 - INFO - volta.train_utils -   [XVNLI]: iter 317000 Ep: 9.38 loss 0.003 score 0.110 lr 1.47572e-06 
12/05/2021 17:39:53 - INFO - volta.train_utils -   [XVNLI]: iter 317160 Ep: 9.38 loss 0.003 score 0.108 lr 1.47507e-06 
12/05/2021 17:40:24 - INFO - volta.train_utils -   [XVNLI]: iter 317320 Ep: 9.39 loss 0.004 score 0.107 lr 1.47441e-06 
12/05/2021 17:40:55 - INFO - volta.train_utils -   [XVNLI]: iter 317480 Ep: 9.39 loss 0.003 score 0.109 lr 1.47375e-06 
12/05/2021 17:41:26 - INFO - volta.train_utils -   [XVNLI]: iter 317640 Ep: 9.40 loss 0.003 score 0.108 lr 1.47309e-06 
12/05/2021 17:41:57 - INFO - volta.train_utils -   [XVNLI]: iter 317800 Ep: 9.40 loss 0.003 score 0.109 lr 1.47244e-06 
12/05/2021 17:42:28 - INFO - volta.train_utils -   [XVNLI]: iter 317960 Ep: 9.41 loss 0.003 score 0.108 lr 1.47178e-06 
12/05/2021 17:42:59 - INFO - volta.train_utils -   [XVNLI]: iter 318120 Ep: 9.41 loss 0.003 score 0.107 lr 1.47112e-06 
12/05/2021 17:43:30 - INFO - volta.train_utils -   [XVNLI]: iter 318280 Ep: 9.41 loss 0.003 score 0.108 lr 1.47047e-06 
12/05/2021 17:44:01 - INFO - volta.train_utils -   [XVNLI]: iter 318440 Ep: 9.42 loss 0.003 score 0.108 lr 1.46981e-06 
12/05/2021 17:44:32 - INFO - volta.train_utils -   [XVNLI]: iter 318600 Ep: 9.42 loss 0.003 score 0.109 lr 1.46915e-06 
12/05/2021 17:45:03 - INFO - volta.train_utils -   [XVNLI]: iter 318760 Ep: 9.43 loss 0.003 score 0.108 lr 1.46849e-06 
12/05/2021 17:45:34 - INFO - volta.train_utils -   [XVNLI]: iter 318920 Ep: 9.43 loss 0.003 score 0.108 lr 1.46784e-06 
12/05/2021 17:46:05 - INFO - volta.train_utils -   [XVNLI]: iter 319080 Ep: 9.44 loss 0.003 score 0.108 lr 1.46718e-06 
12/05/2021 17:46:36 - INFO - volta.train_utils -   [XVNLI]: iter 319240 Ep: 9.44 loss 0.004 score 0.108 lr 1.46652e-06 
12/05/2021 17:47:07 - INFO - volta.train_utils -   [XVNLI]: iter 319400 Ep: 9.45 loss 0.004 score 0.107 lr 1.46586e-06 
12/05/2021 17:47:39 - INFO - volta.train_utils -   [XVNLI]: iter 319560 Ep: 9.45 loss 0.004 score 0.107 lr 1.46521e-06 
12/05/2021 17:48:10 - INFO - volta.train_utils -   [XVNLI]: iter 319720 Ep: 9.46 loss 0.004 score 0.108 lr 1.46455e-06 
12/05/2021 17:48:42 - INFO - volta.train_utils -   [XVNLI]: iter 319880 Ep: 9.46 loss 0.003 score 0.108 lr 1.46389e-06 
12/05/2021 17:49:13 - INFO - volta.train_utils -   [XVNLI]: iter 320040 Ep: 9.47 loss 0.004 score 0.108 lr 1.46323e-06 
12/05/2021 17:49:44 - INFO - volta.train_utils -   [XVNLI]: iter 320200 Ep: 9.47 loss 0.004 score 0.109 lr 1.46258e-06 
12/05/2021 17:50:15 - INFO - volta.train_utils -   [XVNLI]: iter 320360 Ep: 9.48 loss 0.004 score 0.107 lr 1.46192e-06 
12/05/2021 17:50:46 - INFO - volta.train_utils -   [XVNLI]: iter 320520 Ep: 9.48 loss 0.003 score 0.108 lr 1.46126e-06 
12/05/2021 17:51:17 - INFO - volta.train_utils -   [XVNLI]: iter 320680 Ep: 9.49 loss 0.003 score 0.108 lr 1.46061e-06 
12/05/2021 17:51:48 - INFO - volta.train_utils -   [XVNLI]: iter 320840 Ep: 9.49 loss 0.003 score 0.107 lr 1.45995e-06 
12/05/2021 17:52:20 - INFO - volta.train_utils -   [XVNLI]: iter 321000 Ep: 9.50 loss 0.003 score 0.107 lr 1.45929e-06 
12/05/2021 17:52:52 - INFO - volta.train_utils -   [XVNLI]: iter 321160 Ep: 9.50 loss 0.004 score 0.108 lr 1.45863e-06 
12/05/2021 17:53:23 - INFO - volta.train_utils -   [XVNLI]: iter 321320 Ep: 9.50 loss 0.003 score 0.110 lr 1.45798e-06 
12/05/2021 17:53:54 - INFO - volta.train_utils -   [XVNLI]: iter 321480 Ep: 9.51 loss 0.003 score 0.109 lr 1.45732e-06 
12/05/2021 17:54:25 - INFO - volta.train_utils -   [XVNLI]: iter 321640 Ep: 9.51 loss 0.004 score 0.108 lr 1.45666e-06 
12/05/2021 17:54:57 - INFO - volta.train_utils -   [XVNLI]: iter 321800 Ep: 9.52 loss 0.003 score 0.108 lr 1.456e-06 
12/05/2021 17:55:28 - INFO - volta.train_utils -   [XVNLI]: iter 321960 Ep: 9.52 loss 0.004 score 0.107 lr 1.45535e-06 
12/05/2021 17:55:59 - INFO - volta.train_utils -   [XVNLI]: iter 322120 Ep: 9.53 loss 0.003 score 0.108 lr 1.45469e-06 
12/05/2021 17:56:30 - INFO - volta.train_utils -   [XVNLI]: iter 322280 Ep: 9.53 loss 0.004 score 0.109 lr 1.45403e-06 
12/05/2021 17:57:01 - INFO - volta.train_utils -   [XVNLI]: iter 322440 Ep: 9.54 loss 0.003 score 0.108 lr 1.45337e-06 
12/05/2021 17:57:32 - INFO - volta.train_utils -   [XVNLI]: iter 322600 Ep: 9.54 loss 0.003 score 0.109 lr 1.45272e-06 
12/05/2021 17:58:03 - INFO - volta.train_utils -   [XVNLI]: iter 322760 Ep: 9.55 loss 0.003 score 0.108 lr 1.45206e-06 
12/05/2021 17:58:35 - INFO - volta.train_utils -   [XVNLI]: iter 322920 Ep: 9.55 loss 0.003 score 0.107 lr 1.4514e-06 
12/05/2021 17:59:06 - INFO - volta.train_utils -   [XVNLI]: iter 323080 Ep: 9.56 loss 0.003 score 0.108 lr 1.45075e-06 
12/05/2021 17:59:37 - INFO - volta.train_utils -   [XVNLI]: iter 323240 Ep: 9.56 loss 0.004 score 0.108 lr 1.45009e-06 
12/05/2021 18:00:08 - INFO - volta.train_utils -   [XVNLI]: iter 323400 Ep: 9.57 loss 0.003 score 0.108 lr 1.44943e-06 
12/05/2021 18:00:39 - INFO - volta.train_utils -   [XVNLI]: iter 323560 Ep: 9.57 loss 0.003 score 0.108 lr 1.44877e-06 
12/05/2021 18:01:10 - INFO - volta.train_utils -   [XVNLI]: iter 323720 Ep: 9.58 loss 0.003 score 0.108 lr 1.44812e-06 
12/05/2021 18:01:41 - INFO - volta.train_utils -   [XVNLI]: iter 323880 Ep: 9.58 loss 0.003 score 0.107 lr 1.44746e-06 
12/05/2021 18:02:13 - INFO - volta.train_utils -   [XVNLI]: iter 324040 Ep: 9.59 loss 0.004 score 0.107 lr 1.4468e-06 
12/05/2021 18:02:44 - INFO - volta.train_utils -   [XVNLI]: iter 324200 Ep: 9.59 loss 0.003 score 0.109 lr 1.44614e-06 
12/05/2021 18:03:16 - INFO - volta.train_utils -   [XVNLI]: iter 324360 Ep: 9.59 loss 0.003 score 0.108 lr 1.44549e-06 
12/05/2021 18:03:47 - INFO - volta.train_utils -   [XVNLI]: iter 324520 Ep: 9.60 loss 0.004 score 0.108 lr 1.44483e-06 
12/05/2021 18:04:18 - INFO - volta.train_utils -   [XVNLI]: iter 324680 Ep: 9.60 loss 0.003 score 0.109 lr 1.44417e-06 
12/05/2021 18:04:49 - INFO - volta.train_utils -   [XVNLI]: iter 324840 Ep: 9.61 loss 0.004 score 0.107 lr 1.44351e-06 
12/05/2021 18:05:20 - INFO - volta.train_utils -   [XVNLI]: iter 325000 Ep: 9.61 loss 0.004 score 0.107 lr 1.44286e-06 
12/05/2021 18:05:52 - INFO - volta.train_utils -   [XVNLI]: iter 325160 Ep: 9.62 loss 0.004 score 0.108 lr 1.4422e-06 
12/05/2021 18:06:23 - INFO - volta.train_utils -   [XVNLI]: iter 325320 Ep: 9.62 loss 0.003 score 0.108 lr 1.44154e-06 
12/05/2021 18:06:54 - INFO - volta.train_utils -   [XVNLI]: iter 325480 Ep: 9.63 loss 0.003 score 0.108 lr 1.44088e-06 
12/05/2021 18:07:25 - INFO - volta.train_utils -   [XVNLI]: iter 325640 Ep: 9.63 loss 0.003 score 0.109 lr 1.44023e-06 
12/05/2021 18:07:56 - INFO - volta.train_utils -   [XVNLI]: iter 325800 Ep: 9.64 loss 0.004 score 0.108 lr 1.43957e-06 
12/05/2021 18:08:27 - INFO - volta.train_utils -   [XVNLI]: iter 325960 Ep: 9.64 loss 0.003 score 0.109 lr 1.43891e-06 
12/05/2021 18:08:58 - INFO - volta.train_utils -   [XVNLI]: iter 326120 Ep: 9.65 loss 0.004 score 0.108 lr 1.43826e-06 
12/05/2021 18:09:29 - INFO - volta.train_utils -   [XVNLI]: iter 326280 Ep: 9.65 loss 0.003 score 0.108 lr 1.4376e-06 
12/05/2021 18:10:01 - INFO - volta.train_utils -   [XVNLI]: iter 326440 Ep: 9.66 loss 0.003 score 0.108 lr 1.43694e-06 
12/05/2021 18:10:32 - INFO - volta.train_utils -   [XVNLI]: iter 326600 Ep: 9.66 loss 0.004 score 0.107 lr 1.43628e-06 
12/05/2021 18:11:03 - INFO - volta.train_utils -   [XVNLI]: iter 326760 Ep: 9.67 loss 0.003 score 0.108 lr 1.43563e-06 
12/05/2021 18:11:34 - INFO - volta.train_utils -   [XVNLI]: iter 326920 Ep: 9.67 loss 0.004 score 0.109 lr 1.43497e-06 
12/05/2021 18:12:06 - INFO - volta.train_utils -   [XVNLI]: iter 327080 Ep: 9.68 loss 0.003 score 0.108 lr 1.43431e-06 
12/05/2021 18:12:37 - INFO - volta.train_utils -   [XVNLI]: iter 327240 Ep: 9.68 loss 0.003 score 0.108 lr 1.43365e-06 
12/05/2021 18:13:08 - INFO - volta.train_utils -   [XVNLI]: iter 327400 Ep: 9.68 loss 0.004 score 0.108 lr 1.433e-06 
12/05/2021 18:13:39 - INFO - volta.train_utils -   [XVNLI]: iter 327560 Ep: 9.69 loss 0.004 score 0.107 lr 1.43234e-06 
12/05/2021 18:14:10 - INFO - volta.train_utils -   [XVNLI]: iter 327720 Ep: 9.69 loss 0.003 score 0.109 lr 1.43168e-06 
12/05/2021 18:14:41 - INFO - volta.train_utils -   [XVNLI]: iter 327880 Ep: 9.70 loss 0.003 score 0.108 lr 1.43102e-06 
12/05/2021 18:15:13 - INFO - volta.train_utils -   [XVNLI]: iter 328040 Ep: 9.70 loss 0.003 score 0.109 lr 1.43037e-06 
12/05/2021 18:15:44 - INFO - volta.train_utils -   [XVNLI]: iter 328200 Ep: 9.71 loss 0.003 score 0.108 lr 1.42971e-06 
12/05/2021 18:16:15 - INFO - volta.train_utils -   [XVNLI]: iter 328360 Ep: 9.71 loss 0.003 score 0.109 lr 1.42905e-06 
12/05/2021 18:16:46 - INFO - volta.train_utils -   [XVNLI]: iter 328520 Ep: 9.72 loss 0.004 score 0.108 lr 1.4284e-06 
12/05/2021 18:17:17 - INFO - volta.train_utils -   [XVNLI]: iter 328680 Ep: 9.72 loss 0.004 score 0.109 lr 1.42774e-06 
12/05/2021 18:17:48 - INFO - volta.train_utils -   [XVNLI]: iter 328840 Ep: 9.73 loss 0.003 score 0.108 lr 1.42708e-06 
12/05/2021 18:18:20 - INFO - volta.train_utils -   [XVNLI]: iter 329000 Ep: 9.73 loss 0.003 score 0.107 lr 1.42642e-06 
12/05/2021 18:18:51 - INFO - volta.train_utils -   [XVNLI]: iter 329160 Ep: 9.74 loss 0.004 score 0.109 lr 1.42577e-06 
12/05/2021 18:19:22 - INFO - volta.train_utils -   [XVNLI]: iter 329320 Ep: 9.74 loss 0.003 score 0.109 lr 1.42511e-06 
12/05/2021 18:19:53 - INFO - volta.train_utils -   [XVNLI]: iter 329480 Ep: 9.75 loss 0.003 score 0.109 lr 1.42445e-06 
12/05/2021 18:20:24 - INFO - volta.train_utils -   [XVNLI]: iter 329640 Ep: 9.75 loss 0.003 score 0.108 lr 1.42379e-06 
12/05/2021 18:20:55 - INFO - volta.train_utils -   [XVNLI]: iter 329800 Ep: 9.76 loss 0.004 score 0.108 lr 1.42314e-06 
12/05/2021 18:21:26 - INFO - volta.train_utils -   [XVNLI]: iter 329960 Ep: 9.76 loss 0.003 score 0.109 lr 1.42248e-06 
12/05/2021 18:21:57 - INFO - volta.train_utils -   [XVNLI]: iter 330120 Ep: 9.77 loss 0.004 score 0.109 lr 1.42182e-06 
12/05/2021 18:22:29 - INFO - volta.train_utils -   [XVNLI]: iter 330280 Ep: 9.77 loss 0.004 score 0.108 lr 1.42116e-06 
12/05/2021 18:23:00 - INFO - volta.train_utils -   [XVNLI]: iter 330440 Ep: 9.77 loss 0.004 score 0.108 lr 1.42051e-06 
12/05/2021 18:23:31 - INFO - volta.train_utils -   [XVNLI]: iter 330600 Ep: 9.78 loss 0.003 score 0.108 lr 1.41985e-06 
12/05/2021 18:24:02 - INFO - volta.train_utils -   [XVNLI]: iter 330760 Ep: 9.78 loss 0.004 score 0.108 lr 1.41919e-06 
12/05/2021 18:24:33 - INFO - volta.train_utils -   [XVNLI]: iter 330920 Ep: 9.79 loss 0.003 score 0.110 lr 1.41854e-06 
12/05/2021 18:25:04 - INFO - volta.train_utils -   [XVNLI]: iter 331080 Ep: 9.79 loss 0.004 score 0.107 lr 1.41788e-06 
12/05/2021 18:25:36 - INFO - volta.train_utils -   [XVNLI]: iter 331240 Ep: 9.80 loss 0.003 score 0.108 lr 1.41722e-06 
12/05/2021 18:26:07 - INFO - volta.train_utils -   [XVNLI]: iter 331400 Ep: 9.80 loss 0.004 score 0.108 lr 1.41656e-06 
12/05/2021 18:26:38 - INFO - volta.train_utils -   [XVNLI]: iter 331560 Ep: 9.81 loss 0.003 score 0.107 lr 1.41591e-06 
12/05/2021 18:27:09 - INFO - volta.train_utils -   [XVNLI]: iter 331720 Ep: 9.81 loss 0.003 score 0.109 lr 1.41525e-06 
12/05/2021 18:27:40 - INFO - volta.train_utils -   [XVNLI]: iter 331880 Ep: 9.82 loss 0.004 score 0.107 lr 1.41459e-06 
12/05/2021 18:28:11 - INFO - volta.train_utils -   [XVNLI]: iter 332040 Ep: 9.82 loss 0.003 score 0.108 lr 1.41393e-06 
12/05/2021 18:28:42 - INFO - volta.train_utils -   [XVNLI]: iter 332200 Ep: 9.83 loss 0.003 score 0.110 lr 1.41328e-06 
12/05/2021 18:29:13 - INFO - volta.train_utils -   [XVNLI]: iter 332360 Ep: 9.83 loss 0.003 score 0.107 lr 1.41262e-06 
12/05/2021 18:29:44 - INFO - volta.train_utils -   [XVNLI]: iter 332520 Ep: 9.84 loss 0.003 score 0.109 lr 1.41196e-06 
12/05/2021 18:30:15 - INFO - volta.train_utils -   [XVNLI]: iter 332680 Ep: 9.84 loss 0.004 score 0.108 lr 1.4113e-06 
12/05/2021 18:30:47 - INFO - volta.train_utils -   [XVNLI]: iter 332840 Ep: 9.85 loss 0.003 score 0.107 lr 1.41065e-06 
12/05/2021 18:31:18 - INFO - volta.train_utils -   [XVNLI]: iter 333000 Ep: 9.85 loss 0.004 score 0.107 lr 1.40999e-06 
12/05/2021 18:31:49 - INFO - volta.train_utils -   [XVNLI]: iter 333160 Ep: 9.86 loss 0.003 score 0.107 lr 1.40933e-06 
12/05/2021 18:32:20 - INFO - volta.train_utils -   [XVNLI]: iter 333320 Ep: 9.86 loss 0.003 score 0.108 lr 1.40867e-06 
12/05/2021 18:32:51 - INFO - volta.train_utils -   [XVNLI]: iter 333480 Ep: 9.86 loss 0.005 score 0.108 lr 1.40802e-06 
12/05/2021 18:33:23 - INFO - volta.train_utils -   [XVNLI]: iter 333640 Ep: 9.87 loss 0.003 score 0.108 lr 1.40736e-06 
12/05/2021 18:33:55 - INFO - volta.train_utils -   [XVNLI]: iter 333800 Ep: 9.87 loss 0.003 score 0.108 lr 1.4067e-06 
12/05/2021 18:34:26 - INFO - volta.train_utils -   [XVNLI]: iter 333960 Ep: 9.88 loss 0.004 score 0.108 lr 1.40605e-06 
12/05/2021 18:34:57 - INFO - volta.train_utils -   [XVNLI]: iter 334120 Ep: 9.88 loss 0.003 score 0.108 lr 1.40539e-06 
12/05/2021 18:35:28 - INFO - volta.train_utils -   [XVNLI]: iter 334280 Ep: 9.89 loss 0.003 score 0.109 lr 1.40473e-06 
12/05/2021 18:35:59 - INFO - volta.train_utils -   [XVNLI]: iter 334440 Ep: 9.89 loss 0.003 score 0.108 lr 1.40407e-06 
12/05/2021 18:36:30 - INFO - volta.train_utils -   [XVNLI]: iter 334600 Ep: 9.90 loss 0.003 score 0.108 lr 1.40342e-06 
12/05/2021 18:37:01 - INFO - volta.train_utils -   [XVNLI]: iter 334760 Ep: 9.90 loss 0.003 score 0.108 lr 1.40276e-06 
12/05/2021 18:37:32 - INFO - volta.train_utils -   [XVNLI]: iter 334920 Ep: 9.91 loss 0.004 score 0.108 lr 1.4021e-06 
12/05/2021 18:38:04 - INFO - volta.train_utils -   [XVNLI]: iter 335080 Ep: 9.91 loss 0.004 score 0.108 lr 1.40144e-06 
12/05/2021 18:38:35 - INFO - volta.train_utils -   [XVNLI]: iter 335240 Ep: 9.92 loss 0.004 score 0.108 lr 1.40079e-06 
12/05/2021 18:39:06 - INFO - volta.train_utils -   [XVNLI]: iter 335400 Ep: 9.92 loss 0.003 score 0.108 lr 1.40013e-06 
12/05/2021 18:39:38 - INFO - volta.train_utils -   [XVNLI]: iter 335560 Ep: 9.93 loss 0.003 score 0.109 lr 1.39947e-06 
12/05/2021 18:40:09 - INFO - volta.train_utils -   [XVNLI]: iter 335720 Ep: 9.93 loss 0.004 score 0.109 lr 1.39881e-06 
12/05/2021 18:40:40 - INFO - volta.train_utils -   [XVNLI]: iter 335880 Ep: 9.94 loss 0.003 score 0.109 lr 1.39816e-06 
12/05/2021 18:41:11 - INFO - volta.train_utils -   [XVNLI]: iter 336040 Ep: 9.94 loss 0.002 score 0.108 lr 1.3975e-06 
12/05/2021 18:41:42 - INFO - volta.train_utils -   [XVNLI]: iter 336200 Ep: 9.94 loss 0.004 score 0.108 lr 1.39684e-06 
12/05/2021 18:42:14 - INFO - volta.train_utils -   [XVNLI]: iter 336360 Ep: 9.95 loss 0.004 score 0.109 lr 1.39619e-06 
12/05/2021 18:42:45 - INFO - volta.train_utils -   [XVNLI]: iter 336520 Ep: 9.95 loss 0.004 score 0.108 lr 1.39553e-06 
12/05/2021 18:43:17 - INFO - volta.train_utils -   [XVNLI]: iter 336680 Ep: 9.96 loss 0.004 score 0.107 lr 1.39487e-06 
12/05/2021 18:43:48 - INFO - volta.train_utils -   [XVNLI]: iter 336840 Ep: 9.96 loss 0.003 score 0.107 lr 1.39421e-06 
12/05/2021 18:44:19 - INFO - volta.train_utils -   [XVNLI]: iter 337000 Ep: 9.97 loss 0.003 score 0.109 lr 1.39356e-06 
12/05/2021 18:44:51 - INFO - volta.train_utils -   [XVNLI]: iter 337160 Ep: 9.97 loss 0.004 score 0.108 lr 1.3929e-06 
12/05/2021 18:45:22 - INFO - volta.train_utils -   [XVNLI]: iter 337320 Ep: 9.98 loss 0.004 score 0.106 lr 1.39224e-06 
12/05/2021 18:45:53 - INFO - volta.train_utils -   [XVNLI]: iter 337480 Ep: 9.98 loss 0.003 score 0.109 lr 1.39158e-06 
12/05/2021 18:46:24 - INFO - volta.train_utils -   [XVNLI]: iter 337640 Ep: 9.99 loss 0.004 score 0.107 lr 1.39093e-06 
12/05/2021 18:46:55 - INFO - volta.train_utils -   [XVNLI]: iter 337800 Ep: 9.99 loss 0.004 score 0.107 lr 1.39027e-06 
12/05/2021 18:47:26 - INFO - volta.train_utils -   [XVNLI]: iter 337960 Ep: 10.00 loss 0.004 score 0.109 lr 1.38961e-06 
12/05/2021 18:51:20 - INFO - volta.train_utils -   Eval task TASK19 on iteration 338000 
12/05/2021 18:51:20 - INFO - volta.train_utils -   Validation [XVNLI]: loss 0.463 score 75.090 
Epoch: 100%|██████████| 10/10 [19:12:46<00:00, 6841.52s/it] 
