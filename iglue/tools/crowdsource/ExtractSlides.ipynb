{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd0cb6ab-f0a1-4bd0-b3df-a8287d7f6d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "from pptx import Presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "743ce401-4a98-4a8e-a1a8-ae7e448efdf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1007129816.jpg', '1009434119.jpg'] ['97233789.jpg', '97234558.jpg']\n",
      "['COCO_val2014_000000391895.jpg', 'COCO_val2014_000000060623.jpg'] ['COCO_val2014_000000413120.jpg', 'COCO_val2014_000000369771.jpg']\n",
      "['3497238310', '3240048764'] ['3331797838', '3648081498']\n"
     ]
    }
   ],
   "source": [
    "with jsonlines.open('f30k_test.jsonl') as reader:\n",
    "    f30k_fns = [item['img_path'] for item in reader]\n",
    "with jsonlines.open('f30k_test.jsonl') as reader:\n",
    "    f30k_items = [item for item in reader]\n",
    "with jsonlines.open('coco_test.jsonl') as reader:\n",
    "    coco_fns = ['COCO_val2014_%012d.jpg' % item['id'] for item in reader]\n",
    "with jsonlines.open('coco_test.jsonl') as reader:\n",
    "    coco_items = [{'sentences': item['sentences'], 'id': item['id'], 'img_path': 'COCO_val2014_%012d.jpg' % item['id']} \n",
    "                  for item in reader]\n",
    "\n",
    "test_fns = []\n",
    "test_items = []\n",
    "ix = 0\n",
    "cur_dir = 0\n",
    "for ii, fn in enumerate(f30k_fns):\n",
    "    if ix % 100 == 0:\n",
    "        cur_dir += 1\n",
    "    imgpath = 'images/%02d/%s' % (cur_dir, fn)\n",
    "    test_fns.append(imgpath)\n",
    "    test_items.append(f30k_items[ii])\n",
    "    ix += 1\n",
    "for ii, fn in enumerate(coco_fns):\n",
    "    if ix % 100 == 0:\n",
    "        cur_dir += 1\n",
    "    imgpath = 'images/%02d/%s' % (cur_dir, fn)\n",
    "    test_fns.append(imgpath)\n",
    "    test_items.append(coco_items[ii])\n",
    "    ix += 1\n",
    "\n",
    "few_ids = [s.strip() for s in open('f30k_few_train.txt').readlines()]\n",
    "\n",
    "print(f30k_fns[:2], f30k_fns[-2:])\n",
    "print(coco_fns[:2], coco_fns[-2:])\n",
    "print(few_ids[:2], few_ids[-2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8807fc36-e7e7-452b-bf98-717e31584daa",
   "metadata": {},
   "source": [
    "## en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75af83f0-7e29-4b41-a020-362f92fd6234",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_te = [{\"sentences\": [d['sentences'][0]], \"id\": d['id'], \"img_path\": d['img_path']} for d in test_items]\n",
    "with jsonlines.open('annotations/en/test.jsonl', 'w') as writer:\n",
    "    writer.write_all(en_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcadbbb-c21a-42b9-b2c3-6dc80dbd6e94",
   "metadata": {},
   "source": [
    "## de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1188eda-bf3c-44f8-8875-9568b0cd96b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "de_fns = [s.strip() for s in open('annotations/de/train.lst').readlines()]\n",
    "de_caps = [s.strip() for s in open('annotations/de/train.1.de').readlines()]\n",
    "de_tr = [{\"sentences\": [cap], \"id\": fn.split('.')[0], \"img_path\": fn} for (cap, fn) in zip(de_caps, de_fns)]\n",
    "\n",
    "for n in [1, 5, 10, 25, 50, 100]:\n",
    "    de_few = []\n",
    "    for e in de_tr:\n",
    "        if e['id'] in few_ids[:n]:\n",
    "            de_few.append(e)\n",
    "    with jsonlines.open(f'annotations/de/train_{n}.jsonl', 'w') as writer:\n",
    "        writer.write_all(de_few)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "5e487d48-ea72-477a-baa8-785d6fcd27ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    }
   ],
   "source": [
    "de_fns = [s.strip() for s in open('annotations/de/test_2016.lst').readlines()]\n",
    "de_caps = [s.strip() for s in open('annotations/de/test_2016.1.de').readlines()]\n",
    "de_te = [{\"sentences\": [cap], \"id\": fn.split('.')[0], \"img_path\": fn} for (cap, fn) in zip(de_caps, de_fns)]\n",
    "\n",
    "for cur_dir in range(11, 21):\n",
    "    start_ix = 100*(cur_dir-1)\n",
    "    prs = Presentation(f'annotations/de/german_{cur_dir}.pptx')\n",
    "    for ix, slide in enumerate(list(prs.slides)[3:-1]):\n",
    "        t = list(slide.placeholders)[0].text\n",
    "        t = \" \".join(t.strip().split())\n",
    "        fn = test_fns[start_ix+ix]\n",
    "        d = dict(test_items[start_ix+ix])\n",
    "        d['sentences'] = [t]\n",
    "        de_te.append(d)\n",
    "\n",
    "print(len(de_te))\n",
    "with jsonlines.open('annotations/de/test.jsonl', 'w') as writer:\n",
    "    writer.write_all(de_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fecfe8-bc5d-46c6-901d-ff102a9a8f3b",
   "metadata": {},
   "source": [
    "### zh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e83334fb-a085-4a2d-a586-98c9a1757c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "5\n",
      "10\n",
      "25\n",
      "50\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "fn = \"annotations/zh/flickr8k-cn/flickr8kzhc.caption.txt\"  # Human generated!\n",
    "seg_lines = [l.strip() for l in open(fn).readlines()]\n",
    "imgids = [seg_line.split()[0].split('#')[0].split(\"_\")[0] for seg_line in seg_lines]\n",
    "clean_lines = [seg_line.split()[1] for seg_line in seg_lines]\n",
    "\n",
    "for n in [1, 5, 10, 25, 50, 100]:\n",
    "    zh_few = []\n",
    "    cur_imgs = set()\n",
    "    for img, line in zip(imgids, clean_lines):\n",
    "        if img in few_ids[:n] and img not in cur_imgs:\n",
    "            cur_imgs.add(img)\n",
    "            zh_few.append({\"sentences\": [line], \"id\": img, \"img_path\": img + '.jpg'})\n",
    "    print(len(zh_few))\n",
    "    with jsonlines.open(f'annotations/zh/train_{n}.jsonl', 'w') as writer:\n",
    "        writer.write_all(zh_few)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "7888fd19-fe95-485f-8828-285761e3c02d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    }
   ],
   "source": [
    "zh_te = []\n",
    "for cur_dir in range(1, 21):\n",
    "    start_ix = 100*(cur_dir-1)\n",
    "    prs = Presentation('annotations/zh/chinese_%02d.pptx' % cur_dir)\n",
    "    for ix, slide in enumerate(list(prs.slides)[3:-1]):\n",
    "        t = list(slide.placeholders)[0].text\n",
    "        t = \" \".join(t.strip().split())\n",
    "        fn = test_fns[start_ix+ix]\n",
    "        d = dict(test_items[start_ix+ix])\n",
    "        d['sentences'] = [t]\n",
    "        zh_te.append(d)\n",
    "\n",
    "print(len(zh_te))\n",
    "with jsonlines.open('annotations/zh/test.jsonl', 'w') as writer:\n",
    "    writer.write_all(zh_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7921b0d7-dabb-4078-a5b8-704e2b1552d0",
   "metadata": {},
   "source": [
    "## tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "204ef569-e5a1-4696-ace2-74b3b1b01533",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfce388a-7f5f-4f3f-b7ae-a128368d6f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "5\n",
      "10\n",
      "25\n",
      "50\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "fn = \"annotations/tr/flickr8k-tr/tasviret8k_captions.json\"\n",
    "j = json.load(open(fn))\n",
    "flickr8k_tr = dict()\n",
    "for e in j['images']:\n",
    "    img = e['filename'].split('_')[0]\n",
    "    flickr8k_tr[img] = []\n",
    "    for s in e['sentences']:\n",
    "        flickr8k_tr[img].append(s['raw'])\n",
    "\n",
    "for n in [1, 5, 10, 25, 50, 100]:\n",
    "    tr_few = []\n",
    "    cur_imgs = set()\n",
    "    for img, lines in flickr8k_tr.items():\n",
    "        if img in few_ids[:n] and img not in cur_imgs:\n",
    "            cur_imgs.add(img)\n",
    "            tr_few.append({\"sentences\": [lines[0]], \"id\": img, \"img_path\": img + '.jpg'})\n",
    "    print(len(tr_few))\n",
    "    with jsonlines.open(f'annotations/tr/train_{n}.jsonl', 'w') as writer:\n",
    "        writer.write_all(tr_few)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "106a0cc7-e417-494a-ad5f-0a4736bfcade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    }
   ],
   "source": [
    "tr_te = []\n",
    "for cur_dir in range(1, 21):\n",
    "    start_ix = 100*(cur_dir-1)\n",
    "    prs = Presentation('annotations/tr/turkish_%02d.pptx' % cur_dir)\n",
    "    for ix, slide in enumerate(list(prs.slides)[3:-1]):\n",
    "        t = list(slide.placeholders)[0].text\n",
    "        t = \" \".join(t.strip().split())\n",
    "        fn = test_fns[start_ix+ix]\n",
    "        d = dict(test_items[start_ix+ix])\n",
    "        d['sentences'] = [t]\n",
    "        tr_te.append(d)\n",
    "\n",
    "print(len(tr_te))\n",
    "with jsonlines.open('annotations/tr/test.jsonl', 'w') as writer:\n",
    "    writer.write_all(tr_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a4c9aa-dbd2-43f8-ab5b-77cc5db5547a",
   "metadata": {},
   "source": [
    "## ja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "5cb7c205-5b1f-4e70-8671-56fd6e4eb649",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c76a5799-83e6-4962-be9a-c86b9bb57e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "5\n",
      "10\n",
      "25\n",
      "50\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "for n in [1, 5, 10, 25, 50, 100]:\n",
    "    ja_few = []\n",
    "    for img in few_ids[:n]:\n",
    "        fn = f\"annotations/ja/Flickr30kEnt-JP/Sentences_jp_v2/{img}.txt\"\n",
    "        with open(fn) as f:\n",
    "            l = f.readlines()[0]\n",
    "            seg_line = l.strip()\n",
    "            clean_line = ''.join(e.split(':')[0] for e in seg_line.split()[1:]).replace(']', '')\n",
    "            ja_few.append({\"sentences\": [clean_line], \"id\": img, \"img_path\": img + '.jpg'})\n",
    "    print(len(ja_few))\n",
    "    with jsonlines.open(f'annotations/ja/train_{n}.jsonl', 'w') as writer:\n",
    "        writer.write_all(ja_few)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "1d4c88d8-df53-456c-a04d-8d75318548a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    }
   ],
   "source": [
    "j = json.load(open(\"annotations/ja/STAIR-captions/stair_captions_v1.2_val.json\"))\n",
    "coco_ja = dict()\n",
    "for e in j['annotations']:\n",
    "    img = e['image_id']\n",
    "    sent = e['caption']\n",
    "    coco_ja[img] = sent\n",
    "\n",
    "ja_te = []\n",
    "for item in en_te[:1000]:\n",
    "    img = item['id']\n",
    "    fn = f\"annotations/ja/Flickr30kEnt-JP/Sentences_jp_v2/{img}.txt\"\n",
    "    with open(fn) as f:\n",
    "        l = f.readlines()[0]\n",
    "        seg_line = l.strip()\n",
    "        clean_line = ''.join(e.split(':')[0] for e in seg_line.split()[1:]).replace(']', '')\n",
    "        ja_te.append({\"sentences\": [clean_line], \"id\": img, \"img_path\": img + '.jpg'})\n",
    "for item in en_te[1000:]:\n",
    "    img = item['id']\n",
    "    sent = coco_ja[img]\n",
    "    ja_te.append({\"sentences\": [sent], \"id\": img, \"img_path\": 'COCO_val2014_%012d.jpg' % img})\n",
    "    \n",
    "print(len(ja_te))\n",
    "with jsonlines.open('annotations/ja/test.jsonl', 'w') as writer:\n",
    "    writer.write_all(ja_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3f8ecf-a87a-43c8-ae8a-b7da764e10be",
   "metadata": {},
   "source": [
    "## es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90b8d7fc-1a6f-44b2-821f-3339f68f6229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "5\n",
      "10\n",
      "25\n",
      "50\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "for n in [1, 5, 10, 25, 50, 100]:\n",
    "    es_few = []\n",
    "    for cur_dir in range(21, 22):\n",
    "        start_ix = 100*(cur_dir-1)\n",
    "        prs = Presentation('annotations/es/spanish_%02d.pptx' % cur_dir)\n",
    "        for ix, slide in enumerate(list(prs.slides)[4:-1]):\n",
    "            t = list(slide.placeholders)[0].text\n",
    "            t = \" \".join(t.strip().split())\n",
    "            img = few_ids[ix]\n",
    "            if img in few_ids[:n]:\n",
    "                d = {\"sentences\": [t], \"id\": img, \"img_path\": img + '.jpg'}\n",
    "                es_few.append(d)\n",
    "    print(len(es_few))\n",
    "    with jsonlines.open(f'annotations/es/train_{n}.jsonl', 'w') as writer:\n",
    "        writer.write_all(es_few)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "a6d21265-dcdc-4578-82f1-1783ccf56834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    }
   ],
   "source": [
    "es_te = []\n",
    "for cur_dir in range(1, 21):\n",
    "    start_ix = 100*(cur_dir-1)\n",
    "    prs = Presentation('annotations/es/spanish_%02d.pptx' % cur_dir)\n",
    "    for ix, slide in enumerate(list(prs.slides)[4:-1]):\n",
    "        t = list(slide.placeholders)[0].text\n",
    "        t = \" \".join(t.strip().split())\n",
    "        fn = test_fns[start_ix+ix]\n",
    "        d = dict(test_items[start_ix+ix])\n",
    "        d['sentences'] = [t]\n",
    "        es_te.append(d)\n",
    "\n",
    "print(len(es_te))\n",
    "with jsonlines.open('annotations/es/test.jsonl', 'w') as writer:\n",
    "    writer.write_all(es_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a88afb-1dcd-4600-8d18-8b80f3eef35b",
   "metadata": {},
   "source": [
    "## id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "75b76078-35a3-4a23-9da1-c73b00d64631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "5\n",
      "10\n",
      "25\n",
      "50\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "for n in [1, 5, 10, 25, 50, 100]:\n",
    "    id_few = []\n",
    "    for cur_dir in range(21, 22):\n",
    "        start_ix = 100*(cur_dir-1)\n",
    "        prs = Presentation('annotations/id/indonesian_%02d.pptx' % cur_dir)\n",
    "        for ix, slide in enumerate(list(prs.slides)[3:-1]):\n",
    "            t = list(slide.placeholders)[0].text\n",
    "            t = \" \".join(t.strip().split())\n",
    "            img = few_ids[ix]\n",
    "            if img in few_ids[:n]:\n",
    "                d = {\"sentences\": [t], \"id\": img, \"img_path\": img + '.jpg'}\n",
    "                id_few.append(d)\n",
    "    print(len(id_few))\n",
    "    with jsonlines.open(f'annotations/id/train_{n}.jsonl', 'w') as writer:\n",
    "        writer.write_all(id_few)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "5e39babb-cd9e-4714-9e45-9f1f5cc6c90f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    }
   ],
   "source": [
    "id_te = []\n",
    "for cur_dir in range(1, 21):\n",
    "    start_ix = 100*(cur_dir-1)\n",
    "    prs = Presentation('annotations/id/indonesian_%02d.pptx' % cur_dir)\n",
    "    for ix, slide in enumerate(list(prs.slides)[3:-1]):\n",
    "        t = list(slide.placeholders)[0].text\n",
    "        t = \" \".join(t.strip().split())\n",
    "        fn = test_fns[start_ix+ix]\n",
    "        d = dict(test_items[start_ix+ix])\n",
    "        d['sentences'] = [t]\n",
    "        id_te.append(d)\n",
    "\n",
    "print(len(id_te))\n",
    "with jsonlines.open('annotations/id/test.jsonl', 'w') as writer:\n",
    "    writer.write_all(id_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edffb228-3006-458a-93ec-b5ddae24cea0",
   "metadata": {},
   "source": [
    "## ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "759553cb-8b47-403e-bb3a-9aaf7d39d8ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "5\n",
      "10\n",
      "25\n",
      "50\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "for n in [1, 5, 10, 25, 50, 100]:\n",
    "    ru_few = []\n",
    "    for cur_dir in range(21, 22):\n",
    "        start_ix = 100*(cur_dir-1)\n",
    "        prs = Presentation('annotations/ru/russian_%02d.pptx' % cur_dir)\n",
    "        for ix, slide in enumerate(list(prs.slides)[4:-1]):\n",
    "            t = list(slide.placeholders)[0].text\n",
    "            t = \" \".join(t.strip().split())\n",
    "            img = few_ids[ix]\n",
    "            if img in few_ids[:n]:\n",
    "                d = {\"sentences\": [t], \"id\": img, \"img_path\": img + '.jpg'}\n",
    "                ru_few.append(d)\n",
    "    print(len(ru_few))\n",
    "    with jsonlines.open(f'annotations/ru/train_{n}.jsonl', 'w') as writer:\n",
    "        writer.write_all(ru_few)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dceb2b12-679f-4803-b593-88759453a93d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    }
   ],
   "source": [
    "ru_te = []\n",
    "for cur_dir in range(1, 21):\n",
    "    start_ix = 100*(cur_dir-1)\n",
    "    prs = Presentation('annotations/ru/russian_%02d.pptx' % cur_dir)\n",
    "    for ix, slide in enumerate(list(prs.slides)[4:-1]):\n",
    "        t = list(slide.placeholders)[0].text\n",
    "        t = \" \".join(t.strip().split())\n",
    "        fn = test_fns[start_ix+ix]\n",
    "        d = dict(test_items[start_ix+ix])\n",
    "        d['sentences'] = [t]\n",
    "        ru_te.append(d)\n",
    "\n",
    "print(len(ru_te))\n",
    "with jsonlines.open('annotations/ru/test.jsonl', 'w') as writer:\n",
    "    writer.write_all(ru_te)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
